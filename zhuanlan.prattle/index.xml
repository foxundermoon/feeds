<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>迷思</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/</link>
<description>我的博客及微信公众号里的精华内容都会放在这里。</description>
<language>zh-cn</language>
<lastBuildDate>Tue, 13 Feb 2018 14:44:29 +0800</lastBuildDate>
<item>
<title>分布式系统中的监工：Overseer</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-02-13-33801389.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/33801389&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ec12887ca7a1aaec76fef31ff8ac4b60_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;最近从无趣的工作中发现了有趣的事情，工作和业余时间都扑了些精力上去，本待上周末最终的成果出来后再写文章的，无奈事情太多，代码还没写完，二月上旬已过，再不写文章春节就过去了，所以这次程序君先上车，再补票。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;需求&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;事情是这样的：两周前同事催促我升级我之前做的一个轮子 merlin - 见我去年的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827801&amp;amp;idx=1&amp;amp;sn=7ac5e18b2330feab536bda1c0c803adc&amp;amp;chksm=8704abc5b07322d32d72260f6ab1f450a8df88db9015dcc195f54073cc831ca01d3c9d6ec650&amp;amp;scene=21#wechat_redirect&quot;&gt;停下来，歇口气，造轮子&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在那篇文章里我提到了为什么会有需要做这样一个内部的 release 构建工具。自那时起，merlin 为我们内部的几个 elixir service 的 release 保驾护航几个月，总体表现不错。然而，当时在需求和设计上的一些缺陷，导致这款产品有这些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;太依赖 github release —— 如果不生成新的 release，就无法自动构建。这对依赖 staging 进行集成测试的服务不友好。使用者需要在 pull request 里升级版本（才能生成一个 build）。因此，多个开发者间需要在 pull request 中把版本错开，很不方便。开发频繁的时候，我们一天的 patch version（SemVar 里第三位），五个十个地狂跳，比旧金山 TaxiCab 的计价器跳动还要可怕。&lt;/li&gt;&lt;li&gt;merlin 使用的两台机器都是 t2.medium，一次 release build（还包括一次 release upgrade build）花费十来分钟。当构建繁忙的时候，在队列后面的请求要很久才能排到（Latency 不友好）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;所以我要在下一个版本中，将这些问题解决。初步的考虑是，当构建请求来临时，启动一个强大的 spot instance，处理构建任务，构建完成并上传 S3 后，spot instance 自行了断。构建请求可以是来自 github release message（兼容上一版本），也可以是 API —— 进而，我们可以制作 CLI 工具，让用户在 shell 下对任意 git commit 触发构建。有了粗浅的想法后，我们理一理需求：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户（包括 github）可以通过 API 触发构建&lt;/li&gt;&lt;li&gt;构建被触发后，启动一个 spot instance（或 ECS fargate，不过 spot instance 实在太便宜了，如 C5.large $0.03/hour，所以 ECS 没有啥价格优势）&lt;/li&gt;&lt;li&gt;spot instance 基于一个 prebuild 的 AMI（如果 ECS，则 docker）启动，AMI 里包含处理构建的软件。这样启动起来之后，就能自动处理构建任务&lt;/li&gt;&lt;li&gt;描述构建任务的 metadata 放置于 spot instance 启动时的 user data 中，构建软件通过 &lt;code class=&quot;inline&quot;&gt;http://169.254.169.254/latest/user-data&lt;/code&gt; 访问之&lt;/li&gt;&lt;li&gt;构建过程中可能要发送一些 telemetry 到 merlin&lt;/li&gt;&lt;li&gt;构建完成，把状态和构建的信息（比如 tarball 在哪里）发回给 merlin，然后自尽&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这个需求算是比较清晰，实现起来也没有什么难点，无非就是时间问题 —— 对于像我们这样的 startup 来说，它是可以立即撸起袖子干活，逢山开路遇水填桥的那种活儿。&lt;/p&gt;&lt;p&gt;merlin 之前的坑是我埋的，这个业务即不性感，也不紧急；backend 的队友们都扑在一些 visibility 高的，光是名字听起来就热血沸腾的项目上，腾不出手，且我也不舍得就这么浪费他们的时间 —— 所以我只能 eat my own dogshit。我这人白天瞎忙，晚上躲懒 —— 除非有什么能戳到 G 点让我不吃不喝不睡觉也要搞的创意，否则像 merlin 这种一眼就从头看到脚，没有太多挑战的项目，激发不出我的小宇宙。于是需求定下，反正也不着急，我就懒懒地，有一搭没一搭地在脑海中想着。&lt;/p&gt;&lt;p&gt;事实证明，这种懒散，而非全力以赴，促成了我更多，更深的思考。有功夫我把整个思考的过程撰写成文，相信对大家也能有小小的启发。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在上面的需求中，merlin 由一个服务被拆成了两个部分：control plane 和 data plane（请饶恕一个曾经的网络工程师对区分路径的这种骨子里的执着）。简单来说，control plane 负责派活和监控，是个 scheduler，类似于老鸨；data plane 负责干活，是一堆 resource，就好像苏小小，柳如是，李师师们。而一个个构建任务，是要完成的 task，就是赵佶，柳永，阮郁等的不期而至。&lt;/p&gt;&lt;p&gt;把 merlin 的需求稍稍泛化一下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用者可以通过 API 触发一个 task&lt;/li&gt;&lt;li&gt;Control plane 接到 task 后，分配到 data plane 上的某个 resource 上执行&lt;/li&gt;&lt;li&gt;data plane 向 control plane 汇总 telemetry&lt;/li&gt;&lt;li&gt;data plane 完成 task 之后，向 control plane 汇报结果，进入到 idle 状态等待下次调度&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了符合社会主义核心价值观，我们换个比喻：Control plane 类似于 erlang/OTP 里的 Supervisor；data plane 类似于 GenServer。对于 erlang 不太熟悉的同学可以看我的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827691&amp;amp;idx=1&amp;amp;sn=8d6854f91bb9d16470ef6eed9d3ad8ec&amp;amp;chksm=8704ab77b0732261eb63217ad03740a3433cde4491826eeec020f4bbebb8b18837c27ac3e74d&amp;amp;scene=21#wechat_redirect&quot;&gt;上帝说：要有一门面向未来的语言，于是有了 erlang&lt;/a&gt;。你不必理解代码，但需要理解思想。&lt;/p&gt;&lt;p&gt;然而，erlang/OTP 里的 Supervisor 只负责启动和监控 process，如果要启动和监控 node，有很多问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如何在 cloud 里动态启动一个节点？&lt;/li&gt;&lt;li&gt;如何让这个节点自动加入到 cluster 里？&lt;/li&gt;&lt;li&gt;如何让这个节点有运行 task 所必须的软件？&lt;/li&gt;&lt;li&gt;control plane 如何和 data plane 方便地通信？&lt;/li&gt;&lt;li&gt;如何把上面的所有细节屏蔽起来，启动和监控一个节点，像 Supervisor 启动和监控一个 GenServer 一样简单，且对程序员友好？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;1/2/3 如果解决，4 可以直接通过封装 RPC 解决。&lt;/p&gt;&lt;p&gt;2 我们上文中提过 —— 我们可以通过给新启动的 instance 提供 UserData 来解决 —— 在 AWS 里，当我们启动一个新的 instance，可以预设一些 json 数据进去，本地访问 &lt;code class=&quot;inline&quot;&gt;http://169.254.169.254/latest/user-data&lt;/code&gt; 即可获得，因而，我们可以把 cluster 的 cookie，control plane node 的 node name 都放进去，以便于新的节点可以自己加入 cluster。&lt;/p&gt;&lt;p&gt;我们看 1 和 3。最简单解决 1/3 的方法是使用 prebuild AMI —— 把所有相关的，处理 data plane 的软件都烧到 AMI 里，用 request-spot-instance 的 AWS API 创建节点即可。不过，这意味着每次 data plane 的代码改变，我们都要重烧 AMI，即便烧 AMI 的动作 CI 自动化处理了，每次 control plane 还是需要确保使用正确的 AMI 启动 data plane。有些麻烦。&lt;/p&gt;&lt;p&gt;程序员最不爽的就是麻烦。&lt;b&gt;虚心使人进步，麻烦让程序员创新&lt;/b&gt;。咋办？我们能不能做个 loader，把一个编译好的 module，甚至一个 release 动态加载到远端的一个 node 上？&lt;/p&gt;&lt;p&gt;bingo！这是一个好问题，而&lt;b&gt;好问题的价值远胜于好的答案&lt;/b&gt;。于是大概两周前的一个周末，我写了几百行代码，做了一个初始版本的 ex_loader。见 github: tubitv/ex_loader。代码已开源，MIT license。&lt;/p&gt;&lt;p&gt;ex_loader 让你可以很简单地干这样的事情：&lt;/p&gt;&lt;code lang=&quot;elixir&quot;&gt;{:ok, module} = ExLoader.load_module(&quot;hello.beam&quot;, :&quot;awesome-node@awesome.io&quot;)

:ok = ExLoader.load_release(&quot;https://awesome.io/example_complex_app.tar.gz&quot;, :&quot;awesome-node@awesome.io&quot;)&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;你即使不理解 elixir 代码，大概也能猜到第一句它将一个本地的 module 加载到同一个 cluster 里的叫 awesome-node@awesome.io 的节点上；第二句，则将一个在某个 website 上的 erlang release，加载到相同的节点上。&lt;/p&gt;&lt;p&gt;Joe Armstrong 曾经在一次会议上开心地谈到过他自己会在 erlang node 上运行很多空的，什么也不做，也不知道该做什么的 process，但当他有需要的时候，让这些 process 加载新的 module，就摇身一变让其成为拥有某种特定功能 process。ex_loader 在此基础上更进一步，你可以开一些空的 erlang node，有需要的时候，让这些 node 加载你想让其运行的 release，使其成为特定功能的 server。&lt;/p&gt;&lt;p&gt;ex_loader 简化了 control plane 往 data plane 发布软件的工作，我们有了一个更好的解决 1 和 3 的方案。然而，我们还没有触及到上文中所提到的 5。&lt;/p&gt;&lt;p&gt;这就是 Overseer，一个新的，类比 Supervisor 的 OTP behavior。我们先看怎么用 Overseer：&lt;/p&gt;&lt;code lang=&quot;elixir&quot;&gt;local_adapter = {Overseer.Adapters.Local, [prefix: &quot;test_local_&quot;]}
opts = [
strategy: :simple_one_for_one,
max_nodes: 10
]
release = {:release, OverseerTest.Utils.get_fixture_path(&quot;apps/tarball/example_app.tar.gz&quot;)}
MyOverseer.start_link({local_adapter, release, opts}, name: MyOverseer)
MyOverseer.start_child()&lt;/code&gt;&lt;p&gt;定义一个 Overseer 很简单：&lt;/p&gt;&lt;code lang=&quot;elixir&quot;&gt;defmodule MyOverseer do
 use Overseer
 require Logger
 
  def start_link(spec, options) do
    Overseer.start_link(__MODULE__, spec, options)
  end
 
  def init(_) do
    {:ok, %{}}
  end
  
  def handle_connected(node, state) do
    Logger.info(&quot;node #{node} up: state #{inspect(state)}&quot;)
    {:ok, state}
  end
 
  def handle_disconnected(node, state) do
    Logger.info(&quot;node #{node} down: state #{inspect(state)}&quot;)
    {:ok, state}
  end

  def handle_telemetry(_data, state) do
    {:ok, state}
  end

  def handle_terminated(_node, state) do
    {:ok, state}
  end
  
  def handle_event(_event, _node, state) do
    {:ok, state}
  end
end&lt;/code&gt;&lt;p&gt;我们大概讲讲 Overseer 干些什么：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;start_link：启动时，它接受一些参数，关于我们要启动的 node 的 spec。node 目前支持两种 adapter，local 和 ec2。我将其做成 adapter，是为了日后支持更多类型的 node（比如 ECS）。strategy 目前仅支持 simple_one_for_one，亦即所有 node 使用相同的 spec，在需要的时候由 Overseer 创建。&lt;/li&gt;&lt;li&gt;start_child：Overseer 可以根据预置的 spec 启动一个 node —— 比如 ec2 spot instance。这个 node 启动成功之后，初始的代码会使用 UserData 里面的 node_name 和 cookie 连接 Overseer。当 Overseer 监测到一个 node_up 的消息后，会在内部创建一个 Labor 的数据结构，并且把 spec 里面定义的 release 发给这个 labor node 加载和运行。&lt;/li&gt;&lt;li&gt;pairing：比 Supervisor 复杂的是，Overseer 不但需要监听 node up / down 的事件，做相应的决策（比如重启一个新的 node）外，还需要接受 node 传过来的 telemetry，所以 Overseer 所在的 process 要和 labor node 上面的某个 process 建立起关系。我把这个过程称作为 pairing，类比蓝牙设备间的配对。当 start_child 成功后，Overseer 会把自己的 pid 发送给 labor node 上的一个指定的接口，然后 labor node 会在这个接口里显示地给 Overseer 发送 pair 请求，之后，两个 process 就 link 起来。&lt;/li&gt;&lt;li&gt;作为一个类似于 Supervisor 的 GenServer，Overseer 把 labort node 监控的细节和状态机都屏蔽掉，只暴露 connected / disconnected / telemetry 等一些上层软件关心的事件。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下图是大概一周前我手绘的 sequential diagram，当时名字还不叫 Overseer，叫 GenConnector，但基本思路一致：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4a26027f4ca5d6007042928393151503_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1092&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;Overseer 的源码会在这几天完成后释出，敬请期待。&lt;/p&gt;&lt;p&gt;有了 ex_loader 和 Overseer，merlin 剩下要做的事情就简单很多了：把代码库分割成 control plane 和 data plane，control plane 用 Overseer，data plane 沿用之前的代码，稍作修改后我们就有了一个分布式的，可以随意 scale 的构建系统。&lt;/p&gt;&lt;p&gt;最妙的是，ex_loader 和 Overseer 虽为 merlin 而生，却由于不错的抽象程度，能适用于几乎任何 control plane + dynamic data plane 的这种分布式任务处理结构。在我之前的思考中，其实还更进一步，将这个系统设计成了一个叫 Fleet / Carrier / Fighter 结构的分布式系统，Carrier 是 Fleet 的 labor node，Fighter 是 Carrier 的 labor node，类比 Star War 中的帝国舰队。在这个蓝图中，merlin 只是 Fleet 的一个 Carrier 而已（这个估计短期没工夫实现）：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5c30c89f9e919e0a8fe85aa3a1f9d8d7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;630&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;好了，不说废话了，我还是抓紧写代码去。提前祝各位叔叔阿姨哥哥姐姐弟弟妹妹，春节快乐！也祝各位同处本命年「伏吟」的小伙伴们，狗年红红火火，不犯太岁！:)&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-02-13-33801389</guid>
<pubDate>Tue, 13 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>谈谈调度 - Linux O(1)</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-01-31-33461281.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/33461281&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a9fb27eefa9612d39a7626ea10a19eb5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;约莫十五年前，当我刚刚开始参加工作时，赶上 Linux 发布划时代的 2.6 内核。在这个大家都翘首期盼的内核版本中，最令人兴奋的便是 O(1) scheduler。本文来谈谈这个算法是如何实现的。不过，在详细讲解 O(1) scheduler 之前，我们先简单回顾一下让人诟病许久的 2.4 scheduler，了解其传承，同时以史为镜。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2.4 scheduler 的问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Linux 2.4 scheduler 支持 SMP（Symmetric Multi-Processing），然而，由于只用一个 global runqueue，各个 core 需要竞争同一个 runqueue 里面的任务，所以可伸缩性（scalability）不好。我在上一篇文章中提过：&lt;/p&gt;&lt;blockquote&gt;任务如何组织？是所有的资源共享一个任务的 runqueue，调度器调度时通过加锁来保证互斥，还是针对每个资源，我们都为其设置一个 runqueue，以减少锁带来的损耗？那么问题又来了，如果某个资源上的任务列表空了，资源是就此闲置，还是可以去别的资源的 runqueue 上「偷」任务给自己执行？&lt;/blockquote&gt;&lt;p&gt;这个问题 2.6 O(1) scheduler 用 per core runqueue 解决这个问题，我们放下不表。&lt;/p&gt;&lt;p&gt;global runqueue 带来的性能问题其实还可以忍受，毕竟只是在 dequeue 的过程需要加锁；接下来这个问题，就很要命 —— 2.4 scheduler 的时间复杂度是 O(N)。我们知道，现代操作系统都能运行成千上万个进程，O(N) 的算法意味着每次调度时，对于当前执行完的 process，需要把所有在 expired queue 中的 process 过一遍，找到合适的位置插入。这不仅仅会带来性能上的巨大损失，还使得系统的调度时间非常不确定 —— 根据系统的负载，可能有数倍甚至数百倍的差异。我们知道，不确定性是软件系统的大敌，尤其是实时系统。&lt;/p&gt;&lt;p&gt;对于那些对2.4 scheduler 不太了解的同学咱们多说两句：2.4 scheduler 维护两个 queue：runqueue 和 expired queue。两个 queue 都永远保持有序，一个 process 用完时间片，就会被插入 expired queue；当 runqueue 为空时，只需要把 runqueue 和 expired queue 交换一下即可。&lt;/p&gt;&lt;p&gt;注意，所有调度系统的难点不在于寻找下一个可执行的 process，这个操作一般都是 O(1)，因为我们只要妥善对 runqueue 排序，使其第一个 process 永远是下次需要调度的 process 即可。难点在于执行完的 process —— 怎样插入到合适的位置使得 runqueue 是有序的？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;满足 O(1)&lt;/b&gt; &lt;b&gt;的数据结构？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;根据我们在数据结构课程里学到的知识可以知道，大多数算法的时间复杂度，O(log N) 基本上就是最好的结果，那么，2.6 的 O(1) scheduler 是怎么做到的？&lt;/p&gt;&lt;p&gt;在回答这个问题之前，我们先回顾一下数据结构的四种基本操作以及其时间复杂度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;access：随机访问。array 是唯一能够达到，且平均情况和最坏情况均能达到 O(1) 随机访问的数据结构。其它的结构，linked list 是 O(N)，tree 一般是 O(log N)。&lt;/li&gt;&lt;li&gt;search：搜索。谈到搜索，大家第一反应是 hash table 是 O(1) 时间复杂度的。然而，它在最坏情况下是 O(N) 的。除此之外，没有任何算法能在最坏情况下 search 也是 O(1)。大部分 tree（b-tree / red-black tree）平均和最坏情况都是 O(log N)，其实很不错了。&lt;/li&gt;&lt;li&gt;insert/deletion：插入和删除。插入删除是对等的操作，这里放在一起讲。linked list，stack，queue 在平均和最坏情况下都是 O(1)，而大家脑海里的 hash table，同样的，虽然平均是 O(1)，但最坏情况是 O(N)。大部分 tree（b-tree / red-black tree）平均和最坏情况都是 O(log N)，也还不错。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以我们看到，如果想要达成 O(1) scheduler 的目标，操作只能包含纯粹的 access，insert 和 deletion。一定不能有 search。2.4 scheduler 在将执行完的 process insert 回 expired queue 时使用 search，大大拉低整个算法的时间复杂度。这是其一。&lt;/p&gt;&lt;p&gt;此外，对于 scheduler，我们选择算法，尽量要选择平均情况和最坏情况表现一致的算法。如果平均情况是 O(1)，最坏情况是 O(n)，那么这个 scheduler 会给系统带来很大的不确定性，这很伤脑筋 —— 毕竟谁也不愿意面对一个大部分时候表现乖巧，极端情况抽风到不可理喻的系统。这是其二。&lt;/p&gt;&lt;p&gt;在这两个先决条件下，我们可选择的范围就很窄 —— access 只能用 array，insert / deletion 只能用 linked list / queue / stack。&lt;/p&gt;&lt;p&gt;接下来，我们把调度的场景简化一下：假设系统中有六个 process，三种优先级：high，medium，low。没有 preemption，严格按照优先级的顺序执行 process。那么，我们怎么组合上述的数据结构，让 scheduling 是 O(1) 的？&lt;/p&gt;&lt;p&gt;思考一下。&lt;/p&gt;&lt;p&gt;再思考一下。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2.6 O(1) scheduler&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;OK，我们直接看看大神给出的是什么样的答案。先看图：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-729fb18fa3ac1e41beff0fcd817c92a6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1170&quot;&gt;&lt;p&gt;看到这里，估计有部分读者已经领会到其中的奥义。2.6 kernel 里有 140 种优先级，所以我们就用长度为 140 的 array 去记录优先级。每个优先级下面用一个 FIFO queue 管理这个优先级下的 process。新来的插到队尾，先进先出。在这种情况下，insert / deletion 都是 O(1)。&lt;/p&gt;&lt;p&gt;那么，我们怎么找到当前最高优先级下面的可执行的 process 呢？如果从 0 开始一直遍历下去，算法虽然不是 O(N)，但是是跟优先级多寡相关的 O(M)，也不能算作 O(1)。在 2.6 scheduler 里，聪明的先贤们采用 bitarray。它为每种优先级分配一个 bit，如果这个优先级队列下面有 process，那么就对相应的 bit 染色，置为 1，否则置为 0。这样，问题就简化成寻找一个 bitarray 里面最高位是 1 的 bit（left-most bit），这基本上是一条 CPU 指令的事（fls）。&lt;/p&gt;&lt;p&gt;好，大致的思路齐备，我们来捋一捋完整的步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 active bitarray 里，寻找 left-most bit 的位置 x。&lt;/li&gt;&lt;li&gt;在 active priority array（APA）中，找到对应队列 APA[x]。&lt;/li&gt;&lt;li&gt;从 APA[x] 中 dequeue 一个 process，dequeue 后，如果 APA[x] 的 queue 为空，那么将 active bitarray 里第 x bit置为 0。&lt;/li&gt;&lt;li&gt;对于当前执行完的 process，重新计算其 priority，然后 enqueue 到 expired priority array（EPA）相应的队里 EPA[priority]。&lt;/li&gt;&lt;li&gt;如果 priority 在 expired bitarray 里对应的 bit 为 0，将其置 1。&lt;/li&gt;&lt;li&gt;如果 active bitarray 全为零，将 active bitarray 和 expired bitarray 交换一下。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当然，这里面还有一些细节，比如如果是 process 被抢占，其时间片没用完，那么第 4 步，enqueue 回 active priority queue 中。不过这和算法本身没太大关系，我们略过不表。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;历史地位&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2.6 O(1) scheduler 目前已经被性能略输一筹，同时更加强调公平性的 CFS（Completely Fair Scheduler）取代，但其以独特的设计，简单的算法，影响很多系统。在其刚问世时，很多 linux 发行版就迫不及待将其移植回 2.4 kernel。而程序君整个职业生涯中接触过的一些调度器中，都能见到 bitarray + priority queue 的身影。它让我感慨算法之美，同时也告诉我：你手中即便拿着一副并不那么出众的牌，历经辗转腾挪，也能打出精彩。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;本系列文章：&lt;/p&gt;&lt;p&gt;[1] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/33389178&quot;&gt;当我谈 scheduling 时我在谈什么？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] 谈谈调度 - Linux O(1)&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-01-31-33461281</guid>
<pubDate>Wed, 31 Jan 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>当我谈 scheduling 时我在谈什么？</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-01-29-33389178.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/33389178&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-199be96fbea64d352186805b92902bce_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;题记&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这是我 1/25 日 Tubi TV 内部 BBL 的一个主题。scheduling 有很多很多可以谈论的地方，随便一个点就可以做一次讲座。这次我只是讲一个概述。&lt;/p&gt;&lt;p&gt;说两句题外话。我常常在 code review 中评论某某代码要 DRY (don’t repeat yourself)。其实这一原则也适用于生活的其它方面 —— 一成不变的事情，久而久之就会失去色泽，无论其曾经多么光鲜靓丽。所以我们要催动自己的好奇心，让生活保鲜。16 年我做 BBL，基本上都是 markdown + reveal.js（一套 makefile 用 pandoc 编译完成传到 S3），17 年我主动将其换成更加赏心悦目的 shower.js。新年伊始，我把我的 presentation 全面换成使用 paper + notability 手绘 + 实时演示，再度跟过去道别。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9ace3ff60f550a824490a389b17b4607_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1200&quot; data-rawheight=&quot;905&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是 scheduling？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;wikipedia 上是这么说的：&lt;/p&gt;&lt;blockquote&gt;In computing, scheduling is the method by which &lt;b&gt;work&lt;/b&gt; specified by some means is assigned to &lt;b&gt;resources&lt;/b&gt; that complete the work.&lt;/blockquote&gt;&lt;p&gt;这话有点晦涩，我们要拿出初中英语期末考试阅读理解中寻找主谓宾的技巧和专注去面对。这里我给大家用程序员最喜欢的语言翻译翻译：&lt;b&gt;scheduling 是一个函数，它把一组任务的集合映射到一组资源。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们举个例子 —— 拿大家最耳熟能详的 linux CPU scheduler（以下简称 linux scheduler）说事 —— 就是把一系列 process (workload) 映射到一个个 CPU core：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-98b71b8bd6479059cdd354b540588398_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;699&quot;&gt;&lt;p&gt;这里面，主要的 task 有：常驻系统的服务，各种各样的 agent，一次性的脚本，周期性的任务。对于 linux scheduler 来说，其 scheduling 函数，承受着巨大的功能性的压力：公平，优先级，抢占（交互任务要能得到立刻执行），高效，可扩展（从 single core -&amp;gt; multi core -&amp;gt; NUMA），等等。&lt;/p&gt;&lt;p&gt;除去 linux scheduler，我们的生活中还有很多很多你都没有意识到的 scheduler，我们随便举几例：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;erlang scheduler，erlang processes 到 threads 间的映射。&lt;/li&gt;&lt;li&gt;nginx，http/https 请求到 processes / application 间的映射。&lt;/li&gt;&lt;li&gt;Memory manager，virtual memory 到 physical memory 间的映射。&lt;/li&gt;&lt;li&gt;hypervisor，VM 到物理机器间的映射。&lt;/li&gt;&lt;li&gt;AWS EC2 service，VM 到 hypervisor 间的映射。&lt;/li&gt;&lt;li&gt;Spark，map/reduce job 到计算节点间的映射。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过这些映射，我们得到很多好处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;资源得到更高效的利用&lt;/li&gt;&lt;li&gt;由于增加一层 indirection，任务和任务所需要的资源间得到解耦&lt;/li&gt;&lt;li&gt;更好的服务质量（QoS）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;仔细观察上面的例子，我们不难发现，待处理任务的数量往往远大于资源的数量，甚至，二者相差好几个数量级。这种用少量的资源打肿脸充胖子完成大量的任务的无耻行为，在计算机领域有一个漂亮的名字，叫 over subscription。你仔细琢磨，其实很多商业领域尤其是互联网，其秘密就在于 over subscription 这个小小的词语中。比如运营商给你的 50M 包月网络；早期 gmail 提供的不断增长的 1G 邮箱容量；aws 拍着胸脯对每个客户宣传：老表，来我们这场子，S3 管够，EC2 想要多少就有多少。&lt;/p&gt;&lt;p&gt;反过来，我们要想支持 over subscription，那么，通过添加一个 scheduler 把资源的两端解耦，就可以解决。&lt;/p&gt;&lt;p&gt;到目前为止，大家对 scheduling 已有一个粗浅的认知 —— 这时我们的脑海里便会浮现出很多很多的疑问。这其中，最重要的问题是：这世上没有无缘无故的便宜给你占。享受到 scheduler 的马杀鸡，代价是什么？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;scheduling 究竟有多快（多慢）？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;还是拿 linux scheduler 说事。scheduler 本身的运行会消耗资源，这边是其最主要的代价。自然，我们希望这代价越小越好。于是，下一个问题是：当 linux 做一次 reschedule 的动作时，究竟耗费多少资源（CPU 时间）？&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6565c036d7de76256bc215aa95491061_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;527&quot;&gt;&lt;p&gt;要想回答这个问题，我们先得回答另一个问题：怎么测量？&lt;/p&gt;&lt;p&gt;要测量上图中桔色的部分，有两个直观的方法。一种方法是在入口和出口记录时间，然后计算 diff，最后求平均值 —— 然而 scheduling 的动作并不受你我掌控，用户态下很难找到其入口和出口。另一种方法是我们让青色的区域无限接近零，让整个时间片都被桔色的区域占满，这样，任务运行的时长便是 scheudling 花费的总时长。按照这个思路，用户态的代码需要被简化到只做一件事情：一旦被执行就立刻阻塞自己，让 scheduler 毫不犹疑地把 CPU 让给小伙伴们。&lt;/p&gt;&lt;p&gt;这个思路 linux 下面的 perf 工具已经给你实现好，直接调用即可：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;staging$ perf bench sched pipe&lt;/code&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;# Running &#39;sched/pipe&#39; benchmark:&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;# Executed 1000000 pipe operations between two processes&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Total time: 20.026 [sec]&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;20.026324 usecs/op&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;49934 ops/sec&lt;/code&gt;&lt;/p&gt;&lt;p&gt;其原理是两个 process 相互 pipe，礼尚往来，scheduler 夹在其间来回奔波。这里有个问题，由于 process 可能分布在不同的 core 上，测出的性能失真，所以我们应该用 taskset 将其 affinity 到某一个 CPU core 下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;staging$ taskset -c 0 perf bench sched pipe&lt;/code&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;# Running &#39;sched/pipe&#39; benchmark:&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;# Executed 1000000 pipe operations between two processes&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Total time: 3.104 [sec]&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;3.104995 usecs/op&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;322061 ops/sec&lt;/code&gt;&lt;/p&gt;&lt;p&gt;有同学问，kernel 的 scheduler 有工具可以让你偷懒不写代码，那么，用户态的 scheduler，比如 erlang VM process scheduler 的性能，你怎么测量？&lt;/p&gt;&lt;p&gt;我是这么做的：首先启动 100k 个 processes，每个 process 的入口函数传入上一个 process 的 pid（第一个启动的就放 &lt;code class=&quot;inline&quot;&gt;self()&lt;/code&gt;），启动完成后，self 给最后一个 process 发一个最简单的 message，比如 &lt;code class=&quot;inline&quot;&gt;:hello&lt;/code&gt;，每个 process 接到 &lt;code class=&quot;inline&quot;&gt;:hello&lt;/code&gt; 后，就给它知道的 pid 发 &lt;code class=&quot;inline&quot;&gt;:hello&lt;/code&gt;，直到消息回到 self。这样完成一个循环，循环 100 次之后，也就是 10M 次 scheduling，我们计算所花费的时间：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a68d5d25f7635620089fb79794f5e909_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1113&quot;&gt;&lt;p&gt;最终的结果是：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;~/pingpong/elixir master [!]&lt;/code&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;staging$ ./pingpong&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Start 100000 actors&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;All actors are started&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Time elapsed 10000000 runs &lt;b&gt;for&lt;/b&gt; message passing: 5.913704s&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Single op spent: 0.5913704us&lt;/code&gt;&lt;/p&gt;&lt;p&gt;有趣的是，当我们使用 CPU affinity 后，其性能几乎不变：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;~/pingpong/elixir master [!]&lt;/code&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;staging$ taskset -c 0 ./pingpong&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Start 100000 actors&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;All actors are started&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Time elapsed 10000000 runs &lt;b&gt;for&lt;/b&gt; message passing: 6.199335s&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;Single op spent: 0.6199335us&lt;/code&gt;&lt;/p&gt;&lt;p&gt;同样的，我们在两个 goroutine 间 ping/pong：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;~/pingpong/go master [!]&lt;/code&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;staging$ ./pingpong&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;2.895870s elapsed&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;0.144793 us per switch&lt;/code&gt;&lt;/p&gt;&lt;p&gt;CPU affinity 后，性能也几乎不变：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;~/pingpong/go master [!]&lt;/code&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;staging$ taskset -c 0 ./pingpong&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;2.880224s elapsed&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;0.144011 us per switch&lt;/code&gt;&lt;/p&gt;&lt;p&gt;代码见：&lt;b&gt;tyrchen/pingpong&lt;/b&gt;。我就不贴出来详细说。&lt;/p&gt;&lt;p&gt;经过这几组 benchmark，我们学到些什么？&lt;/p&gt;&lt;p&gt;首先，这些测试都不算严谨。我们并未消除系统里其它 process 的影响，因而测量的结果并不精确。但是，我们大概可以了解其处理速度的量级。知道这个量级，非常重要，因为，scheduler 把 CPU 时间切出来的 time slice 应该要高于这个量级，否则，便没有意义。&lt;/p&gt;&lt;p&gt;其次，与其说它是 scheduling 的性能，不若说是 context switch 的性能，不过这两者在非专门对 scheduler 算法 profiling 的我们来说，是可以划上等号的，因为我们关心的是，scheduling 前前后后所处理的各种琐事（从上一个 task 结束执行，到下一个 task 开始执行），挤占多少 CPU 时间。&lt;/p&gt;&lt;p&gt;再次，对比三者，我们可以有些推断 —— linux scheduler 做了大量的工作，这其中耗费的绝大多数时间是在 context switch 上：SAVE-n-LOAD，切换页表等等，所以它的性能最差。erlang scheduler 的性能差不多是 linux scheduler 的 5 倍，这是因为在用户态下切换自身定义的 “process”，无需打扰 kernel，也不涉及到页表的切换，SAVE-n-LOAD 也是处理 VM 上的状态，比较简单，scheduling 本身又没有那么复杂的需求，所以胜出是理所当然 —— 如果不能胜出，反倒是有问题。golang 的 scheduler 性能最好，是 linux scheduler 的 20 倍，erlang scheduler 的 4 倍。和 erlang 一样，golang 用户态下的 scheduler 没有诸多纷繁复杂，性能自然是很好。至于比 erlang 还要好上这么多倍，应该是两个原因导致的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;golang scheduler 最简单，没有优先级，也没有抢占，高度优化（甚至不惜牺牲系统总体效率在没事可干时 spinning thread）&lt;/li&gt;&lt;li&gt;没有运行时解释执行 bytecode 的累赘 —— golang 直接编译成 binary，而 erlang 编译成 beam 解释执行&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;所以，golang scheduler 的胜出无可厚非。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Patterns / Trade-offs&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们只是简单地讨论了三个不同的 scheduler，便发现它们的实现根据其业务需求有不同的 pattern 或 trade-off。在考虑一个 scheduler 时，我们要考虑这些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;任务如何组织？是所有的资源共享一个任务的 runqueue，调度器调度时通过加锁来保证互斥，还是针对每个资源，我们都为其设置一个 runqueue，以减少锁带来的损耗？那么问题又来了，如果某个资源上的任务列表空了，资源是就此闲置，还是可以去别的资源的 runqueue 上「偷」任务给自己执行？&lt;/li&gt;&lt;li&gt;资源如何利用？是 run to completion，还是 time slicing？run to completion 对于计算密集，且在意 latency 的场景非常有价值，因而在网络设备中，除 traffic shaping 的需求外，报文的处理大多采用 run to completion。time slicing 则适用于 I/O 密集，或者在意系统总体的利用率的场景。&lt;/li&gt;&lt;li&gt;用什么数据结构组织 runqueue？是 FIFO queue (linked list)，还是 rb tree，还是 bitmap + FIFO queue，各种结构的优劣如何？&lt;/li&gt;&lt;li&gt;使用什么算法？是用一个 while loop 去 O(N) 地遍历来寻找最合适的任务，还是对于任意任务 round robin（weighted round robin）？Linux 2.6 O(1) scheduler 使用的是什么样的算法？CFS (Completely Fair Scheduler) 为何又将其取而代之？对于目前大集群下的 cluster scheduling，scheduler 如何处理，borg / mesos /omega 这些先后名噪江湖的算法是怎么回事，该怎么选用？&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57e81d435e41ab6600e57106e5a4e30d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1056&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未完待续&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当我写这篇文章的时候，我只是想着把我 BBL 所讲，大致做个摘录。结果一不小心开个头，就碎碎念这么长。也罢，那咱们就干脆趁热打铁，做个系列，希望有功夫能讲一讲 2.6 O(1) scheduler，erlang scheduler，以及 mesos。下篇文章我们讲讲一出江湖就名震天下的 &lt;b&gt;linux 2.6 O(1) scheduler&lt;/b&gt;，敬请期待。&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-01-29-33389178</guid>
<pubDate>Mon, 29 Jan 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>2017，程序人生大串烧</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-01-16-32975146.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32975146&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3ad2b89f497955473dee4795a1e8b151_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;从 2014 年第一篇公众号文章开始，三年多时间我竟然已经写下了 386 篇文章，涵盖技术，管理，创业和一些莫名其妙的感悟。这便是小小的坚持迸发出的能量：不经意间，&lt;b&gt;日拱一卒的零零碎碎&lt;/b&gt;汇集出这般美妙的结果。&lt;/p&gt;&lt;p&gt;我常说：读自己的日记，仿佛在跟过去的自己对话。读自己的文章也是如此。早上在 4S 店保养小车，闲来翻翻自己的文字，感觉很棒 —— 这并不是说我觉得我的文字有多棒，而是文字中透出的我的想法，成熟的不成熟的，都承载着我的成长。有这些文字（以及少量日记）作伴，我的 2017 虽不完美，好些计划也没完成，但起码留下了些什么。&lt;/p&gt;&lt;p&gt;2017 年我的第一篇文章 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827567&amp;amp;idx=1&amp;amp;sn=a001443824781ee8fa02ebd0d9b6d289&amp;amp;chksm=8704aaf3b07323e5dc9b29ed954aff78482de9dd7192917daea06e1619afc0de392c6eefd206&amp;amp;scene=21#wechat_redirect&quot;&gt;Policy Engine 的前世今生&lt;/a&gt; 就振聋发聩 —— 火车上的一次突发奇想加上接下来三天的各种实验，奠定了 Tubi TV 这一年诸多工作的基石，也埋下了一些神坑让 team，甚至 elixir 1.7 去填（比如这个：&lt;a href=&quot;https://github.com/elixir-lang/elixir/issues/7047&quot;&gt;https://github.com/elixir-lang/elixir/issues/7047&lt;/a&gt;）。现在我们线上奔跑的代码已经和文中描述的大大不同，单 policy 一次编译时间也从 10 分钟，优化到几秒钟，但其中的思路，还是值得大家一看，甚至，文中提到的 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=210542047&amp;amp;idx=1&amp;amp;sn=9c813595c727c0fa028651b9dcdbab12&amp;amp;scene=21#wechat_redirect&quot;&gt;如何愉快地撰写 Parser&lt;/a&gt;，也值得大家重读。&lt;/p&gt;&lt;p&gt;elixir 是我在 2015 年就在跟进的语言，但一路来都是写写小的 side project，直到 2017 年，在 Policy Engine 尝到甜头后，才正式在生产环境中大规模使用。这一年中，团队累积了很多经验，尤其在 cluster deployment / release / hot upgrade / rolling upgrade 方面 —— 2018 年 3 月份我会在旧金山的 Code BEAM 2018 大会上谈谈我们在这些方面的收获，希望大家捧场。&lt;/p&gt;&lt;p&gt;学一门新的语言并非学习它的语法那么简单。去年年初我写下了 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827570&amp;amp;idx=1&amp;amp;sn=fe6ca628a5295d52746ff62f2bf84fe2&amp;amp;chksm=8704aaeeb07323f8c0381932a7696917d6d04f3596438e7d7b6083fa26a825c2628a83d8ad67&amp;amp;scene=21#wechat_redirect&quot;&gt;如何使用一门新的语言&lt;/a&gt;，介绍了我的一些思考。它不仅仅适用于 elixir，也适用于其他的语言。&lt;/p&gt;&lt;p&gt;如果你对 elixir / erlang 感兴趣，那么， &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827596&amp;amp;idx=1&amp;amp;sn=9fb32f42760462109143ece34859043e&amp;amp;chksm=8704ab10b07322064f04d0fcb76b9eea929eaf18dcb5a0bac383609ee56b69a13e9584e359bd&amp;amp;scene=21#wechat_redirect&quot;&gt;Let it crash：因为误解，所以瞎说&lt;/a&gt;，&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827636&amp;amp;idx=1&amp;amp;sn=ae805b1b7c41bcfbffe2bcbf992b87db&amp;amp;chksm=8704ab28b073223e8ffb831d12187bb1a7ef7bfff0e4b4dce760c9228ee189dbcdfd6e6d548a&amp;amp;scene=21#wechat_redirect&quot;&gt;Phoenix 1.3，迈向正确的道路&lt;/a&gt;，&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827691&amp;amp;idx=1&amp;amp;sn=8d6854f91bb9d16470ef6eed9d3ad8ec&amp;amp;chksm=8704ab77b0732261eb63217ad03740a3433cde4491826eeec020f4bbebb8b18837c27ac3e74d&amp;amp;scene=21#wechat_redirect&quot;&gt;上帝说：要有一门面向未来的语言，于是有了 erlang&lt;/a&gt;，你也许不想错过。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827578&amp;amp;idx=1&amp;amp;sn=8c68f89f51a48a0e11ec52aa51438285&amp;amp;chksm=8704aae6b07323f063e45b709cd20e948fc516fbd858d0c439b5c014eea74ea9accb95928543&amp;amp;scene=21#wechat_redirect&quot;&gt;如何用正确的姿势打开 TDD 这篇文章&lt;/a&gt;，详细地探讨了我使用 TDD 的一些心得，里面还涵盖了很多和 design/arch 相关的思考。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827625&amp;amp;idx=1&amp;amp;sn=76b275e9c4895d94f7ca963bedca7564&amp;amp;chksm=8704ab35b073222313df7222a944dcccc315ed852ab8390ab016d58bf5f373469e7a3f9084ae&amp;amp;scene=21#wechat_redirect&quot;&gt;是时候想想怎么删除代码了&lt;/a&gt; 是一篇很有争议的文章，但他给你一个独特的视角考虑如何写出更好的代码。如果你赞同 Begin with end in mind，那么，我们要好好考虑这个问题：&lt;b&gt;有没有可能，我们在架构之初，就考虑到这个代码有可能在将来成为一种负债，因此在设计上考虑到如何能轻松地将其删除或者替换？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;去年 3 月份，我参加了 erlang solutions 的一个 OTP 培训，写下了这样的文字：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827661&amp;amp;idx=1&amp;amp;sn=d516a615364c9226356c2f538d643425&amp;amp;chksm=8704ab51b0732247186e98170b465e37bf64c932aca98c36be01baa06980d359b5e05484135b&amp;amp;scene=21#wechat_redirect&quot;&gt;当我参加培训时，我在想些什么？&lt;/a&gt;同样的一件事，不同人眼里有不同的价值，就看我们怎么样去发掘了。&lt;/p&gt;&lt;p&gt;很多人写了很多代码。但是，绝大多数人读过的代码还没有自己写过的代码多。这是一个很奇怪的现象 —— 我们从小到大，少说也读了几百几千万字的书，工作数年甚至十数年，还没有读过同样体量的代码。&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827664&amp;amp;idx=1&amp;amp;sn=9d8570026349398fedb0aecd05dedc3b&amp;amp;chksm=8704ab4cb073225a43c85bf7daab723985f9a56cb4dd611dade9007dac35f73f233c4497a82d&amp;amp;scene=21#wechat_redirect&quot;&gt;为什么我们要阅读源码？&lt;/a&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827677&amp;amp;idx=1&amp;amp;sn=c50072121269e7d11fdf23bb7b76d95a&amp;amp;chksm=8704ab41b073225742403e3959435205d31a388114a050e8805d5ed5defe1ae21d6b546b6288&amp;amp;scene=21#wechat_redirect&quot;&gt;如何阅读一份源码？&lt;/a&gt;希望能让你重燃对读优秀代码的兴趣。&lt;/p&gt;&lt;p&gt;提高软件开发的能力，除了多读代码之外，还要下苦功夫。&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827805&amp;amp;idx=1&amp;amp;sn=f15ed2e753337af039fc5b2a88d35b8a&amp;amp;chksm=8704abc1b07322d7e5db27d69136ce3aa6adcbbf2bcb5bbca02971dded0d0e2ffb7637a4e3c8&amp;amp;scene=21#wechat_redirect&quot;&gt;在提高代码能力这事上，没有银弹&lt;/a&gt; 就是这个意思。停下来，歇口气，造轮子 告诉你，没完没了打零工（do chores），如果不能把它们串起来，时不时来个从零到一，你会陷入 &lt;b&gt;你以为你知道了但其实你并不知道你不知道的&lt;/b&gt; 的窘境。&lt;/p&gt;&lt;p&gt;软件开发是个从起点到终点的高级寻路游戏，考究的是个解决问题的综合能力 —— 虽说条条大路通罗马，但有的路一马平川势如破竹，有的路如临深渊如履薄冰。我们要寻找的是时间空间俱优，还节省开发效率的妥协（compromise）之路。妥协不是件简单的事情 —— Rich Hickey 说，&lt;b&gt;你起码要有两个以上的 solution，才谈得上妥协&lt;/b&gt; —— 所以，见识丰富必不可少。也许下面几篇文章可以帮到你：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827819&amp;amp;idx=1&amp;amp;sn=1d7da4a332c267a625ee5196985ab3e7&amp;amp;chksm=8704abf7b07322e17ebcfede920497ff1c5246be36e6a4494706aa35ac3f112b0e41796162c0&amp;amp;scene=21#wechat_redirect&quot;&gt;bash 的威力&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827770&amp;amp;idx=1&amp;amp;sn=d370f79f5c82bb439583828321e1a74c&amp;amp;chksm=8704aba6b07322b08f3d950b2eed3989cbff65b0cddbc84857cdd469ca5a414b74f7199e8f95&amp;amp;scene=21#wechat_redirect&quot;&gt;谈谈状态机&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827728&amp;amp;idx=1&amp;amp;sn=b8ea0e7d62d747c7736949431d483fd8&amp;amp;chksm=8704ab8cb073229a892aa49a9056bd92619106b68f09bee5fc536596b04443cc877d0e20b8ff&amp;amp;scene=21#wechat_redirect&quot;&gt;谈谈数据结构&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827646&amp;amp;idx=1&amp;amp;sn=9319811a7738d55f97bcb33a80f11c59&amp;amp;chksm=8704ab22b07322343221f938dc57c17f38ca8d75e549411a139e9d9e8f552780b311e0beaa0d&amp;amp;scene=21#wechat_redirect&quot;&gt;谈谈边界&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827718&amp;amp;idx=1&amp;amp;sn=39921d8913b4d72160382f7dac46753b&amp;amp;chksm=8704ab9ab073228c178ffa33e2bd266b51c48c6060b4b656df67d91ca807fdfcca022d30a786&amp;amp;scene=21#wechat_redirect&quot;&gt;思考：快与慢&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827699&amp;amp;idx=1&amp;amp;sn=e97071f2f049b8027c3105b8bd4ade70&amp;amp;chksm=8704ab6fb0732279f3c1b463653a812bbaef4d921fe65fe82cfb397765b01a9c5552a18307fe&amp;amp;scene=21#wechat_redirect&quot;&gt;service performance 101&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827704&amp;amp;idx=1&amp;amp;sn=176e84212578b175b88765a9a21df7a9&amp;amp;chksm=8704ab64b0732272b6d1d71e5b31b405fa9c10a687088c39b11c3c86b3be0c542dd5114a06f6&amp;amp;scene=21#wechat_redirect&quot;&gt;浪费内存？多大个事？&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;看技术文章看累了，换换脑子，我们扯扯淡：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827824&amp;amp;idx=1&amp;amp;sn=2ddf0612f1d25f68dab11ab3f5db02be&amp;amp;chksm=8704abecb07322fa92a4d97b1683c551928389cdb25fe2c005a6fbf92e5f3facb07107d91a1b&amp;amp;scene=21#wechat_redirect&quot;&gt;美帝面试二三事&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827862&amp;amp;idx=1&amp;amp;sn=3544c7f82ececdca36c7285fb77dfceb&amp;amp;chksm=8704a80ab073211cfcc2bf6f942e2d7c0b2a2f361c66de8eb8903cf277e0481085a6acf6a0ef&amp;amp;scene=21#wechat_redirect&quot;&gt;社会我梅姐：美女兼劳模&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827772&amp;amp;idx=1&amp;amp;sn=10407d51a4779fc11a3b46bd5edad3c4&amp;amp;chksm=8704aba0b07322b66c803b39b7aad80fa1fd918ce08daaccb02456ca30d785a5dbf6ecef5497&amp;amp;scene=21#wechat_redirect&quot;&gt;软件工程师成长之路&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827682&amp;amp;idx=1&amp;amp;sn=c96d8a72e6535238cb4b45a35f15b9af&amp;amp;chksm=8704ab7eb073226847dca3ccdd95f9bf6a9ab40697677ba343c9a51bfea0e83e028797162fda&amp;amp;scene=21#wechat_redirect&quot;&gt;创业公司如何组建技术团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827735&amp;amp;idx=1&amp;amp;sn=cc684a300386e7c6446a10d4ad753dcd&amp;amp;chksm=8704ab8bb073229db518703c1cf5c5bb79212b1ab504131604312753d03bcb4a0f5c64ff35c7&amp;amp;scene=21#wechat_redirect&quot;&gt;程序员为什么会忧虑自己的未来&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827812&amp;amp;idx=1&amp;amp;sn=8b2389d4c7221cb439ab0e705dd6e8e9&amp;amp;chksm=8704abf8b07322eee8aecb3bd6ad6f71f2673072feb0ed5b6f2f2fee97f0b0d11411526cc8ef&amp;amp;scene=21#wechat_redirect&quot;&gt;程序员的好日子何时才能到头？&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827870&amp;amp;idx=1&amp;amp;sn=50ad123859bc7b3d5b912e19bc98ad67&amp;amp;chksm=8704a802b0732114e5fc45035498f119309d70530c82b11e10989b95c4c7e12099003641a000&amp;amp;scene=21#wechat_redirect&quot;&gt;不要等客户来通知问题&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;或者开拓一下视野：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827757&amp;amp;idx=1&amp;amp;sn=1b5ee89840ccb9c59ec971bd6f4681a4&amp;amp;chksm=8704abb1b07322a72928ed9cdcd01ed9d9e68a951657d0e30f7ea97f95646edafc2c49847ef0&amp;amp;scene=21#wechat_redirect&quot;&gt;red，不红不专，但性感&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827782&amp;amp;idx=1&amp;amp;sn=122c74dfb32eefc5f9dc9aa648f16b98&amp;amp;chksm=8704abdab07322cc552fff20455549b56ed1ce34cb56e82e5f58b3937aa87032bb87a528311e&amp;amp;scene=21#wechat_redirect&quot;&gt;sound of silence：数据传输的小众黑科技&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827794&amp;amp;idx=1&amp;amp;sn=7e968057cf4ba72f775dde454d89a0ce&amp;amp;chksm=8704abceb07322d8bacc40389e4a0fce0955f7da9b72c0c4a4b613541d6fa69fc65234a8567d&amp;amp;scene=21#wechat_redirect&quot;&gt;闲扯比特币套利交易系统的设计&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827653&amp;amp;idx=1&amp;amp;sn=1d736cfe77ed32babf58ed955f50c2fc&amp;amp;chksm=8704ab59b073224fdfda47376a457be140ef7631ef3f85c7742e2c886b7fc6885de21e9ba010&amp;amp;scene=21#wechat_redirect&quot;&gt;alexa：梦中的女神&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827838&amp;amp;idx=1&amp;amp;sn=e8f12c1631c831cbe6d02c4cd5a82e86&amp;amp;chksm=8704abe2b07322f4fdf8cce03fd5285129f3ac717a88675e56688af515981620ba13f3f11996&amp;amp;scene=21#wechat_redirect&quot;&gt;pixel 2 XL：软件为王&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;或者回顾一下 2017 年发生的灾难性大事件，以史为镜：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827593&amp;amp;idx=1&amp;amp;sn=7cc4aa992210b2a1f0a9cd533250b48b&amp;amp;chksm=8704ab15b07322038d14b8bd38bdbd50b2dc7ff951f0241eb790e84fa61b33fd158699ae848e&amp;amp;scene=21#wechat_redirect&quot;&gt;从 gitlab 事件中吸取的教训&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827622&amp;amp;idx=1&amp;amp;sn=f13648a3f38752f6822026873a2783b2&amp;amp;chksm=8704ab3ab073222c05050a5a1f36c6d74b083b9bacb7f0dd6b99462b8ec4b87e885569e5276e&amp;amp;scene=21#wechat_redirect&quot;&gt;北美互联网哀鸿遍野：号称 99.9% 可用性的 S3 挂了&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;然后，躺在懒人沙发上，想想，作为一个程序员，自己眼中牛逼的自己该是什么样？如果没头绪，参看程序君吐血推荐的这篇：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827589&amp;amp;idx=1&amp;amp;sn=b10f3d0979fd5eda86ebb656fd38186d&amp;amp;chksm=8704ab19b073220f1b4d18cb0aabcb1b4fc34bc0ffa85df1a73bac7502bef42775b9404e8ce8&amp;amp;scene=21#wechat_redirect&quot;&gt;程序员字典：「牛逼」&lt;/a&gt;。然后，再想想。&lt;br&gt;&lt;/p&gt;&lt;p&gt;2018 我会格外忙一些 —— 过去几年输入和输出都不算少，但主要在夯实自己的舒适区。2018 我将会深入踏足一些之前我只有粗鄙认知的领域：ML/DL 和 blockchain (主要是基于智能合约的去中心化应用)。我报了些线下和线上的课程，一季度每周大概有 10 个小时要用来上课，估计也要用同样体量的时间来夯实所学。所以我的原创文章产量会大大削减，争取每旬一更，最差也要双周更。请大家体谅。&lt;/p&gt;&lt;p&gt;希望这些文章能对对你有用。&lt;/p&gt;&lt;p&gt;往期串烧：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827562&amp;amp;idx=1&amp;amp;sn=c7c8a2d4d638fb8eb3d60577829c1034&amp;amp;chksm=8704aaf6b07323e0d3253f6486f25a03bf074636318dd0b6114ff166f249cbfb7016d9fa9e2c&amp;amp;scene=21#wechat_redirect&quot;&gt;2016 程序人生大串烧&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=401107581&amp;amp;idx=1&amp;amp;sn=502830373629d22e5808a8a17dfdf8ae&amp;amp;scene=21#wechat_redirect&quot;&gt;2015程序人生大串烧&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-01-16-32975146</guid>
<pubDate>Tue, 16 Jan 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>不要等愤怒的用户来通知你的问题</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2017-12-12-31956118.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31956118&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e4ad403fb48d9a2e7cf63bcc5799d75a_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;引子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;周日早上爬完香山回来，想起还和一位朋友约了咖啡，赶忙打开微信扫路边的一辆单车。摩拜的小程序提醒我开锁中，请勿关闭小程序。然而这开锁的进度在百分之零的位置停留若干分钟，毫无变化。等了许久，我怀疑网络不畅，于是关闭小程序又重新打开扫描，这下可好，小程序直接告诉我：「您上次用的车还未关锁，暂时不能在用其它车哦」。&lt;/p&gt;&lt;p&gt;这就傻逼了。我对着一辆明明没开锁却被认为已开锁的车扫了又扫，我期望聪明的系统能够发现这一异常行为 —— 如果一辆被认定是开锁使用中的车被同一个用户扫了又扫，那一定是这部车没有正常开锁 —— 尤其对一个信用分有 160，人品还算扎实的老同志来说。&lt;/p&gt;&lt;p&gt;可是摩拜就是固执地不让我用车，每次扫码后那句相同的文案，尤其是最后一个用来卖萌的「哦」字，无情地嘲弄在寒风中拖着鼻涕的我。没办法，周日一天，若干本没有必要打车的短途，我都不得已使用滴滴，给北京人民添了赌加了霾。我在朋友圈吐槽两句，有摩拜的朋友要下我的手机号，看了看后说等后台的任务处理到就能给我解锁。&lt;/p&gt;&lt;p&gt;周一早上，算算过去有二十多小时，再慢的任务也该处理完闭，上班路上我想试试账号是否已恢复正常，就顺手扫了一辆车，结果问题依旧。我出离愤怒，写下这样的话准备和摩拜道别：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f09f4a4321c8b567b31564fb695e59f2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1440&quot; data-rawheight=&quot;979&quot;&gt;&lt;p&gt;很快地，我被两位朋友分别拉进两个群。一个里有 BD director，一个里是某部门的 head of engineering，在大佬们的亲切关切下，我的问题瞬间解决 —— 在我「骑行」1273 分钟，也就是 21 小时之后，那幽灵一般的车子终于「成功关锁」：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-08df2d5669cf1313befb4f18ec0922a6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;988&quot; data-rawheight=&quot;983&quot;&gt;&lt;p&gt;问题解决，该退我的钱也退还给我，借此感谢一下帮忙的各位朋友。在这样一个黑天鹅事件中，我的一众微信好友，还有我在程序员圈子里小小的名气，帮上了大忙。如果换一个用户，这事肯定就没有这么顺利。她的牢骚也许石沉大海，只能通过客服，耗时耗力，才能追回不该产生的费用。&lt;/p&gt;&lt;p&gt;换做别人，这事可能就这么揭过，顶多变成茶余饭后的谈资。但对于一个闲的蛋疼没事就瞎琢磨的程序员来说，没有什么比这样的事情更有趣，跟值得思考。周一晚上回到酒店，在游泳池里消磨脂肪，打发卡路里的时间里，我的脑海里反反复复萦绕着一个问题：如何让系统更好地自行监测和处理类似的问题，而不是由愤怒的用户反馈上报？&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何更快地发现和处理类似问题？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作者按：以下分析纯属扯淡 —— 它并非基于一系列真实的数据，而是做了诸多很可能不靠谱的假设，分析也并非深思熟虑，就是半个多小时的突发奇想。套用菜头叔的一句话：我所说的，都是错的。&lt;/p&gt;&lt;p&gt;按照已公开的专利：一种基于物联网的公共自行车租赁系统（https://www.google.com/patents/CN105354935A?cl=zh）的描述，借车的流程是这样子的（略修改）：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;利用手机APP扫描车身上的二维码，手机APP获取该自行车的唯一标识信息，并把借用请求发送到后台控制系统。后台控制系统同时给自行车的车载控制器发送开锁指令。&lt;/li&gt;&lt;li&gt;车锁打开后，车载控制器会向系统发送开锁成功信息（同时附带GPS定位信息），自行车进入借用状态。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我的情况显然是车载控制器向系统发送开锁成功的信息，系统认为自行车进入到借用状态，而车锁实际并未真正打开。这在实际应用中是很难杜绝的问题，因为机械的开关动作无法完美地和发送开锁成功消息的芯片形成有一个完整的事务（transaction）。&lt;/p&gt;&lt;p&gt;上文中吐槽过，如果一个信誉良好的用户在「刷开」一辆车后，又重新扫相同的车，那么，非常非常大的几率是车锁并未真正打开。从产品的角度上讲，不应该阻止用户用车，而是再次尝试重新开锁，如果用户反复扫码，则应该在 app 中问问用户这辆车是不是无法正常开锁，并提示其汇报问题车辆。用户此时可以扫别的自行车骑行。&lt;/p&gt;&lt;p&gt;当然，这一优化对信誉一般的用户，或者扫一辆车没扫开，便换一辆车来扫的用户来说，不太适用。很多时候还是会出现系统认为你正在用车进而无法借车的问题，我们需要更快地，更妥善地解决它。&lt;/p&gt;&lt;p&gt;我们先做些定义：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;session：每次开锁后，到用户使用完毕关锁前是一个 session。session 有下面若干种。&lt;/li&gt;&lt;li&gt;active session：正在进行中的 session，当用户扫码开锁借用一部车时，就产生一个 active session。一个用户只能有一个 active session。&lt;/li&gt;&lt;li&gt;abnormal session：不正常的 active session，比如开锁后三十分钟却无产生位移。&lt;/li&gt;&lt;li&gt;finished session：结束的 session。当用户关锁后，会结束当前的 active session，用户有资格继续借车。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;还有假设：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;90% 的 session 不超过 1 小时。最长的 session 不会超过 1 天。&lt;/li&gt;&lt;li&gt;如果一个 session 在半小时（1800s）没有任何活动（意味着用户既没有关锁，又没有真正在骑行），那么这个 session 应该做异常处理。&lt;/li&gt;&lt;li&gt;开锁后，车载的智能锁每 N 秒（假定 N=10）会向服务器发送心跳信息 —— 其中包含车辆编号，用户id，当前的地理位置，产生的位移（位移可以通过车轮的转速和周长算出）等。如果用户的 app 处于打开状态，也会以相同的节奏发送类似的数据，包含车辆编号，用户id，当前地理位置，以及根据 4G / WiFi / GPS 的信号来计算产生的位移。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;给定这些定义和假设，我们可以讨论下 session scan 的方法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案一&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最传统的方式是将 active session 组织成一个双向链表，当一个 active session 结束后，将其从链表中拿出释放。然后，后台有一个定时任务扫描这个链表，如果发现 abnormal session，将其拉出来 &lt;b&gt;打上标记&lt;/b&gt; 并插入一个 abnormal session 的双向链表，当其再度达到 timeout 时，进行异常处理。比如说再次关锁并结束这个 session，修正计费问题，或者进而加入到一个有待线下人工处理的队列。&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案二&lt;/b&gt;&lt;/p&gt;&lt;p&gt;方案一简单易行，但最大的问题是 scan 本身是个线性的操作，O(N) 的复杂度避无可避。如果 N 在千万甚至上亿量级，其效果将会很差，可能一次完整的 scan 要数个小时完成，那么很多异常只有在数个小时后才能发现。&lt;/p&gt;&lt;p&gt;所以我们需要更高效的数据结构来避免这种全表的扫描。我们知道，业界使用很多，效果很好，时间复杂度是 O(1) 数据结构是 timer wheel。她大概长这个样子：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f38211ea31fb7ad0450bc5deb96cda1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;479&quot; data-rawheight=&quot;238&quot;&gt;&lt;p&gt;根据业务的需要，timer wheel 可以有不同大小的总槽数（total slots）。slot 和 slot 的间隔我们称为一个 tick。假设一个 tick 是 1s，total slots 128k，那么这个 timer wheel 可以承载最多 1.5 天（128 x 1024 / 86400）内超时的 session，这可以满足我们上述的假定。timer wheel 保持一个 current tick，表明现在时钟走到哪里。时钟走到的位置，如果对应的链表中有 session，那么，这些都是超时的 session，需要被拉下来，由一个或者若干个 worker 来处理。如果在某个 tick 下有一个新的 session 产生，按照上述假设，我们为 session 设置 1800s 的超时时间，那么这个 session 会被安插在 current tick + 1800s 的位置，用双向链表组织起来。下次 current tick 指到这个位置时，这个 session 会被处理。&lt;/p&gt;&lt;p&gt;timer wheel 的好处是，处理超时的 session 是 O(1) 的动作，current tick 指向的位置就是要处理的超时的 session 的列表，非常高效，不用全表扫描来找出需要处理的 session。不过她有一些额外的更新成本，比如说，用户在骑行过程中，每 10s 发送心跳，我们可以通过 GPS 位置的变化，产生的位移来决定是否要刷新这个 session。如果要刷新，那么需要把 session 从 timer wheel 的当前位置取出，放入一个新的位置，从而延缓超时任务对这个 session 的处理。千万级的 session 每 10s 刷新一下，那么每秒有百万级的链表操作，插来插去，非常不经济。一种办法是我们刷新 session 时，在 session 里记录 time diff，当 current tick 到达，worker 处理链表上的超时 session 时，如果发现 session 的 time diff 不为 0，则将其插回到 timer wheel 相应的位置，这样大大节省刷新时的处理（见 patent：www.google.com/patents/US8805988）。&lt;/p&gt;&lt;p&gt;timer wheel 还有一个优化是，如果每个 slot 上链表很长，可以在 slot 上用 array + linklist 的方式，把 session hash 到 array 的不同位置，然后再 link 起来，比如说 array 长度为 32，原来一个 1024 长度的链表，可以被分布在 32 个链表下，每个链表平均 32 个 session。这样，我们可以用 32 个 worker 并发处理这些超时的 session。&lt;/p&gt;&lt;p&gt;这样下来，我们可以把异常 session 的处理时间大大缩短，从而挽回一个个悲痛欲绝的用户。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;技术之外的一些思考&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我们常说，工程师要对其所负责产品有 ownership。这 ownership 说起来简单，但做起来，要付出很多额外的心血。一个业务线的功能做起来并不麻烦，麻烦的是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;哪些路径上的哪些 data point 要送到监控系统（如 statsd）？上线后要在监控平台（如 datadog）上的哪些 dashboard 中添加哪些 graph，monitor，alert？潜在问题发生时的执行手册是什么？&lt;/li&gt;&lt;li&gt;哪些 error log 送错误追踪系统（如 sentry）？&lt;/li&gt;&lt;li&gt;这个功能如何 provision？如何 deploy？如果使用新的资源，如何描述这些资源（infrastructure as code）？&lt;/li&gt;&lt;li&gt;如何保证 performance 不会恶化？&lt;/li&gt;&lt;li&gt;是否有必要要做 A/B testing，做多大的量？&lt;/li&gt;&lt;li&gt;现有的 analytics event（数据埋点）是否完备，如果不够，如何扩展，ETL job 是否要变更，谁来分析处理新收集的数据？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这里面，1 和 2 都是用来帮助我们在问题显现时，能够及时发现和处理。&lt;/p&gt;&lt;p&gt;系统的问题由客户发现，并「被迫发出最后的吼声」，对开发这个系统的程序员来说，不啻是一种耻辱。一个问题为什么由用户报告给我们，我们才开始应对？是我们知道问题的存在假装视而不见？还是压根不知道问题的存在？前者看上去是人品的问题，但八成是程序员被 burn out 之后的自然反应，后者则是技术团队平时对监控和报警不注意导致的。平日里，我们对 UT 没有捕捉到的问题会非常在意，第一时间会补上相关的 UT，让 CI 能够在下次同样的问题发生时，异常退出；然而，对于线上的问题，我们却很少追根溯源，从相应的 data point 是否缺失开始，一路追查到 monitor 和 alert 是否齐备。&lt;/p&gt;&lt;p&gt;前两天，在回顾 11 月我们 Tubi TV 线上问题时，一位同事总结他之前在微软中国 bing team 处理线上问题的一些收获，给大家普及了 TTD / TTA / TTE / TTR 的概念，我觉得很有帮助，列在这里：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TTD（Time To Detect）：问题从发生到被监测出来的时间（可以是通过工具，工程团队，甚至用户发现的）。TTD 越短越好，由工具发现远胜于用户发现并反馈。我们现在大部分问题 TTD 都在 5 分钟之内。&lt;/li&gt;&lt;li&gt;TTA（Time to Aware）：问题从被监测出来到第一个能对此负责的人知道这个问题的时间。TTA 也是越短越好，然而这里有人这个因素的存在，有很多变数。我们用 opsgenie，它接收到报警再通过短信和电话通知到 oncall 的 dev，再到 dev 意识到问题，往往会有 5-10 分钟的间隔；如果 20 分钟无人响应，那么 opsgenie 会打电话给 dev team 的每一个人。所以，绝大多是情况，我们的 TTA 波动很大，大概在 5 - 40 分钟内。&lt;/li&gt;&lt;li&gt;TTE（Time To Engage）：从有人知道发生问题到开始处理问题的时间。有时候，oncall 的 dev 可能在开车，在没有网络的环境，或者手头没有电脑，所以她需要联系下一个她能联系到的，且有资源处理问题的人，这里面也有很多人的因素，我们的 TTE 波动也很大，大致在 5 - 30 分钟之内。&lt;/li&gt;&lt;li&gt;TTR（Time to Resolve）：问题从开始处理到解决。线上的问题，往往是一些固定类型的问题，我们也有相应的处理手册，所以，简单的问题（如重启一下服务）几分钟能够处理完成；中等的问题（如添置更多的资源），半小时内；复杂的问题，可能一下子没有合适的方案，但我们可以 workaround，也在半小时到一小时间可以解决。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于研发团队来说，我们要尽可能缩小 TTD / TTA / TTE / TTR，这样才能尽可能先于用户发现问题，在用户抓狂前，把问题解决掉。要缩小 TTD / TTA / TTE / TTR，我们需要知道，how good/bad we are —— 我们目前这些指标的的 max / min / mean 都是什么，这样才能有的放矢地改进。&lt;/p&gt;&lt;p&gt;比如说，TTD 太长，那么，是监控数据收集地不够充分，还是收集好数据却没有设置相应的警报，还是设置好警报，但阈值过于宽泛，这样一层层追溯下来，我们就能够找到并修复监控的问题，进而可以观察下几次事故发生时，TTD 的曲线是否在下降。&lt;/p&gt;&lt;p&gt;以上。&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2017-12-12-31956118</guid>
<pubDate>Tue, 12 Dec 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>社会我梅姐，美女兼劳模</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2017-11-30-31580165.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31580165&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d133877539224d4086066c3e0e061843_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;Marissa，也就是大家所熟知的梅姐，曾经媒体的宠儿，淡出公众的视线已有一阵子。上次她被大家记起，还是 Yahoo，这个曾经叱咤风云，拥有过千亿市值的互联网鼻祖，委身 50亿下嫁 Verizon 的时候。&lt;/p&gt;&lt;p&gt;然而在五年前，你要问硅谷最炙手可热的人是谁，如果梅姐敢称第二，小扎都不太敢称第一。她职业生涯的头 13 年（1999-2012）神奇而辉煌，从一个斯坦福的应届生起步，逐渐成长为 google 最重要的，负责 google search 的 VP，三巨头的左膀右臂 —— 如果她没离开 google，估计现在没有劈柴同学什么事；而后五年（2012-2017）成为 Yahoo 的 CEO 后，梅姐仿佛一切运气都被抽干了似的，努力但糟糕着，把这家才据掉盖茨叔叔近 500 亿支票没多久，尚能苟延残喘的公司硬生生做到了 50 亿甩卖了事。&lt;/p&gt;&lt;p&gt;人是卑贱的生物，总是容易记得最近发生的事情，而忘却之前发生的一切。有的人前半生做尽好事，最后可能毁在一件错事上面，即所谓晚节不保；也有人一辈子蝇营狗苟，做恶不断，却赶上风口脱颖而出，大富大贵，连马甲都不用换就立地成佛，被人交口称赞，仿佛之前的恶从未发生一样。梅姐便处在这样尴尬的境地：在她 next big thing 还未找到之前，人们永远记得的是她在 Yahoo 的大败局，2016 Fortune 给她贴上的 “one of world’s most disappointing leaders”；谁又还记得，同样是这个 Fortune，极尽谄媚之能，在 2014 年把一切能给的赞誉都给了她：年度 “40 under 40”，排名第六，年度 “world’s most powerful businesswomen”，排名 16，更别说她之前在 Google 的诸多辉煌了。&lt;/p&gt;&lt;p&gt;本来我和梅姐，一只蝼蚁，一尊观音，不太会有交集。不料机缘巧合下，她成了 Tubi TV 的 advisor（关于初创公司的 advisor 制度，也许将来我会另行撰文阐述），于是我有幸和 CEO Farhad / CTO Marios 一起，在我们的 office 里，和她聊了一个小时。&lt;/p&gt;&lt;p&gt;梅姐端庄而漂亮 —— 岁月在她脸上刻了些许痕迹，但我还是很难相信眼前这位佳人是十数年如一日，每周工作 100 小时以上的女强人 —— 这不科学，我一周工作 100 小时的话，估计要苍老到小娃娃见到我都要喊我爷爷了。她充满活力，热情开朗，语速极快，思维跳跃，稍一走神就跟不上她的节奏。不过她的嗓音却是异常嘶哑，像极了一个在讲台上讲课多年毁掉嗓子的教师。&lt;/p&gt;&lt;p&gt;我们和梅姐聊了 Tubi TV，聊了 Google，聊了一些方法论。在这种场合，带个电脑不太合适，所以我只能脑海里反复记述那些点亮我思路的箴言，会议一结束，我便冲出去，打开 mbp，快速记录下脑海中尚且留存的快照。于是，便有了这篇文章。&lt;/p&gt;&lt;p&gt;以下是一些可以公开发表，且我觉得值得大家一看的内容。请原谅一个奔四的国家权威认证的中老年男子的记性 —— 时间，地点，人名，人物的原话如有出入，请以其它文献为准。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;路有很多条，退一步海阔天空&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;梅姐谈了 google 早期的一个「失败」产品：google answer。那时 google search 刚刚起步，和 yahoo 形成了竞争的态势。而 yahoo 有得天独厚的内容优势，尤其是使用率很高的 yahoo answer。google 担心哪一天 yahoo 突然禁止自己的爬虫爬取 yahoo answer 的页面，而对自己构成 unfair competitive advantage（淘宝百度大战，淘宝微信大战，历历在目）。于是 google answer 这样一个防御性的产品上马了。然而，在内容上想要竞争得过有着很久积淀，且用户粘性很高的 yahoo answer 谈何容易，google answer 出师不利，重赏之下，也就日均 100 个问答。随后，大家在一次讨论中突发奇想：我们的目的是抓取和整合尽可能多的信息，而构筑自己的内容并非我们的强项，那为何不激励人们愿意和我们合作，不断构建原创的内容，让 google 索引，从而提高曝光率，获取属于他们的广告收益呢？就这样，google adSense 应运而生。google adSense 解放了很多内容生产者 —— 起初是报纸杂志的编辑，他们发现自己业余时间的产出可以赚取不少收入，甚至超过了他们 day job 工作所得，因而口口相传，越来越多的网站引入了 google adSense，越来越多的个人构筑自己的博客，努力撰写好的内容来提升自己的排名，获得更多的收入。而后 google 不必再为内容忧心 —— 众多的中小网站成为它事实的盟友，二者荣辱与共，利益均沾 —— 因而自己只需要集中精力提供更好的算法，更优秀的基础设施来保证自己是最好的搜索引擎，最棒的广告系统。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;唤起人们的紧迫感&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们问了个问题：google 早年间如何让工程师们以公司为家，心甘情愿地长时间工作？梅姐提到了要让员工感受到 sense of urgency。她讲了这么个故事：&lt;/p&gt;&lt;p&gt;她那时二十岁出头，单身毛头小姑娘，周末没事早上大概11点会去公司干点活，不可谓不努力。有个周六，她在朋友的怂恿下去宜家买了些家具，然后整个周末都在装家具。说来也巧，那周大家都赶上周末有事，有带朋友四处玩的，有参加婚礼的，总之没人在办公室工作。下午两点，她的老板照例来到公司，发现一个人都没有，大发雷霆，周一就把大家召集起来开骂。那老板说：我对你们非常失望。我们每天都在快速增长，有无穷无尽的事情等着我们做。google 肯定会成为一家伟大的公司，我们每个人都有机会成为百万富翁，成为历史的一部分。我不允许任何人打破这个梦想，我也不允许任何人阻碍我们成为百万富翁。你们安装家具，探访朋友，参加婚礼，都是 TMD 不重要的事情。在我这里，要么 all in，要么给我滚蛋。从今天起，周末我们会不限量供应餐饮，我要你们都 TM 坐到你的工位上，亲手缔造历史！&lt;/p&gt;&lt;p&gt;梅姐说她很受感触 —— 之前她是个尽力尽责，有点野心的小姑娘，之后她渐渐蜕变成一个每周工作 100 小时的工作狂。在 google 她养成了这种 sense of urgency，她也把这种理念带去了 yahoo（程序君按：可惜并未成功）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;使命感，人生的北极星&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 yahoo，梅姐怀孕挺着大肚子还在疯狂工作。有天晚上，有个高管和她聊了几句，对她如此拼命很不理解。她说每一刻我都有种「让 yahoo 重回昔日荣光」（程序君按：Make Yahoo Great Again）的使命感，我并不觉得累。高管呵呵，对这个使命不以为然，还反诘她这样做让大家非常 stressful。她说她顿感悲凉，所谓将帅齐心，三军用命。这些养尊处优的 VP 大爷们，惦记的只是自己那一亩三分地，没了使命感，所以工作也就是 TMD 是工作。员工把工作当成工作，无可厚非，但高管如此，其吸引到的追随者的质地也大概能窥到一二。（程序君按：兵熊熊一个，将熊熊一窝）。&lt;/p&gt;&lt;p&gt;在 google，她说早期的那批人疯狂到什么程度 —— Jeff Dean，对，就是那个大名鼎鼎的 Jeff Dean（https://research.google.com/pubs/jeff.html），随便一项成就，拿出来给你我都可以讲一辈子的 Jeff Dean，每天晚上六七点回家，和家人一起晚餐，九点前哄完孩子睡觉后冲回办公室，一干就又干到凌晨12点、1点。&lt;/p&gt;&lt;p&gt;星爷说，人要是没有梦想，那和咸鱼有什么区别？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;哪些事是我们成年后不敢做的？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;孩子们都是梦想家，她们每天都在造梦。给她们一支笔，她们能描绘出一个五彩斑斓的宇宙；给她们一抔土，她们能创造出一个天马行空的世界。我们这些当爹娘的，常常自叹弗如，生怕自己的猪脑子追不上，甚至限制了她们的想象力。&lt;/p&gt;&lt;p&gt;公司也是一样。一家新兴的公司，如同一个满怀好奇心的孩子，其思想不该被市场上成熟的公司禁锢。她说，George（当时负责工程团队）经常跟她们说：你们要常常思考 —— &lt;b&gt;what we can’t do / imagine when we go big？&lt;/b&gt; 这样的事情是我们应该放手做的。&lt;/p&gt;&lt;p&gt;她举了个例子。早年 google 的服务并不稳定，算法也经常调整，因而在爬虫索引网页的时候，会把整个页面都缓存起来，以便服务崩溃后，或者日后重新索引之用，这样可以节省不菲的带宽费用。这事如果搁在其它成型的搜索引擎公司，大家第一反应会是：internet 上有成百上千亿页面，把原始内容都存下来，脑子被驴踢了？大哥，我们是搜索引擎，做好 indexing，能在用户搜索的时候找到对应的内容就够了！第二反应是：这样存储成本就无边无际，知道啥是 TCO 么？d总之这样的事情不会发生，也无法发生在大公司。&lt;/p&gt;&lt;p&gt;还好，有想象力的，孩子般天真的 google，没顾虑那么多，撸起袖子干了再说，逢山开路遇水搭桥。存储太贵，用不起昂贵的 IOE（IBM 服务器，Oracle 数据库，EMC 存储网络），那就用普通的 commodity hardware - 和你我家用的 PC 并无太大差别。我们知道硬盘是 PC 最薄弱的环节，MTBF 一般就是数十万小时。如果按 100 万小时算（大概 115 年），那年均故障率是 0.8%，也就是平均一千个硬盘会有八个出故障。因而 google 不得不为此要开发合适的算法保证在此场景下存储数据的 availability。使用 commodity hardware 是目前互联网界的共识，但那个时候，没人敢这么做。&lt;/p&gt;&lt;p&gt;就这样 google 以很小的代价缓存了整个互联网，做到了其它搜索引擎没能做到的事情。干这事有什么好处呢？梅姐说，作为搜索引擎，在搜索结果中，会包含标题和一段概要内容。其它搜索引擎因为丢弃了原有的页面，这段概要要么来自页面的 meta 信息，要么是内容的第一段的一部分 —— 而这未必是最好的，甚至可能都不包含搜索的关键词。google 缓存了原始页面，于是便可以从容根据搜索词从页面中挑选合适的句子，甚至，自己组织合适的内容来提供这个概要信息。这一下子搜索结果的被点击的概率大大提高，因为人们看到的是更加相关的概要。由于有了原始内容，google 还可以做很多 A/B testing，事后分析，调整算法等等，而不是依赖爬虫爬取得那一瞬间产生的结果。等 yahoo 们醒悟过来自己也应该这么做的时候，已经太晚，而且它们的整个基础架构都要推倒重来才能适应这一变动。&lt;/p&gt;&lt;p&gt;google 早期的其它产品，如 gmail，why not an “unlimited” inbox？也是这一思想的产物。梅姐说，我们坚信摩尔定律，所以我们大胆地做了这个尝试：gmail 被口口相传，每个人都等待着自己有幸被邀请，而一般的用户头一两年用不了多少存储，等累积的数据多起来时，每 GB 存储的价格早已掉了个量级。所以你看，当观念转变，想别人不敢想之事时，思路就开阔许多，做事的路子陡然不同，进而成本结构也完全不一样。当 4M 以下免费，4M 以上收费的 yahoo 邮箱发现用户像潮水般涌入 gmail，急忙跟进时，却发现，自己用的 IOE 体系，成本结构根本无法竞争，这就尴尬了：是硬着头皮流血跟进，还是壮士断腕，重建系统？&lt;/p&gt;&lt;p&gt;这样我想起了《创新者的窘境》。成熟的公司背后有成熟的定价体系和毛利率。当创新者用 5% 的毛利率去打习惯 50% 毛利率的领导者时，其惯有的价值链都会受到冲击：自己的成本结构怎么办（要不要去 IOE？），跟华尔街怎么交代（要不要降低利润率？），上下游的合作伙伴要不要维系，已有的付费用户或者客户怎么安抚等等。伤不起。&lt;/p&gt;&lt;p&gt;所以成人的世界里，到处都是顾虑，到处都要交代，要在站着和跪着间妥协，很多事情不敢做，甚至不敢想。George 让大家保持孩子的初心，去异想天开，打破条条框框，去做看上去不可能完成的事情。gmail，google map，google photos 都是这样一脉相承。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;轶事一则&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;伦敦眼。大概是 99 年的时候，Sergey 带着团队到伦敦玩。大家在伦敦眼下面排队等着待会能够一览伦敦的风光，Sergey 一个人在默默的数伦敦眼的客流。过了一会，他说：我算了一下，像这样一个 stupid 的生意，一年能赚八千万，我们一年也才赚八千万 —— 我们真 TMD 应该要比这做得好得多得多才对。&lt;/p&gt;&lt;p&gt;2016年，google 一天的收入，按照 Sergey 当年计算的结果，顶伦敦眼三年。&lt;/p&gt;&lt;p&gt;Wisdom excels。&lt;/p&gt;&lt;p&gt;以上。&lt;/p&gt;&lt;p&gt;继续给自己打广告。下周回国出差，做两个知乎 live：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/lives/916316021869121536&quot;&gt;回归本源：软件开发中那些基本的概念&lt;/a&gt;（12/06 晚 7pm）&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/lives/916315562223755264&quot;&gt;谈谈工程师常常忽视的软件开发能力&lt;/a&gt;（12/13 晚 7pm）&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2017-11-30-31580165</guid>
<pubDate>Thu, 30 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>2017就要结束了，再学点什么呢？</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2017-11-28-31502476.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31502476&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-75fefc118238f5ffe281c9c8d2f9bf5a_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;下周回京，打算做两场知乎 live。感兴趣的同学可以关注一下。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;回归本源，软件开发中的那些基本概念&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;似乎自小学毕业以后，我们在数学课以外，就很少关注概念（concept）。概念是一切认知的基石 —— 很多时候，我们因为对概念的理解不清不楚，而无法抓住本质。软件开发中有很多你以为你理解了实际上你没有理解的概念，而我们在开发的路上走得太远，需要时不时回过头来重新梳理一下这些最基本的概念。柳总说：撒一层土，夯实，再撒一层。这是任何学习或者求知必经之路。&lt;/p&gt;&lt;p&gt;本次 live，我将抛砖引玉，从软件开发中最基本的四个概念：变量，值，函数，接口讲起，谈谈我们该如何理解这些概念，以及概念后面的编程思想。&lt;/p&gt;&lt;p&gt;大纲如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;什么是变量（variable）？为什么说变量是一个 indirection / separation？&lt;/li&gt;&lt;li&gt;如何给变量取合适的名字？&lt;/li&gt;&lt;li&gt;什么是变量的值（value）？变量所蕴含的信息，该用什么样的容器来承载？&lt;/li&gt;&lt;li&gt;什么是函数（function）？pure / impure function 如何区分？如何将其应用在系统设计中？&lt;/li&gt;&lt;li&gt;什么是接口（interface）？如何设计简单清晰的接口？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本 live 讲述部分约 60 - 75 分钟，答疑会有 30 分钟。&lt;/p&gt;&lt;p&gt;开讲时间：12月6日晚 7:00。&lt;/p&gt;&lt;p&gt;传送门：&lt;a href=&quot;https://www.zhihu.com/lives/916316021869121536&quot;&gt;回归本源：软件开发中那些基本的概念&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;谈谈工程师常常忽视的软件开发能力&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;两周前我发了个招聘贴，讲到我们的广告系统用 scala 撰写。后台于是一下子涌来好多留言：啊啊啊你们为什么要用scala 开发广告系统？为什么不用 erlang？为什么不用 C++？scala 合适吗？编译那么慢？效率也不高？akka 还是偷师的 erlang/OTP？…&lt;/p&gt;&lt;p&gt;根据我过往的经验，我发现很多有趣的点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;程序员容易陷入无所谓的对语言本身的争执上去&lt;/li&gt;&lt;li&gt;两三年工作经验的工程师往往会遇到一个瓶颈 - 过于关注于某个语言和某种技术本身而忽视了系统层面的修为&lt;/li&gt;&lt;li&gt;软件开发是一个系统性的工程，语言占比有多大？你写的代码的占比有多大？&lt;/li&gt;&lt;li&gt;软件是为什么服务？business！你又了解多少和 business 有关的知识呢？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因而，我觉得有必要做一个 live，谈谈工程师常常忽视的软件开发能力。&lt;/p&gt;&lt;p&gt;我常常使用软件系统来描述软件，是因为解决商业问题的逻辑仅仅占据软件开发的一部分。日志，监控，安全，部署，性能，数据分析等一系列由开源软件或第三方工具构建的服务，加上商业逻辑的服务一起，运行在生产环境中，才是真正的软件。工程师提升代码的能力，仅仅是整个 big picture 中的一环。&lt;/p&gt;&lt;p&gt;此外，赚钱，在这个 picture 的诸多能力中，越靠近钱，或者越能够影响钱的能力，对公司的价值就越大。&lt;/p&gt;&lt;p&gt;所以，工程师除了要提升开发的能力外，还应该着力构建业务能力和系统能力。&lt;/p&gt;&lt;p&gt;我们先从软件系统的演进谈起，谈谈软件系统中的重要组成部分，然后聊聊工程师如何打造系统能力：它们和具体的功能无关 —— 如何使用各种工具和资源，建立一套体系，让软件能够正常运行和演进。这包括综合的软件开发和系统架构的能力，收集数据的能力，以及分析数据的能力，快速应对问题，进行决策和解决问题的能力，以及万金油 —— 什么都「略懂」的能力。&lt;/p&gt;&lt;p&gt;然后，谈谈商业知识和业务知识业务的业务获取，比如说，你需要了解你的公司公司如何赚钱？如何获取用户？每个用户身上花费多少（UAC），能够赚多少钱（LTV）？ —— 这些知识，能够帮助你更好地撰写出有价值的软件，能够让你在价值链上越走越高。由于公司和公司的业务不同，在这里，我提出一些基础的概念，然后不断提出问题，不断引发你的思考，从而激发你问出更多的问题，并主动去寻找这些问题的答案，或者找到更好地解决方法。很多时候，问对问题，比寻找答案还要重要。&lt;/p&gt;&lt;p&gt;本 live 讲述部分约 60 - 75 分钟，答疑会有 30 分钟。&lt;/p&gt;&lt;p&gt;大纲如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;什么是软件系统？什么样的能力有助于构建软件系统？&lt;/li&gt;&lt;li&gt;什么是系统能力？如何累积系统知识和经验？&lt;/li&gt;&lt;li&gt;什么是业务知识？如何累积业务知识？&lt;/li&gt;&lt;li&gt;总结：工程师如何提升个人在公司的价值？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;开讲时间：12月13日晚 7:00&lt;/p&gt;&lt;p&gt;传送门：&lt;a href=&quot;https://www.zhihu.com/lives/916315562223755264&quot;&gt;谈谈工程师常常忽视的软件开发能力&lt;/a&gt;&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2017-11-28-31502476</guid>
<pubDate>Tue, 28 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>Tubi TV 继续招贤纳士，你不试一下么？</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2017-11-22-31276566.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31276566&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e02b2ad0c9704d86127de8a9fb99cee4_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;一年多了。&lt;/p&gt;&lt;p&gt;自从去年八月份我受命组建 Tubi TV 的中国团队以来，时光已经飞快地过去了一年多，我们的团队从零到一，然后从一到九。目前已涵盖客户端（web / android），后端（nodejs / elixir / scala）和数据（machine learning / data pipeline）三大方向。和多数外企不同的是，我们的中国团队并非旧金山总部的补充，也并非一个专门处理本地化需求的团队。从建立伊始，我们的目标就是打造一支具有国际化视野的，能力一流，和总部研发团队平起平坐的团队。一年多的磨砺后，这支队伍已然成为 Tubi TV 的核心力量，为千万级用户的观影体验保驾护航。如今，我们还在不断壮大，求贤若渴。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为何你应该考虑一下 Tubi TV？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我们是北美最大的 Free TV 提供者。和 Netflix / Hulu 这样付费的流媒体服务不同的是，我们为用户提供免费的高质量电影电视剧，通过广告获取收益，让我们的用户，内容提供商和广告主三赢。&lt;/p&gt;&lt;p&gt;如果你读过吴军博士的《浪潮之巅》，会大概觉得，这是一种印钞机模式的商业。的确如此。我们已经趟过了最艰难的湍流，跟好莱坞（内容提供商），纽约（广告主）形成了良好的合作关系，每天只要有用户观看 Tubi TV 的视频，收入就会滚滚而来。于是工程师的主要工作为：如何找到 product / market fit？如何让 Tubi TV 变得更好？&lt;/p&gt;&lt;p&gt;比如说（这些仅仅是我想到的一些问题，和我们在做的产品也许无关）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们如何构建一个满足于未来数年数十倍增长的广告系统和 API 系统？&lt;/li&gt;&lt;li&gt;我们如何保证高并发下服务的稳定性，性能和服务质量？&lt;/li&gt;&lt;li&gt;我们如何高效处理视频，让各个平台的用户能够获取性价比最高的视频流？&lt;/li&gt;&lt;li&gt;我们如何打造如丝般顺滑的用户体验，让用户享受整个观影的过程？&lt;/li&gt;&lt;li&gt;我们如何为用户推荐她感兴趣的电影？&lt;/li&gt;&lt;li&gt;我们如何更好地发现广告点，并且为它们的价值分级？&lt;/li&gt;&lt;li&gt;如何把 Tubi TV 在北美的成功，&lt;b&gt;复制&lt;/b&gt; 到全世界？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 Tubi TV 仅仅是一个处于 C 轮的创业公司（上一轮融资：2000w 美元），团队只有有七十多人（研发将近三十人），小而美，非常扁平，每个人都有机会做出杰出的贡献，打造自己的影响力。如果你读过我之前的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827713&amp;amp;idx=2&amp;amp;sn=d744af9c02ebac9bfb1fd2114c5cc6a5&amp;amp;chksm=8704ab9db073228bb3403f8b750e0d25946130c053bf09f5ff1569c91e23a1312f02bc502e78&amp;amp;scene=21#wechat_redirect&quot;&gt;如何选择工作？&lt;/a&gt;那么，为像 Tubi TV 这样规模的公司工作，收益风险比非常舒服。&lt;/p&gt;&lt;p&gt;聊完了公司，我们聊聊中国团队。&lt;/p&gt;&lt;p&gt;对于中国团队的员工，我们提供合理的，有竞争力的薪酬和股票期权，公司足额缴纳五险一金，工资社保和基础福利和微软 Juniper 等大型上市公司一样走 FESCO。除此之外，Tubi TV 中国的工程师还有一些额外的隐性福利：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每年至少一次到旧金山出差的机会（出差期间，丰富多彩的业余生活 —— 比如说：住大 house，打手枪真，napa 品酒，一号公路观海听涛，看 NBA 比赛，泡美式酒吧）&lt;/li&gt;&lt;li&gt;潜在的拿 L1 工作签证肉身翻墙的机会（我们正在为一位员工办理中）&lt;/li&gt;&lt;li&gt;非常弹性的工作时间，非常人性的 WFH 制度，充沛的年假和病假，告别和家人朋友日日思君不见君的无情日子&lt;/li&gt;&lt;li&gt;不断学习的机会：因工作需要的各种培训（比如 English，tech，leadership），技术会议，图书等，公司全额报销&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;办公地点在望京索尼大厦18层（WeWork 望京店），地铁公交非常方便。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9d9240226829e4770a268678a95f0059_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;483&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-16b6b79526a4606053f710595e765e67_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;808&quot;&gt;&lt;p&gt;（办公环境舒服惬意）&lt;/p&gt;&lt;p&gt;再放几张照片，看看刚刚过去的 10 月，中国团队在旧金山如何体验湾区的生活：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f0c4f8689b5db3d58128a17ce07883e9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1200&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-527b76a6da409804457845b723ef0d35_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1200&quot;&gt;&lt;p&gt;（住大 house）&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e02b2ad0c9704d86127de8a9fb99cee4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1066&quot;&gt;&lt;p&gt;（看金门大桥）&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3381c0a8ed547983273681102ab9cf05_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1200&quot;&gt;&lt;p&gt;（一号公路浪）&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4411f22270d85ab3e9f3a562a9d8017d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1066&quot;&gt;&lt;p&gt;（打枪）&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-69bb0112eb8a73b923e3a3335db53f51_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1066&quot;&gt;&lt;p&gt;（为勇士队摇旗呐喊）&lt;/p&gt;&lt;h2&gt;&lt;b&gt;工作机会&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;资深算法工程师（2人）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;要求：熟练掌握 python/scala，熟悉 spark / MLib。对 NLP 及 deep learning 有深入的了解。两年以上 machine learning 相关的项目经验。对 experiment，A/B testing，multivariate testing 有相关的项目经验者优先。&lt;/p&gt;&lt;p&gt;具体工作：帮助我们将现有的 A/B testing framework / recommendation engine 及 data pipeline 提升到一个新的水平。通过数据分析和学习，帮我们制定更加合理的内容获取 / 用户获取 / 广告播放的策略。&lt;/p&gt;&lt;p&gt;我们有海量的数据待发掘。数据业务在 Tubi TV 才刚刚起步，未来有着无穷的潜力和空间。在 Tubi TV，engineering 是整个公司的核心，而 data 是 engineering 的核心 —— 这是公司上上下下的共识。通过对数据的深度学习和分析，你很有可能影响到公司的核心决策。&lt;/p&gt;&lt;p&gt;&lt;b&gt;资深前端工程师（2人）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;要求：熟练掌握 react / redux，热爱前端技术，能够独自完成某款产品的开发。&lt;/p&gt;&lt;p&gt;具体工作：负责 web app 及 Fire TV，Sony TV，Samsung TV，Play Station 等超过十款 OTT 产品的 app（感谢我们强大的 BD 团队，新的平台还在不断添加中），同时也承担内部的核心的内容管理系统的开发。&lt;/p&gt;&lt;p&gt;在 Tubi TV，客户端工程师是工程师中离钱最近的那个。你的每一行代码，每一次部署都直接影响着我们的核心指标：日活 / 月活 / 留存 / 用户观看时长等等。你可以监控你所负责的平台的实时收入，为你和你的团队的工作带来的增长而喜悦。在你贡献的同时，你将会学到很多有关视频产品的知识和技能（尤其是如何处理广告）。此外，web team 定期会有 round table 来分享很多有意思的知识，比如说 webpack，inferno，preact，性能调优等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;资深后端工程师（1人，scala / adTech 方向）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;要求：熟练掌握 scala / akka，对广告系统有深入的了解（最好做过相关的系统，如：exchange，RTB）。&lt;/p&gt;&lt;p&gt;具体工作：用 scala / akka 构建 Tubi TV 的下一代广告系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;算法工程师实习生（1人）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;要求：熟悉 python / scala，熟悉 spark，对 machine learning 相关算法有深入了解。实习期能保证在半年以上。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;谢谢大家！期待您的简历。简历直通车：jobs.china at tubi.tv。&lt;/p&gt;&lt;p&gt;PS：对我们北美职位感兴趣的，请移步：http://tubitv.com/static/careers。&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2017-11-22-31276566</guid>
<pubDate>Wed, 22 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>在提高代码能力这事上，没有银弹</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2017-11-20-31209277.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31209277&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3fc8ad547386910b1ca55eac6f0f1f7b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下。 - 《道德经》&lt;/blockquote&gt;&lt;p&gt;转眼间女儿到了学琴的年龄。我对乐器，纯是叶公好龙，家里摆着钢琴，小提琴，手风琴，自己却连五线谱也不识，所以无法督促丫头练习，于是这重担落在了老婆身上。老婆是个虎妈，严厉起来毫不含糊，说练不完琴不许吃饭，就不许吃饭，丫头撒泼打滚，哭天抢地，姥姥红着眼圈在旁劝阻都无济于事。这种时刻，我自然是于心不忍，明面里却必须和老婆保持高度一致，所以只能默默地滚到一边，安安静静扮个风轻云淡的土肥圆 —— 心里还是会忐忑：这么搞法，不会把娃儿的兴趣折腾没了吧？&lt;/p&gt;&lt;p&gt;然而我的担心是多余的。丫头周六学琴，往往周六和周日最苦，哭嚎也是这两天最甚。这是因为学了新的曲子，她还不熟，经常弹错，弹错就要重弹，老师布置的作业要弹很久很久才能过关。到了周二周三，她渐渐熟络了，指下生风，哭嚎声越来越少，周四周五就游刃有余了，多数情况都能开开心心地弹完。因为妈妈的严厉，她起初吃了不少苦头，但渐渐苦尽甘来，尝到了那种「直挂云帆济沧海」的爽快。在最痛苦的时候，她大哭着叫唤「妈妈我再也不想弹老师布置的作业了」，可在一月一度的「家庭演奏会」上，她还是会喜滋滋地，满满成就感地向远在国内的亲人们展现她的能耐。&lt;/p&gt;&lt;p&gt;好多同学在后台问我，代码的能力怎么练就。其实是一样的理儿。&lt;b&gt;多练，多读，多写。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;软件开发的教育作为一门非常年轻的学问，仅仅走过了几十年，和钢琴教育数百年的历史相比，是沧海一粟。钢琴有成熟的培训和认证体系，软件至今还是撞大运。其实想想钢琴和软件有很多相通之处：学钢琴需要先学习一门指法，和一门语言（五线谱）；学代码也需要先学习一门指法，和一门语言（比如 python）。钢琴的 hello world 是 「哆来咪发咪到来」，软件的 hello world 是，额，hello world。练好了钢琴的基本功，你可以按照某些需求，创作出曲子来；练好了代码的基本功，你也可以照着需求，写出合适的代码来。&lt;/p&gt;&lt;p&gt;可是写代码并不需要像练钢琴那样，讲究把基本功练得谙熟，各种知名的不知名的曲谱练过一圈，一级一级打怪升级，直到所谓的钢琴十级才算出师；往往一门语言或者一个框架，了解了如何使用基本的结构，程序员们就按捺不住，开始上手了。函数不会用，有 google 哩，代码不会写，找 stackoverflow！于是对代码所服务的对象而言，写代码成了一项高风险的活动：我们极其依赖代码的作者碰巧是个能力不错的人，她能在一边完成高质量创作的同时，还可以夯实自己的基本功。&lt;/p&gt;&lt;p&gt;比如说一个简单的任务：遍历一个 list，解析出里面的 tuple，然后将其插入到 priority queue 中排序。&lt;/p&gt;&lt;p&gt;一个有多年经验的软件工程师的做法是（假设用 python 实现）：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;大致想想就开始撸袖子写代码；&lt;/li&gt;&lt;li&gt;囧，不大记得 map 的用法了，究竟第一个参数是 function 还是 iterator，让我先在 ipython 里试试 —— oh，原来第一个参数是 function，看我这记性；&lt;/li&gt;&lt;li&gt;tuple 用得少，如何取 tuple 里面第二个元素，这我得 google 一下 —— ah，原来可以 destructure，赞！（顺便鄙视一下 php）&lt;/li&gt;&lt;li&gt;python 有 priority queue 的支持么？我没用过嗳，没事，祭出 stackoverflow —— python 真心棒，连这个都有现成的 heapq，stackoverflow 这段代码正好是我要的，才五六行而已，直接 copy &amp;amp; paste。一下子就写完了，yeah！（顺便鄙视一下 php）&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;憋笑，我敢打赌这是不下半数工程师的日常。事实上，这个例子并不是我瞎编的，而是我在过去一年的面试中，大多数所谓「资深软件工程师」在面试中的表现：在很多基础的函数上卡壳，不得不 google。这并不算太糟糕，我见过从第一行代码一路 stackoverflow 到最后一行的。&lt;/p&gt;&lt;p&gt;我不知道文字行业是怎么面试的，如果一个面试者现场写段文字还要查字典，翻《古诗词大全》，能过关么？&lt;/p&gt;&lt;p&gt;我们究竟该怎样正确地写代码？&lt;/p&gt;&lt;p&gt;在「创作」新的代码之前，我们就应该已经对如何写代码了如指掌 —— 语言的基础知识，经常使用的类库都不该成为障碍。整个撰写代码的过程是流式的，就像作曲一样，思维飘到哪，手指就落在哪，一气呵成。当然，这有赖于平日里刻意的练习：不知道如何使用 map？OK，分别给定一个 list，dict，tuple，用 lambda 和不用 lambda 将 map / filter / reduce 各处理一遍。&lt;/p&gt;&lt;p&gt;听着很熟悉，是不？小宝的钢琴作业老师就是这么布置的：左手哆咪骚哆咪骚练十遍。这「哆咪骚」就像咱们的 map 函数一样，是基本功。&lt;/p&gt;&lt;p&gt;那位说了，这么做成材期长，成百上千的类库，永无止境的版本升级，每个都练十遍咱程序员伤不起，不现实。&lt;/p&gt;&lt;p&gt;你看，程序员就这么傲娇，三个月培训一下就能拿相对的高薪（硅谷的现实），还要让我做这枯燥的练习，凭什么？&lt;/p&gt;&lt;p&gt;那么我们折中一下，当我们撰写上述的代码时，起码把忘记了怎么使用的函数在 REPL 里好好练习一下；再把从 stackoverflow copy &amp;amp; paste 的代码自个写一遍，里面涉及的类库，函数，在 REPL 里多多练习练习，以至于下次再遇到同样的需求，不至于还要网上寻找答案，这不过分吧？&lt;/p&gt;&lt;p&gt;愿意这么做的依然是少数。&lt;/p&gt;&lt;p&gt;经常跑马拉松的人往往以赛促练。能够以赛促练的人，首先得有大量的训练基础，才能承受一轮又一轮相对密集的比赛。有了这个基础后，比赛进一步将自己的身体调节到合适的节奏，夯实心肺，锤炼肌肉，同样起到了练兵的效果。如果拿跑马拉松类比，我们在日常工作中做的每一个大 feature，都可称得上一次比赛，如果平时不好好积淀，这时而过就显现了：别人一个 sprint 高质量完成的东西，你两三轮 sprint 还做得磕磕绊绊，代码活脱脱是 stackoverflow 的剪辑册。&lt;/p&gt;&lt;p&gt;从直观的感觉来说，软件开发应该比跑马拉松更容易以赛促练，甚至，以赛代练 —— 你做的每一个 feature，都能帮助你夯实你的技能。当然，这个前提是你每周都有大量的代码量来兜底。写的代码多了，总会重复使用一些重要的函数和类库，于是，正确使用它们的能力得到了强化。可惜，对很多很多的软件工程师来说，这是个伪命题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;你一周其实真实代码量并不大。你的大部分时间被消耗在了维护一个大型系统上，平均一周写不了两三百行代码（注意不是 diff）。别忙质疑这个数字 —— 我在 Tubi TV 两年，从零到一做了三四个系统，node 和 elixir 合并在一起，满打满算也就是四万行代码，两年一百周，平均每周撑死了四百行代码。&lt;/li&gt;&lt;li&gt;即便你代码量不小，如果你负责的 scope 很小的话，写多了也是重复劳动 —— 就像练字，别人是一千个字每个练五十遍，你是一百个字每个字练五百遍，同样是五万的量，下的功夫一样，效果却大相径庭：别人亡口月贝凡已经练得谙熟，你还在比划个十百千万。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在提高代码能力这事上，没有银弹，有的只是像钢琴训练那样的 deliberate practicing。没有 practicing，你会败在 1) 上；practicing 够了，但不够 deliberate，你会败在 2) 上。&lt;/p&gt;&lt;p&gt;所以还是那句话，多练，多读，多写，撒一层土，夯实，再撒一层。工作给不了你的，台上没工夫练的，你要在业余时间，在台下，把它找补回来。这才是代码能力提升的奥义。&lt;/p&gt;&lt;p&gt;谢谢欣赏。&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2017-11-20-31209277</guid>
<pubDate>Mon, 20 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>Bash 的威力</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2017-11-20-31209138.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31209138&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-51dbdae3dcef0e81be5f28acea22c385_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;引子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;工作中，我们常常要处理浩瀚如烟的日志。有时候，看日志是为了处理软件中的 bug，更多的时候，是为了从中获取有用的信息 —— 这信息可以用来做 behavior analysis，可以用来做 anomaly detection，甚至也可以做 data recovery。&lt;/p&gt;&lt;p&gt;这个周末两天，家里的活动不少，有一搭没一搭的，在做一个 log parser。这 log parser 说难不难，就是解析几十G 日志文件，从中抓取一些特定的数据，存在数据库中。日志的格式很固定，是标准的 tsv，单条记录解析起来非常容易；说简单也不简单，上百个文件都以 gzip 形式存储在 AWS S3 上，想要高效地处理并不容易。&lt;/p&gt;&lt;p&gt;最直观的方案是写一个 spark job 去处理。在 spark 的生态圈里，处理大量 gzip 文件非常简便，几十行代码就能搞定。如果没有立等可用的 spark cluster 呢？总不能为了这样一个任务去配置一个 spark cluster 吧。这个方案我们且放下不表。&lt;/p&gt;&lt;p&gt;第二个方案是选用对 streaming 支持良好的语言来处理。S3 本身对 stream 支持很好，每个文件都可以一个 chunk 一个 chunk 地去读取，读下来的 chunk，再交给支持 stream 模式的 gzip module 解压，然后对解压后的数据的每一行，进行 tsv 的解析，写入数据库。这个方案听起来简单，实际操作起来小问题不少，尤其 gzip 解压这块，如果一个 chunk 解压后的结果跨行，处理起来还是颇为头疼的。&lt;/p&gt;&lt;p&gt;第三个方案是一次性 &lt;code class=&quot;inline&quot;&gt;aws s3 sync&lt;/code&gt; 把要处理的文件拷贝到本地，然后挨个 gunzip 解压，最后再一行行做 tsv 的解析，把结果写入数据库。&lt;/p&gt;&lt;p&gt;方案二的问题是代码复杂，方案三虽然代码简单，但可操作性很差，占用的磁盘空间太多不说，文件的来回读写还会大大延缓整个处理过程。&lt;/p&gt;&lt;p&gt;有没有办法结合方案二和方案三的优点？&lt;/p&gt;&lt;p&gt;有！我们只需要几行 bash，再加上几十行代码写的 line parser 即可。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;使用 bash 和 pipe&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;bash 代码如下：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;#!/bin/bash
BUCKET=tubitv-awesome-logs
PREFIX=${1:-20171111}
trap ctrl_c INT
function ctrl_c() {
 echo &quot;** User stopped the process with CTRL-C&quot;
 exit $?
}
for key in `aws s3api list-objects --bucket $BUCKET --prefix $PREFIX | jq -r &#39;.Contents[].Key&#39;`
do
 sleep 1
 aws s3 cp s3://$BUCKET/$key - | gunzip -c | log_parser
done&lt;/code&gt;&lt;p&gt;这个 bash 脚本接受一个参数，是 S3 object 的 prefix（文件路径），如果不传，就用默认值。然后，我们用 &lt;code class=&quot;inline&quot;&gt;aws s3api list-objects --bucket $BUCKET --prefix $PREFIX&lt;/code&gt; 这个 CLI 获取 bucket 下所有含有 prefix 的 object。s3api 返回 JSON 格式的数据，我们可以用 jq 对其解析，获取每个 object 的 Key，也就是文件名。注意这里我们用了 pipe，aws CLI 的结果被 pipe 给了 jq。&lt;/p&gt;&lt;p&gt;稍微补充一下 pipe 的概念。在 unix 中，程序的输出如果没有特别指定，会输出到一块叫 stdout 的内存中。pipe 操作会将上一个程序的 stdout 的数据放入下一个程序的 stdin。&lt;/p&gt;&lt;p&gt;对于拿到的每个 key，我们循环处理，怎么处理呢？&lt;/p&gt;&lt;ol&gt;&lt;li&gt;首先 &lt;code class=&quot;inline&quot;&gt;aws s3 cp s3://$BUCKET/$key -&lt;/code&gt;。对于相关的文件，我们将其 cp 到 stdout。“-” 在这里指代 stdout。&lt;/li&gt;&lt;li&gt;接下来，我们将拷贝下来的每个 chunk，pipe 给 &lt;code class=&quot;inline&quot;&gt;gunzip -c&lt;/code&gt;。gunzip 处理 stdin 里的数据，解压到 stdout —— 这里 &lt;code class=&quot;inline&quot;&gt;-c&lt;/code&gt; 告诉 gunzip 的输出是 stdout。&lt;/li&gt;&lt;li&gt;最后，我们把 gunzip 的结果进一步 pipe 给我们自己撰写的 &lt;code class=&quot;inline&quot;&gt;log_parser&lt;/code&gt;。我们只需要妥善处理 log_parser，使其从 stdin &lt;b&gt;按行&lt;/b&gt; 读取数据即可。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;log_parser 可以用任意语言撰写，由于其问题规模被 bash script 大大缩减，所以写起来非常简单，这里放一个 elixir 的例子（具体 tsv 解析放下不表）：&lt;/p&gt;&lt;code lang=&quot;elixir&quot;&gt;defp parse do
 case IO.read(:stdio, :line) do
   :eof -&amp;gt; :ok

    {:error, reason} -&amp;gt; IO.puts &quot;Error: #{reason}&quot;
    line -&amp;gt;
     try do
      line
       |&amp;gt; parse_line()
       |&amp;gt; process()
     rescue
       e -&amp;gt; IO.puts(&quot;Cannot parse: #{line}. error: #{inspect e}&quot;)
     end
parse()
 end
end&lt;/code&gt;&lt;p&gt;这段代码从 stdin 里面读入一行，如果读到 EOF，就结束，否则，会读到一行数据。我们对这行数据进行处理即可。&lt;/p&gt;&lt;p&gt;漂亮不？这就是 unix 的美妙之处，当你 do one thing and do it well 时，整个生态系统会回馈你。&lt;/p&gt;&lt;p&gt;简单不？够简单，但是，我们回头再看看之前的 bash script，当你的机器上有 16 个 core，我们却只能打满一个 core 去处理数据，我们的内心深处还是对这种简单感到不满。能不能让数据并发处理？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;使用 xargs 让任务并行处理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;没问题。我们不需要修改 log_parser，只需对 bash script 稍加调整：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;#!/bin/bash
BUCKET=tubitv-awesome-logs
PREFIX=${1:-20171111}
aws s3api list-objects --bucket $BUCKET --prefix $PREFIX | jq -r &#39;.Contents[].Key&#39; | xargs -n1 -P8 -I{} ./process_one.sh {}&lt;/code&gt;&lt;p&gt;之前的 bash script 主体部分不变，只不过我们使用 &lt;code class=&quot;inline&quot;&gt;xargs -P8&lt;/code&gt; 来将若干个参数分别传递给一个新的脚本 process_one.sh 并行处理，并行的数量为 8。当然你可以将其换成 &lt;code class=&quot;inline&quot;&gt;sysctl -n hw.ncpu&lt;/code&gt; (osx) 或者 &lt;code class=&quot;inline&quot;&gt;nproc --all&lt;/code&gt; (linux) 使用具体的 core 数目。&lt;/p&gt;&lt;p&gt;process_one.sh 很简单：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;#!/bin/bash
BUCKET=tubitv-awesome-logs
KEY=$1
aws s3 cp s3://$BUCKET/$KEY - | gunzip -c | edgecast_parser&lt;/code&gt;&lt;p&gt;这样简单处理之后，CPU 利用率一下子上来了：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-69533f5093c33e4bd9fbf2f4bec76f5a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2872&quot; data-rawheight=&quot;350&quot;&gt;&lt;p&gt;到目前为止，我写了 65 行 elixir 代码处理 tsv，18 行 bash 脚本粘合一切，并在单机并发。很好很强大。如果全部用 elixir 撰写，实现相同的功能，相同的能力，估计要几百行代码。事实上，周末我因为忘记了 databricks 的打开方式，没法用 spark，只得捣鼓方案二，费了好大的功夫，额外引入了三四个库，甚至修改了一个库（elixir 没有封装地不错的支持 stream 的 gunzip 的库），代码还只是个半成品。今天突然开窍，使用 bash offload 不必要的工作，仅花了一个小时（包括写 test case），就搞定了上述的方案，且干净漂亮。&lt;/p&gt;&lt;p&gt;有同学说，这样单机并发，还是有处理上的瓶颈 —— 其实如果问题真到了这一步，最好还是用 spark 解决。当然，用 erlang cluster 也是个不错的替代方案。可以在一个集群下让各个 elixir process 形成一个 cluster，然后其中一个 node 把每个 node 处理的 bucket 和 prefix 发布出去，然后各自执行上述的 bash script。当集群的机器数量是几十这个量级，这个方案也算一个备选。&lt;/p&gt;&lt;p&gt;读完本文，你也许会对我的这几篇历史文章感兴趣：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=201581168&amp;amp;idx=1&amp;amp;sn=14875653e6e880b4952346209b87abfb&amp;amp;scene=21#wechat_redirect&quot;&gt;浅谈unix之美&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827354&amp;amp;idx=1&amp;amp;sn=50c6366bdb4047d62c84d7a910307591&amp;amp;scene=21#wechat_redirect&quot;&gt;Pipe 之美&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827448&amp;amp;idx=1&amp;amp;sn=b952fd52ebb08ce627b296d93cad799b&amp;amp;scene=21#wechat_redirect&quot;&gt;从 Pipe 到 Flow&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2017-11-20-31209138</guid>
<pubDate>Mon, 20 Nov 2017 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
