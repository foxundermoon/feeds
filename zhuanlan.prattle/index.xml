<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>迷思</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/</link>
<description>我的博客及微信公众号里的精华内容都会放在这里。</description>
<language>zh-cn</language>
<lastBuildDate>Tue, 03 Apr 2018 14:19:18 +0800</lastBuildDate>
<item>
<title>2018年3月过去了，我收获到什么？</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-04-03-35250058.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35250058&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2dbaec8466840297879da6b6a5721216_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;最大的收获自然是我和 Joe 老爷子访谈，它是无价的。我前些日子已经放了篇文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827948&amp;amp;idx=1&amp;amp;sn=d4ded0f9cf84328546eb1f31ef5064ff&amp;amp;chksm=8704a870b0732166d04ce8ef9ee73ee63c32619ae31678dceec0205d811b824a18bea513d64a&amp;amp;scene=21#wechat_redirect&quot;&gt;Joe Armstrong 面对面&lt;/a&gt;。没看过的同学可以点进去看看。我希望我六十岁时，也能像老爷子一样，睿智，洞悉世事，和我聊天的人都有这样的感觉 —— 就跟 Frodo 憧憬未来时夸赞 Sam 那样：Tyr the thinker。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Code Beam 演讲&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这次 Code Beam，我做了一个三十多分钟的演讲：Release, Deploy, Upgrade, Monitor Elixir Services in Real World。题目长到没朋友。Slides 可以去我的 github：&lt;a href=&quot;https://github.com/tyrchen/unchained&quot;&gt;tyrchen/unchained&lt;/a&gt; 捞。视频地址：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kwHtlmyxE6c&quot;&gt;https://www.youtube.com/watch?v=kwHtlmyxE6c&lt;/a&gt;（也可以点击「阅读原文」获取，但需要梯子）。&lt;/p&gt;&lt;p&gt;稿子我改了五版，直到上台前十分钟，我还在做最后的修改。这个稿子完全用 notability 手绘而成，算是我这三个月使用 notability 的集大成者。我给 Joe 老爷子看我的初稿，还成功说服他也买了一份 copy 呢。对 notability 的使用，我即便说不上是超神入化，也对得起出类拔萃 —— 我能够更好地控制版面，我对颜色的使用日渐稳定（形成自己的体系），我对构图越来越精进，能够更好地表达我的意图，我还制作各种不同的 template，在不同的场合使用。最重要的一点 —— 现在全手绘已然不是瓶颈，大多数时候，我用 notability 手绘的效率，比用 grafio，gliffy 的效率还高不少。如果大家感兴趣，我改天写篇关于如何使用 notability + iPencil 提高效率的文章。&lt;/p&gt;&lt;p&gt;rehearsal 我做了两遍。一次 BBL，讲给 US Eng team 听；一次 elixir knowledge share，讲给 China elixir team 听。两遍 rehearsal 下来，让我对所讲的内容，关键点，以及时间有不错的把握。rehearsal 和我最后的 talk 出入不小，这得益于 Joe 对我的提点。我虽然对 Great leaders start with why 这句话倒背如流，可在自己的如此重要的 talk 上，还是对 why 重视不够，如果不是 Joe 吐槽，我可能会做一场非常平庸的演讲。“&lt;b&gt;what problem have you solved? Why it matters to me?&lt;/b&gt;” 是每个演讲者都应该重视，并且首先讲明白的问题。&lt;/p&gt;&lt;p&gt;我的演讲本身还是有不少毛病 —— 手势太碎，目光太多聚焦于讲稿而非观众，从头到尾拘囿于一方讲台，没有太多移动，着装可以再精干些，语言可以再简练些，铿锵有力些，少点嗯嗯啊啊，多些着重句子之后的停顿。不过对于第一次对外的英文 talk，我觉得已经不错了 —— 我给自己打 80 分。不积跬步无以至千里，慢慢来。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Erlang VM 培训&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这次 Code Beam，我还参加了当周周六的 Erlang VM 的培训。讲师 Erik Stenman，Beam Book 的作者（我就是因为看了他的书才关注他的）。Erik 博士看着憨憨的一个工程师，其实 NB 得不得了：他 PhD 参与了 erlang 的 HiPE 项目（Erlang Native Compiler），让 Erlang 的执行效率提升 10-50 倍；Post Doc 参与 Scala 第一版 compiler 的开发，为 Scala 完成第一个可用的 compiler。这样一个牛人一天的培训才 300 刀，到哪里找这样的好事去？我去年写过一篇文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827661&amp;amp;idx=1&amp;amp;sn=d516a615364c9226356c2f538d643425&amp;amp;chksm=8704ab51b0732247186e98170b465e37bf64c932aca98c36be01baa06980d359b5e05484135b&amp;amp;scene=21#wechat_redirect&quot;&gt;当我参加培训的时候，我在学什么？&lt;/a&gt;不知道有多少人看过，又有多少人真正将其策略性地应用于自己的工作生活。&lt;/p&gt;&lt;p&gt;对于这种档次的大会的培训，学什么主题其实并不重要。重要的是你选择什么样的讲师，你想从讲师那里得到什么？&lt;b&gt;不要把培训看成培训，把培训看成是廉价的，对等的咨询的机会。&lt;/b&gt; 300 刀一天你找 Erik Stenman 咨询，这跳楼价可以笑到尿裤子吧。我的朋友小山同学显然从我那篇文章里得到了启发，这次花三天时间参加 Joe 老爷子的培训，一千多刀，从老爷子里那里学到很多人生经验（我看他的笔记本上小抄抄下不少），还和老爷子混的谙熟，我这次能跟老爷子约上两个小时单聊，也源自他的大力举荐。&lt;/p&gt;&lt;p&gt;所以，善用培训。善用讲师的时间。花点时间了解讲师，做些功课，看看你想从中得到些什么，或者你能从中得到些什么。说服你的老板把培训费用给报销（连这种费用都不给报的老板，可以把他炒掉），然后把你所有想问的问题都整理出来，利用培训的间歇（一天的培训，茶歇 + 午餐 + QA，怎么着也能匀出来两三个小时），好好「咨询」。:)&lt;/p&gt;&lt;p&gt;我这次本来打算培训前把 erlang emulator 的源码走一遍，攒一堆问题问 Erik，无奈最近在参会和公司的大项目两相夹击下，身心俱疲，没有功夫读代码，只得把 Beam Book 草草过一遍，问了些问题，然后又追着 Erik 聊了不少关于 aeternity 的问题。&lt;/p&gt;&lt;p&gt;去年我参加 OTP training，结识了erlang solution 的老大 Francesco，我们建立了深厚的联系，我去北京出差前我还邀请他来 Tubi HQ 参观，顺便探讨 Hive 和我做的 Overseer；等忙完这一阵，我也会和 Erik reconnect，好好向他取经 aebytecode（ae 里面处理 smart contract 的 compiler）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Data Center 迁移&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 Tubi，过去的几个月我们一直在忙活一个大项目：data center 的迁移。把所有的服务和数据从一个 data center 迁移到另一个 data center 这样的事情，比我们大的公司要么不需要去做，要么有专门的团队处理；比我们小的公司要么还没遇到这种烦恼，要么一开始的设计就很好，避免这样的问题。我们不大不小，又背着数年的技术债，所以工程师才有机会接受这样空前的挑战和考验 —— 可能一辈子也不会遭遇第二回，实在是天赐的机会。data center 的迁移，不算是个脑力活，更多考究的是体力，韧性，和统筹能力。好几种形态各异的数据库服务，几十个 service，几百台机器，以及长长的 action list，由约莫十个后端工程师在流量低峰期的几个小时内迁移完毕，并且要尽可能降低对用户的影响和广告收入的影响，不啻于在一架正在飞行的飞机上更换引擎。几个月的努力，毕其功于一役，每个人所经受的压力非同寻常。&lt;/p&gt;&lt;p&gt;两周前的周四凌晨，也就是我出差前两天，我们的后端团队破釜沉舟，成功完成了这个壮举。详细的过程，有机会我会另行撰文总结。这里说两点收获。&lt;/p&gt;&lt;p&gt;《礼记 中庸》里曰：&lt;b&gt;凡事豫则立，不豫则废。言前定，则不跲；事前定，则不困；行前定，则不疚；道前定，则不穷&lt;/b&gt;。我们做事前如果先有详尽的计划和准备，发生让自己追悔莫及，走投无路的事情的概率就大大降低。Data Center 的迁移，是个苦活累活，考究的是事无巨细均考虑周全。我们都有哪些 service 和 database，哪些对外，哪些对内，哪些第三方，哪些自研，谁来负责，目前状态是什么，ETA 是哪天，这样的 responsibility matrix 要构建好。迁移时分几个阶段，迁移前几个小时干什么，迁移时 DNS 切换的先后顺序，迁移后都要验证些什么，如果出现问题，预案是什么。就跟下棋一样，一步步要先尽可能考虑清楚了，省得到时候焦头烂额，急中生错。这是其一。&lt;/p&gt;&lt;p&gt;其二是测试的重要性。即便新的 data center 测试无误，还是需要导入一些 production 的流量验证 —— 我一直有个担心：新的 Data Center 使用新域名 abc.com，所有的 client 使用 tubitv.com，即便 abc.com 一切服务无误，我们却很难保证当 tubitv.com 指向 abc.com 对应的服务上去时不出错。Tubi TV 整个 business 的麻烦之处是，client 太多太多，有些 legacy 的 client 对于我们自己来说都是黑盒。因而，我们不得已想出了一个非常 hack 的方式来测试 —— 把公司 HQ 的 DNS 服务器切换到了自己用 bind9 搭的 DNS 服务器上。这个 DNS 服务器会 hajack tubitv.com 的所有子域名，指向新的 data center，同时 forward 其它 DNS 请求。这个方法让我们在公司内部 eat our own dogshit，帮助我们测试出了一些严重的，我们完全没有预料到的 bug。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Blockchain 分享会&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我每次出差都尽可能举办个活动，做点分享。这次出差一周，本想简单点，做一个知乎 live，讲讲 bitcoin —— 自从我写文章介绍我在 Tubi 内部的分享后，很多读者都希望我能公开讲一次。无奈知乎 live 的小编一根筋，非要让我证明我是这个领域的牛人，否则不予通过。我觉得我肯定不算牛人 —— 从我真正开始看 blockchain 相关的技术到现在，都不到三个月，和那些动辄三五年前就入行的，从经历上是没法比的。然而以我这段时间在中文社区的观察来看，真正扎在 blockchain 技术领域深耕，且愿意分享的屈指可数。这并不奇怪：1) blockchain 领域的浮躁让江湖地位以金钱，或者说，捞钱的能力来衡量，真正扎在技术里的人的声音被淹没；2) 好的技术专家未必是一个好的分享者 —— 就像写代码能力比我强的人海了去了，但像我这样写了四年技术公众号还有的写的，太少太少。所以即便我不是牛人，我觉得我所讲的内容也能对大多数人有所启发。&lt;/p&gt;&lt;p&gt;可惜事与愿违，我不得不证明我是牛人，而最终我没法证明我是知乎小编眼中的牛人 —— 我把我的 github 上有关 blockchain 的 code 和 talk 的 repo 提交上去，也不晓得对方是否懂得如何用 github，反正我更新两次，被拒绝两次 —— 我一气之下删了 live，这样的猫鼠游戏我没工夫玩。线上做不了，那干脆线下，于是在朋友的推荐下，和云享客牵上了线，线下分享。&lt;/p&gt;&lt;p&gt;且容我再引用一下我引用过无数次的箴言：The brick walls are not there to keep us out; the brick walls are there to give us a chance to show how badly we want something.&lt;/p&gt;&lt;p&gt;在知乎碰壁，我的傲娇被激发出来 —— 一个小时的分享我不够资格，那么，我干脆做一下午的分享如何？我跟云享客的 Helen 敲定了细节：不要嘉宾，就我自己干讲。时间从 1:00 到 5:00，讲四个小时，中间休息两次 —— 四个小时的单口相声，这是我从未尝试过的事情。&lt;/p&gt;&lt;p&gt;虽然我肚子里有那么一点点货，但做过讲座的人都了解，自己理解和讲出来让别人理解，难度不是一个数量级，台上一倍的时间，台下保底翻番。Data Center 迁移完成，新系统稳定下来后，我便开始写 slides，火车上写，睡前写，飞机上写，还几乎把出差期间的业余时间（除了和人吃饭）都搭进去。周五晚上在极客时间做完小分享回到酒店后，老婆问我明天的分享准备得如何？我苦笑到：才准备好三分之一的内容。于是周五又干到半夜。周六早五点半起来，看着剩下的内容，我估计五个小时能完成，写了一个小时后，酒店网络 + VPN 实在是个瓶颈，我便在早餐后大概7点多去公司继续忙活，这一写又是五小时，中午12点10分，我才赶完 120 页的 slides，然后在朋友的车上，简单把稿子过了一遍。&lt;/p&gt;&lt;p&gt;最终，我的分享在周六下午 1:15 开始。由于准备得还算充分，我最担心的事情没有发生：我的内容不足以撑起四个小时的讲座。最终，我讲了近五小时，还因为时间不够，跳过了原计划讲半小时的内容。&lt;/p&gt;&lt;p&gt;slides 同样可以在 &lt;a href=&quot;https://github.com/tyrchen/unchained&quot;&gt;https://github.com/tyrchen/unchained&lt;/a&gt; 下载。我还会继续更新这个 slides，使其装载更多的内容，真正达到我心目中理想的：一份 slides 在手，入门 blockchain 无忧。&lt;/p&gt;&lt;p&gt;讲座的视频，随后会先发给参与讲座的同学，之后看情况公布出来。&lt;/p&gt;&lt;p&gt;在这次讲座的 slides 的末尾，我放了 Roger Banister 的故事来佐证 believe is self-fulfilling prophecy（是的，我偷师于 Tal Ben Shahar 的 Positive psychology 课程）。这也是在这次讲座的整个过程中，我体会最深的地方。很多事情，别人怎么看并不重要，重要的是自己怎么看。信心从来都不是来自外界，而是自己笃定自己能成，就像庄子在逍遥游里说的那样：&lt;b&gt;「举世而誉之而不加劝，举世而非之而不加沮」&lt;/b&gt;。只有这样，才能够守着目标，勇往直前，逢山开路遇水搭桥。&lt;/p&gt;&lt;p&gt;当然，最重要的还是，当一件事情做成，「举世誉之」之时，不要沉湎其中，静静走开，追逐下一个目标。就像费德勒那样，第十九个大满贯奖杯到手，觥筹交错之后，就成了他孩子们的玩具。&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-04-03-35250058</guid>
<pubDate>Tue, 03 Apr 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>眼花缭乱的区块链技术，如何入门？</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-03-22-34841206.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34841206&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6db1390e357d27ca3a4928f3de53eafb_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年，最令人激动的技术便是 blockchain tech —— 我曾在今年的计划中，将 ML 和 blockchain 列为上下半年学习的方向，不料阴差阳错，先上了 blockchain 的贼船。blockchain 让我激动的地方主要有两点：&lt;/p&gt;&lt;p&gt;其一，它集各种现存的技术于一身，解决了一个实实在在的问题：&lt;b&gt;在一个节点之间彼此不能信任的分布式环境下，如何构建一个 open ledger，解决 double spending（双花）问题&lt;/b&gt;。如果说 blockchain 是站在巨人肩膀上的技术，一点也不为过。下图是主流的 cryptocurrency 使用到的技术：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-52e167600649456c9accb386373b083e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;489&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;它涵盖了分布式系统，密码学，网络，编译原理，虚拟机以及各式各样的数据结构，基本上把 CS 所涉及的主要技术都摸了一遍。如若完整走过某个 cryptocurrency（比如 bitcoin / ethereum）的学习，对技术的夯实是显而易见的。&lt;/p&gt;&lt;p&gt;其二，&lt;b&gt;blockchain 领域的创新&lt;/b&gt;（如果是真正要做事情而非圈钱式创新），在目前这个阶段，&lt;b&gt;技术人占主导地位&lt;/b&gt;（翻身农奴把歌唱）。和 SaaS，电商，OMO 等应用领域不同，blockchain 还处在基础研究的阶段，技术起决定性因素。如果没有对现有技术体系完整详尽的了解，你很难找对切入点，甚至都不知道哪些问题可以解决，哪些问题不能解决。我看过一些 Product-driven 的白皮书，连起码的技术都没搞懂，对 blockchain 技术的现状都不清楚，就抨击比特币和以太坊的诸多道听途说过来的问题，然后洋洋洒洒写下大篇毫无意义的文字解释自己如何「发明」了一种新的方法，「解决」现存的问题，从而可以完成某某某应用。&lt;/p&gt;&lt;p&gt;以上两个原因使得我们关注 blockchain 相关的技术变得理所当然。我在「&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827812&amp;amp;idx=1&amp;amp;sn=8b2389d4c7221cb439ab0e705dd6e8e9&amp;amp;chksm=8704abf8b07322eee8aecb3bd6ad6f71f2673072feb0ed5b6f2f2fee97f0b0d11411526cc8ef&amp;amp;scene=21#wechat_redirect&quot;&gt;程序员的好日子什么时候才到头？&lt;/a&gt;」一文中说过：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;市场一直对程序员的需求强劲，可靠的供给却严重不足&lt;/b&gt;。70 年来，几乎平均每五年，对程序员的需求就增长一倍。这意味着市场上大量充斥着 &amp;lt; 5 年工作经验的，新入行的程序员。这意味着什么？在这样一个疯狂的市场下，程序员这个职业本身已经获得比其他职业高得多的溢价，而靠谱的，有经验的程序员，则很容易在这个溢价的基础上，再翻上一两番。没办法，这是供需决定的。&lt;/blockquote&gt;&lt;p&gt;如今 blockchain 领域的投资不断飙升，需求越来越强进，而市场上靠谱的程序员却少之又少，巨大的亏空必然会让有经验有能力的程序员变得超级抢手。所以，对于程序员来说，这是一个非常值得关注的领域 —— 它不像 ML/DL/AI，专业性强，如若没有好的数学底子和开放性的思维，很难出类拔萃；在 blockchain 领域，需要的更多是广博的知识和工程能力。&lt;/p&gt;&lt;p&gt;然而 blockchain 技术比较难以入门，很多人一腔热血扎进去却碰了个钉子 —— 这有几个原因。&lt;/p&gt;&lt;p&gt;一. 整个体系还处在相当早期的阶段，工具和资料都不完善，大部分时间，我们需要 read the fxxking paper / code 来获得正确的认知。这往往令初学者很难窥到门径去深入学习。网络上虽然充斥的大量的文章，但要么蜻蜓点水，流于表面，要么干脆不谈技术，只聊虚头巴脑的应用。&lt;/p&gt;&lt;p&gt;二. 虽然 blockchain tech 还在早期，但各种 cryptocurrency 已经「乱花渐欲迷人眼」，市值在千万美金以上的都有 450 种之多（https://coinmarketcap.com）。generation 也从第一代的 bitcoin，到第二代的 ethereum，再到目前喧嚣的 blockchain 3.0。到底从哪里看起，心里没数。&lt;/p&gt;&lt;p&gt;三. 主流的 cryptocurrency，比如 bitcoin 或者 ethereum，安装个环境，就把你那 mbp 可怜兮兮的 512G disk 快要吃光 —— 还没开始学习呢，家底先败没了。&lt;/p&gt;&lt;p&gt;四. 新概念太多，不好理解。好容易搞清楚了 open ledger，又冒出来个 PoW，然后是 UTXO，然后是 smart contract，然后是 side-chain，无穷无尽。就拿核心的共识机制来说吧 —— 我最近在写一篇关于共识的文章，整理了一下，目前被各种白皮书提及的共识机制就有：PoW，PoS，PoI（NEM），PoD（Nebulas），PBFT（Hyperledger），FBA（Stellar），Hybrid PoW/PoD（peercoin），Tendermint（cosmos），dPoS（EOS)。。。数不胜数，真是黑云压城城欲摧，共识机制惹人悲。再说下去，都快要「从入门到放弃」了，有木有？&lt;/p&gt;&lt;p&gt;不过，我们敬爱的 Professor Randy Pausch 说过：The brick walls are not there to keep us out; the brick walls are there to give us a chance to show how badly we want something.&lt;/p&gt;&lt;p&gt;所以不要畏惧。那么，如果我现在开始看 blockchain，究竟该如何入门？是从 bitcoin 看起？还是直接上 ethereum？甚至，直接研究感兴趣的白皮书？&lt;/p&gt;&lt;p&gt;这次回京，我将和云享客合作，举办一次 blockchain 技术的线下活动，针对初学者，介绍以下几个话题，希望能帮助大家更好地入门：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;什么是 open ledger？从 bitcoin paper 谈起&lt;/li&gt;&lt;li&gt;分布式系统简介&lt;/li&gt;&lt;li&gt;为什么形成共识这么困难？从 paxos 到 PoW，再到一堆 PoX，它们都解决什么问题？&lt;/li&gt;&lt;li&gt;bitcoin 交易是如何完成的？为什么需要引入op code 和虚拟机？&lt;/li&gt;&lt;li&gt;bitcoin 里面那些天才的设计？对我们设计软件有什么启发？&lt;/li&gt;&lt;li&gt;bitcoin 目前都支持哪些应用？它的主要问题是什么？&lt;/li&gt;&lt;li&gt;Ethereum 对于 bitcoin 有哪些技术优势？什么是 smart contract？&lt;/li&gt;&lt;li&gt;什么是 ERC？都有哪些重要的 ERC？&lt;/li&gt;&lt;li&gt;在数百种 cryptocurrency / blockchain solution 中，哪些项目在技术上值得关注？&lt;/li&gt;&lt;li&gt;如何阅读白皮书？有哪些值得读的白皮书？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;分享的时间大概 3-4 小时。&lt;/p&gt;&lt;p&gt;时间：3/31 下午 1:00 - 5:00&lt;/p&gt;&lt;p&gt;地点：云享客长富宫中心（朝阳区建国门外大街26号5号楼一层）&lt;/p&gt;&lt;p&gt;人数上限：80&lt;/p&gt;&lt;p&gt;报名地址：&lt;/p&gt;&lt;a href=&quot;http://www.huodongxing.com/event/9432365777300&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-d80a367c0c9e626813e847e7c4ab9651&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; data-image-size=&quot;180x120&quot;&gt;未来已来——眼花缭乱的区块链技术，如何入门！&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-03-22-34841206</guid>
<pubDate>Thu, 22 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>Joe Armstrong 面对面</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-03-20-34759478.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34759478&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a376c181f87c4c1ee760d240d145bee7_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;Joe 老爷子是 Erlang 世界里的一个图腾。&lt;/p&gt;&lt;p&gt;他书中的句子，他的公开演讲或是私下的谈话，都被不同的人到处引用 —— 今年的 code beam，好些 speaker 用 Joe 的原话来佐证自己的观点。Joe 因为 Erlang 的诞生被视作天才，视作英雄，视作传奇。但 Joe 自己却将其归功于 Ericsson 的「大度」：你知道 Ericsson 为什么把 Erlang 开源了么？因为有一天高层突然宣布：所有项目只能使用 C++ 或者 Java，不能用除此之外的任何语言。于是我们跟头头们商量，既然 Erlang 我们自己都不待见了，那干脆开源吧，头头说：随你便，我不关心。于是 Erlang 才得以摆脱 Ericsson 的控制，获得新生。&lt;/p&gt;&lt;p&gt;感谢 Ericsson 的愚蠢决定，否则这个世界便少了一门如此奇特而优雅的语言，而我也无法对半个地球外的一位老人顶礼膜拜。&lt;/p&gt;&lt;p&gt;如果你对 Erlang 没有了解，可以读一下我之前的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827691&amp;amp;idx=1&amp;amp;sn=8d6854f91bb9d16470ef6eed9d3ad8ec&amp;amp;chksm=8704ab77b0732261eb63217ad03740a3433cde4491826eeec020f4bbebb8b18837c27ac3e74d&amp;amp;scene=21#wechat_redirect&quot;&gt;上帝说：要有一门面向未来的语言，于是有了 erlang&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在那篇文章里，我介绍了 Joe 的 worldview：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;everything is a process.&lt;/li&gt;&lt;li&gt;process are strongly isolated.&lt;/li&gt;&lt;li&gt;process creation and destruction is a lightweight operation.&lt;/li&gt;&lt;li&gt;message passing is the only way for processes to interact.&lt;/li&gt;&lt;li&gt;processes have unique names.&lt;/li&gt;&lt;li&gt;if you know the name of a process you can send it a message.&lt;/li&gt;&lt;li&gt;processes share no resources.&lt;/li&gt;&lt;li&gt;error handling is non-local.&lt;/li&gt;&lt;li&gt;processes do what they are supposed to do or fail.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;他关于 Erlang 的所有想法，都或多或少和这个 worldview 相关。&lt;/p&gt;&lt;p&gt;跟老爷子坐在一起没聊多久，我就问了个「中二」的问题：「Erlang 在未来有没有打算引入 type system？」我知道 type system 会让 hot code reload 变得难以处理；也知道 type system 会让这门语言变得复杂，但就是莫名其妙问了这么一句。Joe 没有直接回复我，而是这样娓娓道来                                                ：&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;John Hughes（haskell 的发明人之一）在谈起 haskell 时总会说：think type first。而我会说：think concurrency first。这是这两门语言的本质不同。我并不关心 type system —— &lt;b&gt;programming is not about code, it’s about understanding&lt;/b&gt;。良好的类型设计反映了设计者对所设计系统的理解，然而 type system 并不能帮助你更好地理解你所设计的系统。在一个对所处理的问题理解错误的情况下，一个人可以写出正常编译通过的代码，并且这代码是可以测试通过的 —— 因为作者对 problem 理解是错误的，因而他写出的 test case 也是错误的。一切都如此漂亮，可是软件却并未解决问题。&lt;br&gt;所以纠结 type system，寄希望于 type system 让你不犯错误（或者让工程团队不犯错误），这是在寻找银弹。&lt;br&gt;think concurrency first。我们的世界本来就是并发/并行的。OOP 试图用一种错误的方式来描绘世界，因而得到的是复杂且不好理解的系统。比如一个电梯调度系统 —— 三部电梯停在各自的楼层，等待指令来决定如何运行。你如果试图用 OOP 描述电梯，为其设置属性，提供方法，其实是把问题复杂化了。三部电梯就是三个独立的 process，有他们自己的 state（所停楼层），它们把 state 通过 message 传递给调度系统，调度系统根据用户输入的 message，给最合适的 process 发消息，然后 process 决定自己如何行动。如果你 think concurrency first，那么，你对问题首先更容易理解，也更容易建模。&lt;/blockquote&gt;&lt;p&gt;随后，老爷子一锤定音：&lt;/p&gt;&lt;blockquote&gt;if you want type system, use a different language.&lt;/blockquote&gt;&lt;p&gt;整个谈话中，老爷子语速很快，往往我还在思考他抛出的上一个结论时，他就把下一个问题抛出来了 —— 这让你很难想象他已经是 67 岁的「高龄」。偶尔，他的思维会跳跃到物理学，比如 Minkowski space —— 跟一个差一点成为物理学家的计算机先驱谈话就是这么不着痕迹地在时空中跳跃。我问他还在写代码么，他给了我非常肯定的回答 —— 他说他在试图解决一些非常基础的问题。当我问是什么问题时，他狡黠一笑：你听了我明天的 keynote 就知道了。&lt;/p&gt;&lt;p&gt;我的好友孙博谈到白日梦旅行时，常说的两个词就是想象力和好奇心。想象力和好奇心是人类作为一个物种而言，最珍贵的品质。在聊天的过程中，Joe 老爷子的声音始终是柔和的，探寻的，他不断地抛出问题，像儿童一样处处充满好奇心，又像哲人一样通过问题启发你探寻事物的本源。他看问题的角度经常出乎我的意料，天马行空却扣着关键之处。讲一会，他会笑一笑，亲和地像一个邻家老爷爷，毫无架子，毫无世故，仿佛对面坐着的不是一个跪着的仰慕者，而是许久未见的忘年交。&lt;/p&gt;&lt;p&gt;聊着聊着，我渐渐轻松起来，问题也随意起来。我问他对这次 Code Beam 怎么看？他坦率地说听了几场，这届 speaker 不行。我会心一笑。他继续说 —— 人们在演讲的时候往往忽略了问题，而直接给出答案。&lt;b&gt;people didn’t really distinguish problem &amp;amp; solution. what’s your problem? why are you doing this?&lt;/b&gt; 在你的问题没有阐述清楚之前，我们之间无法达成共鸣，那么我为什么要关心你的答案？不解决问题，或者不解决我关心的问题（你要想办法让我关心），再光鲜亮丽的 solution 都是没有意义和价值的。我战战兢兢，汗出如浆 —— 因为，我自己的讲稿也是上来就是谈 tubi 的 elixir service 是如何构建，部署，升级和监控的，并没有谈我们遇到了什么问题，为什么要这么做，尤其是讲为什么要单做一个软件来做 release 时，非常突兀。好在，有了这次谈话，我正式讲的时候花了六七分钟来把 problem 和 why 讲清楚。&lt;/p&gt;&lt;p&gt;顺着 what&#39;s your problem 这个话题，他说做研究，找好的 problem 要 look at cracks on a marble floor：&lt;/p&gt;&lt;blockquote&gt;我们现在有太多太多的编程语言了 —— python，ruby 这样如此相似的语言，为什么我们需要发明两个？有了 Java 为什么还要有 C#？大家把太多太多精力都放在构建一门更好的语言，可是，真正称得上有自己思想的语言很少。大部分语言可以被归到几个类目下面。如果把一门门语言看成一个 blackbox 的话，那么，大家都只顾自己的一亩三分地；如果把一台台机器看成一个个 blackbox 的话，那么，大家挤在一方小小的土地上厮杀，此消彼长。我们应该更多地 &lt;b&gt;build things outside the boxes&lt;/b&gt;。在 blackbox 之间，广袤的领地，无人问津。blackbox 如何被连接在一起，如何 communicate &amp;amp; collaborate，还有大量的工作要做。&lt;/blockquote&gt;&lt;p&gt;说到兴起，他继续提点我：look at cracks 也分场合，优先选择那些重要的 cracks。他给我讲了个 Altair 的故事 —— 补充一下：Altair 是 PC 时代的先驱 —— apple I 就是受其启发而发明的，而盖老师在 DOS 之前的主营业务 Basic，生意也是始于 Altair Basic。他说七十年代末，Altair 在 geek 群体间已经很火爆，有个混 synth 圈子的哥们寻思着为 Altair 做一款 synth 的工具，必定火爆。结果软件吭哧吭哧做出来，也就几个人感兴趣。所以你可以在一个小众的，还未被认识的领域有所作为，但不要试图在两个小众的领域的交集间有所作为。这样的话市场太小了，你熬不过黎明前的黑夜。&lt;/p&gt;&lt;p&gt;接下来我问老爷子怎么看 blockchain？&lt;/p&gt;&lt;p&gt;老爷子一下子声音提高了八度。what are you talking about? are you referring cryptocurrency? or open ledger? or smart contract? or something else? people usually mixed these things up with “blockchain”&lt;/p&gt;&lt;p&gt;我赶忙说，我们先聊聊 cryptocurrency，或者 bitcoin。你觉得…&lt;/p&gt;&lt;p&gt;老爷子打断我的话：bitcoin is morally wrong. Isn’t it?&lt;/p&gt;&lt;p&gt;接下去差不多十分钟时间，老爷子就像拷问战犯一样，拷问 bitcoin，或者更严格地说，拷问毫无意义浪费资源，让地球变暖的 PoW。我好几次想插嘴，想把话题往技术上撩，都被老爷子弹开了。老爷子情绪激昂，我怕我再执拗下去，被放在火上烤的就不是 PoW 而是我 —— 毕竟，morally wrong 这顶大帽子是实锤，辨无可辨，因而我知趣地放弃这个话题，静静做个好听众。&lt;/p&gt;&lt;blockquote&gt;Bitcoin created a world of mess… As a software engineer, our responsibility is to &lt;b&gt;reduce complexity&lt;/b&gt;, or to reduce entropy….&lt;/blockquote&gt;&lt;p&gt;这句话我很认同，复杂是软件的天敌，我们搞这么多 principles，methodologies，paradigms，patterns，目的都是减少复杂度。我曾经写的一篇文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827625&amp;amp;idx=1&amp;amp;sn=76b275e9c4895d94f7ca963bedca7564&amp;amp;chksm=8704ab35b073222313df7222a944dcccc315ed852ab8390ab016d58bf5f373469e7a3f9084ae&amp;amp;scene=21#wechat_redirect&quot;&gt;是时候想想该怎么删代码了&lt;/a&gt; 提过一个思路：以构建可删除的代码为设计目标。这也是一种降低 complexity，减少软件中的 entropy 的方式。&lt;/p&gt;&lt;p&gt;在抨击完 bitcoin 道德上立不住后，老爷子显得有些疲态，我赶紧顺势把话题扯回到 Erlang —— 我还有一堆来自于朋友圈的问题有待发问。我挑了个简单的：你最喜欢 erlang 哪一点？&lt;/p&gt;&lt;p&gt;老爷子立刻精神起来，目光炯炯：&lt;/p&gt;&lt;blockquote&gt;简单。你看我们处理 concurrency 的方式 —— 这是唯一一个把 security，isolation，fault tolerance 完整地，且又简单清晰地，涵盖在内的方案。我们八十年代解决掉的问题，大家现在还在穷尽心力去解决。&lt;br&gt;我一个快 70 的老头儿，如果从凳子上摔下来，我能 recover 我自己么？显然不行。我只能发个 signal（message）给你，然后你把我扶起来 —— 甚至，我都不用主动发，我们之间有 link（link 是 erlang process 之间的一种连接），使得你密切关注着我，以至于我一旦跌倒，你立刻得到视觉上的通知（就像 &lt;code class=&quot;inline&quot;&gt;{&#39;EXIT&#39;, Pid, Reason}&lt;/code&gt; 一样），于是你很快把我扶起来。这就是 fault tolerance，简单，明了，不用深奥的计算机知识佐证（说你呢，exception handling），小朋友都能懂。这个方案之所以浅显易懂，是因为这是很自然的 solution，我们每天就是如此生活。你再看，process 只能通过 message 通讯，所以 process 和 process 完全独立（isolation），就像一个个人。由此一个 process 的问题也很难扩展到整个系统，因而 security 也得到了保证。&lt;/blockquote&gt;&lt;p&gt;「完全赞同！」我附和道。「而且 message passing 作为 concurrency 的一种方式，不仅适用于单机，也无缝适用于分布式系统。其它方案，单机内部一种模式，机器间还是要 message passing，因而不得不在两种模式间切换，考虑起来很复杂。」&lt;/p&gt;&lt;p&gt;老爷子点点头。「一件事情如果过于复杂，那么一定是哪里出问题了 —— 大部分情况下是对问题的理解出现偏差」。老爷子话锋一转：&lt;/p&gt;&lt;blockquote&gt;人们总是为没有想明白的问题创造解决方案，这是个严重的问题。比如说 JSON。what’s the reasoning? 我不理解为什么我们需要发明 JSON，也许是 JSON 之前的交流方式太复杂，或者太不可用，所以它就出现了？像 JSON 这样的 serialization 方案，human readable 绝对是个伪命题。想想网络上传输的内容 —— 它们不过是 signal 而已，传输的是一个个 bit —— 那为什么我们要用 text，而不是 binary 来节省带宽，降低消耗？human readable 在屏幕上是有意义的，在网络上，在内存中，完全是无稽之谈。&lt;/blockquote&gt;&lt;p&gt;聊了一个多钟头，快到午餐时间了。老爷子冲我狡黠一笑：你是不是准备了一堆问题？还剩什么问题想问的？我想出去走走，活动活动筋骨了。&lt;/p&gt;&lt;p&gt;我看了看我剩下的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;What’s the future direction of erlang/OTP?&lt;/li&gt;&lt;li&gt;How do you see current status of distributed erlang? Any plan to improve it? for example, will we have gen_raft, or gen_pbft? or replace the full mesh network to p2p network?&lt;/li&gt;&lt;li&gt;How do you compare erlang and elixir?&lt;/li&gt;&lt;li&gt;How do you do trade off between performance and debugability, giving that OTP put so many efforts to make things traceable?&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;还有不少，我便挑了几个问他。&lt;/p&gt;&lt;p&gt;对 erlang/OTP 里加入更多的 distributed consensus behavior，如 gen_raft，老爷子是无所谓的态度。他说这不重要。他虽然有能力影响 OTP team，但这是他们的选择。对于 elixir，老爷子赞赏有加，说他有三个孩子，erlang 是第三个，elixir 是他所喜爱的小孙子。另外一个 erlang VM 上的语言，他的老友 Robert Verding 的 LFE（Lisp Flavored Erlang），就没那么好运气了 —— 老爷子说这是远房的侄子。对于 performance，老爷子看法一直未变：correctness is 1st, performance is the last thing I considered。这让我想起他曾经说过的：&lt;/p&gt;&lt;blockquote&gt;Make it work, then make it beautiful, then if you really, really have to, make it fast. 90% of the time, if you make it beautiful, it will already be fast. So really, just make it beautiful!&lt;/blockquote&gt;&lt;p&gt;临了，我问老爷子对中国的印象。他说他很喜欢中国，很喜欢北京，还拿了他和夫人在天安门前的合影给我看。我说，那你打算什么时候再去中国看看啊？他笑笑，那看你们什么时候邀请我来中国参加有关 erlang 的大会啊。&lt;/p&gt;&lt;hr&gt;&lt;p&gt;一些题外话：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;是的，这里的对话并非原话 —— 我 iPad 上面记录的以及我回忆的，还有很多素材我记不起来或者不知道怎么摆进来。对话的顺序也根据行文的需要进行过调整。&lt;/li&gt;&lt;li&gt;Joe 是英国人，地道的英国腔。瑞典是他的第二故乡。&lt;/li&gt;&lt;li&gt;Joe 问了我一个有趣的问题 —— 在做某个研究前：How do you know if someone else has done it?&lt;/li&gt;&lt;/ul&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-03-20-34759478</guid>
<pubDate>Tue, 20 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>量子计算对 bitcoin 的威胁</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-03-12-34458475.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34458475&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e9b39620e2e9829d8dbad5f83a5bafa2_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;在奉上有关「共识机制」的文章前，我们先来点甜点。&lt;/p&gt;&lt;p&gt;在两周前的 BBL 上，我给团队介绍了 bitcoin，相关的 slides 见：&lt;/p&gt;&lt;p&gt;github.com/tyrchen/unchained&lt;/p&gt;&lt;p&gt;其中花了点时间谈论了 quantum computing 对 bitcoin 的威胁。上周 google 发布了 72 量子比特通用量子计算机，引发了大家的热议 —— 尤其是，看上去牢不可破的 cryptocurrency，是不是到了快要被终结的时刻？&lt;/p&gt;&lt;p&gt;下图是当时我 talk 时讲的内容：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1240064759be2d18083e9b382990e616_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;915&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;首先我们看量子计算中已经比较成型的算法：Shor’s algorithm（下文简称 Shor） 和 Grover’s algorithm（下文简称为 Grover）。&lt;/p&gt;&lt;p&gt;Shor 不是通用的算法，它解决因式分解的问题 —— 给定一个整数 N，找到其质因数。以下是 Wikipedia 的介绍：&lt;/p&gt;&lt;blockquote&gt;On a quantum computer, to factor an integer N, Shor’s algorithm runs in polynomial time (the time taken is polynomial in log N, which is the size of the input).[1] Specifically it takes quantum gates of order O((log N)3) using fast multiplication,[2] demonstrating that the integer factorization problem can be efficiently solved on a quantum computer and is thus in the complexity class BQP. This is substantially faster than the most efficient known classical factoring algorithm, the general number field sieve, which works in sub-exponential time – about O(pow(e, 1.9(log N)1/3(log log N)2/3)).[3] The efficiency of Shor’s algorithm is due to the efficiency of the quantum Fourier transform, and modular exponentiation by repeated squarings.&lt;/blockquote&gt;&lt;p&gt;简单说，Shor 就是把指数级的时间复杂度降维成了 polynomial time，也就是多项式时间。所谓多项式时间，就是 O(nk)，其中 k 是个常量。下图是时间复杂度的对比，大家可以看到，指数（2n）到多项式（n2）差异非常大：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f0c2ca93f95e1d57b15d2707548647ce_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;550&quot; data-rawheight=&quot;319&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;虽然 Shor 只能加速因式分解，但如果你了解非对称加密的算法，你会记得 RSA 的基石就是两个大质数 p 和 q 的合数很难被因式分解出 p 和 q。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d81c75c21e1cd70b09007ae53dd17cb1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;959&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;大概五到十年前，人类通过通用计算机分解出来的最大的整数是 768 bit，因而理论上 RSA 密钥低于这个数字就是不安全的。实际生活中，我们基本会用 4096 长度的密钥：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;$ ssh-keygen -t rsa -b 4096 -C &quot;tyr@awesome.com&quot;&lt;/code&gt;&lt;p&gt;对于一个 768bit（二进制）大小的整数，我们对比两个算法的复杂度：&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;&amp;gt; n = 1230186684530117755130494958384962720772853569595334792197322452151726400507263657518745202199786469389956474942774063845925192557326303453731548268507917026122142913461670429214311602221240479274737794080665351419597459856902143413
1.2301866845301178e+231
&amp;gt; logn = Math.log(n)
532.1043224155328
&amp;gt; loglogn = Math.log(logn)
6.276839564883618
&amp;gt; pow1 = Math.pow(logn, 1/3)
8.103368625868256
&amp;gt; pow2 = Math.pow(loglogn, 2/3)
3.402728919940164
&amp;gt; 1.9 * pow1 * pow
252.389776867137634
&amp;gt; Math.pow(e, 52.389776867137634)
5.65706279069233e+22
&amp;gt; Math.pow(logn, 3)
150657362.61267015&lt;/code&gt;&lt;p&gt;前者是 1022，后者 109，如果 1ns 完成一个 operation（当然两个算法一次 operation 的时间是不等的，但是常量），前者需要 180 万年，后者需要 1s。&lt;/p&gt;&lt;p&gt;由此可见，Shor 对 RSA 体系的破坏性是显而易见的，而且，它的变种，对基于椭圆双曲线的 ECDSA 也有类似的降维杀伤力。从这个角度上讲，量子计算机不断走向成熟，整个非对称加密体系下的算法都会受到巨大的冲击 —— PKI 将坍塌，你访问 chase.com，CA 已经无法证明 chase.com 的 cert 属于 Chase；你也无法使用公钥去验证某个私钥的签名，因为私钥变得可以被公钥推导出来。所以，岌岌可危的并非 bitcoin，而是整个 internet。你无法信任你的银行的网站，银行无法信任你的 USB token 里的私钥提供出来的签名。我们的数字化生活会走向暗黑时代。&lt;/p&gt;&lt;p&gt;然而你还是能信任你的 bitcoin 钱包。虽然 bitcoin 钱包的私钥和钱包地址都来源于 ECDSA 的私钥和公钥，然而钱包地址并非直接是公钥，而是公钥的 hash。因而，你给一个钱包打钱，并不会需要钱包的公钥；只有这个钱包使用里面的钱（给别人打钱）时，才需要把自己的公钥放在 transaction 里。如果一个钱包只是收钱，那么它是安全的 —— 即便 Shor 算法也需要公钥去逆向私钥。因为公钥没有暴露出来，Shor 算法无法使用。因而即便量子计算破解了非对称加密算法，对于那些没有使用过的冷钱包（code wallet），也无法破解。对于那些需要 multisig 的钱包，也是类似。&lt;/p&gt;&lt;p&gt;如果非得破解冷钱包，那么需要先把钱包地址逆向出来其公钥，而这个操作 Shor 无法完成，只能借助其他算法。&lt;/p&gt;&lt;p&gt;这个算法是 Grover。先看 Wiki：&lt;/p&gt;&lt;blockquote&gt;Grover’s algorithm is a quantum algorithm that finds with high probability the unique input to a black box function that produces a particular output value, using just O(sqrt N) evaluations of the function, where N is the size of the function’s domain. It was devised by Lov Grover in 1996.&lt;/blockquote&gt;&lt;p&gt;基本上，Grover 对于函数 f(x) = y，只要给定 y，以及 x 取值的一个列表，它可以以 O(sqrt N) 的时间复杂度，找到这个 x。换句话说，随便一个算法，正常情况下暴力破解（在算法的定义域里一个个试），是 O(N)，Grover 将其降低成 O(sqrt N)，对于时间复杂度来说，这算法虽然看上去不错，但大多数情况下只是聊胜于无。下图是它和 log N 对比：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fec77dab102286f530de1559d89f3d4d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;705&quot; data-rawheight=&quot;535&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我们看一个 256bit 的公钥，其 O(sqrt N) 是多大。我们先得找 256bit 数字的取值范围：&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;&amp;gt; n_max = 0b111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111
5.78960446186581e+76

&amp;gt; Math.sqrt(n_max)
2.4061596916800453e+38

&amp;gt; Math.log(n_max)
176.75253104278605&lt;/code&gt;&lt;p&gt;可以看到，虽然 sqrt 后量级已经大大减少，但还是 trillion trillion trillion 级别，在一个可以预见的时间内无法破解。所以，即便使用了 Grover 算法，也无法有效地通过钱包地址破解出公钥，进而进一步使用 Shor 算法从公钥破解出私钥。&lt;/p&gt;&lt;p&gt;从这个意义上讲，bitcoin 对 quantum computing 还是有一定免疫力的。在大家担忧量子时代到来后（可能二三十年到来，也可能三五十年） bitcoin 的前景时，还是先担忧一下现有的 PKI 体系吧，毕竟，信用卡，网银，微信支付，支付宝等所有基于非对称加密来保证安全的系统，可能都会变得不再可信。你以为你大爷是你大爷，可是你大爷真的不再是你大爷了。&lt;/p&gt;&lt;p&gt;一些问题：&lt;/p&gt;&lt;p&gt;Q: 是不是只是对于从没有交易过的冷钱包来说才是安全的？&lt;/p&gt;&lt;p&gt;A: 对。所以大钱放冷钱包；经常要花的小钱放热钱包，类比 checking / saving account。收钱是不受影响的。如果热钱包被打了很多钱，立刻转到冷钱包里去 —— 不管有没有量子计算，这都是好习惯。冷钱包一旦使用，记得把余额打到新的冷钱包里面。&lt;/p&gt;&lt;p&gt;Q: SHA256呢？这个算法被攻破的话挖矿将瞬时完成，现有的PoW崩溃，网络也就脆弱&lt;/p&gt;&lt;p&gt;A: 我文中最后提 Grover 算法就是在逆向由 ripemd(sha256(pk)) 生成的钱包地址，从中获取pk。是不可行的。量子计算会让 PoW 加速（别人十分钟产块，你理论上可以 3.1 分钟，但 difficulty 会随之而涨），因而量子霸权可以很容易让自己生成新的 block。但是要逆向 pow 是很难的，比如要逆向之前的 6 个区块，那么时间成本是指数增加的。PoW 目前的 difficulty 是 3290605988754，sqrt 后是1814002，对于单个 block，这是压倒性的优势；但要篡改历史上的区块，比如最近 6 个，需要 Math.pow(difficulty, 6)，使用 Grover 后，仍然要应对 3.6e+37 的量级的计算。&lt;/p&gt;&lt;p&gt;Q: 量子霸权会超50%算力进而伪造交易吗？&lt;/p&gt;&lt;p&gt;A: 可以形成算力上的垄断，但这种垄断无法直接伪造交易，只能让垄断者能够 double spend；如果要伪造交易，需要在 10分钟内攻破别人的私钥（使用 Shor 算法），且比别人都快出 block。如果到了到这个时候，我们需要先担心的是整个 PKI 体系坍塌带来的暗黑时代，而非 bitcoin 交易被伪造。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;延伸阅读：&lt;/p&gt;&lt;a href=&quot;https://www.technologyreview.com/s/609408/quantum-computers-pose-imminent-threat-to-bitcoin-security/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-8794519f78d5605a42427192d576396c&quot; data-image-width=&quot;703&quot; data-image-height=&quot;395&quot; data-image-size=&quot;180x120&quot;&gt;Bitcoin security threatened by quantum computers, say cybersecurity experts&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-03-12-34458475</guid>
<pubDate>Mon, 12 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>谈谈如何做研究</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-03-07-34326465.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34326465&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e256b41cda3af495308f3713487c8eea_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;今天谈谈我自己做研究的方法 —— 它跟随我多年，且一直在演进和完善中。我虽然没有读过 PhD（希望有生之年能够尝试一下），但我自认为这法子并不算差 —— 至少，它让我能够更加高效地进入一个新的领域，并且扎根于其中。如果你一直在读我的文章，好奇为何程序君涉猎范围这么广（就是这么爱给自己贴金），又扎得比较深（被自己帅哭了），那么，你可以仔细读读本文 —— 还是那就话，希望它对你有用，能给你哪怕一点点启发。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;从问自己「为什么」开始&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Simon Sneak 说 Great leaders start with why。要进入一个新的领域，你要问清楚自己为什么要进来 —— 它可以是热爱，也可以是恐惧，两种情感都能把你推得很远。热爱是正向的情感，它表达了你的兴趣；恐惧是负向的情感，它意味着你担心失去某些东西。我们当然希望正向的情感促使我们前进，然而如果你做一件事情出于恐惧，也不必太过在意甚至自责，因为情感会随着境遇而转化。有多少人真的热爱加班？对失去一份前途无量的工作的担心，对自己在技术领域会落后于周围的人的忧虑让我们加班，我们投入了时间，做出了成就，这超出预期的反馈让我们开心，从而更愿意投入额外的时间在技术上。我大女儿刚开始学琴的时候很抗拒练习，哭着喊着不配合 —— 是对妈妈威胁弹不好就要在作业上画八叉，然后老师对作业上有八叉的小朋友会批评，且不给 sticker 的这种恐惧让她不得不完成练习。久而久之，练习得到了回报，弹出的乐曲优美动人，于是她渐渐对弹琴从恐惧到热爱，时不时会主动去练习，甚至研究同一首曲子的不同变调，把若干曲子 remix 起来，试图发明新的曲子。所以我们看到，恐惧支配下的努力，在得到回报后，很有机会转化成热爱。&lt;/p&gt;&lt;p&gt;所以好的研究方向，要么是足够前沿（激发热情），要么是能够弥补你目前所缺失部分（化解恐惧）。&lt;/p&gt;&lt;p&gt;当你选好一个方向后，下一步，就是 &lt;b&gt;了解这个方向的 big picture 和 status-quo&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;提纲挈领，掌握全貌&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这一步很重要。上来就扎到细节里并不是一件好事 —— 这就跟画画一样，你先从左上到右下进行构图，把大的形状勾勒出来，然后对此不断递归，直到想要的细节被雕琢出来。&lt;/p&gt;&lt;p&gt;我们以 blockchain 为例。从技术角度来说，最大的 picture 可能是这样的：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-858d13ca93ded58841d927d1cf0cdffc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;969&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这个 picture 下，有些是你比较熟识的，比如 TCP/IP stack，可以先放在一边；有些是新的技术，如 open ledger，可以对此递归，进一步细化。在这个过程中，要问自己很多问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为什么需要这个技术？它解决什么已知的问题？&lt;/li&gt;&lt;li&gt;它涉及到哪些内容？（下一步再递归）&lt;/li&gt;&lt;li&gt;整个技术发展的历史是什么样子？&lt;/li&gt;&lt;li&gt;如果有多个 solutions，每个 solution 的优缺点是什么？&lt;/li&gt;&lt;li&gt;给我一页白纸，我能否画出这个技术所涵盖的 big picture？&lt;/li&gt;&lt;li&gt;这个技术将何去何从？最新的方向是什么？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些问题都很直观，我就不一一细说，他们都是很重要的问题，你需要在研究的时候对此进行回答，但更重要的是，找到你认为更重要的问题。&lt;/p&gt;&lt;p&gt;这里我讲三个要点：问问题，找历史，对比/类比。&lt;/p&gt;&lt;p&gt;忘记是谁说的了，&lt;b&gt;问对问题比找对答案更重要&lt;/b&gt;。问问题的能力反应一个人的科学素养，经常能问到点子上的人科学素养会更高一些。问对问题依赖两个方面：1) 先验知识 2) 问问题的方法。前者需要慢慢累积，后者有方法，比如《麦肯锡方法》里面谈到问问题的方法，以及前人的经验可寻，比如我上文中的这个列表。&lt;/p&gt;&lt;p&gt;如果你也在看 bitcoin，你也许会有这些问题：&lt;/p&gt;&lt;p&gt;和数字相关：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;为什么 block 设计为 1M？&lt;/li&gt;&lt;li&gt;为什么总体供给是 2100w，不是 2048w，不是 4096w，是 2100w 这样一个奇怪的数字？&lt;/li&gt;&lt;li&gt;为什么 10 分钟出一个区块？为什么 6 个区块之后就可以认为之前生成的区块被确认了？&lt;/li&gt;&lt;li&gt;为什么用 base58（WTF）？为什么不用我们熟知的 base64？&lt;/li&gt;&lt;li&gt;为什么交易速度如此之慢，只有若干 tx / s？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如果你不对数字问为什么，你只能是数字的奴隶，是记忆者而难说理解者。&lt;/p&gt;&lt;p&gt;和思想相关：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;为什么要搞 open ledger？优点？缺点？&lt;/li&gt;&lt;li&gt;为什么搞 chain？&lt;/li&gt;&lt;li&gt;为什么 PoW？现有的方法为什么不可用？（呃，现有有什么方法？）&lt;/li&gt;&lt;li&gt;为什么给矿工生成看似无意义的空区块的空间？&lt;/li&gt;&lt;li&gt;为什么钱包的地址要 hash 一遍，而不是直接用 public key 的 base58?&lt;/li&gt;&lt;li&gt;为什么设计 UTXO？&lt;/li&gt;&lt;li&gt;为什么需要 merkle tree？&lt;/li&gt;&lt;li&gt;为什么用 ECDSA 而不是 RSA？&lt;/li&gt;&lt;li&gt;为什么 double hash？&lt;/li&gt;&lt;li&gt;为什么用 little endian，而不是 big endian（network order）？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这个列表可以很长很长。&lt;/p&gt;&lt;p&gt;找历史是一个寻根溯源的动作，它能够让你的知识建立地更加体系化。这个世界上产生的每一样新的知识和理论都有前人的影子，就像牛顿说自己是站在巨人的肩膀上，他这不是谦虚，是事实。我们如果针对一个点去学习，学到的东西是孤立的，很难触发进一步思考的，然而，如果我们将历史代入，把一个个散落的点连成线和面，那么，我们可以更好地比较，综合，抽象。从而获取到属于自己的知识。比如说你看到 bitcoin 的 consensus，了解了 PoW 后，可以看看整个 consensus 的发展历程，知道 bitcoin PoW 来自于 hashcash，而 consensus 的基础问题是 Byzantine generals problem。那么还有什么处在这个 category 之下的 consensus 算法呢？PoS（Proof of Stake），PoI（Proof of Importance），DPoS（Delegated Proof of Stake），PoD（Proof of Devotion），PBFT（Practical Byzantine Fault Tolerance）…。等等，这些都是 blockchain 世界里的 consensus，也就是一个不信任的环境下的 consensus；那么，如果一个可信环境下的 consensus，是怎么解决的？于是，你了解了Paxos，Raft，还有 Zookeeper 所用的 ZAB（Zookeeper Atomic Broadcast Protocol）等等。这样，关于 consensus 的树状知识就有了。&lt;/p&gt;&lt;p&gt;在寻根溯源的过程中注意一点，不要过早耽于细节而迷失了方向。先找到 big picture，然后再细化，永远都是适用的。&lt;/p&gt;&lt;p&gt;追溯历史之后，我们得到一大堆的新名词，新知识，接下来要对他们进行对比和类比，从而归纳总结。对比/类比可以在很多维度上进行，让知识真正成为你的知识 —— 因为，在这个过程中，更多的问题在更多的角度被发现出来。&lt;/p&gt;&lt;p&gt;下面是我在看 blockchain 这种 fully unmanaged distributed system 时，想到的和 solo system，以及 managed distributed system (cloud computing) 的对比：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9598c69b1d73a7cd6be7fc7f18a824ad_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1009&quot;&gt;&lt;p&gt;这虽然只有寥寥数行的比较，但其中凝结了很多思考 —— 纵轴究竟该选取什么维度？我相信你和我会得出不同的列表 —— 这是一个非常开放的思考，没有标准答案，只要有思考，只要去比较，就会有收获。&lt;/p&gt;&lt;p&gt;虽然我把对比和类比放在一起，这两者差别还是蛮大的。对比强调分类，归纳，总结，而类比更多强调引申，演绎。现在大家谈起 blockchain 都将其和九十年代的互联网类比，那么，九十年代的互联网出现了哪些成功的方向，现在 blockchain 又出现了哪些成功的方向？我们是否可以把早期的雅虎（网站的索引）和如今的币安（cryptocurrency 的索引）类比？那么新浪可以和什么类比？google 可以和什么类比？geocities 又可以和什么类比？&lt;/p&gt;&lt;p&gt;很多好的想法都是从类比中获得的，我前几天的文章里提到的 ArcBlock，其将 blockchain 的百家争鸣类比数据库技术的百花齐放，那么 ArcBlock 要做的就是 ODBC/JDBC 做的事情。ArcBlock 提供的服务是 aws for blockchain，清晰，明了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;了解现状&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;其实如果 big picture 按照上文的思路撸过，那么，status quo 就不攻自破了。还是以 blockchain 为例，其 status-quo 是什么？下面这张 slide 说的很清楚，我们在整理某个技术的 status quo 时也可以采用类似的方式：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-02a7bb53acdc5989a1aef5e13e9b400f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1128&quot; data-rawheight=&quot;767&quot;&gt;&lt;p&gt;（图片来源：https://gomedici.com/an-overview-of-blockchain-technology/）&lt;/p&gt;&lt;h2&gt;&lt;b&gt;以教促学&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我在其他场合也提到过，我自己是「以练促学，以教促学」的的忠实拥趸和受益者。分享（知识）是一种快乐，也能让自己收获更多 —— 这便是所谓的「天下皆知取之为取，而莫知与之为取」。当我对所要研究的内容有个 big picture 后，深入细节时我会从如何把我所学到的知识教给别人这个角度研究学习。这个方法主要对我有这些帮助：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;促使我更好地记笔记，将学过的内容汇总起来&lt;/li&gt;&lt;li&gt;强迫我用自己的话将知识复述一遍，巩固之余，还能防止「我以为我懂了实际没懂」的尴尬场景出现。&lt;/li&gt;&lt;li&gt;在将其传授给别人时，要么自己会意识到某些地方是 “I don’t know that I don’t know”，要么是听众问的你自己不会问的「小白」问题，促使自己意识到 “I don’t know that I don’t know”，从而得以对知识查漏补缺。&lt;/li&gt;&lt;li&gt;(副作用) 提高自己的 public speaking 能力&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;偷师&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面说到，这个世界上产生的每一样新的知识和理论都有前人的影子。要想有所突破，仅仅在想突破的那个点发力是远远不够的，我们得先偷师前人，构建一棵完整的知识树。这里的偷师，不仅仅是学习，还包括复制，或者说刻意模仿。我丫头学琴，按着老师教的指法，学着视频里的动作，照着一篇篇乐谱，一遍遍练 —— 这便是模仿，非常非常刻意的模仿。人类（或者说所有生物）非常不善于模仿，花再多的功夫，也仅仅是无限接近原作 —— 比如你无法复刻我的笔迹，甚至我自己，抄十遍咏鹅，三十只鹅，每只都形态各异，总能发现些许的差别。然而，我们要感谢造物主为我们提供的这种 incapable / imperfect，他让我们能够活成我们自己。刚刚拿到奥斯卡的科比，在成为巨星的路上偷师过很多人，包括在投篮上偷师过乔丹和司机，在脚步上偷师过大梦等：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-56f8c492b875c59f7b542d8e7edf7a5e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;480&quot;&gt;&lt;p&gt;可是科比发现自己的身高，体型，臂展，肌肉力量等等所有这些特性都和他所仰慕的前辈不同，因而他无法精确复制（即便上图已经接近像素级），他需要调整很多来让他复制的技巧适应他的身体。即便每个经过改进的动作都有他所复制的巨星的影子，但这一切加起来，谁也不像，它只属于科比这个名字。这印证了那句老话：&lt;b&gt;如果从一个作者身上拷贝，那是剽窃；但从很多人那里拷贝，那是创新。&lt;/b&gt; 当然，拷贝并非复制粘贴那么简单，就像科比，迎着凌晨四点钟的太阳，一遍又一遍苦练，并且不断思索：为什么这个动作要如此展开？姿势要如此角度？如何让这个动作更加适合我？&lt;/p&gt;&lt;p&gt;于是他拷贝的不仅仅是 style，还是背后的思考过程 —— 这是内化（internalize）的一部分。&lt;/p&gt;&lt;p&gt;模仿，拷贝，思考（问问题），内化，博观约取，厚积薄发。之后你就拥有了你的 branch：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-40c329701da84526f4e4f9ba668c0b9a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;559&quot;&gt;&lt;p&gt;这是我们自出生那一刻（或者说成为受精卵那一刻），花一辈子要做的事情：在继承了父母九成多的基因后，点亮一个新的分支：你自己。&lt;/p&gt;&lt;p&gt;这个话题我再多啰嗦两句。最近突然流行起了「古典互联网」和「古典区块链」之说。有个朋友小窗问我怎么看 xxx 白皮书，我说我还在吭哧吭哧看 bitcoin。朋友来了一句：现在都 3.0 了，你怎么还在研究 1.0 的「古典区块链」？&lt;/p&gt;&lt;p&gt;WTF！Are u OK？Are u zhende OK?&lt;/p&gt;&lt;p&gt;你可以用「古典互联网」和「古典区块链」自嘲，但不可以自我否定（如果你身处其中），也不该粗暴地蔑视那些并不在风口浪尖的东西。我们要对前人的智慧保持敬畏，而对满嘴 buzzword，堆叠概念却不求甚解的行为远离 —— 大大不是总告诫我们：见善如不及，见不善如探汤么？没有树根，树干，树枝支撑的树冠是个空中楼阁，无法长存的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;尾声&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;其实还有很多内容可以讲，但是我想就此打住。最后一点：给自己一点点耐心，再来一点点耐心。莎翁说：人生如舞台，有时候你在前台，有时候在后台。做研究，大部分的时间都是吭哧吭哧慢火细熬的功夫，是后台，是里子，是鲲化成鹏之前的沉潜浮动。水击三千里，抟扶摇而上九万里固然轰轰烈烈，气吞山河，但在那之前，要耐得住寂寞，留得住青山。&lt;/p&gt;&lt;p&gt;然而事情并不一定按照你预期的方向去走，终于轮到你上台时，盛宴也许已经结束。这你得认。君不见 bitcoin 矿工空算几亿亿次 hash，最后竹篮打水一场空么？那矿工们还是照样抖抖衣襟上的泥土，心疼电表一秒钟，继续算下一个 block，直到属于自己的时机到来呢。王家卫用「一代宗师」告诉我们：人活一世，有的人活成了面子，有的人活成了里子，都是时势使然。Neil Gaiman 说 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=401127730&amp;amp;idx=1&amp;amp;sn=11ca3c73adc4f0821f387d1e4514a011&amp;amp;scene=21#wechat_redirect&quot;&gt;Make good arts&lt;/a&gt;。这是做研究要有的态度。&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-03-07-34326465</guid>
<pubDate>Wed, 07 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>谈谈分布式系统</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-03-03-34195307.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34195307&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-15d3cda677ea3e824e9938421e9efc6b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;最近一个多月，谈论 blockchain 的人如此之多，以至于连菜头叔都写了篇文章「韭菜席地而坐」。我在朋友圈里转了这篇文章，评论说： &lt;/p&gt;&lt;blockquote&gt;区块链是对此钻研的技术人，场内人士，以及为所有参与者提供服务的人的盛宴，因为他们对此深思熟虑，并且有金钱以外的付出。那些听风就是雨的参与者，仅仅花费时间在 telegram 里打听小道消息，盯盘讨论涨跌的人，都是韭菜，大小而已。&lt;/blockquote&gt;&lt;p&gt;有朋友问，那做技术的，怎么入行？&lt;/p&gt;&lt;p&gt;我虽不算入行，但知道技术是一脉相承的 —— blockchain 不是像孙猴子凭空从石头里蹦出来的，它有它的根。如果把一门门技术看做一棵棵拔地而起，随时间渐渐丰腴而枝繁叶茂的榕树，那么 blockchain 是若干棵已然成年的榕树交织而成的新枝（branch） —— 它快速成长，活力无限，树冠已然盖住了其它 branch 的锋芒。如果你直接爬到它的树冠上，想要抓其脉络，在纷繁复杂面前，会迷失方向；但若你从根部细细往上捋，线索就如钱老笔下的「真理」，赤裸裸而一览无遗。&lt;/p&gt;&lt;p&gt;今天我们先寻其最重要的一个根：分布式系统。这个题目对互联网从业者来说，看着可笑，谁敢说自己不了解分布式系统啊？然而，如果你只是躲在 load balancer 后面做些 stateless 的 service，而没有真正去面对分布式系统那种让人愉悦并忧伤着的不确定性，那么，你可能并不真正了解分布式系统，因而本文还是值得一读。&lt;/p&gt;&lt;p&gt;依旧例，我们还是先看 wikipedia，把概念先熟络起来：&lt;/p&gt;&lt;blockquote&gt;A distributed system is a model in which components located on networked computers &lt;b&gt;communicate and coordinate&lt;/b&gt; their actions by &lt;b&gt;passing messages&lt;/b&gt;.[1] The components interact with each other in order to achieve a common goal. Three significant characteristics of distributed systems are: &lt;b&gt;concurrency of components&lt;/b&gt;, &lt;b&gt;lack of a global clock&lt;/b&gt;, and &lt;b&gt;independent failure of components&lt;/b&gt;. - Wikipedia&lt;/blockquote&gt;&lt;p&gt;其中的的关键词我已经勾勒出来：communication / coordinate，message passing，concurrency，lack of global clock，independent failure。我们看看这些东西，是如何引发不确定性的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;global clock&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们先说说全局时钟 —— global clock。它是分布式系统诸多难题的根源之一。&lt;/p&gt;&lt;p&gt;在单机系统里，无论是 SMP 还是 NUMA，有且只有唯一的全局时钟，这个很容易办到。&lt;/p&gt;&lt;p&gt;时间是什么？抛开相对论，在狭义的局部时空中，时间是因果的表象 —— 一个 cause 引发了一个 effect，这种因果产生了时间的概念：用时间（过去，现在，未来）可以更好地描绘因果。我们在 t0 执行一条指令，t1 得到结果，这结果不可能出现在指令执行之前，这便是时间带给我们的确定性。所以，一个系统有一致的，大家都认可和遵循的时间，非常重要。&lt;/p&gt;&lt;p&gt;在分布式系统里，每个系统都有自己的时钟，即便用 NTP（Network Time Protocol）同步，大家也无法严格步调一致；就算时钟的差异小到可以忽略不计，但取决于带宽，当时的拥塞程度，CPU 的繁忙程度，多个系统互相之间发送消息的延迟还是非常地不确定。就跟一个团队去会议室开会一样，如果都根据自己的手表来决定进入会议室的时间，那么肯定会不一致；即便手表时间一致，大家的走路的速度不同，最终进入会议室的时间，也是不一致。这种不一致会带来很多问题，比如说 out of sync —— 大家都散会了，Alice 才抵达会场，所以她缺失了很多状态的更新，于是她不知道手上的下一件事该做还是不该做。所以在分布式系统里很多时候我们需要一致性，来确保某些东西是有序的，大家在同一个 page，否则这个系统会走入歧途。&lt;/p&gt;&lt;p&gt;要解决因为时钟不同，步调不一致而导致的 out of sync 的问题，我们需要设法形成一个逻辑上的「时钟」，让大家都认可这个「时钟」而不是自己的时钟。这个逻辑时钟的第一个实现是 Lamport timestamps（请记住 Lamport 这位图灵奖获得者，分布式系统的先驱，下文他还会上镜）。Lamport timestamps 学术价值大于实际价值，并没有系统实际使用，然而在它之上演进出的 vector clock 广泛被 AWS S3，DynamoDB，Riak 等系统采用，用于确保同一个 object 的因果关系。我们看看 vector clock 的实现：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4e35e9588c96ff14afd79457d8d3402c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1098&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这个算法的思想很简单：所有 node 都有一个包含所有 timestamp 的 vector，这是个逻辑「时钟」。每个独立的 node 自行处置属于自己的 timestamp，使其有序；但当需要 coordinate 的时候（A 发消息给 B），node A 要发送自己对「时钟」的掌握情况，node B 收到后，更新 vector 里所有比自己已知更大的 timestamp。算法如下（请自行 wiki 以获得更准确的信息）：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;每个 node 都有一个 timestamp vector，初始化为全 0。&lt;/li&gt;&lt;li&gt;如果某个 node k发生了某个事件，将其对应的 vector[k] + 1。&lt;/li&gt;&lt;li&gt;如果 node k 给 node j 发消息，那么先将 node k 自己的 vector[k] + 1，然后将整个 vector 连同 message 一起发给 node j，node j 将自己原有的 vector[j] + 1，再把 node k 发来的 vector 和自己合并（找最大值）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;通过 vector clock，虽然没有绝对的 global clock，但是我们在分布式系统里能够保证因果，从而消灭了在这个维度上的不确定性（还有其他不确定性！）。&lt;/p&gt;&lt;p&gt;我们可以看到，vector clock 的算法严重依赖于节点间的信任，所以它只适用于一个可信赖的分布式环境。而作为运行在节点间互相并不信任的 P2P 网络上的 bitcoin，无法确保这一点。那么，类似 bitcoin 这样的分布式系统，是怎么决定时间（因果）的呢？中本聪在 bitcoin 的设计中，巧妙地应用了 PoW 的产物，block 来作为系统的逻辑时间：&lt;/p&gt;&lt;blockquote&gt;The solution we propose begins with a timestamp server. A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash, such as in a newspaper or Usenet post [2-5]. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash. Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it.&lt;/blockquote&gt;&lt;p&gt;所以，blockchain 不但承载了 ledger 的功能，chain 上的一个个 block 还是一个个 timestamp，代表着这个系统的过去，现在，以及未来，从而协调整个分布式系统步调一致地前进（且让我再奶一下聪哥）。&lt;/p&gt;&lt;p&gt;看到这里，我相信很多人有个疑问 —— 程序君，为什么我做的分布式系统既不用关心 vector clock，也不用 PoW，整个系统也木有 global clock，怎么还一样运行得好好的？没错。你没有感知，并不代表它不存在或者不重要 —— 你的系统里的 postgres，consul，kafka，或者说，分布式系统里一切看似中心化的部分，都使用了类似的机制，只不过它们帮你把这些细节屏蔽掉而已。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;coordination / communication&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;好，了解了 lack of global clock 带来的不确定性，以及如何应对这种不确定性，我们再看分布式系统里下一个会引发不确定性的基础组成部分：沟通协作。&lt;/p&gt;&lt;p&gt;单机系统，协作和沟通也是件轻而易举的事情 —— 同一个线程，在 stack / register 上同步（取决于 ABI）；不同线程，semaphore；不同 CPU，spin lock，memory barrier，反正大家生活在一个屋檐（时钟）下，咋都有办法。&lt;/p&gt;&lt;p&gt;分布式系统下就尴尬了。隔壁老王之所以被称作隔壁老王，是因为你们两家之间至少有一堵墙（住大 house 的有两堵墙），所以在无法四目相对的情况下，你们沟通基本靠吼。吼是个文言文，在现代计算机文明中，我们管它叫：发消息（message passing）。&lt;/p&gt;&lt;p&gt;发消息前先要确保有合适的信道，你得先确保这个信道建立成功并且可以信赖：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-83c6160a3676652306203cc32961411c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1150&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;所谓可信赖，就是消息在网络上不会丢失，我只要发了，对方的 application 就一定能收到（避免下图所示的不确定性）：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5316456228c29586699d879ae35f32f9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;503&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;而且既不会像下面这样乱序，也不会把 partial message 交付给 application（保证消息的完整性）：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8c247c9338359c44b2fae53a0cbc24b8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;632&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;有了可信赖的信道，我们可以通过 message 来达成共识。我们先看两个人达成共识会遇到什么障碍：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5afd121c376187e93527baec6a219a67_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;536&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;发送的节点或者接收的节点可能会 crash —— 即便网络层保证了 application 一定会收到消息，但我们无法避免 application 在处理消息的时候挂掉。因而，message delivery 有两种策略：&lt;b&gt;at least once&lt;/b&gt; 或者 &lt;b&gt;at most once&lt;/b&gt;。at least once 是指同一个消息会被传输 1 到 n 次，而 at most once 是指同一个消息会被传输 0 到 1 次。这很好理解，如果 messaging system 内建了重传机制，并且将消息持久化到磁盘中以保证即便进程崩溃消息依旧能够送达，那么这就是 at least once。反之，如果没有构建任何上述的机制，消息送出后就并不理会，这是 at most once。在一个网络环境中，消息的送达只能是上述两种情况，不可能 exactly once，如果有人这么说，那么一定是在误导。&lt;/p&gt;&lt;p&gt;at least once / at most once 并没有解决不确定性的问题，所以我们还得再努努力 —— kafka / AWS kenisis / AWS SQS 实现了 essentially once 的 message delivery 机制。essentially once 是 at least once 的变种，它需要消息层和应用层同心协力 —— 应用层处理完消息，主动告知消息层，令其删除对应的消息。如果你用过 SQS，应该能感受到这一点：SQS 保证当一个 application 在处理某个消息时，消息对分布式系统里的其他人是不可见的，如果 application crash，消息会在 visibility timeout 后重新可见，如果 application 处理完毕，需要显式地删除这条消息。&lt;/p&gt;&lt;p&gt;最终，我们可以通过消息传递的机制，来达成一致：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-07c7f993fa1ccc7297fa4670c0a9025c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1016&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;到目前为止，我们所谈论的还主要是仅有你和老王参与的 message delivery 的问题。在一个分布式系统里，任意两两节点间都可能有消息往来，而由于缺乏全局的时钟，我们无法保证消息是全局有序的（TCP 只能保证相同发起人发送的消息时有序的），通过 vector clock 或者类似的机制，我们可以进一步保证消息在因果关系上是有序的。这在大多数情况下，已经足够好。&lt;/p&gt;&lt;p&gt;然而，在众多参与者的情况下，即便我们保证了消息局部以及在因果关系上有序，我们还是无法保证所有参与者达成共识。如果大家就该不该做一件事情（比如来了一条数据，怎么写，写到哪，谁来写等）无法达成共识，那么，这样的系统依旧是不确定的。&lt;/p&gt;&lt;p&gt;于是有了 2PC（2 phase commit），3PC，Paxos，Raft 等在可信环境下的共识机制；同样的，对于 blockchain 所面临的不可信环境下（Byzantine General probelm），诞生了 BFT / PBFT，以及 PoW，PoS，DPoS，PoI，PoD，PoDDOS 等一堆 P 字辈靠谱或者不靠谱的共识算法（很快，P 都不够用了）。限于篇幅，关于共识算法，我将另行撰文讨论。&lt;/p&gt;&lt;p&gt;如果你更多了解消息系统及消息传递的 pattern，可以看看我之前的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827495&amp;amp;idx=1&amp;amp;sn=1016abef2a23ab43c6c6253228f7960c&amp;amp;chksm=8704aabbb07323adbfcfcd19b9f65527067f175220b8bf02d86012f96d08ff117255920a82e0&amp;amp;scene=21#wechat_redirect&quot;&gt;ZeroMQ及其模式&lt;/a&gt;（再沉痛悼念一下 Pieter Hintjens）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;分布式系统中的坑&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上文中我们已经把分布式系统中最基本的要素过了一下。接下来我们踩踩坑。&lt;/p&gt;&lt;p&gt;坑一：network is reliable。我们在消息传递中，费尽心思做了很多事情，就是在跟并不 reliable 的 network 斗争。其实 packet loss / out of order 是属于还好解决的问题；不那么好解决的问题是：split brain（脑裂）。split brain 是基于 asymmetric consensus 的分布式系统（亦即常见的 master-slave cluster）的梦魇，一旦 master 过忙，导致 slave 认定它应该卸任，slave 接管后，因为冷启动，也变得太忙，于是又切换回去 —— 于是 master / slave 都在一定时间内异常繁忙，replication 失败，数据出现不一致，接下来双方都认为对方 down 掉，自己成为 master。这就是 split brain。这种级别的问题，修复起来都麻烦（尤其是对于使用了 autoincrement，然后又被 foreign key 引用的数据）。&lt;/p&gt;&lt;p&gt;坑二：消息传递的 latency 可以忽略不计。我们知道网络的 latency 是大致等于两点间距离除以光速。北京到旧金山，极其理想的情况下，一个 round trip 也要 63ms（9516 x 2 / 300, 000），这是一个不小的时间了，如果使用停等的方式互相确认详细，1s 仅仅能打十几个来回。下图是一个完整的计算机系统里各个部分的 latency 的量级的介绍，大家都应该读读，心里有个谱：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-53f2718fba6c8ea3aa4022cd50b8c0de_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1024&quot; data-rawheight=&quot;512&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;坑三：网络带宽不是问题。在 cloud 里，带宽不是问题。但由众多家庭用户参与的 P2P network，带宽，尤其是上行带宽是明显受限的。我家的百兆网络，上行经常也就是 12Mbps。我在上一篇文章 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827914&amp;amp;idx=1&amp;amp;sn=dd991eaef0e108cb9362f6ed9b135bef&amp;amp;chksm=8704a856b073214005b2cc52d2ee7667a02832aa17a676953265b6099696d9dff33fc762ccd0&amp;amp;scene=21#wechat_redirect&quot;&gt;比特币浅析&lt;/a&gt; 里谈到为何比特币使用 1M block，是因为如果这个网络的初衷是所有人都可以参与进来，那么，要考虑到普通用户的带宽承受能力。假设你的电脑费劲巴拉算出一个区块，你要立刻将其广播到 7 个邻居，如果 30s 内完成广播，那么你需要 1.86 Mbps（1MB x 8bit x 7 peers / 30 sec）的带宽；如果 block 是 8M，那么你需要 15 Mbps 的上行带宽。所以，如果设计运行在 cloud 里（&amp;gt; 1Gbps）的分布式系统，可以不必太过在意带宽，但是要做一个人人都用的起的 blockchain，起码不要拍脑门设定 block 大小。&lt;/p&gt;&lt;p&gt;坑四：参与的节点是同构的。像 bitcoin 这样的分布式系统，参与的节点小到手机（钱包软件），大到专门开发的带有 ASIC 或者 GPU 阵列的矿机，不一而足。它们所使用的网络，从 wired，wireless 一路到 cellular，satellite。所以我们要考虑到区别如此之大，范围如此之广的参与者。矿机自然要获取全部数据，但你让手机用户还下载 160G 的 chain，那就是强人所难。bitcoin 对此专门考虑到 blocker headers + merckle tree path + SPV 的方案，允许小型设备只需下载少量数据（几百兆），就可以充当钱包，验证和自己相关的交易。这是我们需要学习的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;CAP 理论&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;分布式系统中，绕不过去的一个话题是 CAP 理论：即对于 Consistency，Availability 和 Partition tolerance，你只能保证其中两个，而牺牲第三个。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-724268f034edc3f4cdc25586f60766a3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1191&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我来简单解释一下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Consistency：所有客户端看到的同样的数据。这里所说的 consistency，是指 atomic consistency (linearizability)。&lt;/li&gt;&lt;li&gt;Availability：每个客户端任何时候都可以读写。&lt;/li&gt;&lt;li&gt;Partition tolerance：当网络出现 partition（split brain）时，系统仍旧可以工作。换句话说，为了能够支持 Partition tolerance，系统需要能够容忍任意多的消息的丢失。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;谈论一个系统是 CA，CP，还是 AP，其实是把复杂的问题过分简化。但分类有分类的好处：它便于比较和记忆。&lt;/p&gt;&lt;p&gt;MongoDB 在上图中被我归到了 CP，这是因为写入是缺省 safe=true，也就是牺牲了 Availability，只能写入 master。然而，这种情况下，MongoDB 仍然难说是 Consistency 的，只有当 readConcern 设为 linearizability，才算得上 Consistency。所以，MongoDB 的 CP 属性很勉强，不同的设置下很难将其归属到某一个分类中。&lt;/p&gt;&lt;p&gt;现在的分布式系统，其实对 CAP 三者都有考虑，只不过是优先级的问题 —— 我更看重哪两个，而愿意牺牲第三个？MySQL 在 master/slave 的配置下，牺牲了 partition tolerance，但我们也可以将其配置成 cluster，牺牲 Availability，才成全 Partition Tolerance。&lt;/p&gt;&lt;p&gt;考大家一个小问题：&lt;b&gt;bitcoin 是 CA，还是 CP，还是 AP？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;先写到这里。有机会再写本文没有展开讲的共识机制，它是分布式系统的基石。&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-03-03-34195307</guid>
<pubDate>Sat, 03 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>比特币浅析</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-02-23-33951079.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/33951079&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0aabab96c27cb225ca66857e4737e5e9_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;与比特币首次结缘大概是 2013 年我结束创业，回到 Juniper 时。有阵子，饭桌上我的同事东哥经常会眉飞色舞地谈起很多关于比特币和中本聪的轶事，还有他做量化交易的有趣经历，并常常劝我也看看这个主题 —— 即便那时我对此并没有太大的感觉。经历过一次如梦般的创业历程，我还在艰难适应朝九晚六的坐班身份，以及，谋划着未来肉身翻墙的事宜。我浅浅看了网上有关比特币的中文资料，简单将其和电子货币画上了等号，根本没有阅读中本聪的论文，也没有关注任何一篇比特币的技术文章，就将其抛诸脑后。&lt;/p&gt;&lt;p&gt;再度被拉回比特币的世界，是去年八九月的事了。有朋想尝试量化交易 —— 我想起了东哥曾经做过这事，又觉得这玩意挺有意思，就拉他一起，业余时间用 elixir 和 datadog 草草做了个 demo（见我的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827794&amp;amp;idx=1&amp;amp;sn=7e968057cf4ba72f775dde454d89a0ce&amp;amp;chksm=8704abceb07322d8bacc40389e4a0fce0955f7da9b72c0c4a4b613541d6fa69fc65234a8567d&amp;amp;scene=21#wechat_redirect&quot;&gt;闲扯比特币套利交易系统的设计&lt;/a&gt;）。后来大家觉得这事投入资金不小，扣除交易手续费后的收益不大，我们又没有太多的时间仔细打磨，就没有继续下去。&lt;/p&gt;&lt;p&gt;这两次和比特币都是擦肩而过，并没有触及其核心，我所有关于比特币和 blockchain 的知识都源自非技术圈的小道消息。直到最近，朋友老冒的 ArcBlock 引起我的注意 —— ArcBlock ICO 公募启动后不到二十分钟便宣告售罄，还因为散客们投资热情过分高涨，让 ethereum tx 大量积压，引发震动。老冒谈起他入坑的心路历程，是这么说的：『一件事情如果我看不懂，要么是这事本身不靠谱，要么是我能力有限，没看透。但是如果靠谱的人做一件不靠谱的事情，那么可能是我错了，事情本身靠谱，我没看透而已。当我微软的同事，我所敬仰的大牛 Flavien Charlon 也出来做 colored coin 时，我被震动了。我开始严肃看待 blockchain。』&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f1469d6325725d55dbcf331e5c49028e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;810&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;（ethereum tx 拥塞）&lt;/p&gt;&lt;p&gt;我一时呆若木鸡，我对比特币和 blockchain 技术的漠不关心，是否也是我并没有看懂看透这本来靠谱的技术？在老冒的鼓动下，我决定真正深入 blockchain 的技术细节，去探究这种让牛人纷纷为其痴迷（我指技术上）的真正原因。我圈了一批 paper 和白皮书，下载了若干源码，找了若干文章后，开始在周末的时间里撸袖子看起来。在草草一刷比特币创世论文（Bitcoin: A Peer-to-Peer Electronic Cash System），一些白皮书，还有各种文章和视频后，我越来越觉得我有必要把那些基础的问题搞懂 —— 尤其是在主流的技术解读都是流于表面的情况下，比如说：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为什么用 PoW？&lt;/li&gt;&lt;li&gt;blockchain 的数据结构长什么样子？&lt;/li&gt;&lt;li&gt;为什么一个 block 要设计成 1M，而一个 block 生成的时间限定为 10min？超过或者小于这个时间怎么办？&lt;/li&gt;&lt;li&gt;为什么币的总量 21M？（为什么 TM 不是 2 的幂？或者一个更大/更小的数字？）&lt;/li&gt;&lt;li&gt;tx 为何设计得如此奇特，可以多 input 多 output？&lt;/li&gt;&lt;li&gt;为何 verification 这样一个看似简单的过程要用 opcode 来完成？&lt;/li&gt;&lt;li&gt;如果使用 open ledger，security 和 privacy 是如何保证的？&lt;/li&gt;&lt;li&gt;WTF base58？&lt;/li&gt;&lt;li&gt;为什么钱包不直接用 public key，而是 hash 一下多此一举？&lt;/li&gt;&lt;li&gt;为什么会允许不包含任何 tx（除了 incentive tx 外）的 empty block 存在？为什么大家不借此 game system，获取先发优势？&lt;/li&gt;&lt;li&gt;钱包是怎么回事？钱包需要整条链的数据么？&lt;/li&gt;&lt;li&gt;量子计算是否是比特币的终结？&lt;/li&gt;&lt;li&gt;为什么，为什么一个 2008 年的学者，能如此清晰冷静地面向未来思考，面向未来编程？十年后，他所提出的架构仅仅是小修小补，作为一个 ledger，并无大的问题（Ethereum 解决的问题 bitcoin 本来也没打算解决）？&lt;/li&gt;&lt;li&gt;…&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这个问题列表几乎是无穷的。带着这些令人兴奋的问题，我重读了中本聪的论文。和上一次的漫不经心相比，这次，我几乎是跪着读完的。为了吃透小小的 8 页文字，我还翻阅了不少他当年向旁人解释论文的邮件（感谢 mail-archive），以及 V 神早期对此解读的一些文章。我发现我陷入了 the more you know, the more you don’t know 的狂喜 —— 有点 Alice 掉进 rabbit hole 的感觉，或者，一种言语难以形容的 serendipity。我终于从以前那种懵懂无知，步入到了知耻后勇的境地。&lt;/p&gt;&lt;p&gt;按照我的 learning by teaching 的尿性，二刷比特币创世论文后，我便忙不迭地做了 slides，给 team 讲 bitcoin 里面那些激动人心的思考和实现。slides 我就一一不贴了，下面是其中一页：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3c857f9b2f0b9c9c4d6d8f6eda90d16b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1138&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;单单就这一页，就有好多好多值得问的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为什么这个数据结构里面的值要用 little endian？这是设计缺陷还是别有用心？（别轻易下结论，考虑约定俗成的网络序都是 big endian）&lt;/li&gt;&lt;li&gt;为什么计算 nounce 时，不用整个 block，而是选择了这些域（尽管 integrity 还是通过 merkle root得到了保证）？&lt;/li&gt;&lt;li&gt;为什么要费力把 tx 组织成 Merkle Tree 的形式？&lt;/li&gt;&lt;li&gt;…&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不多说，大家自行去 &lt;a href=&quot;https://github.com/tyrchen/unchained&quot;&gt;github.com/tyrchen/unchained&lt;/a&gt; 下载阅读（我会根据我所学随时更新它）。&lt;/p&gt;&lt;hr&gt;&lt;p&gt;说些题外话。互联网时代，做网络协议开发的工程师（简称网工）是个吃力不讨好的差事。价值链的上移让网络设备和基础设施管道化，应用赚够了钱而基础设施也就温饱。虽然不应该用「造原子弹的不如卖茶叶蛋的赚钱」来比喻，但有着十年经验的网工收入比不过两三年经验的脚本小哥是不争的事实。论工作的难度，常年跟红黑树，skiplist，ager ring，hash table 打交道，写段代码不得不考虑 endian issue，定义个数据结构要想着 fit in cache line，有时恨不得一个 bit 一个 bit 扣的网工，要比不管三七二十一，什么都塞到一个 object (dict/map) 里，cache line 啥玩意没听过，传个 bit 都用 json 的脚本小哥工作起来困难的多。可惜的是，你不在价值链的上游，你所有的努力，所有的 proof of work，在互联网，移动互联网的浪潮里，好像荷叶上泻过的水，留不下一点痕迹。这很不幸，但这就是现状。&lt;/p&gt;&lt;p&gt;然而 blockchain 在试图扭转这个价值链，让网络层和传输层，而不是应用层，重新变得重要起来：在这次洪流中，网络开发（及系统开发）的价值重新凸显 —— 你看，比特币的设计中处处体现着对网络的深刻理解，对内存的精妙使用，对数据结构和基础知识的无比重视 —— 别的不说，光是 block header 的结构，那个 0xD9B4BEF9 的 magic number 就让人嗅到了初恋的味道（0xdeadbeef，你丫可好？）&lt;/p&gt;&lt;p&gt;所以，blockchain 可能是网工最好的翻身仗 —— 上不上车不重要，先入坑吧，搞些技术储备总归是好的。没准就相当于 44 年入党了呢？&lt;/p&gt;&lt;p&gt;（谨以此段题外话献给那些和程序君打过交道的，或者没打过交道过的网工们）&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-02-23-33951079</guid>
<pubDate>Fri, 23 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>猿来三十五</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-02-14-33817588.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/33817588&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1b8300ea0c204d30c6b865581b567821_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本命年，人生的第四个 iteration 已经开启。今天被朋友发的一段文字给戳中了，本来想胡乱写点什么纪念一下，结果 gitbook init 生成的 36-years.md 前，静静躺着一个 35-years.md。打开看看，才忆起这是去年生日前后胡乱写的文章，不知怎的，写下一半便就此搁笔，只是把其中的一个片段单独成文，标题是：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827599&amp;amp;idx=1&amp;amp;sn=978fe8d2cf396a814463552ab2fac97b&amp;amp;chksm=8704ab13b0732205007723b246a744102624053b95c49b7a5e8b3df2f4ca505656c679516bfb&amp;amp;scene=21#wechat_redirect&quot;&gt;标签&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;痴长了一岁，更加豁达了些，勇敢了些，脸皮也因着加州的阳光晒厚了些，所以，36-years.md 暂时不写了，把 35 岁的我拎出来溜溜。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;（一）&lt;/p&gt;&lt;h2&gt;&lt;b&gt;无可奈何花落去&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这个二月，对我的整个人生而言，是一个特殊的月份，因为，我终于要跨过那个程序猿们闻之变色的三十五岁魔咒了。&lt;/p&gt;&lt;p&gt;在程序猿的远古年代（89-05），坊间流传着这样一个魔咒：程序猿这种职业，干不过三十五。换句话说，三十五你还没转不写代码「只动动脑子」的 architect，PLM，或者转不写代码「只动动嘴皮子」的 manager，sales，那么你一定会被25岁的后浪拍死在沙滩上。&lt;/p&gt;&lt;p&gt;十几年前，我真的为这事惶恐过。在回龙观居住的日子里，案头和书柜里摆满了企业管理的书。附在案几上，我时常想，努力个九年，在三十岁前，逃离做码农的苦海。啊，对了，上古年代程序猿好像还不被称为码农，倒是 CSDN 上一篇文章 「程序员和妓女」，把程序员这个在国内仅仅诞生十余年的职业硬生生拔高到和那个最古老的职业一样香艳的位置。&lt;/p&gt;&lt;p&gt;三十岁前，我还真如愿以偿，做上了 manager。我喜欢管理的工作，喜欢定战略，搭班子，做产品的挑战，喜欢将周围的人培养起来的那种成就感，但不知怎的，我还是不愿放下手中的键盘。当平日的工作渐渐不允许我写代码时，我开始利用周末，或在国图，或在清华科技园，挤出时间写上些许代码，聊以自慰。这种状态有时候让我揪心：我的这种游移究竟是被内心对 coding 的热爱所驱使，还是出于对脱离一线，未来可能「绕树三匝，无枝可依」的恐惧？&lt;/p&gt;&lt;p&gt;我们知道，尽管驱动力不同，爱与惧都能起到激励作用，让人干好一件事。但我不希望生活这五光十色的大泡泡被戳破后，溅出的都是对未来的恐惧。如若这样，那还不如当机立断，换个真正喜爱的职业，开开心心地施展抱负，而非战战兢兢地守候。&lt;/p&gt;&lt;p&gt;幸运的是，后来在创业的日子里，我在创新工场遇到了远古时代被敬为天人的程序员：简晶。如果你听说过 UCDOS 和联众，那么你应该能够回忆起这个名字。那时他已经早早地跨越了三十五岁魔咒 —— 在结束联众的创业后，他做了一段时间的天使投资人，然后开始做一个叫「拨号精灵」的项目。和他寥寥几次对话中，我得知，他还在写代码。后来我看到一篇对他的采访的报道，心有戚戚，便誊了下来：&lt;/p&gt;&lt;blockquote&gt;离开技术已经有十年左右了，但是当我再次接触技术的一瞬间，所有东西都回来了，好像我从来没有离开过，那些东西可能是被我刻意掩盖的。我最终决定跟随内心的指引，选择继续回到过去的生活方式，而不是去做一个旅行家，天天过着“另类”的日子。&lt;/blockquote&gt;&lt;p&gt;我的心结彻底被解开了。从那时起，我不再游移彷徨。三十五岁魔咒，至少，和我无关。&lt;/p&gt;&lt;p&gt;（二）&lt;/p&gt;&lt;h2&gt;&lt;b&gt;十年一觉扬州梦&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;人生在世，不得已被打上许多标签。有些人的被他们的朋友打上了高富帅，白富美的标签。而朋友们给我打的标签是：土肥黑圆 —— 土肥圆的黑化加强版。&lt;/p&gt;&lt;p&gt;在工作中，我当下被贴上的标签是 VP。VP 是个感人的标签，因为它 P 都不是。&lt;/p&gt;&lt;p&gt;在公众号上，我的标签是程序君。程序君，程序君，听上去儒雅倜傥，羽扇纶巾，谈笑间，八阿哥灰飞烟灭。可读者给我的画像是：一个岣嵝着背，扶着厚厚的镜片对着屏幕上的代码流哈喇子的中年抠脚大叔。&lt;/p&gt;&lt;p&gt;回到家里，我的标签总算变得尊荣起来。女儿动不动就封我做国王，因为这给她当 THE princess 法理上铺平了道路。为了这个高贵的标签，我得付出一点点微不足道的代价：她不当公主的闲暇，我需要随时变身为她的坐骑 —— 就是那种趴在地上摇头晃脑，看上去比牛魔王的碧水金睛兽智商略高的萌物。&lt;/p&gt;&lt;p&gt;标签是个很有意思的存在，每个人终其一生都在为了一个又一个的标签而奋斗。别以为自己淡泊名利，无欲无求就没标签，也许你不自觉得给自己打上了 :“赛刘伶”，而你的朋友们私下里亲昵地称你为 :“八戒”。&lt;/p&gt;&lt;p&gt;过去的十余年，我很努力，也很幸运，先后为自己打上了 :husband， :manager，:inventor，:“房奴”，:father，:entrepreneur，:author，:“硅谷码农” 等标签。&lt;/p&gt;&lt;p&gt;然而，标签就跟用过的卫生巾一样，无论之前是多么的洁白光鲜，用过了，履行了它的历史使命，就该扔进垃圾桶，封存在故纸堆里了。一个人不该守着她们让其变成生活的全部 —— 人生还有辣么多新标签去夺取哩！这一点，我得像老费学习 —— 他那闪瞎我的狗眼的大满贯奖杯是儿女们嬉戏时的玩具，而不久前费了九牛二虎之力拿回了丢失了七年之久的澳网奖杯，女儿们却大咧咧地想用它盛汤。&lt;/p&gt;&lt;p&gt;（三）&lt;/p&gt;&lt;h2&gt;&lt;b&gt;任陌头、年少争旗鼓&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;生活是一场接着一场地赶路。经常旅行的人都有一个感受：要用最好的心情接纳最糟糕的事件。因为你很难预料一路上会发生什么。&lt;/p&gt;&lt;p&gt;07年，我和老婆去欧洲旅游，开车从德国过境奥利地时，天气突变，原本湛蓝的天空被一大片黑云裹盖，暴雨如尼亚加拉大瀑布一样倾泻而下，下午四五点的大白天瞬间裹上了黑幕，像是深夜时分。过境时，我们本打算在边境处的休息站歇息片刻，再去下一个目的地，但临时变了主意，想一鼓作气结束战斗，不料却被暴雨困在了高速路上艰难前行。当时雨大到雨刷器最大档疯狂工作都无法让雨水短暂让出视线，而能见度差到只能靠分辨前车微弱的灯光来确保自己的车道。就这么屏着呼吸战战兢兢地开了约莫半小时，天际出现了一条奇妙的分隔线，一半湛蓝，一半黝黑，远处挂着一道美丽的彩虹，和高速路边鳞次栉比，绿意浓浓的小村子相互辉映，美得让人动容。旅途中的惊心动魄换来了难得一见的美景。&lt;/p&gt;&lt;p&gt;但生活中很多时候不会给你这种 happy ending。有时候赶路走了半天又回到了原点，苦心经营却一无所获。然而这好比香料，捣的越碎，磨得越细，香得越浓烈。乔布斯讲 connecting the dots，我是岁数越大，对此就越有感触。&lt;/p&gt;&lt;p&gt;一五年十一月某个阳光明媚的周五，我休了假。把小宝送去幼儿园后，我跟老婆沿着 Cupertino library 附近的一条小路漫无目的地散步。蓝蓝的天，路两旁醉人的红叶，书写着秋景瑰艳。我们难得放松，挽着手享用属于我们的即将变得稀缺的二人世界 —— 隔周的周一，我就要去 Tubi TV 报道，重新回到忙碌的 startup 的世界。未来有多少艰难险阻，谁也不知道。&lt;/p&gt;&lt;p&gt;现在再回想这一年多的征途，我竟然就这么熬了过来：我熬过了加入早期几乎每晚黄金时段准时来一发的 outage；熬过了把整个 API 系统重写的艰难时刻；熬过了同事来来走走；熬过了每天三个半小时的通勤；熬过了一个又一个 offer 对我的诱惑，甚至，熬到了娃儿上 pre-K 的年龄。&lt;/p&gt;&lt;p&gt;冯仑说伟大是熬出来的。熬即坚持。本来普普通通的事情，坚持让其变得与众不同。我写了三年公众号，这三年写下的这些文字，成就了我；我跑了三年步，现在仍坚持跑着。写字和跑步本身没什么特别的意义，只是坚持赋予了它不一样的意义。在这些日复一日，周复一周的坚持中，我的雄心不会被生活中的起起伏伏所磨平，我的热情也不会因他人的看法而高涨或者消亡。如果说早期我写文章还总去迎合一些热点，现在我写的时候一定是我想写的时候，写出来上万阅读的文字，固然很好，如果只有寥寥数百的阅读，我也不会因此沮丧而切换话题。&lt;/p&gt;&lt;p&gt;这就跟我选择用 Elixir，用 Clojure 做一些喜欢的事情一样。我喜欢他们，是因为我真的喜欢他们，无关大众小众，无关工作机会或者薪水多寡。&lt;/p&gt;&lt;p&gt;（去年的文字，并未真正完结，现在即便给它补写下去也顶多是狗尾续貂，因为心境不同了。所以未完就未完吧，咱们不待续）&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-02-14-33817588</guid>
<pubDate>Wed, 14 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>分布式系统中的监工：Overseer</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-02-13-33801389.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/33801389&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ec12887ca7a1aaec76fef31ff8ac4b60_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;最近从无趣的工作中发现了有趣的事情，工作和业余时间都扑了些精力上去，本待上周末最终的成果出来后再写文章的，无奈事情太多，代码还没写完，二月上旬已过，再不写文章春节就过去了，所以这次程序君先上车，再补票。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;需求&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;事情是这样的：两周前同事催促我升级我之前做的一个轮子 merlin - 见我去年的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827801&amp;amp;idx=1&amp;amp;sn=7ac5e18b2330feab536bda1c0c803adc&amp;amp;chksm=8704abc5b07322d32d72260f6ab1f450a8df88db9015dcc195f54073cc831ca01d3c9d6ec650&amp;amp;scene=21#wechat_redirect&quot;&gt;停下来，歇口气，造轮子&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在那篇文章里我提到了为什么会有需要做这样一个内部的 release 构建工具。自那时起，merlin 为我们内部的几个 elixir service 的 release 保驾护航几个月，总体表现不错。然而，当时在需求和设计上的一些缺陷，导致这款产品有这些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;太依赖 github release —— 如果不生成新的 release，就无法自动构建。这对依赖 staging 进行集成测试的服务不友好。使用者需要在 pull request 里升级版本（才能生成一个 build）。因此，多个开发者间需要在 pull request 中把版本错开，很不方便。开发频繁的时候，我们一天的 patch version（SemVar 里第三位），五个十个地狂跳，比旧金山 TaxiCab 的计价器跳动还要可怕。&lt;/li&gt;&lt;li&gt;merlin 使用的两台机器都是 t2.medium，一次 release build（还包括一次 release upgrade build）花费十来分钟。当构建繁忙的时候，在队列后面的请求要很久才能排到（Latency 不友好）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;所以我要在下一个版本中，将这些问题解决。初步的考虑是，当构建请求来临时，启动一个强大的 spot instance，处理构建任务，构建完成并上传 S3 后，spot instance 自行了断。构建请求可以是来自 github release message（兼容上一版本），也可以是 API —— 进而，我们可以制作 CLI 工具，让用户在 shell 下对任意 git commit 触发构建。有了粗浅的想法后，我们理一理需求：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户（包括 github）可以通过 API 触发构建&lt;/li&gt;&lt;li&gt;构建被触发后，启动一个 spot instance（或 ECS fargate，不过 spot instance 实在太便宜了，如 C5.large $0.03/hour，所以 ECS 没有啥价格优势）&lt;/li&gt;&lt;li&gt;spot instance 基于一个 prebuild 的 AMI（如果 ECS，则 docker）启动，AMI 里包含处理构建的软件。这样启动起来之后，就能自动处理构建任务&lt;/li&gt;&lt;li&gt;描述构建任务的 metadata 放置于 spot instance 启动时的 user data 中，构建软件通过 &lt;code class=&quot;inline&quot;&gt;http://169.254.169.254/latest/user-data&lt;/code&gt; 访问之&lt;/li&gt;&lt;li&gt;构建过程中可能要发送一些 telemetry 到 merlin&lt;/li&gt;&lt;li&gt;构建完成，把状态和构建的信息（比如 tarball 在哪里）发回给 merlin，然后自尽&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这个需求算是比较清晰，实现起来也没有什么难点，无非就是时间问题 —— 对于像我们这样的 startup 来说，它是可以立即撸起袖子干活，逢山开路遇水填桥的那种活儿。&lt;/p&gt;&lt;p&gt;merlin 之前的坑是我埋的，这个业务即不性感，也不紧急；backend 的队友们都扑在一些 visibility 高的，光是名字听起来就热血沸腾的项目上，腾不出手，且我也不舍得就这么浪费他们的时间 —— 所以我只能 eat my own dogshit。我这人白天瞎忙，晚上躲懒 —— 除非有什么能戳到 G 点让我不吃不喝不睡觉也要搞的创意，否则像 merlin 这种一眼就从头看到脚，没有太多挑战的项目，激发不出我的小宇宙。于是需求定下，反正也不着急，我就懒懒地，有一搭没一搭地在脑海中想着。&lt;/p&gt;&lt;p&gt;事实证明，这种懒散，而非全力以赴，促成了我更多，更深的思考。有功夫我把整个思考的过程撰写成文，相信对大家也能有小小的启发。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在上面的需求中，merlin 由一个服务被拆成了两个部分：control plane 和 data plane（请饶恕一个曾经的网络工程师对区分路径的这种骨子里的执着）。简单来说，control plane 负责派活和监控，是个 scheduler，类似于老鸨；data plane 负责干活，是一堆 resource，就好像苏小小，柳如是，李师师们。而一个个构建任务，是要完成的 task，就是赵佶，柳永，阮郁等的不期而至。&lt;/p&gt;&lt;p&gt;把 merlin 的需求稍稍泛化一下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用者可以通过 API 触发一个 task&lt;/li&gt;&lt;li&gt;Control plane 接到 task 后，分配到 data plane 上的某个 resource 上执行&lt;/li&gt;&lt;li&gt;data plane 向 control plane 汇总 telemetry&lt;/li&gt;&lt;li&gt;data plane 完成 task 之后，向 control plane 汇报结果，进入到 idle 状态等待下次调度&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了符合社会主义核心价值观，我们换个比喻：Control plane 类似于 erlang/OTP 里的 Supervisor；data plane 类似于 GenServer。对于 erlang 不太熟悉的同学可以看我的文章：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3NDM0ODQwMw==&amp;amp;mid=2649827691&amp;amp;idx=1&amp;amp;sn=8d6854f91bb9d16470ef6eed9d3ad8ec&amp;amp;chksm=8704ab77b0732261eb63217ad03740a3433cde4491826eeec020f4bbebb8b18837c27ac3e74d&amp;amp;scene=21#wechat_redirect&quot;&gt;上帝说：要有一门面向未来的语言，于是有了 erlang&lt;/a&gt;。你不必理解代码，但需要理解思想。&lt;/p&gt;&lt;p&gt;然而，erlang/OTP 里的 Supervisor 只负责启动和监控 process，如果要启动和监控 node，有很多问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如何在 cloud 里动态启动一个节点？&lt;/li&gt;&lt;li&gt;如何让这个节点自动加入到 cluster 里？&lt;/li&gt;&lt;li&gt;如何让这个节点有运行 task 所必须的软件？&lt;/li&gt;&lt;li&gt;control plane 如何和 data plane 方便地通信？&lt;/li&gt;&lt;li&gt;如何把上面的所有细节屏蔽起来，启动和监控一个节点，像 Supervisor 启动和监控一个 GenServer 一样简单，且对程序员友好？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;1/2/3 如果解决，4 可以直接通过封装 RPC 解决。&lt;/p&gt;&lt;p&gt;2 我们上文中提过 —— 我们可以通过给新启动的 instance 提供 UserData 来解决 —— 在 AWS 里，当我们启动一个新的 instance，可以预设一些 json 数据进去，本地访问 &lt;code class=&quot;inline&quot;&gt;http://169.254.169.254/latest/user-data&lt;/code&gt; 即可获得，因而，我们可以把 cluster 的 cookie，control plane node 的 node name 都放进去，以便于新的节点可以自己加入 cluster。&lt;/p&gt;&lt;p&gt;我们看 1 和 3。最简单解决 1/3 的方法是使用 prebuild AMI —— 把所有相关的，处理 data plane 的软件都烧到 AMI 里，用 request-spot-instance 的 AWS API 创建节点即可。不过，这意味着每次 data plane 的代码改变，我们都要重烧 AMI，即便烧 AMI 的动作 CI 自动化处理了，每次 control plane 还是需要确保使用正确的 AMI 启动 data plane。有些麻烦。&lt;/p&gt;&lt;p&gt;程序员最不爽的就是麻烦。&lt;b&gt;虚心使人进步，麻烦让程序员创新&lt;/b&gt;。咋办？我们能不能做个 loader，把一个编译好的 module，甚至一个 release 动态加载到远端的一个 node 上？&lt;/p&gt;&lt;p&gt;bingo！这是一个好问题，而&lt;b&gt;好问题的价值远胜于好的答案&lt;/b&gt;。于是大概两周前的一个周末，我写了几百行代码，做了一个初始版本的 ex_loader。见 github: tubitv/ex_loader。代码已开源，MIT license。&lt;/p&gt;&lt;p&gt;ex_loader 让你可以很简单地干这样的事情：&lt;/p&gt;&lt;code lang=&quot;elixir&quot;&gt;{:ok, module} = ExLoader.load_module(&quot;hello.beam&quot;, :&quot;awesome-node@awesome.io&quot;)

:ok = ExLoader.load_release(&quot;https://awesome.io/example_complex_app.tar.gz&quot;, :&quot;awesome-node@awesome.io&quot;)&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;你即使不理解 elixir 代码，大概也能猜到第一句它将一个本地的 module 加载到同一个 cluster 里的叫 awesome-node@awesome.io 的节点上；第二句，则将一个在某个 website 上的 erlang release，加载到相同的节点上。&lt;/p&gt;&lt;p&gt;Joe Armstrong 曾经在一次会议上开心地谈到过他自己会在 erlang node 上运行很多空的，什么也不做，也不知道该做什么的 process，但当他有需要的时候，让这些 process 加载新的 module，就摇身一变让其成为拥有某种特定功能 process。ex_loader 在此基础上更进一步，你可以开一些空的 erlang node，有需要的时候，让这些 node 加载你想让其运行的 release，使其成为特定功能的 server。&lt;/p&gt;&lt;p&gt;ex_loader 简化了 control plane 往 data plane 发布软件的工作，我们有了一个更好的解决 1 和 3 的方案。然而，我们还没有触及到上文中所提到的 5。&lt;/p&gt;&lt;p&gt;这就是 Overseer，一个新的，类比 Supervisor 的 OTP behavior。我们先看怎么用 Overseer：&lt;/p&gt;&lt;code lang=&quot;elixir&quot;&gt;local_adapter = {Overseer.Adapters.Local, [prefix: &quot;test_local_&quot;]}
opts = [
strategy: :simple_one_for_one,
max_nodes: 10
]
release = {:release, OverseerTest.Utils.get_fixture_path(&quot;apps/tarball/example_app.tar.gz&quot;)}
MyOverseer.start_link({local_adapter, release, opts}, name: MyOverseer)
MyOverseer.start_child()&lt;/code&gt;&lt;p&gt;定义一个 Overseer 很简单：&lt;/p&gt;&lt;code lang=&quot;elixir&quot;&gt;defmodule MyOverseer do
 use Overseer
 require Logger
 
  def start_link(spec, options) do
    Overseer.start_link(__MODULE__, spec, options)
  end
 
  def init(_) do
    {:ok, %{}}
  end
  
  def handle_connected(node, state) do
    Logger.info(&quot;node #{node} up: state #{inspect(state)}&quot;)
    {:ok, state}
  end
 
  def handle_disconnected(node, state) do
    Logger.info(&quot;node #{node} down: state #{inspect(state)}&quot;)
    {:ok, state}
  end

  def handle_telemetry(_data, state) do
    {:ok, state}
  end

  def handle_terminated(_node, state) do
    {:ok, state}
  end
  
  def handle_event(_event, _node, state) do
    {:ok, state}
  end
end&lt;/code&gt;&lt;p&gt;我们大概讲讲 Overseer 干些什么：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;start_link：启动时，它接受一些参数，关于我们要启动的 node 的 spec。node 目前支持两种 adapter，local 和 ec2。我将其做成 adapter，是为了日后支持更多类型的 node（比如 ECS）。strategy 目前仅支持 simple_one_for_one，亦即所有 node 使用相同的 spec，在需要的时候由 Overseer 创建。&lt;/li&gt;&lt;li&gt;start_child：Overseer 可以根据预置的 spec 启动一个 node —— 比如 ec2 spot instance。这个 node 启动成功之后，初始的代码会使用 UserData 里面的 node_name 和 cookie 连接 Overseer。当 Overseer 监测到一个 node_up 的消息后，会在内部创建一个 Labor 的数据结构，并且把 spec 里面定义的 release 发给这个 labor node 加载和运行。&lt;/li&gt;&lt;li&gt;pairing：比 Supervisor 复杂的是，Overseer 不但需要监听 node up / down 的事件，做相应的决策（比如重启一个新的 node）外，还需要接受 node 传过来的 telemetry，所以 Overseer 所在的 process 要和 labor node 上面的某个 process 建立起关系。我把这个过程称作为 pairing，类比蓝牙设备间的配对。当 start_child 成功后，Overseer 会把自己的 pid 发送给 labor node 上的一个指定的接口，然后 labor node 会在这个接口里显示地给 Overseer 发送 pair 请求，之后，两个 process 就 link 起来。&lt;/li&gt;&lt;li&gt;作为一个类似于 Supervisor 的 GenServer，Overseer 把 labort node 监控的细节和状态机都屏蔽掉，只暴露 connected / disconnected / telemetry 等一些上层软件关心的事件。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下图是大概一周前我手绘的 sequential diagram，当时名字还不叫 Overseer，叫 GenConnector，但基本思路一致：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4a26027f4ca5d6007042928393151503_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1092&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;Overseer 的源码会在这几天完成后释出，敬请期待。&lt;/p&gt;&lt;p&gt;有了 ex_loader 和 Overseer，merlin 剩下要做的事情就简单很多了：把代码库分割成 control plane 和 data plane，control plane 用 Overseer，data plane 沿用之前的代码，稍作修改后我们就有了一个分布式的，可以随意 scale 的构建系统。&lt;/p&gt;&lt;p&gt;最妙的是，ex_loader 和 Overseer 虽为 merlin 而生，却由于不错的抽象程度，能适用于几乎任何 control plane + dynamic data plane 的这种分布式任务处理结构。在我之前的思考中，其实还更进一步，将这个系统设计成了一个叫 Fleet / Carrier / Fighter 结构的分布式系统，Carrier 是 Fleet 的 labor node，Fighter 是 Carrier 的 labor node，类比 Star War 中的帝国舰队。在这个蓝图中，merlin 只是 Fleet 的一个 Carrier 而已（这个估计短期没工夫实现）：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5c30c89f9e919e0a8fe85aa3a1f9d8d7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;630&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;好了，不说废话了，我还是抓紧写代码去。提前祝各位叔叔阿姨哥哥姐姐弟弟妹妹，春节快乐！也祝各位同处本命年「伏吟」的小伙伴们，狗年红红火火，不犯太岁！:)&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-02-13-33801389</guid>
<pubDate>Tue, 13 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>谈谈调度 - Linux O(1)</title>
<link>https://henix.github.io/feeds/zhuanlan.prattle/2018-01-31-33461281.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/33461281&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a9fb27eefa9612d39a7626ea10a19eb5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;约莫十五年前，当我刚刚开始参加工作时，赶上 Linux 发布划时代的 2.6 内核。在这个大家都翘首期盼的内核版本中，最令人兴奋的便是 O(1) scheduler。本文来谈谈这个算法是如何实现的。不过，在详细讲解 O(1) scheduler 之前，我们先简单回顾一下让人诟病许久的 2.4 scheduler，了解其传承，同时以史为镜。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2.4 scheduler 的问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Linux 2.4 scheduler 支持 SMP（Symmetric Multi-Processing），然而，由于只用一个 global runqueue，各个 core 需要竞争同一个 runqueue 里面的任务，所以可伸缩性（scalability）不好。我在上一篇文章中提过：&lt;/p&gt;&lt;blockquote&gt;任务如何组织？是所有的资源共享一个任务的 runqueue，调度器调度时通过加锁来保证互斥，还是针对每个资源，我们都为其设置一个 runqueue，以减少锁带来的损耗？那么问题又来了，如果某个资源上的任务列表空了，资源是就此闲置，还是可以去别的资源的 runqueue 上「偷」任务给自己执行？&lt;/blockquote&gt;&lt;p&gt;这个问题 2.6 O(1) scheduler 用 per core runqueue 解决这个问题，我们放下不表。&lt;/p&gt;&lt;p&gt;global runqueue 带来的性能问题其实还可以忍受，毕竟只是在 dequeue 的过程需要加锁；接下来这个问题，就很要命 —— 2.4 scheduler 的时间复杂度是 O(N)。我们知道，现代操作系统都能运行成千上万个进程，O(N) 的算法意味着每次调度时，对于当前执行完的 process，需要把所有在 expired queue 中的 process 过一遍，找到合适的位置插入。这不仅仅会带来性能上的巨大损失，还使得系统的调度时间非常不确定 —— 根据系统的负载，可能有数倍甚至数百倍的差异。我们知道，不确定性是软件系统的大敌，尤其是实时系统。&lt;/p&gt;&lt;p&gt;对于那些对2.4 scheduler 不太了解的同学咱们多说两句：2.4 scheduler 维护两个 queue：runqueue 和 expired queue。两个 queue 都永远保持有序，一个 process 用完时间片，就会被插入 expired queue；当 runqueue 为空时，只需要把 runqueue 和 expired queue 交换一下即可。&lt;/p&gt;&lt;p&gt;注意，所有调度系统的难点不在于寻找下一个可执行的 process，这个操作一般都是 O(1)，因为我们只要妥善对 runqueue 排序，使其第一个 process 永远是下次需要调度的 process 即可。难点在于执行完的 process —— 怎样插入到合适的位置使得 runqueue 是有序的？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;满足 O(1)&lt;/b&gt; &lt;b&gt;的数据结构？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;根据我们在数据结构课程里学到的知识可以知道，大多数算法的时间复杂度，O(log N) 基本上就是最好的结果，那么，2.6 的 O(1) scheduler 是怎么做到的？&lt;/p&gt;&lt;p&gt;在回答这个问题之前，我们先回顾一下数据结构的四种基本操作以及其时间复杂度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;access：随机访问。array 是唯一能够达到，且平均情况和最坏情况均能达到 O(1) 随机访问的数据结构。其它的结构，linked list 是 O(N)，tree 一般是 O(log N)。&lt;/li&gt;&lt;li&gt;search：搜索。谈到搜索，大家第一反应是 hash table 是 O(1) 时间复杂度的。然而，它在最坏情况下是 O(N) 的。除此之外，没有任何算法能在最坏情况下 search 也是 O(1)。大部分 tree（b-tree / red-black tree）平均和最坏情况都是 O(log N)，其实很不错了。&lt;/li&gt;&lt;li&gt;insert/deletion：插入和删除。插入删除是对等的操作，这里放在一起讲。linked list，stack，queue 在平均和最坏情况下都是 O(1)，而大家脑海里的 hash table，同样的，虽然平均是 O(1)，但最坏情况是 O(N)。大部分 tree（b-tree / red-black tree）平均和最坏情况都是 O(log N)，也还不错。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以我们看到，如果想要达成 O(1) scheduler 的目标，操作只能包含纯粹的 access，insert 和 deletion。一定不能有 search。2.4 scheduler 在将执行完的 process insert 回 expired queue 时使用 search，大大拉低整个算法的时间复杂度。这是其一。&lt;/p&gt;&lt;p&gt;此外，对于 scheduler，我们选择算法，尽量要选择平均情况和最坏情况表现一致的算法。如果平均情况是 O(1)，最坏情况是 O(n)，那么这个 scheduler 会给系统带来很大的不确定性，这很伤脑筋 —— 毕竟谁也不愿意面对一个大部分时候表现乖巧，极端情况抽风到不可理喻的系统。这是其二。&lt;/p&gt;&lt;p&gt;在这两个先决条件下，我们可选择的范围就很窄 —— access 只能用 array，insert / deletion 只能用 linked list / queue / stack。&lt;/p&gt;&lt;p&gt;接下来，我们把调度的场景简化一下：假设系统中有六个 process，三种优先级：high，medium，low。没有 preemption，严格按照优先级的顺序执行 process。那么，我们怎么组合上述的数据结构，让 scheduling 是 O(1) 的？&lt;/p&gt;&lt;p&gt;思考一下。&lt;/p&gt;&lt;p&gt;再思考一下。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2.6 O(1) scheduler&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;OK，我们直接看看大神给出的是什么样的答案。先看图：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-729fb18fa3ac1e41beff0fcd817c92a6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1170&quot;&gt;&lt;p&gt;看到这里，估计有部分读者已经领会到其中的奥义。2.6 kernel 里有 140 种优先级，所以我们就用长度为 140 的 array 去记录优先级。每个优先级下面用一个 FIFO queue 管理这个优先级下的 process。新来的插到队尾，先进先出。在这种情况下，insert / deletion 都是 O(1)。&lt;/p&gt;&lt;p&gt;那么，我们怎么找到当前最高优先级下面的可执行的 process 呢？如果从 0 开始一直遍历下去，算法虽然不是 O(N)，但是是跟优先级多寡相关的 O(M)，也不能算作 O(1)。在 2.6 scheduler 里，聪明的先贤们采用 bitarray。它为每种优先级分配一个 bit，如果这个优先级队列下面有 process，那么就对相应的 bit 染色，置为 1，否则置为 0。这样，问题就简化成寻找一个 bitarray 里面最高位是 1 的 bit（left-most bit），这基本上是一条 CPU 指令的事（fls）。&lt;/p&gt;&lt;p&gt;好，大致的思路齐备，我们来捋一捋完整的步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 active bitarray 里，寻找 left-most bit 的位置 x。&lt;/li&gt;&lt;li&gt;在 active priority array（APA）中，找到对应队列 APA[x]。&lt;/li&gt;&lt;li&gt;从 APA[x] 中 dequeue 一个 process，dequeue 后，如果 APA[x] 的 queue 为空，那么将 active bitarray 里第 x bit置为 0。&lt;/li&gt;&lt;li&gt;对于当前执行完的 process，重新计算其 priority，然后 enqueue 到 expired priority array（EPA）相应的队里 EPA[priority]。&lt;/li&gt;&lt;li&gt;如果 priority 在 expired bitarray 里对应的 bit 为 0，将其置 1。&lt;/li&gt;&lt;li&gt;如果 active bitarray 全为零，将 active bitarray 和 expired bitarray 交换一下。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当然，这里面还有一些细节，比如如果是 process 被抢占，其时间片没用完，那么第 4 步，enqueue 回 active priority queue 中。不过这和算法本身没太大关系，我们略过不表。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;历史地位&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2.6 O(1) scheduler 目前已经被性能略输一筹，同时更加强调公平性的 CFS（Completely Fair Scheduler）取代，但其以独特的设计，简单的算法，影响很多系统。在其刚问世时，很多 linux 发行版就迫不及待将其移植回 2.4 kernel。而程序君整个职业生涯中接触过的一些调度器中，都能见到 bitarray + priority queue 的身影。它让我感慨算法之美，同时也告诉我：你手中即便拿着一副并不那么出众的牌，历经辗转腾挪，也能打出精彩。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;本系列文章：&lt;/p&gt;&lt;p&gt;[1] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/33389178&quot;&gt;当我谈 scheduling 时我在谈什么？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] 谈谈调度 - Linux O(1)&lt;/p&gt;</description>
<author>陈天</author>
<guid isPermaLink="false">2018-01-31-33461281</guid>
<pubDate>Wed, 31 Jan 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
