<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>babyquant谈量化金融</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 25 Jul 2018 08:03:46 +0800</lastBuildDate>
<item>
<title>算法||LSTM</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-24-40449368.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40449368&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;LSTM Networks是递归神经网络（RNNs）的一种，该算法由Sepp Hochreiter和Jurgen Schmidhuber在Neural Computation上首次公布。后经过人们的不断改进，LSTM的内部结构逐渐变得完善起来（图1）。在处理和预测时间序列相关的数据时会比一般的RNNs表现的更好。目前，LSTM Networks已经被广泛应用在机器人控制、文本识别及预测、语音识别、蛋白质同源检测等领域。基于LSTM Networks在这些方面的优异表现，本推文旨在探究LSTM是否可以应用于股票时间序列的预测。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-40e8a6c2517c2d9f2324d0a2fdc9814b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;412&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-40e8a6c2517c2d9f2324d0a2fdc9814b&quot; data-watermark-src=&quot;v2-b5f7fdb6f2245c6b7e91de03d93903a6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;LSTM Networks 建模流程&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;处理股票时间序列的流程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本推文使用的LSTM处理股票序列的流程如图2。构建LSTM模型使用库主要为Keras。&lt;/p&gt;&lt;p&gt;&lt;b&gt;数据获取与处理：&lt;/b&gt;对于时间序列，我们通常会以[X(t-n),X(t-n+1),…,X(t-1),X(t)]这n个时刻的数据作为输入来预测(t+1)时刻的输出。对于股票来说，在t时刻会有若干个features，因此，为了丰富features以使模型更加精确，本推文将n(time series)×s(features per time series)的二维向量作为输入。LSTM对于数据标准化的要求很高，因此本推文所有input数据均经过z-score标准化处理。&lt;/p&gt;&lt;p&gt;&lt;b&gt;LSTM模型构建：&lt;/b&gt;作为循环层的一种神经网络结构，只使用LSTM并不能构建出一个完整的模型，LSTM还需要与其他神经网络层（如Dense层、卷积层等）配合使用。此外，还可以构建多层LSTM层来增加模型的复杂性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;回测：&lt;/b&gt;本推文进行的回测分为两种，一是直接将LSTM输出结果作为做单信号在个股上进行回测，二是将LSTM的预测结果作为一种择时信号，再配合其他选股模型（如BigQuant平台的StockRanker）进行回测。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-49b808f7911ab3dee7dae7491b18bcf3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;196&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-49b808f7911ab3dee7dae7491b18bcf3&quot; data-watermark-src=&quot;v2-6bbf089b1ab53b41c8625bcc4af35b7c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;LSTM对沪深300未来五日收益率预测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;综合以上两点，本推文所使用的输入和输出为利用过去30天的数据预测将来五天的收益。&lt;/p&gt;&lt;p&gt;测试对象：沪深300&lt;/p&gt;&lt;p&gt;数据选择和处理：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;input的时间跨度为30天，每天的features为[&#39;close&#39;,&#39;open&#39;,&#39;high&#39;,&#39;low&#39;,&#39;amount&#39;,&#39;volume&#39;]共6个，因此每个input为30×6的二维向量。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;output为未来5日收益future_return_5（future_return_5&amp;gt;0.2,取0.2;future_return_5&amp;lt;-0.2,取-0.2)，为使训练效果更加明显，output=future_return_5×10； features均经过标准化处理(在每个样本内每个feature标准化处理一次)。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;训练数据：沪深300 2005-01-01至2014-12-31时间段的数据；测试数据：沪深300 2015-01-01至2017-05-01时间段数据。&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;模型构建：鉴于数据较少（训练数据约2500个，预测数据约500个），因此模型构建的相对简单。模型共四层，为一层LSTM层+三层Dense层（图3）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;回测：得到LSTM预测结果后，若LSTM预测值小于0，则记为-1，若大于0，记为1。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;部分代码：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;# 数据处理：设定每个input（30time series×6features）以及数据标准化
train_input = []
train_output = []
test_input = []
test_output = []
for i in range(conf.seq_len-1, len(traindata)):
    a = scale(scaledata[i+1-conf.seq_len:i+1])
    train_input.append(a)
    c = data[&#39;return&#39;][i]
    train_output.append(c)
for j in range(len(traindata), len(data)):
    b = scale(scaledata[j+1-conf.seq_len:j+1])
    test_input.append(b)
    c = data[&#39;return&#39;][j]
    test_output.append(c)

# LSTM接受数组类型的输入
train_x = np.array(train_input)
train_y = np.array(train_output)
test_x = np.array(test_input) 
test_y = np.array(test_output)
# 自定义激活函数
import tensorflow as tf
def atan(x): 
    return tf.atan(x)

# 构建神经网络层 1层LSTM层+3层Dense层
# 用于1个输入情况
lstm_input = Input(shape=(30,6), name=&#39;lstm_input&#39;)
lstm_output = LSTM(128, activation=atan, dropout_W=0.2, dropout_U=0.1)(lstm_input)
Dense_output_1 = Dense(64, activation=&#39;linear&#39;)(lstm_output)
Dense_output_2 = Dense(16, activation=&#39;linear&#39;)(Dense_output_1)
predictions = Dense(1, activation=atan)(Dense_output_2)

model = Model(input=lstm_input, output=predictions)

model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;, metrics=[&#39;mse&#39;])

model.fit(train_x, train_y, batch_size=conf.batch, nb_epoch=10, verbose=2)

# 预测
predictions = model.predict(test_x)

# 预测值和真实值的关系
data1 = test_y
data2 = predictions
fig, ax = plt.subplots(figsize=(8, 6))
ax.plot(data2,data1, &#39;o&#39;, label=&quot;data&quot;)
ax.legend(loc=&#39;best&#39;)&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fba00d7cf1300546eff924d31bbe5dc7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;495&quot; data-rawheight=&quot;361&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fba00d7cf1300546eff924d31bbe5dc7&quot; data-watermark-src=&quot;v2-546896e11fffb7b6590b73b8d2668a6d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;# 如果预测值&amp;gt;0,取为1；如果预测值&amp;lt;=0,取为-1.为回测做准备
for i in range(len(predictions)):    
    if predictions[i]&amp;gt;0:
        predictions[i]=1    elif predictions[i]&amp;lt;=0:
        predictions[i]=-1

# 将预测值与时间整合作为回测数据
cc = np.reshape(predictions,len(predictions), 1)
databacktest = pd.DataFrame()
databacktest[&#39;date&#39;] = datatime
databacktest[&#39;direction&#39;]=np.round(cc)&lt;/code&gt;&lt;p&gt;每个模型做两次回测，第一次回测（后文简称回测1）为直接以LSTM预测值在沪深300上做单：若LSTM预测值为1，买入并持有5day（若之前已持仓，则更新持有天数），若LSTM预测值为-1，若为空仓期，则继续空仓，若已持有股票，则不更新持有天数；&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;第二次回测（后文简称回测2）为以LSTM为择时指标，与StockRanker结合在3000只股票做单：若LSTM预测值为1，则允许StockRanker根据其排序分数买入股票，若LSTM预测值为-1，若为空仓期，则继续空仓，若已持有股票，则禁止StockRanker买入股票，根据现有股票的买入时间，5天内清仓；&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b1e30f42a79e874c0bc3b2d1a395035f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;136&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b1e30f42a79e874c0bc3b2d1a395035f&quot; data-watermark-src=&quot;v2-78e81f4dd1c057e0a56c0d4d160d6ee1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;1)future_return_5是否二极化处理比较&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于future_return_5的处理分为两种情况，一种为直接将future_return_5作为output进行模型训练，二是将future_return_5二极化（future_return_5&amp;gt;0,取1；future_return_5&amp;lt;=0,取-1），然后将二极化后的数据作为output进行模型训练。&lt;/p&gt;&lt;p&gt;两种处理方法的回测情况如图4，图5。由于模型每次初始化权重不一样，每次预测和回测结果会有一些差别，但经过多次回测统计，直接将future_return_5作为output进行模型训练是一个更好的选择。在本推文接下来的讨论中，将会直接将future_return_5作为output进行模型训练。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-03bdabfee8f59a75e6eda470baeb893d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;468&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-03bdabfee8f59a75e6eda470baeb893d&quot; data-watermark-src=&quot;v2-2fadda2fb35a9479a343c43dda2bb81c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2ee3e51fe1ab0a31f5564506a9cbb7ec_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;474&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2ee3e51fe1ab0a31f5564506a9cbb7ec&quot; data-watermark-src=&quot;v2-dbe6b9707d8cfe131f5adb6cb63350d7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2)在权重上施加正则项探究&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;神经网络的过拟合：在训练神经网络过程中，“过拟合”是一项尽量要避免的事。神经网络“死记”训练数据。过拟合意味着模型在训练数据的表现会很好，但对于训练以外的预测则效果很差。原因通常为模型“死记”训练数据及其噪声，从而导致模型过于复杂。本推文使用的沪深300的数据量不是太多，因此防止模型过拟合就尤为重要。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;训练LSTM模型时，在参数层面上有两个十分重要的参数可以控制模型的过拟合：Dropout参数和在权重上施加正则项。Dropout是指在每次输入时随机丢弃一些features，从而提高模型的鲁棒性。它的出发点是通过不停去改变网络的结构，使神经网络记住的不是训练数据本身，而是能学出一些规律性的东西。正则项则是通过在计算损失函数时增加一项L2范数，使一些权重的值趋近于0，避免模型对每个feature强行适应与拟合，从而提高鲁棒性，也有因子选择的效果；在1)的模型训练中，我们加入了Dropout参数来避免过拟合。接下来我们尝试额外在权重上施加正则项来测试模型的表现。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;回测结果如图6，加入正则项之后回测1和回测2的最大回撤均有下降，说明加入正则项后确实减轻了模型的过拟合。比较加入正则项前后回测1的持仓情况，可以看到加入正则化后空仓期更长,做单次数减少(19/17)，可以理解为：加入正则项之后，模型会变得更加保守。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;正则项的问题：经过试验,对于一个LSTM模型来说，正则项的参数十分重要，调参也需要长时间尝试，不合适的参数选择会造成模型的预测值偏正分布(大部分预测值大于0)或偏负分布，从而导致预测结果不准确，而较好的正则参数会使模型泛化性非常好(图6所用参数训练出来的模型的预测值属于轻度偏正分布)。本文之后的讨论仍会基于未加权重正则项的LSTM模型。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-33156ad39591613a03c2f4001326ae99_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;473&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-33156ad39591613a03c2f4001326ae99&quot; data-watermark-src=&quot;v2-5310c6835ceeb0f0c32e6804f2fc2c41&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3)双输入模型探究&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;除了传统的Sequential Model(一输入，一输出)外，本推文还尝试构建了Functional Model(支持多输入，多输出)。前面提到的features处理方法丢失了一项重要的信息：价格的高低。相同的input处在3000点和6000点时的future_return_5可能有很大不同。因此，本文尝试构建了&quot;二输入一输出&quot;的Functional Model：标准化后的features作为input输入LSTM，LSTM层的输出结果和一个指标-label(label=np.round(close/500))作为input输入后面的Dense层，最终输出仍为future_return_5(图7)。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1960872c7a2a2199ea4a906552f861f8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;177&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-1960872c7a2a2199ea4a906552f861f8&quot; data-watermark-src=&quot;v2-d3ec043369162e1ff233548b5d6a6720&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;部分代码：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;# LSTM与stockranker配合回测
class conf:    start_date = &#39;2010-01-01&#39;    end_date=&#39;2017-05-01&#39;    # split_date 之前的数据用于训练，之后的数据用作效果评估    split_date = &#39;2015-01-01&#39;    instruments = D.instruments(start_date, end_date)    
    label_expr = [&#39;return * 100&#39;, &#39;where(label &amp;gt; {0}, {0}, where(label &amp;lt; -{0}, -{0}, label)) + {0}&#39;.format(20)]    # 持有天数，用于计算label_expr中的return值(收益)    hold_days = 5
    # 特征    features = [&#39;close_5/close_0&#39;,  # 5日收益    &#39;close_10/close_0&#39;,  # 10日收益    &#39;close_20/close_0&#39;,  # 20日收益    &#39;avg_amount_0/avg_amount_5&#39;,  # 当日/5日平均交易额    &#39;avg_amount_5/avg_amount_20&#39;,  # 5日/20日平均交易额    &#39;rank_avg_amount_0/rank_avg_amount_5&#39;,  # 当日/5日平均交易额排名    &#39;rank_avg_amount_5/rank_avg_amount_10&#39;,  # 5日/10日平均交易额排名    &#39;rank_return_0&#39;,  # 当日收益    &#39;rank_return_5&#39;,  # 5日收益    &#39;rank_return_10&#39;,  # 10日收益    &#39;rank_return_0/rank_return_5&#39;,  # 当日/5日收益排名    &#39;rank_return_5/rank_return_10&#39;,  # 5日/10日收益排名    &#39;pe_ttm_0&#39;,  # 市盈率TTM    ]
# 给数据做标注：给每一行数据（样本）打分，一般分数越高表示越好
m1 = M.fast_auto_labeler.v5(
    instruments=conf.instruments, start_date=conf.start_date, end_date=conf.end_date,
    label_expr=conf.label_expr, hold_days=conf.hold_days,
    benchmark=&#39;000300.SHA&#39;, sell_at=&#39;open&#39;, buy_at=&#39;open&#39;
)

# 计算特征数据
m2 = M.general_feature_extractor.v5(
    instruments=conf.instruments, start_date=conf.start_date, end_date=conf.end_date,
    features=conf.features)

# 数据预处理：缺失数据处理，数据规范化，T.get_stock_ranker_default_transforms为StockRanker模型做数据预处理
m3 = M.transform.v2(
    data=m2.data, transforms=T.get_stock_ranker_default_transforms(),
    drop_null=True, astype=&#39;int32&#39;, except_columns=[&#39;date&#39;, &#39;instrument&#39;],
    clip_lower=0, clip_upper=200000000)

# 合并标注和特征数据
m4 = M.join.v2(data1=m1.data, data2=m3.data, on=[&#39;date&#39;, &#39;instrument&#39;], sort=True)

# 训练数据集
m5_training = M.filter.v2(data=m4.data, expr=&#39;date &amp;lt; &quot;%s&quot;&#39; % conf.split_date)

# 评估数据集
m5_evaluation = M.filter.v2(data=m4.data, expr=&#39;&quot;%s&quot; &amp;lt;= date&#39; % conf.split_date)

# StockRanker机器学习训练
m6 = M.stock_ranker_train.v2(training_ds=m5_training.data, features=conf.features)

# 对评估集做预测
m7 = M.stock_ranker_predict.v2(model_id=m6.model_id, data=m5_evaluation.data)

# 生成卖出订单：hold_days天之后才开始卖出；对持仓的股票，按StockRanker预测的排序末位淘汰
if databacktest[&#39;direction&#39;].values[databacktest.date==current_dt]==-1: # LSTM择时卖    instruments = list(reversed(list(ranker_prediction.instrument[ranker_prediction.instrument.apply(lambda x: x in equities and not context.has_unfinished_sell_order(equities[x]))])))        
     for instrument in instruments:            
         if context.trading_calendar.session_distance(pd.Timestamp(context.date[instrument]), pd.Timestamp(current_dt))&amp;gt;=5:
                context.order_target(context.symbol(instrument), 0)if not is_staging and cash_for_sell &amp;gt; 0:
    instruments = list(reversed(list(ranker_prediction.instrument[ranker_prediction.instrument.apply(lambda x: x in equities and not context.has_unfinished_sell_order(equities[x]))])))        
    # print(&#39;rank order for sell %s&#39; % instruments)    for instrument in instruments:
        context.order_target(context.symbol(instrument), 0)
        cash_for_sell -= positions[instrument]            
        if cash_for_sell &amp;lt;= 0:                
            break
            
# 生成买入订单：按StockRanker预测的排序，买入前面的stock_count只股票
if databacktest[&#39;direction&#39;].values[databacktest.date==current_dt]==1: # LSTM择时买    buy_dt = data.current_dt.strftime(&#39;%Y-%m-%d&#39;)
    context.date=buy_dt
    buy_cash_weights = context.stock_weights
    buy_instruments = list(ranker_prediction.instrument[:len(buy_cash_weights)])
    max_cash_per_instrument = context.portfolio.portfolio_value * context.max_cash_per_instrument        
    for i, instrument in enumerate(buy_instruments):
        cash = cash_for_buy * buy_cash_weights[i]            
        if cash &amp;gt; max_cash_per_instrument - positions.get(instrument, 0): # 确保股票持仓量不会超过每次股票最大的占用资金量            cash = max_cash_per_instrument - positions.get(instrument, 0)            
        if cash &amp;gt; 0:
            context.order_value(context.symbol(instrument), cash)
            buy_dates[instrument] = current_dt

context.date = buy_dates&lt;/code&gt;&lt;p&gt;回测结果如图8。由回测结果可以看出，加入指示标后的LSTM模型收益率相对下降，但是回撤更小。LSTM预测值小于0的时间段覆盖了沪深300上大多数大幅下跌的时间段,虽然也错误地将一些震荡或上涨趋势划归为下跌趋势。或许这是不可避免的，俗话说高风险高回报，风险低那么回报也不会非常高，高回报和低风险往往不可兼得。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3b68f728634de83ee3dd394e8de8e1a1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;472&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3b68f728634de83ee3dd394e8de8e1a1&quot; data-watermark-src=&quot;v2-49198b1d13b4b81b1149699dc27afb39&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;结论与展望&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;结论：&lt;/b&gt;本推文通过探究性地应用LSTM对沪深300未来五日收益率进行预测，初步说明了LSTM Networks是可以用在股票市场上的。由于LSTM更适用于处理个股/指数，因此，将LSTM作为择时模型与其他选股模型配合使用效果较好。利用LSTM模型对沪深300数据进行预测并将结果作为择时信号，可以显著改善stockranker选股模型在回测阶段的回撤。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;展望：&lt;/b&gt;由于个股数据量较少，LSTM模型的可扩展程度和复杂度受到很大制约，features的选择也受到限制（若input的features太多，而data较少的话，会使一部分features不能发挥出应有的作用，也极易造成过拟合）。将来我们希望能在个股/指数的小时或分钟数据上测试LSTM的性能。另外，将探究LSTM模型能否将属于一个行业的所有股票data一起处理也是一个可选的方向。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;说明：&lt;/b&gt;由于每次训练LSTM模型权重更新情况不同以及Dropout的随机性，LSTM模型的每次训练训练结果都会有差异。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;提示：&lt;/b&gt;由于LSTM涉及参数众多，目前还不能保证LSTM模型的稳定性，本推文所附回测结果均为多次训练模型后选取的较为理想的情况，目的是说明LSTM是可以应用于股票市场的以及将其作为择时模型是可能的。本推文所述以及提供的代码仅供探究及讨论，若要形成一个在股票市场比较实用的LSTM模型，还需要在features选择、模型构建、模型参数选择以及调优等方面花费大量精力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化家</author>
<guid isPermaLink="false">2018-07-24-40449368</guid>
<pubDate>Tue, 24 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>【中信证券】量化实习生招聘（2019应届生）</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-24-40441698.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40441698&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;中信证券招聘量化实习生，优异者可留用（2019年校园招聘）。&lt;/p&gt;&lt;p&gt;实习招聘部门：中信证券股权衍生品业务线&lt;/p&gt;&lt;p&gt;股权衍生品业务线是中信证券开展权益类产品交易的业务部门，其业务模式是依托中信证券的信用和资产负债表，作为产品设计者和交易对手方，面向机构和零售客户提供种类丰富的与权益资产相关的投融资产品，满足客户各项需求。 &lt;/p&gt;&lt;p&gt;工作地：北京 亮马桥 中信证券总部。 &lt;/p&gt;&lt;p&gt;有意者请将简历寄送至EQ_HR@citics.com，2018年8月15日之前有效。 &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;职责： &lt;/p&gt;&lt;p&gt;1、负责数据整理、挖掘、统计分析、展示； &lt;/p&gt;&lt;p&gt;2、从数据中发现规律，为量化分析提供支持； &lt;/p&gt;&lt;p&gt;3、开发量化模型策略； &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;要求：&lt;/p&gt;&lt;p&gt;1、2019年毕业的硕士、博士。&lt;/p&gt;&lt;p&gt;2、知名院校的数学/统计、物理、计算机、电子或其他相关理工科专业； &lt;/p&gt;&lt;p&gt;3、一流的概率统计能力，严谨的研究习惯； &lt;/p&gt;&lt;p&gt;4、有一定的编程能力，至少熟悉Python和C++其中一门编程语言； &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;加分项： &lt;/p&gt;&lt;p&gt;1、顶级的研究能力，有领先的学术成果； &lt;/p&gt;&lt;p&gt;2、学科竞赛、ACM-ICPC获奖； &lt;/p&gt;&lt;p&gt;3、熟悉深度学习原理和基本模型，熟练使用 Tensorflow，并能够灵活的解决实际问题。有过大型机器学习、数据挖掘实践项目者优先； &lt;/p&gt;&lt;p&gt;4、爬虫以及文本处理项目经历； &lt;/p&gt;&lt;p&gt;5、熟悉linux系统的非桌面环境, 良好的编码风格； &lt;/p&gt;</description>
<author>zhiqiang</author>
<guid isPermaLink="false">2018-07-24-40441698</guid>
<pubDate>Tue, 24 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>策略||缠论</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-23-40365211.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40365211&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;一． 缠论理论体系梳理及精髓解读&lt;/b&gt;&lt;br&gt;&lt;b&gt;1.1 K线包含处理目的：清洗K线数据，识别顶底分型&lt;/b&gt;&lt;br&gt;相邻两K线可能出现包含关系（ 注： K线包含影线，且不分阴阳线）&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-77a4e20aa1f3f37b5445dfdd3c659b22_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;252&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-77a4e20aa1f3f37b5445dfdd3c659b22&quot; data-watermark-src=&quot;v2-3c9ce02a9f838d4c5d0d2944527f3b58&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-acecc35dcab111429f574b6939731977_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;448&quot; data-rawheight=&quot;255&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-acecc35dcab111429f574b6939731977&quot; data-watermark-src=&quot;v2-373053262ff437d6b247fadafb0b48d1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;1.2 分型：对局部高低点的识别（ K线已经过包含处理）&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ec90effb7ea2a6cccfe42e202e86f8a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;255&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2ec90effb7ea2a6cccfe42e202e86f8a&quot; data-watermark-src=&quot;v2-f6d6f773ebdf6195cb77a64b82e208e3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;1.3 笔：对阶段性高低点的识别（ K线已经过包含处理）&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-531677a7cc6175114502dc9e0d2db4d6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;148&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-531677a7cc6175114502dc9e0d2db4d6&quot; data-watermark-src=&quot;v2-9899fe874d70723ca4f7a35f404dfe26&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;两个相邻的顶和底，并且顶分型和底分型之间至少有一根独立的K线，这就构成一笔，笔从其构成的K线走向看分为向上笔和向下笔。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b179f3df18fbdac3b584476e6297a69e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;212&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b179f3df18fbdac3b584476e6297a69e&quot; data-watermark-src=&quot;v2-e76f65c6d34e3f83fc13f9e531502fdc&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;将K线图的分型按照一顶一低交替出现的方式进行笔的连接，遇到连续两&lt;br&gt;个分型是同类分型时，笔将延伸， 忽略前面出现的，连接后面出现的分型。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.4 线段：&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-963e091df9696d9481533bda8f806d72_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;566&quot; data-rawheight=&quot;172&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-963e091df9696d9481533bda8f806d72&quot; data-watermark-src=&quot;v2-6362ee719e5532f3289c09f9ab2f4dc8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;/b&gt;&lt;p&gt;连续的三笔之间若存在重叠部分，其起点和终点之间的连线为线段。&lt;br&gt;同样，线段依据走势分为向上线段和向下线段。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fc3977988f50bc0279019c85f0400487_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;176&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fc3977988f50bc0279019c85f0400487&quot; data-watermark-src=&quot;v2-6eb17792d75aeba2a098d811f58a2d9a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;线段产生以后，若不在相反方向产生新线段，那么这个线段在同方向上继续延伸，否则称为线段被线段破环。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d49d9647e71aa215004198f51a8a436c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;147&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d49d9647e71aa215004198f51a8a436c&quot; data-watermark-src=&quot;v2-5fdadae63f7a5a7290656036bac14539&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;•  向上线段用笔的序列表示成： S1X1S2X2…Sn。反向往下运动的笔序列X1X2…Xn称&lt;br&gt;  之为向上线段的特征序列， 同理 S1S2…Sn序列称为向下线段的特征序列。&lt;/p&gt;&lt;p&gt;•  特征序列两相邻元素之间没有重叠的区间，称为序列的缺口。&lt;br&gt;•  对于特征序列，将每一元素看成一K线，也存在所谓的包含关系，也可以对此进行K线&lt;br&gt;  合并处理。经过处理的特征序列，称为标准特征序列。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-befe74e7113d2c83bf82c6e8432e4d77_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;172&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-befe74e7113d2c83bf82c6e8432e4d77&quot; data-watermark-src=&quot;v2-94f865afaab650085cc877ca5ea6c010&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;准特征序列分型中，第一二元素无缺口&lt;br&gt;• 向上线段出现顶分型，线段结束于该顶分型的顶&lt;br&gt;• 向下线段出现底分型，线段结束于该底分型的底&lt;br&gt;&lt;/p&gt;&lt;p&gt;标准特征序列分型中，第一二元素存在缺口&lt;br&gt;• 向上线段出现顶分型，如果从该分型最高点开始的向下一笔开始的序列的特征序列出现底      分型，并且在完成底分型前不破顶分型最高点，那么该线段在该顶分型的高点处结束&lt;br&gt;• 向下线段同理&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.5 中枢&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8dc78093dfda14be87ec0cc124d6ce5c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;553&quot; data-rawheight=&quot;134&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8dc78093dfda14be87ec0cc124d6ce5c&quot; data-watermark-src=&quot;v2-e00783fac3aed0f327361bea2038034a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;•  某级别走势类型中，被至少三个连续次级别走势类型所重叠的部分称为&lt;b&gt;中枢&lt;/b&gt;。向上走势 考察下上下…的次级别，向下走势考察下上下…的次级别。&lt;br&gt;•  对上升的线段，取其回撤构成中枢，对下降的线段，取其回升构成中枢。&lt;br&gt;•  中枢三种生长方式： 新生（前后两个中枢波动区间无重合）， 延伸（前后两个中枢中枢 区间重合），扩展（前后两个中枢中枢区间无重合，波动区间有重合）。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ad414ff98321bbf3d6fd6934a61a341_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;558&quot; data-rawheight=&quot;151&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7ad414ff98321bbf3d6fd6934a61a341&quot; data-watermark-src=&quot;v2-9e27310c196afde637c39d661ff2aba1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;根据中枢的相对位置关系和数量，可将走势类型分为两类：&lt;br&gt;•  一个已完成的走势类型若只包含一个中枢，称其为盘整。&lt;br&gt;•  一个已完成的走势类型若包含两个以上的同向中枢，称其为趋势。中枢依次向上且波&lt;br&gt;动区间无重合，为上涨趋势；中枢依次向下且波动区间无重合，为下降趋势。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2c0c3c2a526aeb33898f9818ea5eb183_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;160&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2c0c3c2a526aeb33898f9818ea5eb183&quot; data-watermark-src=&quot;v2-95c3d59ba1030d8bef2fcaa4b835f174&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;背驰：是指围绕同一中枢的前后两个次级别波动，后面的力度弱于前面。力度有多种衡量方式，缠论中用MACD， MACD又有三种标准（红绿柱子面积/红绿柱子高度/黄白线高度）。&lt;br&gt;&lt;/p&gt;&lt;p&gt;趋势背驰：趋势的最后一个中枢前后两个次级别波动，必须创新高/新低。例如， b段对应&lt;br&gt;的MACD柱子面积（向上看红柱子，向下看绿柱子）比a段对应的面积小,且b段创新高，这&lt;br&gt;就构成标准的趋势背驰。&lt;br&gt;&lt;/p&gt;&lt;p&gt;盘整背驰：与趋势背驰类似，但定义相对宽松。 通常比较的是同向的相邻两个次级别波动，并且不需要考虑是否创新高/低。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.7 三类买卖点&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f9f98a85b0c2234ced68d6c5ffe438af_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;197&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f9f98a85b0c2234ced68d6c5ffe438af&quot; data-watermark-src=&quot;v2-972c09a34d91eac3266a7bfa56606722&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;/b&gt;&lt;p&gt;•  第一类买卖点由趋势背驰产生，第一类买卖点出现意味着原走势终结。&lt;br&gt;•  第二类买卖点出现在第一类买卖点之后，如果走势不创新低新高或者新低新高之后盘整背驰，都构成第二类买卖点。&lt;br&gt;•  第三类买卖点出现在最近的一个同级别中枢之上/之下，如果次级别离开后次级别回抽，回不到最近的一个同级别中枢中，则构成第三类买卖点，意味着中枢的新生或者中枢级别的扩展。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化家</author>
<guid isPermaLink="false">2018-07-23-40365211</guid>
<pubDate>Mon, 23 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>策略||文字数据</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-20-40184624.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40184624&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;   一直以来策略用到的即时文字数据，获取和处理都比较麻烦，这里笔者简单介绍一下获取和处理方法，关于文字数据因子的使用放到下一章节&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1&lt;b&gt;数据的获取&lt;/b&gt;&lt;/p&gt;&lt;p&gt;依旧以对证券市场分析为例，常用到的数据有“财经新闻、上市公司公告、股吧网友讨论等”。我们希望从这些数据源中能得到有价值的信息，可能是一段时间的新闻热点、可能是网友对不同事件的正负面情绪、或者其他一些。&lt;br&gt;&lt;br&gt;第一步就是获取数据，新闻相关的有新浪财经、华尔街见闻等；上市公司公告有巨潮资讯网、交易所官网；股吧有东方财富网、雪球等。&lt;br&gt;&lt;br&gt;&lt;br&gt;一般选用的方法就是爬虫了，根据各网站的不同，爬取难易程度不一 。大规模爬虫可以选用：scrapy  分布式爬取，而一般简单的爬虫可以用： lxml、BeautifulSoup、 Requests、Selenium等。具体操作过程中，有些网站有比较强的反爬虫机制，需要加ip代理池等操作。&lt;br&gt; &lt;br&gt;&lt;b&gt;举个简单例子 —— 爬取中国证券报网站上近一周的所有公司新闻。&lt;/b&gt;&lt;br&gt;简单过程就是：&lt;br&gt;a. 找到目标网页的URL。&lt;br&gt;b. 在目标页面URL中找到目标内容并保存。&lt;br&gt;一般可以通过lxml.etree用xpath定位实现、或者用BeautifulSoup根据CSS定位实现。&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1d658dea70008150395d29266a3e2165_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;546&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-1d658dea70008150395d29266a3e2165&quot; data-watermark-src=&quot;v2-86cb9e775c20923511b3af6b6a5e2cc6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-776a5e334ca5b7e7a8045fc4f042f6ae_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;605&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-776a5e334ca5b7e7a8045fc4f042f6ae&quot; data-watermark-src=&quot;v2-5fbecc75e54aea4ad620e4f6084a13ea&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;至于数据的储存，各种数据库就依个人喜好了，例子中直接保存到txt里了。多说一句，例子中取的数据不牵涉到动态加载内容，如有需要最简单是selenium模拟，另外方法是Chrome F12 network，分析Ajax内容，构造请求。具体今天就先略去了。&lt;br&gt;&lt;/p&gt;&lt;p&gt;2&lt;b&gt;文本初步处理&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a994af8d7f9d07b77f54a2e7c8a5d760_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;445&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a994af8d7f9d07b77f54a2e7c8a5d760&quot; data-watermark-src=&quot;v2-5274c1e955905cdb9b53501b66d51e30&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;取得数据之后下一步就是简单的处理了，对中文来说，就是分词，去停用词这些，可用的工具有： Jieba 、PyNlpir等。具体选哪个还是去试一下看哪个合适，自己选吧。&lt;br&gt;&lt;br&gt;&lt;br&gt;对于要让程序到practical的程度，分词还是很重要的，因为很多专业术语，所以自定义字典userdict比较重要。上面提到的两个包都可以导入自定义字典，要达到令人满意的结果，这userdict就看个人了。去停用词就是删除一些没什么实际意义的形容词、助词等。&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;分词程序：&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6d60a082b20dd98c28966fd42e30dea6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;662&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6d60a082b20dd98c28966fd42e30dea6&quot; data-watermark-src=&quot;v2-73ea147cc1d37a984818faa73138eed3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;分词结果：&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;b&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-444ba97f68375ba86484d0dbbf83ee82_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;393&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-444ba97f68375ba86484d0dbbf83ee82&quot; data-watermark-src=&quot;v2-85793a8327f3749d4b7bb8ba021afda7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;/b&gt;&lt;p&gt;3&lt;b&gt;提取关键词&lt;/b&gt;&lt;br&gt;下一步是把每个文本提取关键词，用关键词向量代表每个文本。&lt;br&gt;一般用的方法是有TF－IDF，具体细节可以wiki一下。很简单，主要意思就是一个词在文档中出现频率越高，对文档而言更重要； 同时一个词要是在所有文档中都出现，比如“的”，那就重要性减弱。于是抽象出 &quot;TF : termfrequency&quot; 和  &quot;IDF: inverse documentary frequency&quot;。以“国企改革”为例，“TF”算的是“国企改革”在文章中出现的频率，“IDF”算“国企改革”在所有文档中出现频率。&lt;br&gt;&lt;/p&gt;&lt;p&gt;一般采用log(...) * log(...)的形式，不过这个也可以变，没有一个规定。&lt;br&gt;scikit-learn中有直接封装好的TF-IDF程序，在这里我贴出一个自己写的：&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;关键词提取程序：&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c016872bd77dd93252d4c91108168646_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;425&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c016872bd77dd93252d4c91108168646&quot; data-watermark-src=&quot;v2-416d3e45fc7ca2852d640bdb187192e0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;关键词提取结果：&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;b&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-08ee558afad11ec2b699764df6e3e808_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;400&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-08ee558afad11ec2b699764df6e3e808&quot; data-watermark-src=&quot;v2-424aafdfda9a32b39ff108566caa64c0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;/b&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;这样处理之后，一片文章就可以用几十个关键词表示，再进行下一步的聚类分析等。&lt;br&gt;&lt;br&gt;常用的文本相关性分析方法有：求文档间的余弦Cosine、KMeans等。&lt;/p&gt;</description>
<author>量化家</author>
<guid isPermaLink="false">2018-07-20-40184624</guid>
<pubDate>Fri, 20 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>策略||遗传算法</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-19-40082674.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40082674&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;通常所说的量化交易，是指使用大量的指标和操作的组合，来定义买/卖操作规则。除了决定使用哪些指标，更重要的是为指标设置正确的参数。&lt;/p&gt;&lt;p&gt;一个简化的例子（&lt;b&gt;随机写的，请勿作为投资参考&lt;/b&gt;）：选择 300成份股 + 市值小于150亿 + 去年分红 + 最近半年有回购行为 的股票。我们可以把不同指标扩展到成千上万个，根据参数做出投资决策。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;为参数寻找最优解的问题，梯度下降法（常用于深度学习）是一个很好的解决方案。但有些时候1、问题有多个局部最优解；2、错误函数不平滑；这时梯度下降算法就不能很好工作。这里我们介绍遗传算法，用来为市场指标的参数找到最优解。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;遗传算法是受物种进化和自然选择启发得到的优化方法。它是一个“古老”的算法，并且在上个世纪就有人尝试应用于金融市场研究。严格来说它不属于机器学习领域，但机器学习工程实际上可以在它的理论基础上来实现。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;遗传算法过程如下:&lt;/p&gt;&lt;p&gt;&lt;b&gt;- 初始化：&lt;/b&gt;算法从初始化一个种群开始，可以完全随机生成。每种可能的解决方案 -- 例如每个种群中的个体—被称为染色体。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;- 迭代过程：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;*  交叉：&lt;/b&gt;染色体被组合起来，产生一个新的种群。新一代种群中的每一条染色体都是它们祖先的基因（染色体由基因组成）交叉混合组成。&lt;/p&gt;&lt;p&gt;&lt;b&gt;*  突变：&lt;/b&gt;通常，还引入突变因子，目的是允许现有基因的特征有一些变化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;*  评估：&lt;/b&gt;计算每个新染色体个体的适应值。&lt;/p&gt;&lt;p&gt;交叉迭代过程的理念是创建一个优于第一代种群的后代，因为只有&lt;b&gt;最合格的个体才能存活下来&lt;/b&gt;。 这意味着我们将选择得到最佳结果的染色体作为下一代染色体的父染色体。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1992c9e52486da53afed9fc9b01d2901_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;356&quot; data-rawheight=&quot;325&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-1992c9e52486da53afed9fc9b01d2901&quot; data-watermark-src=&quot;v2-c009722f801e96dd4f5c6cacbc823612&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;-  停止条件：&lt;/b&gt;我们可以使用两三种不同的标准作为停止迭代过程的条件：&lt;/p&gt;&lt;p&gt;   *  群众中个体数量不再变化；&lt;/p&gt;&lt;p&gt;   *  获得满意的适应性水平。&lt;/p&gt;&lt;p&gt;   *  算法得到收敛。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我个人特别喜欢第一和第三个标准（除非时间极为有限，我会使用第二个标准)。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;实现遗传算法实际上是一项简单的任务。最具挑战的部分是如何将我们的问题转化为“染色体”模型。 我们需要可以轻松转换、组合的变量，以及无需大量的内存的算法，那么遗传算法就会有效。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;伪算法代码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;以下代码是使用Python语法的遗传算法实施的简单示例，其中：&lt;/p&gt;&lt;p&gt;max_iter：是算法停止前允许的最大迭代次数。&lt;/p&gt;&lt;p&gt;n_repeats：是允许所有过程中的最佳适应度比通常总体达到的最佳适应度差的最大迭代次数。 这是用来控制方法的收敛程度的简单方法: 如果我们不使用这种方法，当算法已经停在局部最优时，我们还在花时间执行代码。&lt;/p&gt;&lt;p&gt;N：是在每次迭代中被选择成为下一代父染色体的个体数量。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;i=0 &lt;/p&gt;&lt;p&gt;fitness = 0 &lt;/p&gt;&lt;p&gt;counter = 0 &lt;/p&gt;&lt;p&gt;while i &amp;lt; max_iter: &lt;/p&gt;&lt;p&gt;   if counter &amp;gt; n_repeats: &lt;/p&gt;&lt;p&gt;      STOP &lt;/p&gt;&lt;p&gt;   Y = [ ]&lt;/p&gt;&lt;p&gt;   fit = [ ] &lt;/p&gt;&lt;p&gt;   pairs = randompairsfrom (X) &lt;/p&gt;&lt;p&gt;   for j in pairs: &lt;/p&gt;&lt;p&gt;      y = crossover ( j )&lt;/p&gt;&lt;p&gt;      y = randommutation ( y )&lt;/p&gt;&lt;p&gt;      Y. append (y)&lt;/p&gt;&lt;p&gt;      fit.append (fitness(y))&lt;/p&gt;&lt;p&gt;   Y, fit = ordermaxtomin (Y, fit ) &lt;/p&gt;&lt;p&gt;   bestfitness = fit[ 0 ]&lt;/p&gt;&lt;p&gt;   if bestfitness &amp;lt; fitness: &lt;/p&gt;&lt;p&gt;      counter = counter+1&lt;/p&gt;&lt;p&gt;   else: &lt;/p&gt;&lt;p&gt;      counter = 0&lt;/p&gt;&lt;p&gt;      X = Y [0: N] &lt;/p&gt;&lt;p&gt;      i=i+1 &lt;/p&gt;&lt;p&gt;      fitness = bestfitness&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;改进&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;另外一点需要重点考虑到，如上所述，由于遗传算法是一种优化方法，因此很容易得到问题的局部最优值。当发生这种情况时，很难进一步发展并且找到问题的另一最优值 。 为了强制算法“跳出”局部最优，我们可以做的一件事是改变“选择过程”。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;当算法“正常工作”时，我们从由上一代和新一代形成的组合中选择更好的基因。 如果我们发现算法“结果不理想” – 产生了一些迭代之后，最好的适应度没有变得更好 -- 我们就要做一个“强行跳跃”，具体做法是对最后的那一代基因不进行最优选择，然后继续迭代。当然，这样做，当前最优适应度会比上一代差，但是通过改变父亲一代，能让我们跳出当前局部最优，从而找到一套不同的解决方案（我们希望比其他的更好）。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;应用&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在你已经知道遗传算法的基本思路了。&lt;/p&gt;&lt;p&gt;下一步是决定如何将市场指标的参数的映射为对应的染色体。如果我们决定使用一种通用的方法来做转换，那就意味着我们能使用相同的遗传算法来优化多个不同的指标参数。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;还是文章开头的极简例子，如果我们对多个指标进行0、1编码，1表示选中，0表示剔除。那么指标模型就是类似 01110001110001111001 这样的“基因”字符串。通过遗传算法得到的历史数据适应性最佳字符串，就是我们想要的策略了。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;思考1：&lt;/p&gt;&lt;p&gt;使用遗传算法寻找到市场指标（在时间序列上）的最优参数，有什么好处，又有什么缺点？&lt;/p&gt;&lt;p&gt;遗传算法的优点是不用花太多的时间找到交易模型的有益参数。缺点也很清楚：使用优化方法的最大风险是过度拟合。算法只能拟合历史数据，在未来的博弈中未必有效。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;继续思考2：如果我们设计一种算法机制，能够检测出当前交易模型的参数不再有良好回报，然后再找到适合当前市场约束条件其它算法，会如何？&lt;/p&gt;</description>
<author>量化家</author>
<guid isPermaLink="false">2018-07-19-40082674</guid>
<pubDate>Thu, 19 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>仓位控制||启发</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-18-40038927.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40038927&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;资金管理是投资体系中非常重要的部分，却是大多数投资者忽略的环节，至少在我认识的投资朋友中，很少看到注重资金管理的，也很少讨论资金管理问题，很多朋友喜欢总是满仓的，喜欢全部资金或大部分资金重仓一只或两只股票；要么就空仓，资金撤离。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;国内一些知名的价值投资者，也几乎总是处于满仓状态。在熊市中，资金管理不好的问题会逐步暴露出来，让投资者陷入困境或被动之中。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;主要表现：过早加仓并用完资金，当持有的证券出现低得更多的价格时，已经没有能力买入补仓；满仓的一只或两只证券出现大幅向下波动后，带来巨额的账面浮亏，给投资者带来巨大的心理压力，并在压力下做出非理性的投资操作等等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我所说的资金管理主要指&lt;b&gt;现金管理和仓位管理。&lt;/b&gt;现金管理指投资者在所管理的投资资产对现金占比的考虑及安排，这里的现金既指货币现金，也指现金等价物，如短期国债等。仓位管理主要指对单只证券或同类证券在投资组合中的控制比例及额度管理等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;投资者到底该如何进行资金管理，从而在各种环境下都能应对自如呢？我们看看几位着名的价值投资大师是如何做进行资金管理的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;格雷厄姆&lt;/b&gt;——价值投资的鼻祖，巴菲特最尊敬的恩师，《证券分析》、《聪明投资者》的作者。格雷厄姆很早就开始进行投资，为客户管理资金，但在1929年大危机中，损失惨重，几乎破产。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在经历过九死一生的大危机后，格雷厄姆在资金管理方面提出了「&lt;b&gt;75—25」法则&lt;/b&gt;，即：持有普通股的资金比例控制在25%至75%的范围，现金及债券则控制在75%至25%的互补区间之中，当股票资产因占比超过75%时，卖出一定数量的股票，增加现金或债券比例，当因股票资产占比到低于25%时，则卖出一定的债权增加股票的比例。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;当然，股票资产与债券（现金）的比例并不是完全铁定的75%至25%，投资者可以根据市场的高估或低估情况以及投资自身的特点设定一个合适的比例，如50%至50%等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;格雷厄姆说，这样的做法有两个好处：克服人性的弱点；让投资者总是有点事情可做，不至于太单调。同时，格雷厄姆的投资组合非常分散，持有很多数量的证券，单只证券的占比很小。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;巴菲特&lt;/b&gt;——价值投资集大成者，在54年的投资生涯，累计获利62021.72倍，年复合收益率22.67%。巴菲特投资业绩还表现出了极高的稳定性，在54年的漫长投资生涯中，只有两个年份出现小幅亏损（2001年的-6.2%和2008年的-9.6%），这是业绩的稳定性是众多职业投资者梦寐以求的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;巴菲特在1956年至1969年管理合伙投资期间，13年里没有发生一次亏损，累计获利28.88倍，年复合收益率29.5%。在此期间，巴菲特将投资机会类型分为低估类投资、控制类投资、套利类投资三类，并将资金分散投资于这些不同的投资机会上，巴菲特单只股票投资比例最大的股票是美国运通，从1964年开始陆续投入了1300万美元，占到所管理的合伙资产的40%左右。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在巴菲特后期的投资生涯中，投资比例最大的是可口可乐，先后陆续投资了10.24亿美元，占到当时伯克希尔34亿美元净资产的30%左右。巴菲特认为：控制不好的「集中投资」有点类似于再乱流中行驶的飞机，它比地下的火车快，可上下左右摇晃的幅度太大，让人受不了，尽管最后安全着陆。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在现金管理方面，巴菲特喜欢总是保留一定数额的现金，在近10年以来，巴菲特总是保持至少200亿美元的现金，截止2011年6月30日，伯克希尔持有的现金是478.9亿美元。在2008年美国金融危机期间投资了通用电气和高盛后，巴菲特减持了部分股票，他减持的理由是：现金偏少，让他觉得不踏实。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;他对于保持大量现金的理由是：不希望命运掌握他人手中，而是掌握在自己的手中，大量的现金可以让人睡得踏实等。事实上，正是由于总是喜欢持有一定的现金，巴菲特才可以安然度过多次经济危机及金融危机，并能够在危机中优秀公司出现非常低估的价格时，还有能力买入，而大部分投资者此时已经失去买卡入能力。巴菲特在资金管理方面堪称完美，是最值得借鉴、学习的投资大师。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;卡拉曼&lt;/b&gt;——Baupost基金公司总裁，最受投资者尊敬的价值投资大师之一，他的代表作《安全边际》（Margin of Safety）已成为重要的投资经典着作。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;卡拉曼管理的基金从1982 年到2009年的27年间年均收益率为19%，而同期的标准普尔500指数收益率仅为10.7%，更为难得的是，这25年里仅有一年亏损记录。卡拉曼投资管理的一大特点就是喜欢持有大量的现金。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;他在《晚上睡得着比什么都重要》的演讲说到：在过去的25年中，我们试图每天为客户做正确的事情，从不使用融资杠杆，且有时会持有大量现金，他有时候会持有40%多的现金（如1999年4月30日投资组合现金比例为42.1%）。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;他认为：在任何时候都保持满仓投资简化了投资任务，投资者似乎只要找到的最好的投资就可以了。相对诱人成了唯一的投资准绳，而无需满足绝对的价值标准。此类投资顶多只会带来普通的回报，最糟糕的情就是会产生高昂的机会成本——指错过了下一个出色的投资机会——并承受了出现巨大损失的风险。同时，卡拉曼的投资组合比较分散，单只证券投资比例不高。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;分析这三位价值投资大师的资金管理模式后，可以看到有两个共同特点：总是保留一定的现金；控制单只证券的投资比例，进行一定程度的分散。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;「保留一定的现金」的内在逻辑：&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;对市场保持敬畏，市场未来的发展是无法预测的，必须为可能出现的极端情况做一定准备；当没有非常具有吸引力的投资机会时，保留现金，宁缺毋滥；追求绝对回报，而不是相对表现；在意所管理资产表现的稳定性等。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;「进行一定的分散」的内在逻辑：&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;投资判断可能出错，或者发生小概率事件，避免判断失误或发生的小概率事件带来致命的损失；考虑到其它机会成本；在意资产整体的稳定性等。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;面三位价值投资的大师都是价值投资者的精神导师，他们资金管理模式给我们带来什么样的启示呢？&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;事实上，一个投资者的资金管理模式反映了他的投资哲学、世界观甚至性格。总是保留部分现金的投资者，他的投资哲学或性格可能是：认为对市场的未来持难以预测，对市场总是保持敬畏，担心会发生更为极端的情况，并为此对有所准备；追求绝对回报，坚持严格的投资标准，当没有满足符合条件的投资机会时，宁愿保留现金等；担心自己的判断有错误的可能，并为此留有余地等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;而总是满仓的投资者：对自己的判断具有绝对的信心；希望资金总是处于高效使用状态；担心错过现在的投资机会；在意跑赢市场，而不是追求绝对回报等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;只持有一只或两只股票的过度集中投资者，反映了他们：对自己的判断有绝对信心，总是认为有十足的把握；投资的证券是最好的等。而适当分散的投资者，则：担心自己判断可能出错；担心发生不利的小概率事件；希望保持资产组合表现一定的稳定性等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我自己经过多次惨痛的教训后，认识到了资金管理的重要性，一直在探索适合自己的资金管理的模式，经过多年的学习和实践之后，逐步形成了适合自己的资金管理模式。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;比如：总是喜欢保留至少10%的现金；单只证券的投资比例一般控制在20%以下，确定性特别高的投资机会则控制在40%以下；当确定投资目标后，喜欢分批建仓等。在这种资金管理模式下，我会觉得非常坦然，晚上睡觉也非常非常踏实。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;每个投资者可能因为自身投资哲学、性格等方面的不同，而选择不同的资金模式，只有这种模式是经过深思熟虑并适合自己的，都无可厚非。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;但对于专业投资者来说，特别是对于那些管理客户资金的职业投资者来说，格雷厄姆、巴菲特、卡拉曼三位投资大师的资金管理模式非常值得学习和借鉴，这种模式不仅带来了非常高的长期投资回报率，更为重要的是，业绩表现非常稳定。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在不断惨烈下跌的熊市下，做好资金管理的重要性更加彰显。做好资金管理最大的障碍还是人性，特别是贪婪！&lt;/p&gt;&lt;p&gt;在量化上进行资金管理更为重要，因为一开始就设置好仓位逻辑，不进行人为的干预，才能更完全实现的策略的精准化。&lt;/p&gt;</description>
<author>量化家</author>
<guid isPermaLink="false">2018-07-18-40038927</guid>
<pubDate>Wed, 18 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>世界区块链大会&amp;YOYOW创始人白菜受邀参加圆桌座谈</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-18-40002081.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40002081&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-63b28b4f9bab05a187a134a492e306a2_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;乌镇开启区块链2018新征程&lt;/b&gt;&lt;br&gt;“世界区块链大会”于2018年6月28日至6月30日进行，会址位于乌镇的“互联网国际会展中心”（浙江省桐乡市乌镇西栅景区）。乌镇，是优雅而富庶的历史文化名城，更在2014年11月19日成为“世界互联网大会”的永久举办地，自此乌镇从安逸的江南水乡转变成了财富出发和技术进步的先锋起点。在蝉鸣悠远的夏天，主题为《2018看见未来》的“世界区块链大会” &lt;br&gt;拉开了帷幕。&lt;br&gt;&lt;/p&gt;&lt;p&gt;“世界区块链大会”于2018年6月28日至6月30日进行，会址位于乌镇的“互联网国际会展中心”。YOYOW项目创始人白菜受邀参与了此次圆桌会，并就行业关心的热点话题表达了自己的专业见解。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d41076bdfa674574bb199dbca32b2ca8_r.jpg&quot; data-caption=&quot;世界区块链大会圆桌座谈现场&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d41076bdfa674574bb199dbca32b2ca8&quot; data-watermark-src=&quot;v2-53adf69b80b8e77b3eb8c08860bf1f83&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;行业先锋座谈共绘蓝图&lt;/b&gt;&lt;br&gt;这些区块链行业的资深从业者和长期爱好者来到这里，寻求加强海内外同行的交流碰撞，探讨和分享行业内共同面对的问题和挑战。并期待能够推进区块链技术和商业应用在中国更加健康、理性的发展。&lt;br&gt;在整个会议期间，有超过50+的知名嘉宾通过演讲分享实际案例，更有浙江电视台知名主持人小强主持的行业圆桌会，将区块链行业即将面对的机遇和挑战平摊在台面上，将会议气氛和实质探寻的深度推向了一个新的高度。&lt;br&gt;YOYOW项目创始人白菜受邀参与了此次圆桌会，并就行业关心的热点话题表达了自己的专业见解。YOYOW作为服务于内容领域的公链项目，旨在为类似知乎等UGC内容平台的内容创作者提供价值变现的服务。白菜本人从2013年起开始关注区块链技术，是行业成长的资深见证和参与者。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21ad66de912190826a3942ca8b5a0a30_r.jpg&quot; data-caption=&quot;YOYOW创始人白菜参与世界区块链大会圆桌座谈 &quot; data-size=&quot;normal&quot; data-rawwidth=&quot;600&quot; data-rawheight=&quot;400&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-21ad66de912190826a3942ca8b5a0a30&quot; data-watermark-src=&quot;v2-abffddfde7c59eaac023ccd2e20ad823&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;研究探讨 几个重要行业问题&lt;/b&gt;&lt;br&gt;在这场圆桌会上，来自浙江卫视的主持人小强提出了几个非常重要的问题供嘉宾作答。&lt;br&gt;在面对“有从业者将区块链技术分化为1.0、2.0甚至3.0的观点”时，白菜认为这种分化方式并不科学，他举例称曾经为大家所畅想的web3.0并没有发生，取而代之的是移动互联网时代，打车外卖等应用营运而生。他认为在区块链行业的基础建设完成之后，更多的发展应该是集中在行业应用上。&lt;br&gt;随后主持人提到“不可能的三角理论”：高效、去中心化、安全性几乎不可能同时出现在区块链应用上。面对这个尖锐的问题，各个嘉宾则都表现出足够的信心，均认为在具体应用上都可以得到有效的解决，如同互联网采用七层协议解决问题，区块链也并不需要在一个层面上解决所有的问题。&lt;br&gt;本次世界区块链大会的主题是：2018看见未来。在圆桌会的最后阶段，主持人询问在场嘉宾：在2018年百链齐发的状况下，各位来宾到底看见了怎样的未来，区块链会面对什么？这就像互联网在开始成长的过程中遇到的泡沫等问题一样，区块链也可能需要去面对这些。&lt;br&gt;白菜回应称：公链的开发是一项成本高、技术门槛高的事业，再加上技术成长是一件同步的事情，较早进入行业的项目优势会更加明显，在平台这个层面上的争夺恐怕年内就会结束，而面对互联网泡沫距离，BAT并不是当时的优胜者，他们只是活了下来，区块链的未来也依然会是个剩者为王的时代。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fed07687700e89f96bd00bc4f4461a43_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;600&quot; data-rawheight=&quot;400&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fed07687700e89f96bd00bc4f4461a43&quot; data-watermark-src=&quot;v2-df4d35bad3f13514a19a29b55ebbfc51&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt; 消息来源：&lt;a href=&quot;https://mp.weixin.qq.com/s/i9KuoE2y9X3Tp7jMTU_Lhw&quot;&gt;YOYOW官方&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>瘦子</author>
<guid isPermaLink="false">2018-07-18-40002081</guid>
<pubDate>Wed, 18 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>策略||因子回溯</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-17-39944861.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39944861&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;1. 目前的因子测试方法&lt;/b&gt;&lt;br&gt;目前的因子分析方法一般包括两方面：&lt;br&gt;1、 对因子收益率和 IC 的筛选：&lt;br&gt;◆     收益率：要求胜率或者 Top-Bottom 收益率超过设定值；&lt;br&gt;◆     IC：要求 IC 或者 T 检验超过设定值；&lt;br&gt;2、 对因子的单调性或者区分度的限制：&lt;br&gt;◆     单调性：要求因子收益率随因子的增加具有一定的单调性；&lt;br&gt;◆     区分度： 要求因子的不同分位数组合的收益率具有一定的差距；&lt;/p&gt;&lt;p&gt;&lt;b&gt;现有的因子筛选方法&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-96077b56eed8c6c9d9a056f1ce886b8f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;333&quot; data-rawheight=&quot;232&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-96077b56eed8c6c9d9a056f1ce886b8f&quot; data-watermark-src=&quot;v2-a8724a6a0a5d7ae055aabcb2f4b5f39c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;如果只从上述角度考虑，对因子的分析就仅仅局限于静态分析：&lt;/b&gt;&lt;br&gt;(1) 没有考虑因子有效性的时间变化：因子的有效性具有时变性，随着持&lt;br&gt;有期的变化因子的有效性是不断变化的，不同因子的有效性呈现出不&lt;br&gt;同的衰变规律；&lt;br&gt;(2) 没有考虑环境或者风格板块对因子有效性的影响： 因子的有效性在不&lt;br&gt;同的股票池、不同的风格板块上可能具有不同的规律，不同的宏观环&lt;br&gt;境下因子可能具有不同的特征。&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;针对上述缺陷，我重新设计了测试的框架，着重增加了对因子有效性的动态&lt;/b&gt;&lt;br&gt;&lt;b&gt;分析：&lt;/b&gt;&lt;br&gt;(1) 增加了对因子时间变化特征的分析：&lt;br&gt;包括 IC 的分布、 IC 的衰变、自相关性的衰变、买入信号的保持或逆转等内容；&lt;br&gt;(2) 增加了对因子的情境特征分析：&lt;br&gt;包括不同股票池（指数成分股/行业/风格）上的因子选股分析，宏观指标与因&lt;br&gt;&lt;br&gt;子组合的分析，不同市场阶段上的因子表现等，目的是发现因子适应于什么样的股票群体，什么样的市场阶段和宏观环境。&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;其他考虑因素&lt;/b&gt;&lt;br&gt;(1) 改进了数据清洗方法， 增加了平均绝对偏差方法；&lt;br&gt;(2) 设定了标准化/分位数/组合权重/残余收益率四个层次，便于从不同角&lt;br&gt;度过滤特定风格对因子的影响，实现风格中性化，例如对于行业影响，&lt;br&gt;可以从因子的行业标准化、因子的行业分位、组合权重的行业中性和&lt;br&gt;从个股收益率中直接剔除行业收益率四个方面剔除因子中的行业影响；&lt;br&gt;(3) 增加了初步的风险控制方面的内容：如因子回测的历史变动、组合的&lt;br&gt;跟踪误差以及组合业绩的归因等；&lt;br&gt;(4) 考虑了幸存者偏差： 各种股票池的设定， 根据的都是历史成分股， 保&lt;br&gt;证了回溯测试的有效性；&lt;br&gt;(5)详细校订了因子的信息公布时间：保证了因子的实时性；&lt;br&gt;(6)对增长因子，采用趋势化的方法，避免采用算术增长率或者几&lt;br&gt;何增长率所造长的两点偏差；&lt;br&gt;(7) 建立了初步的因子库， 分为估值因子/成长因子/规模因子/动量因子/&lt;br&gt;财务质量因子/技术因子/预测因子六个部分。&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 数据输入&lt;/b&gt;&lt;br&gt;数据输入部分， 主要工作包括数据的采集和整理、数据结构的设计， 生成最终&lt;br&gt;因子分析所需的数据集。 测试所需的数据主要包括股票/指数/风格/宏观四个&lt;br&gt;方面， 对各类数据和因子， 我们进行了细致的处理和校对， 包括消除幸存者偏&lt;br&gt;差、前视偏差等等；&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;2. 样本筛选&lt;/b&gt;&lt;br&gt;样本筛选部分， 主要功能是实现对股票池的初步筛选， 在因子测试时， 设定了三条筛选规则：&lt;br&gt;1) 剔除选股日的 ST/PT 股票；&lt;br&gt;2) 剔除上市不满一年的股票；&lt;br&gt;3) 剔除选股日由于停牌等原因而无法买入的股票；&lt;br&gt;当然，不同逻辑下可能会有不同的筛选，在这个测试框架下，允许添加对股&lt;/p&gt;&lt;p&gt;票池的其他筛选，但是所有筛选都要在样本筛选部分实现。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;4. 数据清洗&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;数据清洗部分， 主要功能是完成对因子和收益率数据的清洗。 数据清洗的目的&lt;br&gt;是去掉可能的数据错误和极端数据， 保证最终得到的模型具有稳健性。&lt;br&gt;数据清洗的内容包括两部分，即异常值的处理和缺失值的处理。&lt;/p&gt;&lt;p&gt;(1) 异常值的处理：&lt;/p&gt;&lt;p&gt;对于异常值的定义， 用一种更为稳健的绝对中位偏差方法（ MAD）：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-22093468ede00a5b3e7879f964ba828c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;380&quot; data-rawheight=&quot;35&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这里&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bcd5e298a43dc0317d2906e13c49a566_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;38&quot; data-rawheight=&quot;30&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;是数据集。&lt;br&gt;实际上， 对于异常值的处理，不同的因子可能采用不同的方式， 可供选择的处&lt;br&gt;理方式包括定义为 NA 或者用相近值替代， 具体的处理方式取决于对异常值的&lt;br&gt;逻辑解释。&lt;br&gt;需要说明的是异常值只是一个相对概念，有许多不同的异常值定义方法，如对&lt;br&gt;单因子异常值通常的定义方法是利用方差、中位数和四分位数，具体剔除多少，选择哪种方法，取决于数据本身的特征和对数据的主观理解， 以及对敏感性和稳健型的平衡。&lt;br&gt;&lt;/p&gt;&lt;p&gt;(2) 缺省值的处理：&lt;br&gt;数据的缺失值有不同的来源，如有些是原始数据缺失，有些是异常值处理产生&lt;br&gt;的。对缺失值的处理方式要依据缺失值的来源和逻辑解释， 选取不同的操作，&lt;br&gt;包括剔除或者替代。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5.分析计算&lt;/b&gt;&lt;br&gt;分析计算部分， 主要功能是完成对因子特征的各种分析。 对不同的因子，依据&lt;br&gt;不同的逻辑，可以分不同层次设定因子分析的方式：&lt;br&gt;(1) 因子的标准化方法：&lt;br&gt;新版测试中可供选择的因子标准化方法包括四种，&lt;br&gt;(a)   普通标准化方法，即通常求 z 值的方法；&lt;br&gt;(b)   市值标准化方法， 相对于普通标准化方法，考虑了规模对均值的影响， 均&lt;br&gt;值为市值加权平均数；&lt;br&gt;(c)    随机数标准化，根据因子的样本分布随机生成一个样本，将随机生成的样&lt;br&gt;本值依次赋给对应股票作为标准化后的因子值，优点是可以将因子值转换&lt;br&gt;为服从特定分布的得分；&lt;br&gt;(d)    风格标准化，即将股票池划分为不同的风格， 将每个股票的因子值用所属&lt;br&gt;风格的风格平均值和风格标准差进行标准化，一个特例就是用不同行业的&lt;br&gt;行业均值和行业标准差进行因子的行业标准化。&lt;/p&gt;&lt;p&gt;&lt;br&gt;(2) 因子的分位数方法&lt;br&gt;可供选择的分位数方法有两种：&lt;br&gt;(a)    普通分位数方法，即在整个股票池进行分位数计算；&lt;br&gt;(b)    风格分位数方法， 即在每个风格上进行分位数计算，然后构成整体股票池&lt;br&gt;的分位数结果。&lt;/p&gt;&lt;p&gt;风格分位方法，能够保证在每个分位组上，从数目上看各个风格是均匀分布的。风格分位的一个特例就是行业分位，即分别在每个行业上进行分位数计算，从而保证各个分位组中的行业分布在数目上是均匀的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;(3) 组合的权重方法&lt;br&gt;可供选择的组合权重方法有三种，&lt;br&gt;(a) 等权重方法，即组合中的每个股票具有同等的权重；&lt;br&gt;(b) 市值加权方法，即组合中的股票权重取决于股票的市值大小；&lt;br&gt;(c) 风格中性权重方法，即组合中的股票权重由股票的市值和股票所属风格在指数中所占的权重决定；&lt;/p&gt;&lt;p&gt;实际上，采用风格分位+市值加权，与采用普通分位+风格中性权重， 当指数权&lt;br&gt;&lt;/p&gt;&lt;p&gt;重与市值权重一致时，两种方法都能达到同样的风格中性效果。&lt;/p&gt;&lt;p&gt;&lt;br&gt;(4) 残余收益率方法&lt;br&gt;对风格影响的剔除，除了从上述标准化、分位数和权重三个角度考虑外，最后&lt;br&gt;一个方法就是直接从股票收益率中剔除所在风格板块的收益率。&lt;br&gt;下图说明了上述四种处理方式的关系，分位数、 标准化和残余收益率三种方法&lt;br&gt;是从影响 IC 角度影响因子的有效性，而权重是从收益率角度影响因子的有效&lt;br&gt;性。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-907287182d341e74d135f34fc3ab4603_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;578&quot; data-rawheight=&quot;248&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-907287182d341e74d135f34fc3ab4603&quot; data-watermark-src=&quot;v2-458b4c3933f003dff0e33b502797c4f6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化家</author>
<guid isPermaLink="false">2018-07-17-39944861</guid>
<pubDate>Tue, 17 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>量化||择时</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-13-39655070.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39655070&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;1、什么叫量化择时？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;量化择时的本质是寻找一个或多个识别趋势的因子，然后用一个机械化的规则告诉你买卖时点，最简单的量化择时是利用均线系统，比如指数收盘价上穿20日均线，买入！下穿20日均线，则卖出！这样一种完全按照既定规则和指标办事的择时策略就是量化择时。事实上，任何一种持之以恒的单均线择时策略，长期来看一定是赚钱的，这是因为趋势整体是向上的，下穿均线离场又是一种风控保护。不过量化择时策略远远不限于传统的技术指标。任何价格曲线可以分解成两项：趋势项+噪音项，比如用分形几何、小波分析、傅里叶信号处理等复杂的数据处理方法去除非趋势项的噪音，这样就会让趋势项露出“尖尖角”，从而抓住趋势吃到“大头”。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9b555813f01a70b2cae6c2a693a68d99_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;556&quot; data-rawheight=&quot;137&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9b555813f01a70b2cae6c2a693a68d99&quot; data-watermark-src=&quot;v2-fed4a397a5825a79f2e38d1211933e94&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;2、量化择时等于技术分析吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我曾经听过一个说法，技术分析就是量化择时的一种。或者有人问我“你的择时模型是不是都是技术面的？”我的理解是技术分析不等于量化择时，两者甚至互相不是子集关系。&lt;/p&gt;&lt;p&gt;技术分析是自成体系的一个流派，帮助交易者选择较好进场或离场的时点，它基于三个假设：市场价格包含一切信息，价格沿趋势移动，历史会重演。每个人运用技术指标或形态得出的结论会一定是不同的，这也正是技术分析的魅力所在，看法不同大家才会成交，比如同样运用波浪理论：A认为目前处在第3浪，B可能觉得处在第5浪，C却认为在大1浪。&lt;/p&gt;&lt;p&gt;而量化择时策略不可能出现因人而异的情况。只要两个人所使用的因子、参数、和既定规则是一样的，两个人得到的买入信号或卖出信号发出日就是同一日。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a511ab5194a83f9a786e6df9c4d08518_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;320&quot; data-rawheight=&quot;197&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a511ab5194a83f9a786e6df9c4d08518&quot; data-watermark-src=&quot;v2-3759272690d0c3c2ea7644358e4862ba&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3、胜率与赔率，“鱼与熊掌不可兼得”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;择时策略从时间的维度看，可以分成日内择时、日频择时、周频择时等。简而言之，日内择时就是加工分钟甚至秒级别价、量信息，然后发出日内买卖信号；日频择时是每日收盘发出买卖信号，指导我下一个交易日的买卖操作；周频自然就是每周末发出信号指导下周的操作。除了日内择时外，几乎所有的日频、周频择时策略都难以突破“胜率与赔率，两者不可兼得”的魔咒！&lt;/p&gt;&lt;p&gt;高胜率低赔率的择时策略虽然一段时间内胜率不错，但每次都只赢一点点就走人，赔率显得很低，这就好比你认为某国家男足冲击世界杯未果，50多年以来大概率（只有2002年输过一次）你能够获胜，胜率奇高，但卖这样的足彩每次只能赚一点点，因为赔率很低；&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2ca86fc136985b508ac133740ce22bfa_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;336&quot; data-rawheight=&quot;215&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2ca86fc136985b508ac133740ce22bfa&quot; data-watermark-src=&quot;v2-0fe2a095f7c9ff025291edb7d8fdde62&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;而低胜率高频率的择时策略就很像买彩票，可能连续买了都没中奖，但亏损都很小，一旦买对一次，则牛逼了！如此一来赔率就会很高！所有依赖于均线、趋势线择时策略都必然是低胜率高赔率的策略，因为它们用下穿趋势线的风控代价保证了每次亏损的有限性，为的就是博到某次正确时满满地吃到一波趋势！&lt;/p&gt;&lt;p&gt;&lt;b&gt;4、你更在乎哪一点，信号次数与胜率的反向关系？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;老天爷是公平的，有句老话叫：“不做不错，多做多错，该出手时就出手”。国际投资大师巴菲特、索罗斯一年就出手几次，但笔笔是狠招！所以开发量化择时策略时，我们必须兼顾信号次数的频繁性和胜率的关系，通常而言，信号越频繁，出错概率就越大，策略的胜率就会越低！下表就是某个择时策略，输入不同的参数得到不同的信号次数，随之而来的就是胜率的降低。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6bdc8207d73befd30ab6bf13f19db27c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;276&quot; data-rawheight=&quot;208&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6bdc8207d73befd30ab6bf13f19db27c&quot; data-watermark-src=&quot;v2-74a298d9d0313c94ad555a59bec62508&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;信号次数、胜率之间，你更在乎哪点？那就用不同的参数去做敏感性测试吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;5、日内择时，降低择时回撤的极致手法！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有别于量化选股+对冲的策略，量化择时策略是一个beta型的策略（大盘涨择时净值也涨，大盘跌择时净值也很难涨），因此它不可避免的有回撤。在第1问中的绩效表格里，你会发现简单的单均线择时策略大部分回撤都超过30%（因为上证综指在过去10年里的最大回撤都超过了70%），优秀一些的日频择时策略可以做到过去10年内的最大回撤20%以下，然而超过一个跌停板的回撤是无论如何无法避免的。于是你会遇见一个两个字，叫“瓶颈”。&lt;/p&gt;&lt;p&gt;任何瓶颈的突破本质上是维度的突破。爱因斯坦突破了牛顿的绝对时空观，把物理学推向新的高度；概率论把数学从确定性的研究推向了随机性的研究；微积分的诞生把有限的算术变成了无限的数学。而要在高赔率的前提下尽量提高胜率不可兼得的瓶颈，只能从时间的维度进行压缩，把日频择时策略“压缩”成日内择时策略。类似西蒙斯的文艺复兴基金等知名对冲基金，便也是依赖日内择时策略等高频交易策略。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c7d780ed65552e64fac7540d0a5d1357_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;328&quot; data-rawheight=&quot;202&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c7d780ed65552e64fac7540d0a5d1357&quot; data-watermark-src=&quot;v2-8c7ef3d145685c43ee85b38de1f950bb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt; &lt;/p&gt;&lt;p&gt;&lt;b&gt;6、择时信号除了告诉你方向，还有什么吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好的量化择时信号器应该至少输出两个维度的信息：一个是多空方向（买入还是卖出），另一个是信号的强弱。为什么后一个信息也如此的重要？因为它能够指导您的仓位、资金管理，比如：在信号处于“很强”，分配50%的beta仓位；在信号处于“强”时，分配30%，在信号处于“极弱”时，宁愿放弃本次买入信号等等。再如某些量化择时策略是通过一个打分体系建立的，信号本身就是0-10分，那么在10分时您可以给予更多的多头仓位，而在0分时给予更多的空头仓位。这样的择时方法提供了更多的一个信息维度，而不是每次都不切合实际地假设满仓操作！&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d046249a1d70b6848c7e5ddf337d54cc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;280&quot; data-rawheight=&quot;208&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d046249a1d70b6848c7e5ddf337d54cc&quot; data-watermark-src=&quot;v2-9fea0de6934c266d22cfe78538d96740&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;7、量化择时与期权有神马关系吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;回答是太有关系了！期权的价、量信息里处处蕴含着市场交易者对未来的预期看法。最常见运用期权信息得到的量化择时信号就是华尔街的对冲基金大佬们每天关注的VIX指数，这个指数就是由期权价格反推出来的，反映的是市场对标普500未来30天的恐慌程度。&lt;/p&gt;&lt;p&gt;下面先截取了1995.12-1999.12的VIX日线图，您会发现有两段处于明显的上升区间，一个是1997的亚洲金融危机，一个则是1998年长期资本管理公司破产。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e4d920ad2e4589ad7a55c8f161a9939c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;432&quot; data-rawheight=&quot;229&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e4d920ad2e4589ad7a55c8f161a9939c&quot; data-watermark-src=&quot;v2-43c989e25abba2d07e8b6fa7403230d2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;下面再截取了2001.7-2002.6的VIX日线图，您会发现有一段处于明显的上升区间，它就发生在令人不寒而栗的美国9.11恐怖袭击事件的当月。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8036dcf6ec0feebe3b92467f2a284469_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;332&quot; data-rawheight=&quot;263&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8036dcf6ec0feebe3b92467f2a284469&quot; data-watermark-src=&quot;v2-6a29575158e7f9911eda3d0a657264c7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;下面再截取了2008.5-2009.4的VIX日线图，您会发现VIX指数有一段处于明显的上升区间，达到了史上最高的89.53！在此期间又发生了什么呢？您可能已经知道了~~~臭名昭著的2008年次贷危机，雷曼兄弟破产！&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-978817b3f007722b2763c650aa9ddd8c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;432&quot; data-rawheight=&quot;276&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-978817b3f007722b2763c650aa9ddd8c&quot; data-watermark-src=&quot;v2-ce61b9f1156a33fe68b7f29a2db75604&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;最后，我们截取今年5月至今的VIX日线图，会发现也有两段陡峭上升的阶段，一个就是6.23英国不作就不会死的脱欧事件，另一个就是希拉里邮件门与特朗普的惊天大逆袭！&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-02691d77ab0a6d26f02b95a2aeeb20f9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;440&quot; data-rawheight=&quot;254&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-02691d77ab0a6d26f02b95a2aeeb20f9&quot; data-watermark-src=&quot;v2-a620c581d77fc25595346bd4266c4def&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;我们举了这些活生生的案例，是为了得出这样的结论：当市场出现黑天鹅事件时，所有的交易者都会陷入恐慌，对未来风险（波动率）的预期会达到一个高值，于是VIX指数便扶摇而上。所以说，VIX指数被称为恐慌指数，是市场黑天鹅事件的预警器。&lt;/p&gt;&lt;p&gt;幸运的是，我们的证券市场上也有了自己VIX指数，叫做“中国波指”，它反映的是市场对50指数未来30天的波动率预期值。&lt;/p&gt;&lt;p&gt;不仅如此，除了波动率指数可以加入择时策略的因子库以外，还有诸如认购-认沽比之类的因子也可以帮助我们建立漂亮的量化择时策略。认购-认沽比通常定义为全部认购期权的成交量/全部认沽期权的成交量，该值越高则反映市场看涨气氛越浓厚，反之则看空气氛越浓厚。下面就是一个基于认购-认沽比等信息挖掘得出的择时模型，在固定收益资产与期权90-10搭配下的净值曲线。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aff5626132c065fc0fd533db9d333eee_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;400&quot; data-rawheight=&quot;212&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-aff5626132c065fc0fd533db9d333eee&quot; data-watermark-src=&quot;v2-c95017bb4c4a6215d5bcca9380cca8f4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化家</author>
<guid isPermaLink="false">2018-07-13-39655070</guid>
<pubDate>Fri, 13 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>基于event-driven量化回测交易python开源框架</title>
<link>https://henix.github.io/feeds/zhuanlan.c_106548378/2018-07-11-39536634.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39536634&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4d2f51c7b2ca67418b7ff842f102b056_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;AmazingQuant&lt;/b&gt;&lt;br&gt;&lt;/h2&gt;&lt;h2&gt;&lt;b&gt;1.简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/zhanggao2013/AmazingQuant&quot;&gt;https://github.com/zhanggao2013/AmazingQuant&lt;/a&gt; &lt;/p&gt;&lt;p&gt;AmazingQuant是一款基于event-driven的量化回测交易开源框架，下图是总体框架架构。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-47a2203d5b890ce537c558e77882643d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1537&quot; data-rawheight=&quot;1032&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-47a2203d5b890ce537c558e77882643d&quot; data-watermark-src=&quot;v2-fd3f0eab53331717ac9e80a10a5ed0e9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;data_center&lt;/li&gt;&lt;ul&gt;&lt;li&gt;to_mongoDB 存放行情、财务等各种数据到MongoDB的存储模块&lt;/li&gt;&lt;li&gt;get_data   策略中从数据库中取数据的接口模块&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;trade_center&lt;/li&gt;&lt;ul&gt;&lt;li&gt;mossion_engine   包含下单任务（event_order）和风控（event_risk_management）两部分的engine，分别完成下单前的检查和风控&lt;/li&gt;&lt;li&gt;broker_engine    分为回测时的simulate的broker（主要是event_deal）撮合成交和连接实盘交易CTP、xSpeed等接口两部分&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;strategy_center&lt;/li&gt;&lt;ul&gt;&lt;li&gt;bar_engine       在回测或者交易模式下，用`逐K线`的方式执行每一根bar的交易逻辑，可在日线、分钟线、分笔下运行&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;analysis_center&lt;/li&gt;&lt;ul&gt;&lt;li&gt;analysis_engine  对回测形成的交易记录进行分析和可视化，净值、年化收益、alpha、beta、回撤等指标，brison、Fama等经典模型的实现&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;2.安装配置&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;MongoDB 3.4 &lt;br&gt;&lt;br&gt; 建议使用shard，配置启动项示例&lt;/li&gt;&lt;li&gt;pymongo &lt;br&gt;&lt;br&gt; python调用MongoDB&lt;/li&gt;&lt;li&gt;talib &lt;br&gt;&lt;br&gt; 技术指标计算库&lt;/li&gt;&lt;li&gt;anaconda &lt;br&gt;&lt;br&gt; python 3.5 的版本，如果大于3.5的版本，ctp的接口暂时不能用，因为编译问题，后续可以解决&lt;/li&gt;&lt;li&gt;Linux Ubuntu &lt;br&gt;&lt;br&gt; 开发环境是ubuntu，当然也可以在windows下用，但是数据库的配置和ctp等交易接口需要重新做&lt;/li&gt;&lt;li&gt;安装AmazingQuant&lt;br&gt;&lt;br&gt; pip install AmazingQuant  直接安装&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;3.策略编写&lt;/b&gt;&lt;/h2&gt;&lt;code lang=&quot;text&quot;&gt;# -*- coding: utf-8 -*-

__author__ = &quot;gao&quot;

import numpy as np
import talib

# import strategy基类
from AmazingQuant.strategy_center.strategy import *

# import 交易模块
from AmazingQuant.trade_center.trade import Trade


# 继承strategy基类
class MaStrategy(StrategyBase):
    def initialize(self):
        # 设置运行模式，回测或者交易
        self.run_mode = RunMode.BACKTESTING.value
        # 设置回测资金账号
        self.account = [&quot;test0&quot;, &quot;test1&quot;]
        # 设置回测资金账号资金量
        self.capital = {&quot;test0&quot;: 2000000, &quot;test1&quot;: 1000}
        # 设置回测基准
        self.benchmark = &quot;000300.SH&quot;
        # 设置复权方式
        self.rights_adjustment = RightsAdjustment.NONE.value
        # 设置回测起止时间
        self.start = &quot;2015-01-11&quot;
        self.end = &quot;2016-01-16&quot;
        # 设置运行周期
        self.period = &quot;daily&quot;
        # 设置股票池
        self.universe = [&#39;000001.SZ&#39;, &#39;000002.SZ&#39;, &#39;000008.SZ&#39;, &#39;000060.SZ&#39;, &#39;000063.SZ&#39;, &#39;000069.SZ&#39;, &#39;000100.SZ&#39;,
                         &#39;000157.SZ&#39;, &#39;000166.SZ&#39;, &#39;000333.SZ&#39;, &#39;000338.SZ&#39;, &#39;000402.SZ&#39;, &#39;000413.SZ&#39;, &#39;000415.SZ&#39;,
                         &#39;000423.SZ&#39;, &#39;000425.SZ&#39;, &#39;000503.SZ&#39;, &#39;000538.SZ&#39;, &#39;000540.SZ&#39;, &#39;000559.SZ&#39;, &#39;000568.SZ&#39;,
                         &#39;000623.SZ&#39;, &#39;000625.SZ&#39;, &#39;000627.SZ&#39;, &#39;000630.SZ&#39;, &#39;000651.SZ&#39;, &#39;000671.SZ&#39;, &#39;000686.SZ&#39;,
                         &#39;000709.SZ&#39;, &#39;000723.SZ&#39;, &#39;000725.SZ&#39;, &#39;000728.SZ&#39;, &#39;000738.SZ&#39;, &#39;000750.SZ&#39;, &#39;000768.SZ&#39;,
                         &#39;000776.SZ&#39;, &#39;000783.SZ&#39;, &#39;000792.SZ&#39;, &#39;000826.SZ&#39;, &#39;000839.SZ&#39;, &#39;000858.SZ&#39;, &#39;000876.SZ&#39;,
                         &#39;000895.SZ&#39;, &#39;000898.SZ&#39;, &#39;000938.SZ&#39;, &#39;000959.SZ&#39;, &#39;000961.SZ&#39;, &#39;000963.SZ&#39;, &#39;000983.SZ&#39;,
                         &#39;001979.SZ&#39;, &#39;002007.SZ&#39;, &#39;002008.SZ&#39;, &#39;002024.SZ&#39;, &#39;002027.SZ&#39;, &#39;002044.SZ&#39;, &#39;002065.SZ&#39;,
                         &#39;002074.SZ&#39;, &#39;002081.SZ&#39;, &#39;002142.SZ&#39;, &#39;002146.SZ&#39;, &#39;002153.SZ&#39;, &#39;002174.SZ&#39;, &#39;002202.SZ&#39;,
                         &#39;002230.SZ&#39;, &#39;002236.SZ&#39;, &#39;002241.SZ&#39;, &#39;002252.SZ&#39;, &#39;002292.SZ&#39;, &#39;002294.SZ&#39;, &#39;002304.SZ&#39;,
                         &#39;002310.SZ&#39;, &#39;002352.SZ&#39;, &#39;002385.SZ&#39;, &#39;002411.SZ&#39;, &#39;002415.SZ&#39;, &#39;002424.SZ&#39;, &#39;002426.SZ&#39;,
                         &#39;002450.SZ&#39;, &#39;002456.SZ&#39;, &#39;002460.SZ&#39;, &#39;002465.SZ&#39;, &#39;002466.SZ&#39;, &#39;002468.SZ&#39;, &#39;002470.SZ&#39;,
                         &#39;002475.SZ&#39;, &#39;002500.SZ&#39;, &#39;002508.SZ&#39;, &#39;002555.SZ&#39;, &#39;002558.SZ&#39;, &#39;002572.SZ&#39;, &#39;002594.SZ&#39;,
                         &#39;002601.SZ&#39;, &#39;002602.SZ&#39;, &#39;002608.SZ&#39;, &#39;002624.SZ&#39;, &#39;002673.SZ&#39;, &#39;002714.SZ&#39;, &#39;002736.SZ&#39;,
                         &#39;002739.SZ&#39;, &#39;002797.SZ&#39;, &#39;002831.SZ&#39;, &#39;002839.SZ&#39;, &#39;002841.SZ&#39;, &#39;300003.SZ&#39;, &#39;300015.SZ&#39;,
                         &#39;300017.SZ&#39;, &#39;300024.SZ&#39;, &#39;300027.SZ&#39;, &#39;300033.SZ&#39;, &#39;300059.SZ&#39;, &#39;300070.SZ&#39;, &#39;300072.SZ&#39;,
                         &#39;300122.SZ&#39;, &#39;300124.SZ&#39;, &#39;300136.SZ&#39;, &#39;300144.SZ&#39;, &#39;300251.SZ&#39;, &#39;300315.SZ&#39;, &#39;600000.SH&#39;,
                         &#39;600008.SH&#39;, &#39;600009.SH&#39;, &#39;600010.SH&#39;, &#39;600011.SH&#39;, &#39;600015.SH&#39;, &#39;600016.SH&#39;, &#39;600018.SH&#39;,
                         &#39;600019.SH&#39;, &#39;600021.SH&#39;, &#39;600023.SH&#39;, &#39;600028.SH&#39;, &#39;600029.SH&#39;, &#39;600030.SH&#39;, &#39;600031.SH&#39;,
                         &#39;600036.SH&#39;, &#39;600038.SH&#39;, &#39;600048.SH&#39;, &#39;600050.SH&#39;, &#39;600061.SH&#39;, &#39;600066.SH&#39;, &#39;600068.SH&#39;,
                         &#39;600074.SH&#39;, &#39;600085.SH&#39;, &#39;600089.SH&#39;, &#39;600100.SH&#39;, &#39;600104.SH&#39;, &#39;600109.SH&#39;, &#39;600111.SH&#39;,
                         &#39;600115.SH&#39;, &#39;600118.SH&#39;, &#39;600153.SH&#39;, &#39;600157.SH&#39;, &#39;600170.SH&#39;, &#39;600177.SH&#39;, &#39;600188.SH&#39;,
                         &#39;600196.SH&#39;, &#39;600208.SH&#39;, &#39;600219.SH&#39;, &#39;600221.SH&#39;, &#39;600233.SH&#39;, &#39;600271.SH&#39;, &#39;600276.SH&#39;,
                         &#39;600297.SH&#39;, &#39;600309.SH&#39;, &#39;600332.SH&#39;, &#39;600340.SH&#39;, &#39;600352.SH&#39;, &#39;600362.SH&#39;, &#39;600369.SH&#39;,
                         &#39;600372.SH&#39;, &#39;600373.SH&#39;, &#39;600376.SH&#39;, &#39;600383.SH&#39;, &#39;600390.SH&#39;, &#39;600406.SH&#39;, &#39;600415.SH&#39;,
                         &#39;600436.SH&#39;, &#39;600482.SH&#39;, &#39;600485.SH&#39;, &#39;600489.SH&#39;, &#39;600498.SH&#39;, &#39;600518.SH&#39;, &#39;600519.SH&#39;,
                         &#39;600522.SH&#39;, &#39;600535.SH&#39;, &#39;600547.SH&#39;, &#39;600549.SH&#39;, &#39;600570.SH&#39;, &#39;600583.SH&#39;, &#39;600585.SH&#39;,
                         &#39;600588.SH&#39;, &#39;600606.SH&#39;, &#39;600637.SH&#39;, &#39;600649.SH&#39;, &#39;600660.SH&#39;, &#39;600663.SH&#39;, &#39;600674.SH&#39;,
                         &#39;600682.SH&#39;, &#39;600685.SH&#39;, &#39;600688.SH&#39;, &#39;600690.SH&#39;, &#39;600703.SH&#39;, &#39;600704.SH&#39;, &#39;600705.SH&#39;,
                         &#39;600739.SH&#39;, &#39;600741.SH&#39;, &#39;600795.SH&#39;, &#39;600804.SH&#39;, &#39;600816.SH&#39;, &#39;600820.SH&#39;, &#39;600827.SH&#39;,
                         &#39;600837.SH&#39;, &#39;600871.SH&#39;, &#39;600886.SH&#39;, &#39;600887.SH&#39;, &#39;600893.SH&#39;, &#39;600895.SH&#39;, &#39;600900.SH&#39;,
                         &#39;600909.SH&#39;, &#39;600919.SH&#39;, &#39;600926.SH&#39;, &#39;600958.SH&#39;, &#39;600959.SH&#39;, &#39;600977.SH&#39;, &#39;600999.SH&#39;,
                         &#39;601006.SH&#39;, &#39;601009.SH&#39;, &#39;601012.SH&#39;, &#39;601018.SH&#39;, &#39;601021.SH&#39;, &#39;601088.SH&#39;, &#39;601099.SH&#39;,
                         &#39;601111.SH&#39;, &#39;601117.SH&#39;, &#39;601118.SH&#39;, &#39;601155.SH&#39;, &#39;601163.SH&#39;, &#39;601166.SH&#39;, &#39;601169.SH&#39;,
                         &#39;601186.SH&#39;, &#39;601198.SH&#39;, &#39;601211.SH&#39;, &#39;601212.SH&#39;, &#39;601216.SH&#39;, &#39;601225.SH&#39;, &#39;601228.SH&#39;,
                         &#39;601229.SH&#39;, &#39;601288.SH&#39;, &#39;601318.SH&#39;, &#39;601328.SH&#39;, &#39;601333.SH&#39;, &#39;601336.SH&#39;, &#39;601375.SH&#39;,
                         &#39;601377.SH&#39;, &#39;601390.SH&#39;, &#39;601398.SH&#39;, &#39;601555.SH&#39;, &#39;601600.SH&#39;, &#39;601601.SH&#39;, &#39;601607.SH&#39;,
                         &#39;601608.SH&#39;, &#39;601611.SH&#39;, &#39;601618.SH&#39;, &#39;601628.SH&#39;, &#39;601633.SH&#39;, &#39;601668.SH&#39;, &#39;601669.SH&#39;,
                         &#39;601688.SH&#39;, &#39;601718.SH&#39;, &#39;601727.SH&#39;, &#39;601766.SH&#39;, &#39;601788.SH&#39;, &#39;601800.SH&#39;, &#39;601818.SH&#39;,
                         &#39;601857.SH&#39;, &#39;601866.SH&#39;, &#39;601872.SH&#39;, &#39;601877.SH&#39;, &#39;601878.SH&#39;, &#39;601881.SH&#39;, &#39;601888.SH&#39;,
                         &#39;601898.SH&#39;, &#39;601899.SH&#39;, &#39;601901.SH&#39;, &#39;601919.SH&#39;, &#39;601933.SH&#39;, &#39;601939.SH&#39;, &#39;601958.SH&#39;,
                         &#39;601966.SH&#39;, &#39;601985.SH&#39;, &#39;601988.SH&#39;, &#39;601989.SH&#39;, &#39;601991.SH&#39;, &#39;601992.SH&#39;, &#39;601997.SH&#39;,
                         &#39;601998.SH&#39;, &#39;603160.SH&#39;, &#39;603799.SH&#39;, &#39;603833.SH&#39;, &#39;603858.SH&#39;, &#39;603993.SH&#39;]

        # 设置在运行前是否缓存日线，分钟线等各个周期数据
        self.daily_data_cache = True
        print(self.universe)

        # 回测滑点设置，按固定值0.01,20-0.01 = 19.99;百分比0.01,20*(1-0.01) = 19.98;平仓时用&quot;+&quot;
        self.set_slippage(stock_type=StockType.STOCK.value, slippage_type=SlippageType.SLIPPAGE_FIX.value, value=0.01)

        # 回测股票手续费和印花税，卖出印花税，千分之一；开仓手续费，万分之三；平仓手续费，万分之三，最低手续费，５元
        # 沪市，卖出有万分之二的过户费，加入到卖出手续费
        self.set_commission(stock_type=StockType.STOCK_SH.value, tax=0.001, open_commission=0.0003,
                            close_commission=0.0003,
                            close_today_commission=0, min_commission=5)
        # 深市不加过户费
        self.set_commission(stock_type=StockType.STOCK_SZ.value, tax=0.001, open_commission=0.0003,
                            close_commission=0.0005,
                            close_today_commission=0, min_commission=5)

    def handle_bar(self, event):
        # 取当前bar的持仓情况
        available_position_dict = {}
        for position in Environment.bar_position_data_list:
            available_position_dict[position.instrument + &quot;.&quot; + position.exchange] = position.position - position.frozen
        # 当前bar的具体时间戳
        current_date = data_transfer.millisecond_to_date(millisecond=self.timetag, format=&quot;%Y-%m-%d&quot;)
        # 时间戳转换成int，方便后面取数据
        current_date_int = data_transfer.date_str_to_int(current_date)
        print(current_date)
        # 取数据实例
        data_class = GetData()
        # 循环遍历股票池
        for stock in self.universe:
            # 取当前股票的收盘价
            close_price = data_class.get_market_data(Environment.daily_data, stock_code=[stock], field=[&quot;close&quot;],
                                                     end=current_date)
            # print(self.start, current_date)
            close_array = np.array(close_price)
            if len(close_array) &amp;gt; 0:
                # 利用talib计算MA
                ma5 = talib.MA(np.array(close_price), timeperiod=5)
                ma20 = talib.MA(np.array(close_price), timeperiod=20)
                # print(type(close_price.keys()))
                # 过滤因为停牌没有数据
                if current_date_int in close_price.keys():
                    # 如果5日均线突破20日均线，并且没有持仓，则买入这只股票100股，以收盘价为指定价交易
                    if ma5[-1] &amp;gt; ma20[-1] and stock not in available_position_dict.keys():
                        Trade(self).order_shares(stock_code=stock, shares=100, price_type=&quot;fix&quot;,
                                                 order_price=close_price[current_date_int],
                                                 account=self.account[0])
                        print(&quot;buy&quot;, stock, 1, &quot;fix&quot;, close_price[current_date_int], self.account)
                    # 如果20日均线突破5日均线，并且有持仓，则卖出这只股票100股，以收盘价为指定价交易
                    elif ma5[-1] &amp;lt; ma20[-1] and stock in available_position_dict.keys():
                        Trade(self).order_shares(stock_code=stock, shares=-100, price_type=&quot;fix&quot;,
                                                 order_price=close_price[current_date_int],
                                                 account=self.account[0])
                        print(&quot;sell&quot;, stock, -1, &quot;fix&quot;, close_price[current_date_int], self.account)


if __name__ == &quot;__main__&quot;:
    # 测试运行完整个策略所需时间，目前没有做过多优化，
    # 300只股票，日线数据，一年的时间区间，4000多次交易记录，在我的虚拟机大概80s，换个性能稍好点的机器，应该会快很多
    from AmazingQuant.utils.performance_test import Timer

    time_test = Timer(True)
    with time_test:
        # 运行策略，设置是否保存委托，成交，资金，持仓
        MaStrategy().run(save_trade_record=True)
&lt;/code&gt;&lt;h2&gt;&lt;b&gt;4.回测结果分析&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;自动生成回测结果&lt;br&gt;&lt;br&gt;产生的委托，成交，资金，持仓的cvs文件写入到策略所在文件夹&lt;/li&gt;&lt;li&gt;自动生成回测报告&lt;br&gt;&lt;br&gt;回测报告是html格式，可在浏览器中打开查看，效果如下图： &lt;br&gt;&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4319e7503d50d8a47999c5f12f04f8e5_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1196&quot; data-rawheight=&quot;811&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4319e7503d50d8a47999c5f12f04f8e5&quot; data-watermark-src=&quot;v2-96490f4f682e4aa2e6e2334ef2894cf1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;5.实盘交易&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前已实现根据vnpy的方式封装的使用boost对CTP的C++接口进行python3.5的封装，后续将实现与broker_engine的对接&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6.已实现和即将实现的功能&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;已实现&lt;/li&gt;&lt;li&gt;数据库搭建&lt;/li&gt;&lt;li&gt;读取数据&lt;/li&gt;&lt;li&gt;策略运行回测&lt;/li&gt;&lt;li&gt;回测交易记录的保存和分析&lt;/li&gt;&lt;li&gt;实盘CTP接口的封装&lt;/li&gt;&lt;li&gt;即将实现&lt;/li&gt;&lt;li&gt;各种数据的对接&lt;br&gt;&lt;br&gt;例如股票的分钟数据、股票财务数据、股票板块成分股、期货分钟数据、日线数据等&lt;/li&gt;&lt;li&gt;CTP等交易接口与broker_engine对接&lt;br&gt;&lt;br&gt;CTP、xSpeed等&lt;/li&gt;&lt;li&gt;对回测区间的每一根bar的交易和持仓情况可视化&lt;br&gt;&lt;/li&gt;&lt;li&gt;回测分析模块的丰富&lt;br&gt;&lt;br&gt;增加brison、FAMA等各种绩效归因模型的分析和可视化&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;7.联系方式&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;欢迎加qq群讨论: 788279189&lt;br&gt;&lt;br&gt;我的qq：82045571&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>zhanggao2013</author>
<guid isPermaLink="false">2018-07-11-39536634</guid>
<pubDate>Wed, 11 Jul 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
