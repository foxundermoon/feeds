<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>川流不息</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/</link>
<description>北京量信投资管理有限公司是一家在中国基金业协会备案登记的专业私募基金管理人。本专栏作者石川是量信投资的联合创始人。希望通过这个平台和各位小伙伴分享我们在量化投资领域的知识和心得。原创不易，请保护版权，请在获得授权后转载。已委托“维权骑士”(http://rightknights.com) 为进行维权行动。</description>
<language>zh-cn</language>
<lastBuildDate>Fri, 19 Oct 2018 03:00:29 +0800</lastBuildDate>
<item>
<title>简单多样化，资产配置的优秀基准</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-10-17-46971981.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46971981&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-91339cbde94a3172bed635fb1005d85e_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;简单多样化是一个客观的比较基准；任何复杂的资产配置方法都需要至少要在统计上显著战胜简单多样化才能被称之为有效。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;资产配置（Asset Allocation） 在量化投资中无处不在。&lt;/b&gt;投资者需要把资金配置在不同的资产中，比如股票、债券、商品期货等；多因子选股策略需要决定使用哪些因子以及资金在这些因子中的配置比例（每一个因子就是一个投资组合）；Fund of Fund（FOF）需要调研大量的基金从而在相关性低的基金之间进行配置。&lt;/p&gt;&lt;p&gt;&lt;b&gt;科学的资产配置对于投资的成功至关重要。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;然而由于每种资产的收益存在不确定性（风险），且不同资产之间的相关性也不同，因此在几十年前人们并不知道应该怎么“科学”配置，直到马科维茨的 Modern Portfolio Theory （MPT）横空出世（Markowitz 1952）。&lt;/p&gt;&lt;p&gt;MPT 使用 mean-variance optimization 确定最佳的配置权重，在数学上十分优雅。然而在实战中，MPT 却因在样本外的表现很差而声名狼藉。&lt;b&gt;这是因为优化结果对于输入异常敏感，而仅使用历史样本数据进行均值和协方差进行估计的估计误差（estimation error）非常大。&lt;/b&gt;如何减少 estimation error 就成了学术界关注的重点。&lt;/p&gt;&lt;p&gt;改进仅使用样本历史数据的 mean-variance optimization 的努力主要有以下几个方向：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;贝叶斯收缩：&lt;/b&gt;在金融领域，最重要的是 prediction 是否准确，而不是参数估计是否 unbiased。使用历史数据进行参数估计是 unbiased，但是 estimation error 很大。在贝叶斯方法中，对于收益率均值（以及协方差，主要是均值）&lt;b&gt;假设有一个先验，然后采用 shrinkage 的方法得到后验&lt;/b&gt;。这个先验往往是基于某种 data generating process 假设的，因此是 biased 的，但是这种方法可以改善 estimation error。（需要贝叶斯收缩背景知识的小伙伴请参考&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38614373&quot;&gt;《收益率预测的贝叶斯收缩》&lt;/a&gt;、&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38282835&quot;&gt;《Black-Litterman 模型 —— 贝叶斯框架下的资产配置利器》&lt;/a&gt;。）&lt;/li&gt;&lt;li&gt;&lt;b&gt;“猜不出就绕过去”：&lt;/b&gt;名字比较草根、是我起的，但方法绝对靠谱。MPT 最被诟病的是它计算出来的配置权重非常离谱（可能会很大或者很小）；往往对均值的一点点改变都能造成权重的剧烈变化。&lt;b&gt;Chopra and Ziemba（1993）的研究表明，收益率期望的误差对资产配置的影响比协方差误差的影响高一个数量级。&lt;/b&gt;但是预测期望是非常难的，所以索性就不猜期望了，而把预测的重点放在协方差矩阵的改进中。著名的 minimum-variance portfolio 就是这样一个例子，它只需要估计协方差矩阵，并以最小化 variance 为目标构建最优组合。&lt;/li&gt;&lt;li&gt;&lt;b&gt;“从群众中来、到群众中去”：&lt;/b&gt;传统的 MPT 是无约束优化。当资产间相关性为负或者一些资产的预期收益率为负时，最优的权重可能会出现小于零（做空）的情况。无约束优化给了 mean-variance optimization 更大的出错空间，且做空在现实中也有很强的限制。为此，在很多研究中都在最优化时加上了&lt;b&gt;权重非负的限制（shortsale constraint）&lt;/b&gt;，这种贴近实际的做法虽然在数学上的目标函数没有无约束优化好，但却大大改善了配置在样本外的效果。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这些对 MPT 的改进方法在学术期刊的论文中至少都获得了很好的效果，但是它们在实战中又如何呢？为了客观的评价它们的效果，需要选择一个合适的基准。这个基准就是 —— &lt;b&gt;简单多样化（naïve diversification）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;简单多样化又称为 1/N 法，即我们把资金平均的分配到 N 个待配置的资产中（配合适当的再平衡）。&lt;/b&gt;简单多样化背后的含义是：&lt;b&gt;不预测不同投资组合或者投资策略未来表现的相对强弱，以期实现样本外最大的随机性、到达“最大熵”的状态，使得配置结果在样本外的适应性更强。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;毫无疑问，简单多样化是一个客观的基准。&lt;b&gt;任一个复杂的资产配置算法如果要宣称有效，至少都要在样本外、从统计上显著的战胜简单多样化的配置结果。&lt;/b&gt;这里，战胜意味着考虑了更高换手率造成的交易成本后仍能够带来更高的风险收益比，如夏普率。&lt;/p&gt;&lt;p&gt;长期以来关注公众号的小伙伴可能会有印象：我其实非常喜欢简单多样化。这一点在&lt;a href=&quot;https://mp.weixin.qq.com/s/PlOMPjmt8NrWZqMBmNgL9A&quot;&gt;《多个因子配置实证》&lt;/a&gt;、&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38315648&quot;&gt;《你用因子、他也用因子；你没赚钱、他却赚钱了》&lt;/a&gt;均有体现。当然，这种观点的主观情绪太浓厚，咱们还要用数据说话。&lt;/p&gt;&lt;p&gt;在金融领域顶刊 Review of Financial Studies 于 2009 年发表的一篇文章中，DeMiguel et al. (2009) 使用了 7 个股票数据集（大部分都是来自美股）比较了简单多样化和 14 种基于 MPT 的资产配置方法。孰优孰劣了？一起来看看。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 资产配置方法与数据集&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;假设  &lt;equation&gt;\mu&lt;/equation&gt;  和  &lt;equation&gt;\Sigma&lt;/equation&gt;  分别代表 N 个资产的收益率均值向量和协方差矩阵、 &lt;equation&gt;\gamma&lt;/equation&gt; 表示投资者的风险厌恶系数，则 mean-variance optimization 求解如下最优化问题得到最优配置 &lt;equation&gt;\omega&lt;/equation&gt; ：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle\max_\omega \omega^T\mu-\frac{\gamma}{2}\omega^T\Sigma \omega&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;如果考虑所有资产的权重之和加起来等于 1 这个约束条件，则上述问题的最优解为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle w^\star = \frac{\Sigma^{-1}\mu}{\mathbf{1}_N\Sigma^{-1}\mu}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中 &lt;equation&gt;\mathbf{1}_N = [1, 1, …, 1]^T&lt;/equation&gt; 。值得一提的是，MPT 是单期资产配置算法，它假设投资者仅对下一期的最优资产配置感兴趣。接下来，本文介绍一些有代表性的改进资产配置方法（更多的可见 DeMiguel et al. 2009）。对它们的描述、分类以及参考文献如下表所示。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d048de848aa189307384bba8b627bd9c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;890&quot; data-rawheight=&quot;636&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d048de848aa189307384bba8b627bd9c&quot; data-watermark-src=&quot;v2-83a453e3c984bfe547b1e526978fbeb2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;模型 0 和模型 1 无需多言，对其他模型的简单说明如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;Bayes-Stein：&lt;/b&gt;贝叶斯收缩的开山鼻祖（Stein 1955），它的收益率均值先验是 sample global minimum-variance portfolio、收缩以最小化 estimation error 为目标。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Bayesian Data-and-Model：&lt;/b&gt;以给定的资产定价模型（比如 CAPM 或者 Fama-French 三因子模型）为先验进行收缩。对先验有很强的结构性假设，具体请参考 Pastor (2000) 及 Pastor and Stambaugh (2000)。这种方法需要指定选为先验的资产定价模型。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Minimum-variance：&lt;/b&gt;该方法仅需估计协方差矩阵，它的数学描述是：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle \min_\omega \omega^T\Sigma\omega, ~~~\mbox{s.t. }~~~\mathbf{1}_N^T\omega=1&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;&lt;b&gt;Value-weighted market portfolio：&lt;/b&gt;对于给定的股票数据集，构建一个“market”组合，通过 buy-and-hold 策略作为这种配置方法。该方法的换手率为零。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Missing-factor model：&lt;/b&gt;该方法由 MacKinlay and Pastor (2000) 提出。它的动机是收益率由 &lt;b&gt;factor 未知&lt;/b&gt;的资产定价模型来决定。因此，在使用 mean-variance optimization 框架时，假设收益率均值仍然来自样本数据，但是对协方差进行修正，以反映这个未知的 factor 模型。它对  &lt;equation&gt;\Sigma&lt;/equation&gt;  的修正为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle\Sigma= \nu\mu\mu^T+\sigma^2I_N&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中 &lt;equation&gt;\nu&lt;/equation&gt; 、 &lt;equation&gt;\sigma^2&lt;/equation&gt; 都是标量，它们和 &lt;equation&gt;\mu&lt;/equation&gt; 一起通过 maximum-likelihood 估计得到。&lt;/p&gt;&lt;p&gt;第 7、8、9 种方法分别为第 1、2、4 种方法加上了 shortsale 约束，即要求配置权重非负。Jagannathan and Ma (2003) 指出，&lt;b&gt;对 minimum-variance 加上 shortsale 权重相当于收缩协方差矩阵。&lt;/b&gt;因此方法 9 也代表了一大类收缩协方差矩阵的配置方法，例如 Ledoit and Wolf (2004)。&lt;/p&gt;&lt;p&gt;下面再来看看用到的数据集。在考察的 7 个股票数据集中，除了第 3 个之外均来自美股。下表对它们进行了总结。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7f9085999abf547533a1f62a346bde17_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;902&quot; data-rawheight=&quot;583&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7f9085999abf547533a1f62a346bde17&quot; data-watermark-src=&quot;v2-c82753d501a4b10bf29cc2a2c738fa90&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;表中唯一可能造成困惑的地方是，它使用 x + y 的形式表示了资产个数 N。例如，第一个数据集的 N = 10 + 1 = 11。这么做的原因是 Bayesian Data-and-Model 这个模型需要使用给定的因子模型（资产定价模型）作为先验。因此上述表达式中加号后面的数字代表了因子的个数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;特别需要说明的是，这些因子投资组合除了在 Bayesian Data-and-Model 模型中计算先验外；在所有实验中，它们也都作为独立的资产参与配置。&lt;/b&gt;举例来说，在第一个数据集中，参与配置的不仅仅是 10 个 S&amp;amp;P 500 sectors 投资组合，而且也包括了 US equity market portfolio 这个作为因子的组合，因此一共有 11 个资产参与资产配置。&lt;/p&gt;&lt;p&gt;这 7 个数据集中用于计算先验的因子分别为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;数据集 1：&lt;/b&gt;US equity market portfolio&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据集 2：&lt;/b&gt;US equity market portfolio&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据集 3：&lt;/b&gt;World Index&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据集 4：&lt;/b&gt;US equity market portfolio&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据集 5：&lt;/b&gt;MKT（来自 Fama-French 三因子中的市场组合）&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据集 6：&lt;/b&gt;MKT、SMB、HML（来自 Fama-French 三因子）&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据集 7：&lt;/b&gt;MKT、SMB、HML、UMD（来自 Fama-French 三因子和 UMD 动量因子）&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;3 评价指标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;除了简单多样化外，上述所有这些配置算法（包括 sample-based mv 和其他 8 个改进方法）都需要使用历史数据来计算参数。在实证中，DeMiguel et al. (2009) 采用月频数据并使用长度为 120 个月的滚动窗口进行参数估计，按月调仓以评价不同配置方法在样本内的表现。&lt;/p&gt;&lt;p&gt;评价指标包括以下三个：&lt;/p&gt;&lt;p&gt;&lt;b&gt;夏普率：&lt;/b&gt;夏普率的定义大家都熟悉，无需过多介绍。这里想说明的是，不同策略的夏普率都是未知夏普率的一个样本点，它们的取值自然会有不同。为了检验不同策略的效果是否有差别需要在统计上检验夏普率是否显著不同。在统计上检验两个夏普率差别的方法请参考 Jobson and Korkie (1981) 以及 Memmel (2003)。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Certain-equivalent return (CEQ，确定性等值收益率)：&lt;/b&gt;它是与给定的风险投资组合等价的无风险收益率。换句话说，对于给定风险偏好的投资者，投资收益为 CEQ 的无风险资产和投资该风险投资组合没有区别。因此，CEQ 的表达式为（μ 和 σ 均使用样本外数据）：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle \mu-\frac{1}{2}\gamma\sigma^2&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;同样，为了比较不同策略的 CEQ 是否不同，也需要从统计上进行检验。&lt;/p&gt;&lt;p&gt;&lt;b&gt;换手率：&lt;/b&gt;mv 以及改进的方法较简单多样化来说有更多的主动投资，因此平均来说有更高的换手率。高换手率的直接结果是更高的交易成本。因此，为了评价不同资产配置的效果，换手率也是一个必要的指标。&lt;/p&gt;&lt;p&gt;下一节就来看看实证结果。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 实证结果&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下表显示了不同资产配置策略在不同数据集上的夏普率。从第二列开始，每一列代表了一个数据集（由于数据集 6 和数据集 5 的效果很接近，因此被省略了）；每一行是一个策略，由策略名的缩写表示。其中 mv (in sample) 代表了在整段数据上开天眼计算均值和协方差矩阵后使用 mean-variance optimization的 表现，因此它是样本内的表现，相当于所有样本外表现的上限。其他所有非括号内的数字都是不同策略的&lt;b&gt;样本外&lt;/b&gt;夏普率。括号中的数字表示样本外，给定策略和简单多样化策略夏普率差值的 p-value。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fa871349c66e29546ea0802deb5b08db_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;807&quot; data-rawheight=&quot;548&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fa871349c66e29546ea0802deb5b08db&quot; data-watermark-src=&quot;v2-8057fb746fa5e33c2fac40ee8b09b5f6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;以第一个数据集 S&amp;amp;P sectors 为例，简单多样化即 1/N 策略的样本外夏普率是 0.1876，而 mv 样本内的夏普率高达 0.3848，其样本外的夏普率仅有 0.0794。0.0794 下方括号内的数字表示 mv 和 1/N 这两个策略样本外夏普率差值的 p-value —— 0.12。&lt;/p&gt;&lt;p&gt;观察表中数据不难发现如下结论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;所有策略的样本外的夏普率都不如开天眼的 mv in-sample 夏普率，这说明&lt;b&gt;所有这些方法都存在 estimation error&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;除了最后一个数据集外，1/N 均战胜了 mv（大部分 p-value 比较低），&lt;b&gt;说明仅仅基于历史样本数据的、不经任何改进的 mean-variance optimization 确实不好使&lt;/b&gt;，这也解释了它为什么在实战中名声不好。&lt;/li&gt;&lt;li&gt;基于贝叶斯收缩的方法（bs 和 dm）并没有显著的改进 mv。DeMiguel et al. (2009) 观察到 bs 和 mv 的结果接近，这可能和滚动窗口的长度有关，导致收缩后的权重和 mv 的权重很接近（即先验的作用很微弱）。&lt;b&gt;而对于 dm，它是否有效和待配置的资产以及被选为先验的因子密切相关。&lt;/b&gt;比如，dm 在最后一个四因子为先验的数据集上战胜了 1/N，但是同样的表现并没有出现在其他数据集上。&lt;/li&gt;&lt;li&gt;对于 min、vw、mp 这三个不猜收益率均值的配置方法，min 在 4 个数据集上战胜了 1/N，不过大部分的 p-value 都不算小。而 vm 以及 mp 这两个方法基本上都败给了简单多样化。&lt;/li&gt;&lt;li&gt;mv-c 和 bs-c 的效果可以理解为仅仅加入了不能做空的限制（bs 对收益率的收缩很微弱）。从结果来看，&lt;b&gt;仅仅加入做空的限制并不能带来更高的夏普率&lt;/b&gt;。这两个方法也不如 1/N 法。&lt;/li&gt;&lt;li&gt;最后来看看 min-c。它在最小化 variance 的同时加上做空限制，相当于对协方差矩阵进行贝叶斯收缩。&lt;b&gt;这种“收缩”+“限制”的组合拳在 4 个数据集上战胜了简单多样化，同时也是这几种改进方法中最好的。&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下表是以 CEQ 为评价指标的结果。它传递出的信息和夏普率一致，且结果更加偏向于简单多样化策略 —— &lt;b&gt;如果考虑 CEQ 的话，这些策略更难以战胜简单多样化。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2d34dfebec5ad0ce1913076801ea53fe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;790&quot; data-rawheight=&quot;546&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2d34dfebec5ad0ce1913076801ea53fe&quot; data-watermark-src=&quot;v2-7691c5c0fc80c223c71818d2f2f8e3f3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最后是换手率。下表中，1/N 那一行的结果是绝对的换手率，其他策略的结果是相对于 1/N 策略的相对换手率。首先，我们被仅仅基于样本数据的 mv 策略的相对换手率震惊了。&lt;b&gt;由于 mean-variance optimization 对输入数据异常敏感，它经常求解出令人难以理解的“最优权重”。由于马科维茨的资产配置是单期配置，因此不同期之间的最优权重可能完全不同，这导致了非常不切实际的巨大的换手率。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-01dedc38c02085c7abeaa74655369f8c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;810&quot; data-rawheight=&quot;422&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-01dedc38c02085c7abeaa74655369f8c&quot; data-watermark-src=&quot;v2-656f31c8b64e7d39832200a552d0e173&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其他几种方法有效的降低了换手率，特别是最后三种加上做空限制的方法。它们直接把优化问题变成约束优化，从根儿上限制了求解空间，使得最优权重更加合理、不同期之间的最优权重相对连续，有效的降低了换手率。&lt;/p&gt;&lt;p&gt;即便如此，除了 vm 这种方法是 buy-and-hold 因此换手率为零外，其他配置策略的换手率均高于简单多样化。&lt;b&gt;从夏普率以及 CEQ 的分析可知，复杂配置策略并不能持续的战胜简单多样化；考虑到由此造成的潜在更高的交易成本，它们和简单多样化比起来就更难言有优势了。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实证结果有些令人失望，因为这些复杂配置方法都不能显著战胜简单多样化。为了研究资产个数 N、参数估计窗口长度 M 对 mean-variance 和 1/N 方法的影响，DeMiguel et al. (2009) 根据 Kan and Zhou (2007) 的思路进行了理论分析。&lt;/p&gt;&lt;p&gt;为此，他们定义了 expected loss 函数：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle L(x^\star,\hat x)=\frac{1}{2\gamma}S^2(x^\star)-\mbox{E}\left[\frac{1}{2\gamma}S^2(\hat x)\right]&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中 &lt;equation&gt;S^2(x^\star)&lt;/equation&gt; 是未知最优权重  &lt;equation&gt;x^\star&lt;/equation&gt;  实现的最优夏普率的平方（也是未知的），而 &lt;equation&gt;S^2(\hat x)&lt;/equation&gt; 是在给定权重下夏普率的平方。最优夏普率平方和实现的夏普率平方的期望之间差别就是 expected loss。&lt;/p&gt;&lt;p&gt;DeMiguel et al. (2009) 指出 mean-variance 要想战胜简单多样化的前提条件是 M 足够大，以及 N 足够小。&lt;b&gt;这意味着，当参数估计的窗口很大（从 DeMiguel et al. 2009 的结果来看，M 非常大，长过很多实际中资产的历史数据）以及待配置的资产数量较少时，基于 mean-variance 的配置方法才有希望战胜简单多样化。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DeMiguel et al. (2009) 通过蒙特卡洛仿真模拟收益率数据验证了上述观点（下表）。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6cdae16540f81b2a47bc972e01a002f8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;778&quot; data-rawheight=&quot;512&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6cdae16540f81b2a47bc972e01a002f8&quot; data-watermark-src=&quot;v2-d1437a4646b6b03e18790443c4098ed5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;5 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;又到了总结的时间了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;有必要强调的是，本文和 DeMiguel et al. (2009)&lt;/b&gt; &lt;b&gt;都没有主张一定要用简单多样化进行资产配置。&lt;/b&gt;如果对未来的判断很准确，那么以此为先验是可以战胜简单多样化的，比如大名鼎鼎的 Black-Litterman 方法。另外，风险平价也是一种资产配置方法，它也是以准确的主观判断为前提的（因为需要构建夏普率相当、且相关性很低的不同大类资产，见&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38301218&quot;&gt;《你真的搞懂了风险平价吗？》&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;但是，对未来准确判断谈何容易？大部分投资者擅长的仅仅是使用历史数据外推而已。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DeMiguel et al. (2009) 传递出来的两个清晰的观点是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;仅仅使用历史样本数据，即便是改进的基于 mean-variance 的方法也很难战胜简单多样化。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;简单多样化是一个客观的比较基准；任何复杂的资产配置方法都需要至少要在统计上显著战胜简单多样化才能被称之为有效。&lt;/b&gt;比如一个大类资产轮动策略，它的业绩比较基准不应该是股票或者债券这种单一投资标的，而应该是基于其投资组合的简单多样化策略的效果。如果该策略无法战胜简单多样化，那它就没有带来超额收益。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在投资中，资产配置是最核心的问题（没有之一，相信很多人会认同）。这个问题值得我们持续的探索。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4db13db783cba1e40a865c5b085fa170_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;835&quot; data-rawheight=&quot;385&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4db13db783cba1e40a865c5b085fa170&quot; data-watermark-src=&quot;v2-282901e43af0fd2df66250982d2d25d6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Chopra, V. K. and W. T. Ziemba (1993). The effort of errors in means, variances, and covariances on optimal portfolio choice. &lt;i&gt;Journal of Portfolio Management&lt;/i&gt;, Vol. 19(2), 6 – 11&lt;/li&gt;&lt;li&gt;DeMiguel, V., L. Garlappi, and R. Uppal (2009). Optimal versus naïve diversification: how inefficient is the 1/N portfolio strategy? &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 22(5), 1915 – 1953.&lt;/li&gt;&lt;li&gt;Jagannathan, R. and T. Ma (2003). Risk reduction in large portfolios: why imposing the wrong constraints helps. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 58(4), 1651 – 1683.&lt;/li&gt;&lt;li&gt;Jobson, J. D. and R. Korkie (1981). Performance hypothesis testing with the Sharpe and Treynor measures. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 36(4), 889 – 908.&lt;/li&gt;&lt;li&gt;Kan, R. and G. Zhou (2007). Optimal portfolio choice with parameter uncertainty. &lt;i&gt;Journal of Financial and Quantitative Analysis&lt;/i&gt;, Vol. 42(3), 621 – 656.&lt;/li&gt;&lt;li&gt;Ledoit, O. and M. Wolf (2004). A well-conditioned estimator for large-dimensional covariance matrices. &lt;i&gt;Journal of Multivariate Analysis&lt;/i&gt;, Vol. 88(2), 365 – 411.&lt;/li&gt;&lt;li&gt;Markowitz, H. (1952). Portfolio Selection. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 7(1), 77 – 91.&lt;/li&gt;&lt;li&gt;MacKinlay, A. C. and L. Pastor (2000). Asset pricing models: implications for expected returns and portfolio selection. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 13(4), 883 – 916.&lt;/li&gt;&lt;li&gt;Memmel, C. (2003). Performance hypothesis testing with the Sharpe ratio. &lt;i&gt;Finance Letters&lt;/i&gt;, Vol. 1(1), 21 – 23.&lt;/li&gt;&lt;li&gt;Pastor, L. (2000). Portfolio selection and asset pricing models. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 55(1), 179 – 223.&lt;/li&gt;&lt;li&gt;Pastor, L. and R. F. Stambaugh (2000). Comparing asset pricing models: an investment perspective. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 56(3), 335 – 381.&lt;/li&gt;&lt;li&gt;Stein, C. (1955). &lt;i&gt;Inadmissibility of the usual estimator for the mean of a multivariate normal distribution&lt;/i&gt;. In 3rd Berkeley Symposium on Probability and Statistics, 197 – 206.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-10-17-46971981</guid>
<pubDate>Wed, 17 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>量化壳价值</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-10-10-46386808.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46386808&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-84c72ef20937ee327289e98b5e7012b5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;中国股市的壳价值是不健全的 IPO 机制以及相对不透明的监管造成的负面结果；壳价值反映了市场的非有效性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在&lt;a href=&quot;https://mp.weixin.qq.com/s/ZhKQLHGq_QGz7T2NWIqAEw&quot;&gt;《国内因子量化选股的七宗罪》&lt;/a&gt;中提出的一宗罪是大 A 股的特殊国情。&lt;/p&gt;&lt;p&gt;在 A 股中，主流因子选出的股票中经常看到 ST 股票的身影，而这些股票确实能获得更高的收益，对评价因子造成不利影响。作为 A 股的一道独特的风景，这些 ST 股票经常在业务萎靡、亏损放大和面临退市的不利局面下上演反转剧情：业绩扭亏保壳成功（这是一个浪子回头的故事）、或者成为壳资源被优秀企业借壳上市（这是一个屌丝变身高富帅的故事），股价进而逆转飙升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这背后本质的原因在于 A 股的 IPO 发审制度的不健全，造成上市公司的壳资源价值非常高。&lt;/b&gt;由于 A 股上市成本高、时间长，使得通过收购已经上市、但市值不大的股票实现借壳上市，是一件性价比不低的生意。同时 A 股小市值成长股估值偏高、可以以更高市盈率发行股票、以极低的成本融资（30 倍市盈率发行股票就相当于 3.3% 的利率借款、还不用还、还可以进一步去作为资本金上债务杠杆），非常合算。&lt;/p&gt;&lt;p&gt;&lt;b&gt;鉴于很高的壳价值，已经 ST 的股票有非常大的动力保壳。&lt;/b&gt;这一方面会使得市场预期公司盈利扭亏为盈的概率显著变大，带来股票价值的增长；另一方面，如果 ST 股票市值低到 10 至 20 亿左右的时候，由于收购成本变低，市场又会预期被作为壳资源被收购并注入优质资产的可能性变大，带来股票价值的反转。由于 A 股财务造假难度低、发审制度造成上市困难，这两种情况都很容易带来基本面实质改变产生的股价触底反弹。上述原因解释了为什么 ST 股票有不错的收益率。&lt;/p&gt;&lt;p&gt;今天我们就来聊聊 A 股中的壳价值（shell value）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 一个简单实验&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下图是使用资产回报率、是否 ST、前十大股东持股比例以及市值构建的一个简单实验。这四个指标模拟了上市公司是否有壳价值。评分越高的公司壳价值越高、越低的公司壳价值越低。&lt;/p&gt;&lt;p&gt;按照这个粗糙的壳价值因子将股票分成五档。这五个投资组合的预期收益率在截面上有非常明显的单调性，说明壳价值能够解释股票预期收益率截面差异。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cd3c7c69d906693ed530fb972505cac2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;735&quot; data-rawheight=&quot;685&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-cd3c7c69d906693ed530fb972505cac2&quot; data-watermark-src=&quot;v2-3dabbebd1e95e2949ba1a6770d1e7404&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上面这个实验的灵感来自 Lee et al. (2017)。该文用量化的手段研究了中国股市的壳价值和监管风险，指出冗长的 IPO 发审制度造就了中国股市中独有的壳价值，而壳价值可以造成其他主流因子解释不了的预期收益率截面差异。此外，对于壳价值的研究还可以解释中国股市的一些现象 —— 比如，当考虑了壳价值因子后，小市值因子几乎就消失了，因此可以说小市值股票有效的内在原因是潜在的壳价值。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 计算壳价值&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了绕开 IPO，未上市公司通过&lt;b&gt;借壳（reverse merger、reverse takeover）&lt;/b&gt;的方法把资产注入市值较低的上市公司（壳公司），得到该公司一定的控股权，利用其上市公司的地位使母公司的资产得以上市。&lt;/p&gt;&lt;p&gt;在 Lee et al. (2017) 中，作为“壳”的上式公司的壳价值的计算公式为：&lt;/p&gt;&lt;p&gt;SV = (MVCE × SFS) – OC&lt;/p&gt;&lt;p&gt;其中 SV 代表壳价值（Shell Value），MVCE 是 Market Value of Combined Entity，SFS 为借壳后原壳公司的股份所有权，OC 是在借壳过程中壳公司所有者付出的资本。下面简单介绍下 MVCE 和 SFS 的计算方法，OC 的计算公式请参考 Lee et al. (2017)。&lt;/p&gt;&lt;p&gt;SFS 的公式为：SFS = (S - TS) / (S + ΔS)&lt;/p&gt;&lt;p&gt;其中，S 是借壳前壳公司的股本，ΔS 是在借壳上市过程中增发的、给予未上市公司的股本。如果 ΔS 的股本数不足以使未上市公司对壳公司拥有控股权，壳公司会将一部分股本，记为 TS，转给未上市公司。在这种情况下，壳公司最终的股本是 S – TS。因此借壳上市之后，壳公司的控股权为 (S - TS) / (S + ΔS)，即 SFS。&lt;/p&gt;&lt;p&gt;对于 MVCE，Lee et al. (2017) 考虑了三种计算方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;第一种方法：&lt;/b&gt;MVCE = PE_pre × E + W&lt;/li&gt;&lt;li&gt;&lt;b&gt;第二种方法：&lt;/b&gt;MVCE = PE_ind × E + W&lt;/li&gt;&lt;li&gt;&lt;b&gt;第三种方法：&lt;/b&gt;MVCE = P_Day1 × (S + ΔS)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;前两种方法中，E 是未上市公司的 earning forecast；W 是壳公司和未上市公司的净资产总和。这两种方法的区别在于市盈率 PE 的计算。在第一种方法中，PE_pre 代表了 peer-based PE ratio，它是壳公司自己根据同类公司的 PE 估计出来的市盈率；而在第二种方法中，PE_ind 代表了 industry-based PE ratio，它是壳公司所在行业的全部公司的平均市盈率。通常来说，PE_pre 大于 PE_ind。&lt;/p&gt;&lt;p&gt;在一个完整的借壳上市过程中，壳公司首先会被停牌，随后会出现和它有关的资产重组的公告（不涉及任何细节）。在三到四个月后，壳公司会复牌，并伴随最初的 reverse merger 的提案。由于 reverse merger 对壳公司是极大的利好，复牌后它的股票通常会经历几个涨停，P_Day1 代表了复牌后第一个非涨停的交易日的收盘价，它表示着市场已经完全 priced in 这个潜在的 reverse merger。P_Day1 × (S + ΔS) 就是第三种 MVCE 的计算方法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;相对前两种方法，第三种计算 MVCE 的方法最为保守。&lt;/b&gt;这是因为最初的提案需要经过股东和董事会的批准得到最终的提案，而最终的提案还要经过证监会的审批，这其中存在很高的失败风险。因此，P_Day1 反映出来的壳价值是存在折价的，这就是第三种方法相对保守的原因。&lt;/p&gt;&lt;p&gt;Lee et al. (2017) 考察了 2007 年 1 月到 2016 年 4 月之间，A 股中成功的 reverse merger 样本（一共 134 个）。按照上述三种方法计算的壳价值统计数据如下表所示。&lt;b&gt;按照三种方法，壳价值的平均值介于 29 到 44 亿人民币之间，相当于所有上市公司市值中位数的 66% 到 92%&lt;/b&gt;（Panel C）。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3eb479d4d0b6a8127f9ded805854c08c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;766&quot; data-rawheight=&quot;490&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3eb479d4d0b6a8127f9ded805854c08c&quot; data-watermark-src=&quot;v2-ac5948f3f85783b2fe1aafe5e4ed732f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;如此高的壳价值带来了中国股市独特的“壳溢价”，可以解释股票截面收益率的差异。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 壳价值和截面收益率&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了研究“壳溢价”，我们需要围绕壳价值构建一个选股因子。计算该因子的核心是一个&lt;b&gt;上市公司成为壳公司的概率：大概率能成为壳的上市公司比小概率的公司在壳价值因子上有更高的暴露。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Lee et al. (2017) 根据 Campbell et al. (2008) 以及大量业界反馈总结出成为壳公司的概率和以下几个指标联系紧密：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;市值（Rsize）：&lt;/b&gt;小市值的公司更容易成为壳公司；&lt;/li&gt;&lt;li&gt;&lt;b&gt;利润（Profit）：&lt;/b&gt;利润低和基本面差的公司更容易成为壳公司，Lee et al. (2017) 使用 Operating profit to Assets 作为其代理指标；&lt;/li&gt;&lt;li&gt;&lt;b&gt;退市风险（ST）：&lt;/b&gt;由于退市风险，被 ST 标记的公司更容易成为可公司；&lt;/li&gt;&lt;li&gt;&lt;b&gt;所有权集中度（ShrCon）：&lt;/b&gt;对于所有权分散的上市公司，未上市公司更容易获得其控制权，因此这些公司更有可能成为壳公司。Lee et al. (2017) 使用前十大股东控股比例作为该指标的代理变量。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除此之外，Lee et al. (2017) 还考虑了杠杆等其他四个指标，并构建逻辑回归模型得到了成为壳公司的概率和这些变量之间的关系（在建模中，壳公司的样本一共有 252 个）。从下表可见，这些指标的回归系数和预期的符号相一致；且考虑了前四个指标后，其他指标均不显著。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ea65ebee069da7dce50fbd013ccf0503_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;692&quot; data-rawheight=&quot;561&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ea65ebee069da7dce50fbd013ccf0503&quot; data-watermark-src=&quot;v2-402266faab484c7d2180f711f093d86c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;使用上述逻辑回归模型就可以算出每个上市公司成为壳的概率。值得一提的是，上面的回归是在整个样本内进行的（为了说明解释变量的有效性），在下面使用壳价值因子选股时，逻辑回归是滚动进行的。&lt;/p&gt;&lt;p&gt;有了成为壳的概率，Lee et al. (2017) 提出了一个 Expected Shell Value to Market (ESVM) 指标作为壳价值因子。顾名思义，它是预期壳价值和市值之比。Expected Shell Value 是成为壳的概率与 Shell Value 的乘积。&lt;/p&gt;&lt;p&gt;为了考察 ESVM 是否能解释截面预期收益率，Lee et al. (2017) 首先使用个股的月收益率和 ESVM 等因子进行了 Fama-MacBeth regression（Fama and MacBeth 1973）。在检验中，同时考察了其他 A 股中的常见因子，包括：log(ME)、log(BM)、ret01（上一个月的收益率）、ret212（之前第 12 个月到之前第 2 个月之间的累积收益率）、ChgAt（asset growth）、Profit、EP 以及 Turnover。回归结果如下表所示。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e96ec88d14918a2fdf7206f7f26673b8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;617&quot; data-rawheight=&quot;553&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e96ec88d14918a2fdf7206f7f26673b8&quot; data-watermark-src=&quot;v2-d85117ffc6ec6f4bfe48244725610b95&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;在所有考察的因子中，能够显著解释股票预期收益率截面差异的只有 ESVM、log(ME) —— Size 因子、ret01（负的因子收益率说明短期反转在 A 股十分有效）、以及换手率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除此之外，Lee et al. (2017) 也进行了 portfolio tests。根据 ESVM 因子将股票分成 10 档（第十档为 ESVM 最高），并通过做多第十档、做空第一档构建多空组合。考察该组合的收益率能否被现有因子解释。现有因子模型包括 CAPM、Fama-French 三因子模型（Fama and French 1993）、Fama-French 三因子 + Carhart (1997) 的四因子模型、以及 Fama-French 五因子模型（Fama and French 2015）。Portfolio tests 的结果如下。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8253bdebf493ef6c20fbe36ba55c2e98_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;447&quot; data-rawheight=&quot;404&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8253bdebf493ef6c20fbe36ba55c2e98&quot; data-watermark-src=&quot;v2-e995875911250a5b3d880bbcbbcdff96&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;结果表明，通过 ESVM 构建的多空组合能够获得这些现有因子无法解释的 α。&lt;/b&gt;从五因子模型的结果可见，ESVM 投资组合在市场、HML 和 RMW 上均有负的暴露。说明它在市场下行时有较好的表现，以及壳价值因子选出的股票通常具有市值小、成长性高以及利润率低的特点。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 壳价值因子和市值因子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在中国股市中长期存在的一个现象是 SMB（Size）可以解释很大一部分截面预期收益率差异 —— 小市值股票比大市值股票获得更高的超额收益。然而这背后的机制并不清晰。&lt;/p&gt;&lt;p&gt;Lee et al. (2017) 认为，壳价值可能是 Size 因子有效的原因。为了检验这个说法，他们将股票根据 Size 分成 10 档（第一档为市值最小），然后通过 Fama-French 五因子模型加上新的 ESVM 因子来对这 10 个组合进行回归分析，结果如下。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e794356a4998b1a80ef215615d7d95dd_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;656&quot; data-rawheight=&quot;689&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e794356a4998b1a80ef215615d7d95dd&quot; data-watermark-src=&quot;v2-be55e617d67e9c9094aafb3a43c5a466&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f06e971553e0341862907c98c22f6c95_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;678&quot; data-rawheight=&quot;644&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f06e971553e0341862907c98c22f6c95&quot; data-watermark-src=&quot;v2-971a076be96b45a8262a1256f7edc129&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图中，Panel A 考虑了传统的五因子，而 Panel B 中加入了新的壳价值因子（SV）。加入壳价值因子后，SMB 因子对于这 10 档按照 Size 分类构建的投资组合的收益率的解释力度被极大的削弱了。此外，使用 Size 因子构建的多空组合（1-10）的 α 在考虑了壳价值因子后也显著的减弱了。&lt;/p&gt;&lt;p&gt;这两个现象说明&lt;b&gt;壳价值很大程度的支撑了 Size 因子；小市值公司获得更高收益背后的原因很可能是它们对于壳价值因子有更高的暴露造成的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 监管风险&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;壳价值无疑和困难重重的 IPO 有关。&lt;b&gt;当 IPO 收紧的时候，我们预期壳价值因子能够获得更高的收益率；而当 reverse merger 收紧的时候，我们预期壳价值因子获得较低的收益率。&lt;/b&gt;Lee et al. (2017) 通过 event study 验证了上述两点。&lt;/p&gt;&lt;p&gt;通过查询相关资料，Lee et al. (2017) 找到了六个相关事件（三个针对 IPO；三个针对 reverse merger）。三个收紧 reverse merger 的通告为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;2011 年 5 月 13 日，关于《关于修改上市公司重大资产重组与配套融资相关规定的决定（征求意见稿）》公开征求意见的通知，http://www.csrc.gov.cn/pub/zjhpublic/G00306201/201105/t20110513_195492.htm；&lt;/li&gt;&lt;li&gt;2013 年 11 月 30 日，借壳上市审核严格执行首次公开发行股票上市标准，http://www.csrc.gov.cn/pub/newsite/zjhxwfb/xwdd/201311/t20131130_239075.html；&lt;/li&gt;&lt;li&gt;2016 年 6 月 17 日，关于就修改《上市公司重大资产重组管理办法》公开征求意见的通知，http://www.csrc.gov.cn/pub/zjhpublic/G00306201/201606/t20160617_299035.htm。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和收紧 IPO 相关的通告为（这些标题并不直接涉及收紧 IPO，但是它们均传达出了类似的信号）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;http://www.csrc.gov.cn/pub/newsite/zjhxwfb/xwdd/201405/t20140529_255106.html&lt;/li&gt;&lt;li&gt;http://www.xinhuanet.com//finance/2016-03/15/c_128802090.htm&lt;/li&gt;&lt;li&gt;http://www.csrc.gov.cn/pub/zjhpublic/G00306201/201609/t20160909_303259.htm&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Lee et al. (2017) 考察了在这些事件发生的三日窗口内，ESVM 多空组合的收益率情况（下表）。&lt;b&gt;当 reverse merger 被收紧时，该组合在事件窗口内获得了显著的负收益；而当 IPO 被收紧时，该组合在事件窗口内获得了显著的正收益。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b062761e0f27d18ed145412f1bb68bec_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;647&quot; data-rawheight=&quot;308&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b062761e0f27d18ed145412f1bb68bec&quot; data-watermark-src=&quot;v2-42843127d505cc22e5b4bb6c42a883b1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;由此可见，ESVM 投资组合暴露于很高的监管风险之中。&lt;b&gt;中国股市的壳价值是不健全的 IPO 机制以及相对不透明的监管造成的负面结果。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;壳价值强烈的反映了中国股市的非有效性。造成这种怪象背后的原因值得深思。&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;… because of the high value attached to their listing status, owners and managers of poorly performing public companies can continue to acquire and operate new businesses. Therefore,&lt;/i&gt; &lt;i&gt;&lt;b&gt;the restrictive IPO regulations not only prevent successful businesses from accessing capital, they also prevent unsuccessful businesses from facing the natural consequences of their poor stewardship.&lt;/b&gt;&lt;/i&gt;&lt;br&gt;&lt;i&gt;译：由于上市地位具有很高的价值，业绩不佳的上市公司的所有者和管理者可以继续收购和经营新业务。因此，&lt;b&gt;限制重重的 IPO 监管不仅阻碍了优秀企业[通过上市]获得资本，也阻止了失败企业为因自己经营不善而造成的不良后果埋单。&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;在证监会官网的 banner 上，醒目的写着“维护市场公开、公平、公正；维护投资者特别是中小投资者合法权益；促进资本市场健康发展”。希望在未来，针对金融市场和监管的改革能够更好的为市场服务，使得壳价值逐渐消失、为 A 股的投资者以及因子投资的践行者提供更好的环境。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Campbell, J. Y., J. Hilscher, and J. Szilagyi (2008). In search of distress risk. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 63(6), 2899 – 2939.&lt;/li&gt;&lt;li&gt;Carhart, M. M. (1997). On Persistence in Mutual Fund Performance. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 52(1), 57 – 82.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (1993). Common Risk Factors in the Returns on Stocks and Bonds. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 33(1), 3 – 56.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (2015). A Five-Factor Asset Pricing Model. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 116(1), 1 – 22.&lt;/li&gt;&lt;li&gt;Fama, E. F. and J. D. MacBeth (1973). Risk, return, and equilibrium: empirical tests. &lt;i&gt;Journal of Political Economy&lt;/i&gt;, Vol. 81(3), 607 – 636.&lt;/li&gt;&lt;li&gt;Lee, C. M. C., Y. Qu, and T. Shen (2017). Reverse mergers, shell value, and regulation risk in Chinese equity markets. Working paper.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-10-10-46386808</guid>
<pubDate>Wed, 10 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>出色不如走运 (II)？</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-09-30-45715632.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45715632&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-855cd03b16ba45e8a97700205e450a7e_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文介绍几种主流的多重检验方法。它们可以排除 data mining 造成的运气成分，从而有效的从大量因子中选出真正能够解释截面收益率的好因子；该方法也可用于基金经理或投资策略的筛选。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;两年前，我写了一篇&lt;a href=&quot;https://mp.weixin.qq.com/s/GTrwXcZ0AbvRLdUS546Kpw&quot;&gt;《出色不如走运？》&lt;/a&gt;。该文使用顺序统计量（order statistics）解释了当很多投资者（或基金）使用相同的数据构建不同的策略时，最好的那个一定是非常优秀的，但它很有可能仅仅是因为运气好，而非真正的水平高。&lt;/p&gt;&lt;p&gt;如果我们&lt;b&gt;直接&lt;/b&gt;从某个经济学规律中找出了&lt;b&gt;一个&lt;/b&gt;解释股票预期收益截面差异的因子，并且该因子在统计上显著，那么它可能是真的显著；但如果我们试了 500 个因子，然后找到了一个最牛逼的，那么哪怕它的 t-statistic 非常高，我们也不能保证它就一定是个真的因子。&lt;/p&gt;&lt;p&gt;这就好比我们在大街上随便抓了一个人让他猜 20 次扔硬币的结果，如果他全都猜对了，那么他很可能真的拥有天生神力；但是如果我们让 3 亿人同时玩猜 20 次扔硬币结果的游戏，20 轮过后全对的还会有 250 人左右，但是我们会认为这些人仅仅是运气好。&lt;/p&gt;&lt;p&gt;这些例子背后的数学逻辑是，如果有一个因变量 Y 和一个解释变量 X，通过回归分析后我们发现回归系数的 t-statistic 很高（比如 2.0，对应 5% 的显著性水平），那么从传统的单因素假设检验角度可以认为 X 能够显著的解释 Y。然而，如果我们有很多个变量（比如 100 个） &lt;equation&gt;X_1&lt;/equation&gt; 、 &lt;equation&gt;X_2&lt;/equation&gt; 、…、 &lt;equation&gt;X_{100}&lt;/equation&gt; ，我们全都试了之后发现第 55 个变量最好。这时，如果它的 t-statistic 也是 2.0，我们却不能说 X_{55} 显著的解释 Y。&lt;b&gt;这是因为仅仅靠运气，这 100 个变量（假设独立）中最好的那个的 t-statistic 大于 2.0 的概率高达 99%。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如何在层出不穷的因子中排除靠 data mining 挖掘的、而找到真正能够解释股票预期收益截面差异的？如何在大量的基金经理（或策略）中排除走运的、而找到真正能够战胜市场的？这些已成为非常迫切的问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在&lt;a href=&quot;http://www.liang-xin.com/website/w/h?mt=2&amp;amp;mc=3194266&amp;amp;cc=3021364&amp;amp;fp=d&amp;amp;c=3195119&quot;&gt;《出色不如走运》&lt;/a&gt;中，我们只说了仅仅凭运气就能得到非常好的结果，却没有说应该怎样排除运气，找到真正的好因子或者好策略。带着这些问题，今天就来一篇升级版 —— 出色不如走运 (II)？&lt;/p&gt;&lt;p&gt;最后一点提示，本文非常 technical，建议静下心来阅读。此外，熟悉&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40984029&quot;&gt;《股票多因子模型的回归检验》&lt;/a&gt;、&lt;a href=&quot;http://zhuanlan.zhihu.com/p/41993542&quot;&gt;《为什么要进行因子正交化处理？》&lt;/a&gt;、以及&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41099219&quot;&gt;《用 Bootstrap 进行参数估计大有可为》&lt;/a&gt;对阅读本文会有帮助。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 理论依据&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;既然是升级版，就不能光靠 order statistics 说事儿了，咱也得武装升级一下理论。&lt;/p&gt;&lt;p&gt;&lt;b&gt;当学术界有大量因子来解释同一个问题 —— 股票截面预期收益（或者有许多不同的策略在同一个市场中交易时），传统的单一统计检验（single testing ，即每次检验一个 hypothesis，比如一个单因子是否有效？某一个基金经理是否能带来超额收益？）就不再适合了；这时候需要 multiple testing（多重检验）。在统计上，multiple testing 指的是同时检验多个 hypotheses。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在金融领域应用 multiple testing 在最近几年得到了飞速发展。这其中的代表人物要数杜克大学的 Campbell Harvey 教授（曾于 2016 年任美国金融协会主席），他自 2014 年以来发表了多篇文章、进行了多个演讲。其中最具代表性的文章包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Harvey et al. (2016) 研究了学术界发表的 316 个显著的选股因子，在已有的多重检验方法 —— 包括 Bonferroni adjustment、Holm adjustment以及 Benjamini-Hochberg-Yekutieli (BHY) adjustment —— 的基础上，提出了一种能够利用不同因子之间相关性的全新的多重检验框架，并指出&lt;b&gt;只有在 single testing 中 t-statistic 超过 3（而非人们传统认为的 5% 的显著性水平对应的 2）的因子才有可能在考虑了多重检验之后依然有效。&lt;/b&gt;Harvey 同时也指出，3 其实都是非常保守的。&lt;/li&gt;&lt;li&gt;Harvey and Liu (2015a) 利用 Harvey et al. (2016) 的多重检验研究了如何修正策略的 Sharpe Ratio。一般的经验认为策略在实盘中的 Sharpe Ratio 应该是其在回测期内 Sharpe Ratio 的 50%。&lt;b&gt;Harvey and Liu (2015a) 定量计算了不同大小的 Sharpe Ratio 在实盘外的“打折程度”（他们称为 haircut ratio），发现了 haircut ratio 和 Sharpe Ratio 之间的非线性关系。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除上述研究外，Harvey and Liu (2015b) 提出了一个全新的基于 regression 的多重检验框架解决因子挑选问题。&lt;b&gt;它的优势是可以按顺序逐一挑出最显著的因子、第二显著的因子，以此类推，直到再没有显著因子。这么做的好处是可以评价每个新增加的因子在解释股票截面收益率时的增量贡献。&lt;/b&gt;这是传统的多重检验无法做到的。此外，该方法也可以被用来找到真正能够战胜市场的基金经理或投资策略。&lt;/p&gt;&lt;p&gt;本文的主要目标是介绍 Harvey and Liu (2015b) 提出的基于 regression 的多重检验方法。考虑到早期的多重检验方法（即 Bonferroni、Holm、BHY adjustments）也非常容易上手便捎带着加以说明。至于 Harvey et al. (2016) 提出的方法，其技术性较强，复制起来比较困难，因此我们今后找机会再聊它（倒是可以先记住它的结论，即 t-statistic 要至少大于 3 才有可能通过该多重检验）。&lt;/p&gt;&lt;p&gt;下面首先来看容易上手的 Bonferroni、Holm 以及 BHY adjustments。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 Bonferroni、Holm、BHY Adjustments&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这三种多重检验方法可以分为两类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Bonferroni 和 Holm adjustments 的目的是控制 family-wise error rate（族错误率）；&lt;/li&gt;&lt;li&gt;BHY adjustment 的目的是控制 false discovery rate。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;在多重检验中，family-wise error rate（FWER）和 false discovery rate（FDR）代表着 Type I error 的两个不同的定义。Type I error 是错误的拒绝原假设，也叫 false positive 或 false discovery。&lt;/b&gt;在我们的上下文中，它意味着错误的发现了一个其实没用的因子。&lt;/p&gt;&lt;p&gt;假设 K 个 hypotheses 的 p-value 分别为 &lt;equation&gt;p_1&lt;/equation&gt; 、 &lt;equation&gt;p_2&lt;/equation&gt; 、…、 &lt;equation&gt;p_K&lt;/equation&gt; 。根据事先选定的显著性水平，比如 0.05，其中 R 个 hypotheses 被拒绝了。换句话说，我们有 R 个发现（discoveries） —— 包括 true discoveries 和 false discoveries。令  &lt;equation&gt;N_r \le R&lt;/equation&gt;  代表 false discoveries 的个数。由此，FWER 和 FDR 的定义如下：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\begin{array}{rll} \mbox{FWER}&amp;amp;=&amp;amp;\mbox{prob}(N_r\ge 1)\\ \mbox{FDR}&amp;amp;=&amp;amp;\mbox{E}[N_r/R] \end{array}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;从定义不难看出，&lt;b&gt;FWER 是至少出现一个 false discovery 的概率，控制它对单个 hypothesis 来说是相当严格的，会大大提升 Type II Error。相比之下，FDR 控制的是 false discoveries 的比例，它允许 &lt;/b&gt;&lt;equation&gt;N_r&lt;/equation&gt;&lt;b&gt; 随 R 增加，是一种更温和的方法。&lt;/b&gt;无论采用哪种方法，都会有相当一部分在 single testing 中存活下来的“显著”因子被拒绝。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要说明的是 Bonferroni、Holm 以及 BHY 这三种方法都是为了修正 single testing 得到的 p-value，修正后的 p-value 往往会大于原始的 p-value，也就意味着修正后的 t-statistic&lt;/b&gt; &lt;b&gt;更小，即 hypotheses 不再那么显著。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面通过简单的例子（出自 Harvey and Liu 2015a）解释这三种方法。假设一共有六个因子，它们 single testing 的 p-value 从小到大依次是 0.005、0.009、0.0128、0.0135、0.045、0.06。按照 0.05 的显著性水平来看，前五个因子是显著的。&lt;/p&gt;&lt;p&gt;首先来看 Bonferroni correction（中文称作邦费罗尼校正），它对每个原始 p-value 的调整如下：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle p_i^{\mbox{Bonferroni}}=\min\{Kp_i,1\},~~i=1,\cdots,K&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;根据定义，这六个因子的 Bonferroni p-value 分别为 0.03、0.054、0.0768、0.081、0.27 和 0.36。经过修正后，在 0.05 的显著性水平下，仅第一个因子依然显著。&lt;/p&gt;&lt;p&gt;接下来看看 Holm 修正（Holm 1979）。它按照原始 p-value &lt;b&gt;从小到大&lt;/b&gt;依次修正，公式为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle p_i^{\mbox{Holm}}=\min\left\{\max_{j\le i}\{(K-j+1)p_j\},1\right\},~~i=1,\cdots,K&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;根据上述定义，原始 p-value 最小的因子被修正后，其 Holm p-value 为 0.06；第二个因子的 Holm p-value 为  &lt;equation&gt;\max\{6×0.005, 5×0.009\} = 0.045&lt;/equation&gt; 。以此类推就能计算出其他四个因子的 Holm p-value：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\begin{array}{rll} p_3^{\mbox{Holm}}&amp;amp;=&amp;amp;\max\{6p_1,5p_2,4p_3\}=4p_3=0.0512\\ p_4^{\mbox{Holm}}&amp;amp;=&amp;amp;\max\{6p_1,5p_2,4p_3,3p_4\}=4p_3=0.0512\\ p_5^{\mbox{Holm}}&amp;amp;=&amp;amp;\max\{6p_1,5p_2,4p_3,3p_4,2p_5\}=2p_5=0.09\\ p_6^{\mbox{Holm}}&amp;amp;=&amp;amp;\max\{6p_1,5p_2,4p_3,3p_4,2p_5,p_6\}=2p_5=0.09 \end{array} &lt;/equation&gt; &lt;/p&gt;&lt;p&gt;经过 Holm 修正后，在 0.05 的显著性水平下，只有前两个因子依然显著。&lt;/p&gt;&lt;p&gt;最后来看看 BHY 修正（Benjamini and Hochberg 1995, Benjamini and Yekutieli 2001）。它从原始 p-value 中最大的一个开始&lt;b&gt;从大到小逆向修正&lt;/b&gt;，公示如下：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;p_i^{\mbox{BHY}}=\left\{ \begin{array}{lll} p_K&amp;amp;\mbox{if}&amp;amp;i=K\\\\ \min\left\{p_{i+1}^{\mbox{BHY}},\displaystyle\frac{K\times c(K)}{i}p_i\right\}&amp;amp;\mbox{if}&amp;amp;i\le K-1 \end{array} \right. &lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中，&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle c(K)=\sum_{j=1}^K\frac{1}{j}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;在本例中，因为 K = 6，因此 c(K) = 2.45。由 BHY 的定义可知原始 p-value 最大的因子调整后的 BHY p-value 就是它自己。然后从第二大的开始，依次按照上述公式计算，最终得到了全部因子调整后的 BHY p-value，它们是（从小到大排列）：0.0496、0.0496、0.0496、0.0496、0.06、0.06。在 0.05 的显著性水平下，前四个因子依然显著。&lt;/p&gt;&lt;p&gt;&lt;b&gt;BHY 方法是以控制 false discovery rate 为目标，它的修正比另外两种以控制 family-wise error rate 的方法更加温和。这体现出来的结果就是在 BHY 调整下，有更多的因子依然显著。&lt;/b&gt;此外，BHY 方法对检验统计量之间的相关性不敏感，它的适应性很强。&lt;/p&gt;&lt;p&gt;各位小伙伴不妨使用上面介绍的这三种方法对因子的 p-value 进行修正试试。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 基于 Regression 的多重检验&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节介绍 Harvey and Liu (2015b) 提出的基于 regression 的多重检验方法，该方法受到了 Foster et al. (1997) 以及 Fama and French (2010) 的启发，在这二者的基础上又有不少的创新。它的目的是为了从一大堆号称显著的因子中排除 data mining、找到真正显著的；该方法也可以被用于从一大堆基金经理或策略中找出真正能够战胜市场的。&lt;/p&gt;&lt;p&gt;当很多因子被用来解释截面收益时，效果最显著（最显著可以由最高的 t-statistic、R-squared 等指标代表）的因子中一定包含了运气的成分。&lt;b&gt;这个方法的巧妙之处在于通过正交化和 Bootstrap 得到了仅靠运气能够得到的显著性的经验分布；如果在排除了运气带来的显著性之后某个因子依然显著，那它就是真正的因子，而非 data mining 的结果。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着处理方式略有不同，Harvey and Liu (2015b) 这个方法可以用于 predictive regression（考察哪个 X 能预测 Y）、panel regression 以及 Fama-MacBeth regression（这两类回归可以用于挑选好因子），但它们背后的逻辑完全一致。下面高度概括一下该方法的逻辑（&lt;b&gt;正交化和 Bootstrap 是核心&lt;/b&gt;）：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9b950beb90d32ba5c12959b5f0377582_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;560&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9b950beb90d32ba5c12959b5f0377582&quot; data-watermark-src=&quot;v2-c955dcb496aeb056f3541a57df8fdfd9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;接下来以 predictive regression 为例说明这个多重检验方法的具体步骤。Harvey and Liu (2015b) 中给出了使用 panel regression 和 Fama-MacBeth regression 时所需的改动。为了评价哪个因子有效，需要用到 panel regression，因此下一节会介绍针对 panel regression 的改动。&lt;/p&gt;&lt;p&gt;假设有因变量 Y 和 100 个解释变量 X 的 500 期样本数据，我们想看看哪个 X 能够预测 Y。多重检验的步骤为：&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一步：&lt;/b&gt;用每个 X 和 Y 回归（在我们的例子中就是 100 次回归），得到 100 个残差 OX，它们和 Y 正交。这构成了 null hypothesis：所有 OX 对 Y 没有预测性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二步：&lt;/b&gt;以这 500 期的 Y 和正交化得到的 OX 为原始数据（500 × 101 的矩阵，每一行代表一期，第一列为 Y，第二到第 101 列为 100 个 OX 变量），使用&lt;b&gt;带放回&lt;/b&gt;的 Bootstrap 重采样从这 500 行中不断的随机抽取，构建和原始长度一样的 bootstrapped 数据（也是 500 × 101 矩阵）。&lt;b&gt;整行抽取保留了这 100 个变量在截面上的相关性。此外 Bootstrap 的好处是不对原始数据中的概率分布做任何假设。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三步：&lt;/b&gt;使用 bootstrapped 数据，用每个 OX 和 Y 回归得到一个检验统计量（比如是 t-statistic）；找出所有 OX 中该检验统计量最大的那个值，称为 max statistic。如果我们的检验统计量是 t-statistic，那么这个 max statistic 就是 500 个 t-statistic 中最大的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四步：&lt;/b&gt;重复上述第二、第三步 10000 次，&lt;b&gt;得到 max statistic 的经验分布（empirical distribution），这是纯靠运气（因为 null hypothesis 已经是 OX 对 Y 没有任何预测性了）能够得到的 max statistic 的分布。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;第五步：&lt;/b&gt;比较原始数据 Y 和每个 X 回归得到的 max statistic 和第四步得到的 max statistic 的经验分布：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;a. &lt;/b&gt;如果来自真实数据的 max statistic 超过了经验分布中的阈值（比如 95% 显著性水平对应的经验分布中 max statistic 的取值），那么真实数据中 max statistic 对应的解释变量就是真正显著的。假设这个解释变量是 X_7。&lt;/li&gt;&lt;li&gt;&lt;b&gt;b.&lt;/b&gt; 如果来自真实数据的 max statistic 没有超过经验分布中的阈值，则这 100 个解释变量全都是不显著的。本过程结束，无需继续进行。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;第六步：使用目前为止已被挑出来的全部显著解释变量对 Y 进行正交化，得到残差 OY。&lt;/b&gt;它是原始 Y 中这些变量无法解释的部分。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第七步：&lt;/b&gt;使用 OY 来正交化剩余的 X（已经选出来显著变量，比如 X_7，不再参与余下的挑选过程）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第八步：&lt;/b&gt;重复上述第三步到第七步：&lt;b&gt;反复使用已挑出的显著因子来正交化 Y，再用 OY 来正交化剩余解释变量 X；在 Bootstrap 重采样时，使用 OY、k 个已经选出的 X、和剩余 500 - k 个正交化后的 OX 作为原始数据生成 bootstrapped 样本；通过大量的 Bootstrap 实验得到新的 max statistic 的经验分布，并判断剩余解释变量中是否仍然有显著的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;第九步：&lt;/b&gt;当剩余解释变量的 max statistic 无法超过 null hypothesis 下 max statistic 的经验分布阈值时，整个过程结束，剩余的解释变量全都是不显著的。&lt;/p&gt;&lt;p&gt;以上以 predictive regression 为例介绍了 Harvey and Liu (2015b) 提出的多重检验框架。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 用 Panel Regression 多重检验挑选好因子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在分析因子是否能显著的解释股票或投资组合的截面预期收益率时，回归方法是 panel / cross-sectional regression 而非前一节的 predictive regression。&lt;b&gt;需要说明的是，这里的选股因子都是某个投资组合的（超额）收益率，比如 MKT，HML，SMB 这种。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;在使用 panel regression 的多重检验过程中，Bootstrap 的思想和上一节介绍的完全一致，但是在正交化、回归分析、以及 max statistic 的选取有上些差异。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5.1 正交化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;在挑选因子中，null hypothesis 是因子对解释预期收益率截面差异没有作用。&lt;/b&gt;如果能够拒绝原假设，则说明因子是有效的。但是运气的成分往往带来 false discovery，即本来这个因子没用，但是 data mining （尝试了一大堆因子中找到的效果最好的那个）使得它看起来有用。为此，和前一节的 predictive regression 一样，多重检验的第一步通过正交化来构造出一个“纯净”的 null hypothesis，即因子不能解释截面收益率。&lt;/p&gt;&lt;p&gt;正交化的方法为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在尚未选出任何显著因子时，对所有潜在因子的正交化处理方法是&lt;/b&gt; &lt;b&gt;demean（去均值）。&lt;/b&gt;由于每个因子都是一个收益率，因此使用原始的因子值减去它在时序上的均值就排除了它在截面上的解释性（因为 demean 后该因子在截面上的期望收益是零）。&lt;/li&gt;&lt;li&gt;&lt;b&gt;如果已经选出了 k 个显著的因子，在继续挑选第 k + 1 个显著因子时，正交化的方法是使用这 k 个因子作为解释变量和第 k + 1 个因子在时序上回归，得到的残差就是正交化之后的待检验因子。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;5.2 回归分析&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 predictive regression 中，我们会对因变量和解释变量都进行正交化。假设已经选出了 k ≥ 0 个显著变量。在选择第 k + 1 个时，首先将 Y 投影到这 k 个变量上得到残差 OY，这就是对 Y 的正交化。之后，再把剩余待检验的解释变量 X 逐一投影到 OY 上，得到 OX。然后再用 OY 和每个 OX 独立回归进行后续 Bootstrap 步骤。这使得我们可以评估新加入变量 X 在预测 Y 时的增量贡献。&lt;/p&gt;&lt;p&gt;&lt;b&gt;进行 panel regression 时，个股或者投资组合的收益率作为因变量出现在回归方程的左侧，对它们不进行正交化处理。&lt;/b&gt;在回归方程的右侧，使用已经选出的 k（k ≥ 0）个显著因子和正交化后的第 k + 1 个因子（正交化方法参考 5.1 节）作为解释变量。&lt;b&gt;始终将已经选出的前 k 个因子加入回归方程的右侧可保证检验第 k + 1 个因子对解释截面收益率的增量贡献。&lt;/b&gt;将因变量和解释变量在时序上回归，得到的截距项就是这些因子无法解释的 pricing error。&lt;/p&gt;&lt;p&gt;上面的对比说明：在 predictive regression 中，回归方程的左侧是 OY（用已经选出的 k 个 X 正交化 Y），而右侧只有一个 OX（每个剩余的 X 依次和 OY 回归）；而在 panel regression 中，回归方程的左侧是 Y（不正交化），而是把已经选出的 k 个 X 都放在回归方程的右侧，因此右侧为 k 个 X 以及一个新的待检验的正交化后的 OX。不同的方法是由于这两种回归中 null hypothesis 的性质不同造成的。虽然这两种方法的略有不同，但都保证了考察待检验变量对解释 Y 的增量贡献。&lt;/p&gt;&lt;p&gt;在 Harvey and Liu (2015b) 的最新版本 Harvey and Liu (2018) 中对上述回归有非常详细的说明。值得一提的是，虽然作者将这个回归称为 panel regression，但 Harvey and Liu (2018) 对每个投资品单独的使用这些因子进行时序回归。&lt;b&gt;因此对于 N 个投资品，一共得到了 N 个 pricing errors；&lt;/b&gt;如果直接使用 N 个投资品一起做 panel regression 并加入 fixed effects 也可以得到 N 个不同的截距。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5.3 “Max statistic”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 null hypothesis 下，因子不能解释收益率的截面差异。这意味着回归的截距（pricing error）应该距离零越远越好。由于因子挖掘界 data mining 的“优良传统”，当很多因子被测试后，最好的那个仅仅靠着运气的成分也可以让 pricing error 非常接近零。&lt;b&gt;为了量化并排除运气的影响，Bootstrap 的目标就是得到 null hypothesis 下 pricing error 的经验分布，即仅靠运气能够得到的 pricing error 的经验分布。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;从 asset pricing 角度来说，如果一个因子能够解释收益率截面差异，那么回归截距应十分接近零。&lt;/b&gt;由于一共有 N 个投资品，使用这 &lt;b&gt;N 个投资品的 pricing error 绝对值的中位数作为“max statistic”&lt;/b&gt;（实际上是希望 pricing error  的绝对值越小越好，因此应称之为 min statistic；为了和前一节对应，故称之为带了引号的“max statistic”）来评价因子。通过 Bootstrap 得到“max statistic”的经验分布。&lt;b&gt;如果来自真实数据的最小 pricing error 绝对值的中位数小于从经验分布中得到的阈值，则它对应的因子就是真正有效的因子。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;还有点乱？实在抱歉，我真的尽力了。&lt;/p&gt;&lt;p&gt;没关系，下面介绍 Harvey and Liu (2015b) 中的一个例子来说明挑选因子的过程。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 一个例子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Harvey and Liu (2015b) 给出了一个示例性例子说明如何应用他们提出的多重检验框架挑选真正有效的因子。这个例子考察了学术界的 13 个“显著”因子。加个双引号是因为它们都在 single testing 中显著，但是在新的多重检验下很多就失效了。&lt;/p&gt;&lt;p&gt;这 13 个因子为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Fama and French (1993)：MKT、SMB、HML；&lt;/li&gt;&lt;li&gt;Fama and French (2015)：RMW、CMA；&lt;/li&gt;&lt;li&gt;Hou et al. (2015)：ROE、IA；&lt;/li&gt;&lt;li&gt;Frazzini and Pedersen (2014)：BAB；&lt;/li&gt;&lt;li&gt;Novy-Marx (2013)：GP；&lt;/li&gt;&lt;li&gt;Pastor and Stambaugh (2003)：PSL；&lt;/li&gt;&lt;li&gt;Carhart (1997)：MOM；&lt;/li&gt;&lt;li&gt;Asness et al. (2013)：QMJ；&lt;/li&gt;&lt;li&gt;Harvey and Siddique (2000)：SKEW。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些因子的 single testing 结果（以因子收益率的 t-statistic 表示）以及它们之间的相关性如下图所示。从图中不难看出：（1）除了 SMB 外，所有因子的 t-statistic 都大于 2，在 0.05 的显著性水平下显著；有些因子的 t-statistic 甚至超过 5！（2）这些因子中有一些对的相关性非常高，比如 ROE 和 QMJ、CMA 和 IA（它们都是 investment 类的因子）、CMA 和 HML 等。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-73f3216a8eb45ac1a7025fd8c270fc2d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1077&quot; data-rawheight=&quot;670&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-73f3216a8eb45ac1a7025fd8c270fc2d&quot; data-watermark-src=&quot;v2-2536089cdebbd28f21149a53a86b49b3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;为了测试因子，最好的因变量应该是一揽子股票，因为我们希望考察这些因子在解释股票预期收益率截面差异上的作用。在 Harvey and Liu (2015b) 给出的例子中，二位作者使用的是 25 个投资组合，而非个股。他们强调例子的目的是为了说明多重检验的步骤。用来作为因变量的 25 个投资组合来自使用 Fama-French 三因子中的 SMB 和 HML 两个因子各自把股池分成 5 组并交叉配对，因此一共 5 × 5 = 25 个组合。&lt;/p&gt;&lt;p&gt;Harvey and Liu (2015b) 使用了这 25 个组合的 pricing error 绝对值的中位数作为挑选因子的指标（在文章中，这个指标被记为 m_1^a）。除了这个指标外还有其他三个指标，这里不做讨论。&lt;/p&gt;&lt;p&gt;首先用这 13 个因子各自对这 25 个投资组合进行回归。每个因子 pricing error 绝对值的中位数如下图所示。从单个因子回归结果来看，MKT（市场）因子是最显著的（它的指标 0.285% 是所有因子中最小的），但是里面包含了运气的成分。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be18d4d81f1063e77dd32082edd1f920_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;763&quot; data-rawheight=&quot;694&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-be18d4d81f1063e77dd32082edd1f920&quot; data-watermark-src=&quot;v2-aeb22ad3807c503ae0ce71ccfacf34cc&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;下面应用多重检验来排除运气的成分。对这 13 个因子分别正交化（demean），然后使用 Bootstrap 重采样进行反复多次的大量实验。每个实验中，单独使用 13 个正交化后的因子和 25 个投资组合收益率回归，得到每个因子的 pricing error 绝对值中位数的最小值（我们的“max statistic”）。大量 Bootstrap 实验便得到了“max statistic”的经验分布。MKT 因子的取值（0.285%）在这个分布下出现的概率仅为 3.9%，即 p-value = 3.9%，小于常用的 5% 的阈值。&lt;b&gt;因此我们说即便考虑了运气成分后，MKT 因子依然是显著的。市场因子是第一个被选出来的显著因子，这多少符合预期。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在接下来的步骤中，使用 MKT 因子正交化其余 12 个因子。然后用 MKT 因子和正交化之后的每个剩余因子独立对这 25 个投资组合进行回归分析，得到考虑了每个剩余因子的 pricing error 绝对值的中位数，如下图所示。不难看出，在剩余的 12 个因子中，CMA 是最好的（它的 pricing error 最低），但是 HML 和 BAB 和它也难分伯仲！因此，在真实数据中，“max statistic”的取值为 0.112%（来自 CMA）。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ecac5f060f18f8d3227ccf449541af1c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;581&quot; data-rawheight=&quot;524&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ecac5f060f18f8d3227ccf449541af1c&quot; data-watermark-src=&quot;v2-64f80e7143f14273de2126b91b0d98c4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;再一次，使用 Bootstrap 重采样进行反复多次的大量实验得到“max statistic”的经验分布。CMA 因子的取值（0.112%）在这个分布下出现的概率仅为 2.2%，依然小于常用的 5% 的阈值。&lt;b&gt;在考虑了运气以及 MKT 因子之后，CMA 因子依然是显著的。&lt;/b&gt;如果不选 CMA 作为第二个，也可以选 HML（&lt;b&gt;价值投资！&lt;/b&gt;）或 BAB 作为第二个显著的因子。&lt;/p&gt;&lt;p&gt;如上所述，重复这个过程就可以一直分析下去。在找到了最有效的两个因子 —— MKT 和 CMA —— 之后，剩余 11 个因子中第三个最显著的因子是 SMB，它的 pricing error 是 0.074%。然而，使用 Bootstrap 得到“max statistic”的经验分布后发现，SMB 因子的取值（0.074%）在这个分布下出现的概率高达 13.9%，大于常用的 5% 的阈值，因此认为 &lt;b&gt;SMB 以及其他 10 个因子在进一步解释截面收益率差异时都不显著。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bad61ab4feb4be20e4764a35c6f70a5c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;542&quot; data-rawheight=&quot;483&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bad61ab4feb4be20e4764a35c6f70a5c&quot; data-watermark-src=&quot;v2-d89ec6017fd0014c644600b16ca0ec33&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;经过多重检验发现，MKT 和 CMA（也可以选 HML 或 BAB）是两个显著的因子，其他因子均不显著，均为 data mining 的产物。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;以上便实现了从一揽子所谓显著的因子中提出运气成分、找到真正有效的因子。这就是这套多重检验体系最大的价值。这套体系也可以用于基金经理的筛选，具体的例子见 Harvey and Liu (2015b)。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2015 年，Harvey 教授在 Jacobs Levy Center’s Conference 上进行了题为 Lucky Factors 的演讲。在演讲的开篇，他从生物进化的角度指出人类可能有 overfitting 或者 data mining 的倾向。&lt;/p&gt;&lt;p&gt;假设一只机警的羚羊在草原中听到了沙沙响声。如果它开始奔跑，但事后发现响声只是由于一阵微风造成的（即没有威胁），那么它无疑犯了 Type I error，为此付出的代价是消耗一定的能量；但是如果它不奔跑，但事后发现响声是因为一只猎豹冲向它造成的，那么它则犯了 Type II error，为此则付出了生命的代价。可见，从 cost 的角度，它必须选择奔跑。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-54c245b9be238610b8042135a9f95aa4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;996&quot; data-rawheight=&quot;310&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-54c245b9be238610b8042135a9f95aa4&quot; data-watermark-src=&quot;v2-0a42a6a9dd09e8a7f98c157ace72f3aa&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这个故事告诉我们，动物想生存，就必须控制 Type II error，而可以允许更高的 Type I error（false discovery）。这种倾向在进化中被一代代传下来。因此，人类在分析问题时允许更高的 Type I error、存在 overfitting 或者 data mining 的倾向。&lt;/p&gt;&lt;p&gt;下图左侧是一个假想的策略净值曲线，它持续上涨，回撤可控，Sharpe Ratio 理想。然而，它仅仅是下图右侧中展示的 200 个使用零均值纯随机生成的策略净值中表现最好的那个。换句话说，它的表现完全来自运气。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6ba6c73ea0429abf54ec5f1352dc2016_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;992&quot; data-rawheight=&quot;304&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6ba6c73ea0429abf54ec5f1352dc2016&quot; data-watermark-src=&quot;v2-566ea7f6f18bafc9c6779e237cedc771&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;出色还是走运？回答这个问题刻不容缓。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;S&amp;amp;P Capital IQ 有一个 Alpha Factor Library（α 因子库），宣称有 500 个 α 因子！这里面有多少是运气？有多少是真正的 α？本文介绍的几种方法是为了回答这个问题所做的努力。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a2260213720045bbc889a67b7576d28_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1111&quot; data-rawheight=&quot;455&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5a2260213720045bbc889a67b7576d28&quot; data-watermark-src=&quot;v2-48f39436e1f80ddd00c414c3ec11ff5e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;美国统计协会（American Statistical Association）的 Ethical Guidelines for Statistical Practice 中，有这样一句话，发人深省：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;Selecting the one &quot;significant&quot; result from a multiplicity of parallel tests poses a grave risk of an incorrect conclusion. Failure to disclose the full extent of tests and their results in such a case would be highly misleading.&lt;/i&gt;&lt;br&gt;&lt;i&gt;译：从多项检验中挑出 “最重要”结果很有可能造成不正确的结论。在这种情况下，如不披露检验的全部内容及其结果，便会造成极大的误导。&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;哪有那么多阿尔法？！&lt;/p&gt;&lt;p&gt;感谢阅读，祝各位国庆节快乐。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Asness, C. S., A. Frazzini, and L. H. Pedersen (2013). Quality minus junk. AQR Capital Management working paper.&lt;/li&gt;&lt;li&gt;Benjamini, Y. and Y. Hochberg (1995). Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. &lt;i&gt;Journal of the Royal Statistical Society&lt;/i&gt;, Series B, Vol. 57, 289 – 300.&lt;/li&gt;&lt;li&gt;Benjamini, Y. and D. Yekutieli (2001). The Control of the False Discovery Rate in Multiple Testing under Dependency. &lt;i&gt;Annals of Statistics&lt;/i&gt;, Vol. 29, 1165 – 1188.&lt;/li&gt;&lt;li&gt;Carhart, M. M. (1997). On Persistence in Mutual Fund Performance. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 52(1), 57 – 82.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (1993). Common Risk Factors in the Returns on Stocks and Bonds. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 33(1), 3 – 56.&lt;/li&gt;&lt;li&gt;Fama, E.F. and K.R. French (2010). Luck versus skill in the cross-section of mutual fund returns. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 65(5), 1915 – 1947.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (2015). A Five-Factor Asset Pricing Model. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 116(1), 1 – 22.&lt;/li&gt;&lt;li&gt;Foster, F. D., T. Smith and R. E. Whaley (1997). Assessing goodness-of-fit of asset pricing models: The distribution of the maximal R2. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 52(2), 591 – 607.&lt;/li&gt;&lt;li&gt;Harvey, C.R. and A. Siddique (2000). Conditional skewness in asset pricing tests. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 55(3), 1263 – 1295.&lt;/li&gt;&lt;li&gt;Harvey, C. R. and Y. Liu (2015a). Backtesting. &lt;i&gt;Journal of Portfolio Management&lt;/i&gt;, Vol. 42(1), 13 – 28.&lt;/li&gt;&lt;li&gt;Harvey, C. R. and Y. Liu (2015b). Lucky Factors. Working paper, available at https://jacobslevycenter.wharton.upenn.edu/wp-content/uploads/2015/05/Lucky-Factors.pdf.&lt;/li&gt;&lt;li&gt;Harvey, C. R. and Y. Liu (2018). Lucky Factors. Working paper, available at SSRN: https://ssrn.com/abstract=2528780.&lt;/li&gt;&lt;li&gt;Harvey, C. R., Y. Liu, and H. Zhu (2016). … and the cross-section of expected returns. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 29(1), 5 – 68.&lt;/li&gt;&lt;li&gt;Holm, S. (1979). A simple sequentially rejective multiple test procedure. &lt;i&gt;Scandinavian Journal of Statistics&lt;/i&gt;, Vol. 6, 65 – 70.&lt;/li&gt;&lt;li&gt;Hou, K., C. Xue, and L. Zhang (2015). Digesting anomalies: An investment approach. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 28(3), 650 – 705.&lt;/li&gt;&lt;li&gt;Novy-Marx, R. (2013). The other side of value: The gross profitability premium. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 108 (1), 1 – 28.&lt;/li&gt;&lt;li&gt;Pastor, L. and R.F. Stambaugh (2003). Liquidity risk and expected stock returns. &lt;i&gt;Journal of Political Economy&lt;/i&gt;, Vol. 111(3), 642 – 685.&lt;/li&gt;&lt;li&gt;https://en.wikipedia.org/wiki/Bonferroni_correction&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com/&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-09-30-45715632</guid>
<pubDate>Sun, 30 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>未知风险，错误定价，还是数据迁就？</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-09-26-45371443.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45371443&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-aa2cbfb23b02cfd64ab52c8d2b860bf4_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过对比样本内、外的表现，Linnainmaa and Roberts (2018) 发现从会计数据中挖出的 36 个美股截面收益异象中的大部分都是 data snooping 的产物。这些异象在样本外的表现令人失望。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;每当学术界和业界试图解释一个新发现的关于股票收益截面差异的异象（anomaly，或者用我们更熟悉的语言来说 —— “因子”；在下文“异象”和“因子”将会交替使用）时，&lt;b&gt;未知风险（unmodeled risk）&lt;/b&gt;和&lt;b&gt;错误定价（mispricing）&lt;/b&gt;是最主流的两种角度。诚然，一些长期有效的因子确实是因为上述两种原因造成的。但是面对如今如雨后春笋般层出不穷的因子，除上述两者之外的第三种解释 —— &lt;b&gt;数据迁就（data snooping）&lt;/b&gt; —— 却慢慢的进入了大众的视野。&lt;/p&gt;&lt;p&gt;早在 1990 年，Lo and MacKinlay (1990) 就指出 data snooping 在检验资产定价模型中会造成一定的问题。而美国金融协会（AFA，American Finance Association）前主席 Campbell Harvey 于 2017 年协会年会上做的主席演讲The Scientific Outlook in Financial Economics（Harvey 2017）也指出 &lt;b&gt;data snooping 问题在如今的“因子挖掘界”普遍存在&lt;/b&gt;。关于这篇演讲，我写过一篇读后感，请参考&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38663777&quot;&gt;《在追逐 p-value 的道路上狂奔，却在科学的道路上渐行渐远》&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;Harvey 和他的 co-authors 于 2016 年发表了一篇著名的文章（Harvey et al. 2016），题为 … and the Cross-Section of Expected Returns。我当年看到该文题目中的 … 的第一反应是懵了，以为缺字了。后来读了才回过味儿来：学术界发现新因子的论文题目一般都是 XXX and the cross-section of expected returns，其中 XXX 代表新因子的名字。因此 Harvey et al. (2016) 这篇文章的题目中用了 … 是为了说明该文的研究对象是众多解释股票截面收益的文章。该文分析了学术界发现的 316个 异象，并指出在更严格的 multiple hypothesis testing 框架下，绝大多数因子都难言有效。&lt;/p&gt;&lt;p&gt;近日，来自 USC 的 Juhani Linnainmaa 和来自 UPenn Wharton 商学院的 Michael Roberts 在 Review of Financial Studies 上发表了 The History of the Cross-Section of Stock Returns（Linnainmaa and Roberts 2018）。这两位学者花费了很大的经历构建了&lt;b&gt;全新的样本外数据&lt;/b&gt;，从而比较了来&lt;b&gt;美股中&lt;/b&gt;源于&lt;b&gt;会计数据&lt;/b&gt;中的 36 个异象（下表）在它们各自的样本内和样本外的表现。&lt;b&gt;分析表明，绝大部分异象在样本外明显失效，这种现象和未知风险以及错误定价两种解释严重不符，因此它们很有可能仅是 data snooping 的产物。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-afa7a9c5a45d606da8bd069102497606_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;704&quot; data-rawheight=&quot;755&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-afa7a9c5a45d606da8bd069102497606&quot; data-watermark-src=&quot;v2-f65644db4790b192d96dd5a0f861521a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;The History of the Cross-Section of Stock Returns 无疑是学术界关于 data snooping 如何影响因子挖掘的最新探索。因此，本文就对它进行简要的介绍。该文作者 Linnainmaa 和 Roberts 都是美国 NBER（National Bureau of Economic Research）的学者，他们的发现最早是以 NBER 报告的形式于 2016 年底问世；在 The Jacobs Levy Center’s 2017 Conference，该文也作为三篇入选文章之一得到了与会者的充分讨论；最终该文在今年 7 月于顶刊 RFS 发表。&lt;/p&gt;&lt;p&gt;下面马上进入正题，来聊聊这篇 The History of the Cross-Section of Stock Returns。以下介绍参考 NBER 的这篇论文以及 Roberts 在 2017 年会议上所做的报告。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 数据构建&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;让我们仔细看一下上一节这个大表中汇总的这 36 个来自会计数据的异象。&lt;b&gt;所有这些论文的 in-sample 回测开始时间都是 1963 年之后&lt;/b&gt;（回测结束时间因论文提交和发表时间而不同）。这是因为标准普尔公司在 1962 年创建了 Compustats 数据库，它包含了比较理想的会计数据，为各种研究中的回测奠定了基础。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Linnainmaa and Roberts (2018) 的第一个贡献是综合了 CRSP 的收益率数据（1926 年至今）、Compustat 的会计数据（1962 年至今）、以及 Moody’s Industrial and Railroad 手册中的数据（1918 – 1970），从而构建了从 1926 年至 1963 年之间的会计数据。&lt;/b&gt;这些宝贵的数据对于上述这 36 个异象来说无疑是样本外数据。由于这些数据存在于这些研究的 in-sample 时期之前，它们被称为 &lt;b&gt;pre-sample 数据&lt;/b&gt;。虽然这些 pre-sample 数据较 Compustat 有一定不足（比如没有金融和公用事业这两个行业的数据，以及一些指标的粒度不如 Compustat），但是 Linnainmaa and Roberts (2018) 指出，pre-sample 的数据在数据质量上不输给 Compustat 的数据，而且时间足够长、样本足够多，因此使用这些新的数据来检验那 36 个异象没有问题。下表展示了 pre-sample 数据所覆盖的公司数量。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-095230307673d2940bfc18f727fe9a3b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;578&quot; data-rawheight=&quot;707&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-095230307673d2940bfc18f727fe9a3b&quot; data-watermark-src=&quot;v2-6b4d810d5b09b12e35ca50a4b3f562d7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;此外，每个异象的 in-sample 回测期的终点至今这段时间就构成了 &lt;b&gt;post-sample 数据&lt;/b&gt;。Pre-sample 和 post-sample 数据对于这些异象来说就是样本外数据。&lt;b&gt;如果这些异象背后的原因不是 data snooping 而是未知风险或者错误定价，那么它们应该在样本外依然成立。&lt;/b&gt;特别的，考虑到早期更高的交易费用代表着更高的套利成本，那些由错误定价解释的异象应该在 pre-sample 内更加显著。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 检验框架 —— 以 investment 和 profitability 异象为例&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节以 investment 和 profitability 这两个异象为例考察它们在样本外（pre-sample 和 post-sample 时期）的表现。这两个因子的定义如下（来自 Fama and French 2015 以及 Hou et al. 2015）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Investment：&lt;/b&gt;Change in the Book Value of Total Assets over the Previous Fiscal Year（总资产账面价值相对于上一财年的变化）；&lt;/li&gt;&lt;li&gt;&lt;b&gt;Profitability：&lt;/b&gt;Operating profits over Book Value of Equity（营业利润与权益账面价值之比）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了排除市值因素的影响，在分析目标因子时使用市值将股票分成大小两部分（各 50%），然后在这两组中分别使用目标因子选取因子取值首尾的各 30% 的股票构建多空组合，然后再把这两组中的多空组合收益率取均值作为该因子的投资组合的收益率。&lt;/p&gt;&lt;p&gt;以 investment 因子为例，上述过程相当于使用 size 和 investment 因子将所有股票分成六份：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-696ff2212888d76f5b179f0f91a629f0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;961&quot; data-rawheight=&quot;261&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-696ff2212888d76f5b179f0f91a629f0&quot; data-watermark-src=&quot;v2-c4a79697400a497e9c8dded9887b9011&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在 Small 和 Big 两组中，使用 investment 因子大小将每组的股票分成 Low（30%），Neutral（40%）和 High（30%）三份。之后按照因子本身的业务含义，使用 Low 减 High 或者 High 减 Low 构建市值加权的投资组合。最后把 Small 和 Big 这两组的两个组合的收益率取平均，作为因子投资组合的收益率，以此就可以分析该因子是否能够解释预期收益率的截面差异。&lt;/p&gt;&lt;p&gt;对于 investment 因子，按照其业务含义，Low 的组合（投资比较保守）相对于 High 的组合（投资比较激进）能够获得超额收益，因此这个因子又称为 CMA（Conservative Minus Aggressive）。对于 profitability 因子，按照其业务含义，High 的组合（利润更高）相对于 Low 的组合（利润较低）能够获得超额收益，因此 Fama and French (2015) 称之为 RMW（Robust Minus Weak）因子。&lt;/p&gt;&lt;p&gt;下表展示了 investment 和 profitability 这两个因子在 1963 年（pre-sample）之前每月相对于无风险收益率的超额收益（之所以有 1938 年那个进一步细分是为了考虑 1934 年的 Securities and Exchange Act 所带来的潜在影响）：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-46e61fe971c32f6fa342edcb61d37bd2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;997&quot; data-rawheight=&quot;379&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-46e61fe971c32f6fa342edcb61d37bd2&quot; data-watermark-src=&quot;v2-aac0c8df2e7dfd3457f3e2ac79ba6431&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;结果显示，&lt;b&gt;这两个因子在整个 pre-1963 年的回测期内完全失效。&lt;/b&gt;与之形成鲜明对比的是它们在 in-sample 的显著性（t-statistic 均在 3 以上）。此外，Linnainmaa and Roberts (2018) 指出，在 pre-sample 期间每个投资组合都有不少于 50 支股票，且回测期间长达 37 年，这个级别的数据量保证了统计检验的可靠性，从而排除了数据不足造成的两个因子失效的可能性。&lt;/p&gt;&lt;p&gt;再来看看这两个因子的 CAPM-α —— 使用因子收益率和市场收益率在时序上回归，得到的截距就是在截面上市场无法解释的预期收益率差异，它称为 CAPM-α。下表显示了这两个因子的 CAPM-α 在 1963 年之前的表现，低 t-statistic 同样说明它们完全失效。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07a687bb65550b232e078e88b03606c5_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1001&quot; data-rawheight=&quot;367&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-07a687bb65550b232e078e88b03606c5&quot; data-watermark-src=&quot;v2-e8bd8b867f8ea10cf527b76b606d9157&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;除此之外，这两个因子的 3-Factor-α —— 使用因子收益率和 Fama-French 三因子收益率在时序上回归，得到的截距就是在截面上三因子无法解释的预期收益率差异，它称为 3-Factor-α —— 在 pre-sample 的表现如下。其中 RMW（profitability 因子）在 1938 年到 1963 年之间依然显著。对于 profitability 因子来说，它的 3-Factor-α 比 CAPM-α 更显著是因为 profitability 与 value 因子在回测期内呈现负相关造成的（Novy-Marx 2013）。和它们各自 in-sample 的 3-Factor-α 比较来看，这两个因子（尤其是 investment 因子）在 pre-sample 的表现依然远不如它们 in-sample 的表现。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-39f0df6f8d2945c89d1b71978be62c5e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1006&quot; data-rawheight=&quot;382&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-39f0df6f8d2945c89d1b71978be62c5e&quot; data-watermark-src=&quot;v2-a9d1929b32ea1ac7f2732296bbcc524f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;作为比较，下图展示了 Value（HML），profitability（RMW）以及 investment（CMA）三个因子在 1926 年到 2015 年之间的滚动月收益率均值。其中 RMWO 和 CMAO 代表使用 Fama-French 三因子正交化之后的 RMW 和 CMA 因子。从图中不难看出，&lt;b&gt;价值因子几乎可以持续的获得正收益（直到最近几年才开始亏损），说明价值因子（价值投资）确实是长期立于不败之地的正道。&lt;/b&gt;反观另外两个，investment 因子在 1970 年之前几乎是完全失效的，它的月收益率几乎持续在 0 以下；而 profitability 的 RMWO 收益率在多数时间位于 0 之上，但其在 1940 年之前以及 1980 年前后也有不少的时间录得负收益。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4b4dcf8f920a4211dbdf46d94d6c9731_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;510&quot; data-rawheight=&quot;724&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4b4dcf8f920a4211dbdf46d94d6c9731&quot; data-watermark-src=&quot;v2-409d04e44c680571c8e6197dc8eb1506&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最后，Linnainmaa and Roberts (2018) 从投资的角度考察了 investment 和 profitability 因子。使用这二者，以及market、size 和 value 共五个因子 in-sample 的表现计算出预期收益率和标准差，并通过马科维茨的 mean-variance efficient 策略构建最优投资组合，考察了该组合在 in-sample（1963 年之后）和 pre-sample（1963 年之前）的表现。在 pre-sample，该组合完全无法战胜市场（下图比较了市场和最优组合的滚动夏普率）：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-98b7b38408eb0ef79f9a4af52fdae543_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;759&quot; data-rawheight=&quot;367&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-98b7b38408eb0ef79f9a4af52fdae543&quot; data-watermark-src=&quot;v2-0491df8780dc949de5ff93bd72a8ec04&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;本节的分析（超额收益、CAPM-α、3-Factor-α、最优投资组合）表明，investment 和 profitability 两个因子仅在它们被提出的样本内有效，而在 pre-sample 几乎完全失效。&lt;b&gt;它们极有可能是 data snooping 的结果，而非错误定价或未知风险能够解释的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 其他异象&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;按照上一节介绍的分析思路，Linnainmaa and Roberts (2018) 分析了所有 36 个和会计数据有关的异象。本节简单介绍一下综合的结果，对单因子检验结果感兴趣的小伙伴请阅读原文。&lt;/p&gt;&lt;p&gt;按照性质，这 36 个异象可以分为七大类：profitability，earnings quality，valuation，investment and growth，financing，distress，以及 composite（复合类，比如 AQR 提出的 QML —— Quality Minus Junk 因子）。这七大类因子在 pre-sample、in-sample 以及 post-sample 的平均表现如下表所示 —— &lt;b&gt;平均来说，它们在样本外（包括 pre-sample 和 post-sample）的表现均远远不如其在样本内的表现。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-39b7c8cb560ce6fd37e80cc2d80055ca_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;780&quot; data-rawheight=&quot;763&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-39b7c8cb560ce6fd37e80cc2d80055ca&quot; data-watermark-src=&quot;v2-6f76ff537fd10ad0a9868fc5a5bdf833&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;再来看看全部 36 个因子的平均表现（下表）。在样本内，这些因子获得的收益率更高、波动率却更低，因此带来了更高的夏普率。&lt;b&gt;而在样本外，所有的指标都在往坏的方向变化 —— 更低的收益率、更高的波动率以及更低的夏普率。&lt;/b&gt;无论从超额收益，还是从 CAPM-α 或 3-Factor-α 来说，样本内、外的巨大反差都说明这些因子中有很大一部分难逃 data-snooping 之嫌。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fcab1e16ec17e5f74c72ec2e59439127_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;797&quot; data-rawheight=&quot;653&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fcab1e16ec17e5f74c72ec2e59439127&quot; data-watermark-src=&quot;v2-6797f46d5a5ab2f2f10a8b32b1f8a85d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最终，Linnainmaa and Roberts (2018) 发现，在 in-sample，无论从超额收益、CAPM-α 还是 3-Factor-α 来看，这 36 个因子均显著。这三个指标下显著因子的个数分别为 36、36 和 36。而在 pre-sample 期间，这三个数字变为 8，8 和 16；在 post-sample 期间，这三个数字变为 1，10 和 9。&lt;/p&gt;&lt;p&gt;在 pre-sample 依然有效的因子和 real investment、equity financing、distress 以及 ROE/ROA 有关；在 post-sample 依然有效的因子和 sales/earnings to price ratio、total financing、distress 以及 ROE/ROA 有关。随着宏观经济的变化，在整个回测期的前半段，有效的因子和有形投资以及股权融资相关；在回测期的后半段，有效的因子和无形投资以及债券融资有关。可见，&lt;b&gt;只有那些真正和 economic fundamental 相关的因子背后才可能存在未知风险或错误定价的解释。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 来自数据迁就的证据&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Data snooping 的表现之一是刻意的挑选回测期让因子看起来更加有效。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;虽然 Compustat 数据库包含了从 1963 年以来的数据，但是这 36 个异象中的很多个回测期的起始点并不是 1963 年，这足以引起我们的不安。 &lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3600a1b9f2684064677a6871725826ed_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;855&quot; data-rawheight=&quot;466&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3600a1b9f2684064677a6871725826ed&quot; data-watermark-src=&quot;v2-9d4dfe368465beda6dfdebf610eaa55e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如果把回测期的起点追溯到 1963 年会怎样呢？通过加入一个 dummy 变量代表 1963 年到因子 in-sample 回测期的起点之间这段时间，Linnainmaa and Roberts (2018) 发现仅仅是这个微小的调整也能让大部分因子失效（都无需使用 pre-1963 年的数据）。这无疑是 data snooping 的证据之一。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e40b3576a1c5c74d52ca4e0349c4b50b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;919&quot; data-rawheight=&quot;656&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e40b3576a1c5c74d52ca4e0349c4b50b&quot; data-watermark-src=&quot;v2-a7029c88112e1a804a99673de6848d25&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;下表显示了以 1963 年到 1973 年分别为回测起点时，这 36 个异象的收益率、CAPM-α、3-Factor-α 均有所下降。下降幅度分别为收益率下降 40% 到 80%、CAPM-α 下降 50% 到 75%、3-Factor-α 下降 30% 到 90%。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9beb0e1f361d7f721504573851fa4fae_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;708&quot; data-rawheight=&quot;579&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9beb0e1f361d7f721504573851fa4fae&quot; data-watermark-src=&quot;v2-ea7f36898eb11cb7b6f05b49f799736a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于因子在被发现后表现失效，学术界有另一种被接受的来自&lt;b&gt;套利者&lt;/b&gt;的解释（Mclean and Pontiff 2016）：&lt;b&gt;当因子被发现后，套利者开始交易该因子，导致因子的非有效性较低，表现逐渐失效。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果这个解释成立，那么当因子被发现后，它的收益率应该和其他已经被发现的因子的收益率的相关性更高。这是因为市场上的聪明交易者同时在交易这些不同的因子，使得按这些因子构建的策略的资金流入和流出相对一致，从而造成因子表现的趋同。&lt;/b&gt;为了检验这个说法，Linnainmaa and Roberts (2018) 依照 Mclean and Pontiff (2016) 的思路考察了如下回归模型：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\begin{array}{rll} \mbox{anomaly}_{i,t}&amp;amp;=&amp;amp;a+b_1\times\mbox{in-sample index}_{-i,t}+b_2\times\mbox{post-sample index}_{-i,t}+b_3\times\mbox{post}_{i,t}\\ &amp;amp;=&amp;amp;+b_4\times\mbox{post}_{i,t}\times\mbox{in-sample index}_{-i,t}+b_5\times\mbox{post}_{i,t}\times\mbox{post-sample index}_{-i,t}+e_{i,t} \end{array} &lt;/equation&gt; &lt;/p&gt;&lt;p&gt;这个模型中最核心的就是系数 b_5。其中，post_{i,t} 是一个 binary 变量，取 1 表示目标因子 i 在 post-sample 时期；post-sample index_{-i,t} 则是 post-sample 时期所有其他已有因子的平均收益率。如果 b_5 在统计上显著大于零，则说明因子被学术界发现后，业界确实开始交易它，从而增加了它和其他已有因子的相关性，并由于交易造成了该因子的效果减弱。回归的结果如下表所示，b_5 确实显著大于零，似乎与上述解释相符。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5b015d1b89ae19259923efdf81cfd58e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;767&quot; data-rawheight=&quot;357&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5b015d1b89ae19259923efdf81cfd58e&quot; data-watermark-src=&quot;v2-a4c7ed96086843c9a360686298331ae9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;不过，先不要高兴的太早。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Linnainmaa and Roberts (2018) 将上述回归模型中的所有 &lt;b&gt;post-&lt;/b&gt; 都换成了 &lt;b&gt;pre-&lt;/b&gt;，分析了&lt;b&gt;该因子在它被提出之前和其它尚未被提出的因子之间的相关性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\begin{array}{rll} \mbox{anomaly}_{i,t}&amp;amp;=&amp;amp;a+b_1\times\mbox{in-sample index}_{-i,t}+b_2\times\mbox{pre-sample index}_{-i,t}+b_3\times\mbox{post}_{i,t}\\ &amp;amp;=&amp;amp;+b_4\times\mbox{pre}_{i,t}\times\mbox{in-sample index}_{-i,t}+b_5\times\mbox{pre}_{i,t}\times\mbox{pre-sample index}_{-i,t}+e_{i,t} \end{array}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;结果（下表）显示，在这个回归中，b_5 依然显著大于零，说明&lt;b&gt;目标因子在 pre-sample 期间（被发现前）和其它所有因子在 pre-sample 期间的收益率成正相关。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d773c1e8b970aa57d8cb5433baa0bd65_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;677&quot; data-rawheight=&quot;317&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d773c1e8b970aa57d8cb5433baa0bd65&quot; data-watermark-src=&quot;v2-7d234105f3898cc068ae86dd27d1c65e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;这就尴尬了。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这种正相关就不能再让套利者的交易行为“背锅”了，因为在 pre-sample 期间因子还没有被发现，套利者又怎么能交易它们呢？&lt;b&gt;更不幸的是，由于在 pre-sample 和 post-sample 上观察到了几乎一致的现象，我们对于 post-sample 中的套利者这个解说也动摇了。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Linnainmaa and Roberts (2018) 认为，&lt;b&gt;上述现象的一个合理的解释是在样本内，data mining 不仅仅是对异象的一阶矩（预期收益）造成了影响，而是对于异象之间的高阶矩（相关性）也造成了错误的影响。&lt;/b&gt;唯有此才能够解释在 pre-sample 和 post-sample 期间都观测到的因子之间不正常的正相关性。这便是 data snooping 的另一个证据。Data snooping 在样本内对于收益率的分析到底有怎样的影响值得今后持续的研究。&lt;/p&gt;&lt;p&gt;以上便结束了我对 Linnainmaa and Roberts (2018) 这篇文章的介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下图高度概括了 Linnainmaa and Roberts (2018) 的结果：78% 的异象在样本外失效了，它们在样本内的好结果似乎只能是来自 data snooping 这一种解释。用一句话来表达 Linnainmaa and Roberts (2018) 所传达的信息那就是：&lt;b&gt;找到一个真正在样本内、外均有效的因子（异象）其实是非常困难的。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-265a9add9d95e000d2313289e77554a0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1045&quot; data-rawheight=&quot;578&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-265a9add9d95e000d2313289e77554a0&quot; data-watermark-src=&quot;v2-0dde88f3ca8e2a3cbfb8924d5e79695c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;当很多人都在使用同样的数据来分析大量不同的指标时，最终被发表在顶级期刊上的那些异象注定是在样本内表现非常优秀的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这就好比把 300+ 因子（甚至 1000+ 或更多）分成 10+ 大类，然后一个一个的试，再把挑出来最好的十几个在组合在一起通过什么 ICIR 动态选股，那在样本内的净值恐怕不上天比上天还难。但是样本外呢？&lt;/p&gt;&lt;p&gt;即便学者们试图从未知风险和定价错误去解释这些异象，但它们背后仍然存在着严重的 publication bias 以及 data snooping bias。Linnainmaa and Roberts (2018) 指出，对于这些 biases，以提高 t-statistic 阈值为目标的统计调整方法（如 Harvey et al. 2016）由于针对的仍然是样本内数据，因此作用有限；&lt;b&gt;最有效的方法仍然是使用样本外的全新数据进行检验。&lt;/b&gt;Harvey et al. (2016) 也指出：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;When feasible, out-of-sample testing is the cleanest way to rule out spurious factors.&lt;/i&gt;&lt;br&gt;&lt;i&gt;译：在条件允许下，使用样本外数据检验是排除虚假因子的最好办法。&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;在这方面，Linnainmaa and Roberts (2018) 整理了 1963 年以前美股的财务数据，供学术界和业界使用，可谓贡献巨大。&lt;/p&gt;&lt;p&gt;2011 年，John Cochrane 教授在美国金融协会主席演讲时&lt;b&gt;调侃&lt;/b&gt;道（Cochrane 2011）：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;We thought 100% of the cross-sectional variation in expected returns came from the CAPM, now we think that&#39;s about zero and a zoo of new factors describes the cross section.&lt;/i&gt;&lt;br&gt;&lt;i&gt;译：我们曾认为股票预期收益率的截面差异全部来自资本资产定价模型（CAPM）；如今我们认为能被 CAPM 解释的部分约为零，取而代之的是我们有了一揽子全新的描述截面预期收益率的因子。&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;这就是“因子挖掘界”的现状，多少有些令人无奈。&lt;/b&gt;但至少（海外）学术界和业界已经意识到了这一点并已经开始采取行动 —— &lt;b&gt;使用更严谨的统计手段和更多的数据来检验因子。&lt;/b&gt;对于不依赖于会计数据的因子（比如动量因子），回测数据的可得性要高的多，可以跨市场、跨时空来检验；对于依赖于会计数据的因子，相信 Linnainmaa 和 Roberts 两位教授构建的全新样本外数据会在未来发挥更大的作用。&lt;/p&gt;&lt;p&gt;虽然越来越多的分析指出 data snooping 的问题很严峻，但我们也无需过度悲观。在研究股票预期收益率截面差异的道路上，所有这些努力都不会白费。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Abarbanell, J. S. and B. J. Bushee (1998). Abnormal returns to a fundamental analysis strategy. &lt;i&gt;The Accounting Review&lt;/i&gt;, Vol. 73(1), 19 – 45.&lt;/li&gt;&lt;li&gt;Alwathainani, A. M. (2009). Consistency of firms&#39; past financial performance measures and future returns. &lt;i&gt;British Accounting Review&lt;/i&gt;, Vol. 41, 184 – 196.&lt;/li&gt;&lt;li&gt;Asness, C. S., A. Frazzini, and L. H. Pedersen (2013). Quality minus junk. AQR Capital Management working paper.&lt;/li&gt;&lt;li&gt;Barbee, Jr., W. C., S. Mukherji, and G. A. Raines (1996). Do sales-price and debt-equity explain stock returns better than book-market and firm size? &lt;i&gt;Financial Analysts Journal&lt;/i&gt;, Vol. 52(2), 56 – 60.&lt;/li&gt;&lt;li&gt;Bartov, E. and M. Kim (2004). Risk, mispricing, and value investing. &lt;i&gt;Review of Quantitative Finance and Accounting&lt;/i&gt;, Vol. 23(4), 353 – 376.&lt;/li&gt;&lt;li&gt;Basu, S. (1977). Investment performance of common stocks in relation to their price-earnings ratios: A test of the efficient market hypothesis. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 32(3), 663 – 682.&lt;/li&gt;&lt;li&gt;Bhandari, L. C. (1988). Debt/equity ratio and expected common stock returns: Empirical evidence. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 43(2), 507 – 528.&lt;/li&gt;&lt;li&gt;Bradshaw, M. T., S. A. Richardson, and R. G. Sloan (2006). The relation between corporate financing activities, analysts&#39; forecasts and stock returns. &lt;i&gt;Journal of Accounting and Economics&lt;/i&gt;, Vol. 42(1-2), 53 – 85.&lt;/li&gt;&lt;li&gt;Campbell, J. Y., J. Hilscher, and J. Szilagyi (2008). In search of distress risk. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 63(6), 2899 – 2939.&lt;/li&gt;&lt;li&gt;Cooper, M. J., H. Gulen, and M. J. Schill (2008). Asset growth and the cross-section of stock returns. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 63(4), 1609 – 1651.&lt;/li&gt;&lt;li&gt;Cochrane, J. H. (2011). Presidential address: Discount rates. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 66(4), 1047 – 1108.&lt;/li&gt;&lt;li&gt;Daniel, K. and S. Titman (2006). Market reactions to tangible and intangible information. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 61(4), 1605 – 1643.&lt;/li&gt;&lt;li&gt;Dichev, I. A. (1998). Is the risk of bankruptcy a systematic risk? &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 53(3), 1131 – 1147.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (1992). The cross-section of expected stock returns. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 47(2), 427 – 465.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (2015). A Five-Factor Asset Pricing Model. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 116(1), 1 – 22.&lt;/li&gt;&lt;li&gt;Harvey, C. R. (2017). Presidential Address: the scientific outlook in financial economics. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 72(4), 1399 – 1440.&lt;/li&gt;&lt;li&gt;Harvey, C. R., Y. Liu, and H. Zhu (2016). … and the cross-section of expected returns. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 29(1), 5 – 68.&lt;/li&gt;&lt;li&gt;Haugen, R. A. and N. L. Baker (1996). Commonality in the determinants of expected stock returns. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 41(3), 401 – 439.&lt;/li&gt;&lt;li&gt;Hirshleifer, D., K. Hou, S. H. Teoh, and Y. Zhang (2004). Do investors overvalue firms with bloated balance sheets? &lt;i&gt;Journal of Accounting and Economics&lt;/i&gt;, Vol. 38, 297 – 331.&lt;/li&gt;&lt;li&gt;Hou, K., C. Xue, and L. Zhang (2015). Digesting anomalies: An investment approach. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 28(3), 650 – 705.&lt;/li&gt;&lt;li&gt;Lakonishok, J., A. Shleifer, and R. Vishny (1994). Contrarian investment, extrapolation and investment risk. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 49(5), 1541 – 1578.&lt;/li&gt;&lt;li&gt;Linnainmaa, J. T. and M. R. Roberts (2018). The history of the cross-section of stock returns. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 31(7), 2606 – 2649.&lt;/li&gt;&lt;li&gt;Lo, A. W. and A. C. MacKinlay (1990). Data-snooping biases in tests of financial asset pricing models. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 3(3), 431 – 467.&lt;/li&gt;&lt;li&gt;Lockwood, L. and W. Prombutr (2010). Sustainable growth and stock returns. &lt;i&gt;Journal of Financial Research&lt;/i&gt;, Vol. 33(4), 519 – 538.&lt;/li&gt;&lt;li&gt;Loughran, T. and J. W. Wellman (2011). New evidence on the relation between the enterprise multiple and average stock returns. &lt;i&gt;Journal of Financial and Quantitative Analysis&lt;/i&gt;, Vol. 46(6), 1629 – 1650.&lt;/li&gt;&lt;li&gt;Lyandres, E., L. Sun, and L. Zhang (2008). The new issues puzzle: Testing the investment-based explanation. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 21(6), 2825 – 2855.&lt;/li&gt;&lt;li&gt;McLean, R. D. and J. Pontiff (2016). Does academic research destroy stock return predictability? &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 71(1), 5 – 32.&lt;/li&gt;&lt;li&gt;Novy-Marx, R. (2013). The other side of value: The gross profitability premium. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 108 (1), 1 – 28.&lt;/li&gt;&lt;li&gt;Piotroski, J. D. (2000). Value investing: The use of historical financial statement information to separate winners from losers. &lt;i&gt;Journal of Accounting Research&lt;/i&gt;, Vol. 38, 1 – 41.&lt;/li&gt;&lt;li&gt;Pontiff, J. and A. Woodgate (2008). Share issuance and cross-sectional returns. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 63(2), 921 – 945.&lt;/li&gt;&lt;li&gt;Sloan, R. G. (1996). Do stock prices fully reflect information in accruals and cash flows about future earnings? &lt;i&gt;The Accounting Review&lt;/i&gt;, Vol. 71(3), 289 – 315.&lt;/li&gt;&lt;li&gt;Soliman, M. T. (2008). The use of DuPont analysis by market participants. &lt;i&gt;The Accounting Review&lt;/i&gt;, Vol. 83(3), 823 – 853.&lt;/li&gt;&lt;li&gt;Spiess, D. K. and J. Affleck-Graves (1999). The long-run performance of stock returns following debt offerings. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 54(1), 45 – 73.&lt;/li&gt;&lt;li&gt;Thomas, J. K. and H. Zhang (2002). Inventory changes and future returns. &lt;i&gt;Review of Accounting Studies&lt;/i&gt;, Vol. 7(2), 163 – 187.&lt;/li&gt;&lt;li&gt;Titman, S., K. C. J. Wei, and F. Xie (2004). Capital investments and stock returns. &lt;i&gt;Journal of Financial and Quantitative Analysis&lt;/i&gt;, Vol. 39(4), 677 – 700.&lt;/li&gt;&lt;li&gt;Xing, Y. (2008). Interpreting the value effect through the q-theory: An empirical investigation. &lt;i&gt;Review of Financial Studies&lt;/i&gt;, Vol. 21(4), 1767 – 1795.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-09-26-45371443</guid>
<pubDate>Wed, 26 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>获取 α 的新思路：科技关联度</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-09-18-44781908.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/44781908&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f237adb737ed689b2af54c056af415f8_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在寻找 α 的努力中，最重要的是获得新的数据或者是对已有数据的创新用法。与数据相比，算法先进性的作用相对有限。本文介绍的 Lee et al. (2018) 提出了获取 α 的新视角。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;今天给大家介绍一篇新鲜出炉的文章，题为 Technological links and predictable returns（Lee et al. 2018），它即将刊发于 Journal of Financial Economics，领衔作者是斯坦福大学的 Charles M. C. Lee 教授和北京大学的张然教授，这两位均长期从事基本面量化投资的研究。&lt;/p&gt;&lt;p&gt;该文提出了一个获取 α 的新思路：&lt;b&gt;科技关联度（technological links）&lt;/b&gt;。虽然它是以美股为研究背景（使用该因子构建的多空投资组合每个月可以获得 1.17% 的超额收益），但相信对投资 A 股的小伙伴也会有很大的启发。更重要的是，该文的行文逻辑堪称因子研究的典范。相信读过本文的介绍后，你就能够认可这种说法。&lt;/p&gt;&lt;p&gt;下面马上进入正题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 科技关联度&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在知识经济时代，科技实力已经成为一个公司短期盈利和长期生存的重要因素。世界上的科技巨头，如亚马逊、谷歌、苹果、英特尔等公司，它们的产品可能截然不同，但在科技层面却有着千丝万缕的联系。这些科技上的关联超越了传统的行业界限，却通常不易从公司的财务报告中辨别出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Technological links and predictable returns 一文研究了公司之间的科技关联度和公司股票未来预期收益率之间的关系。&lt;/b&gt;它背后的逻辑是公司的科研并不是独立的，一项科技进步的溢出效应将会影响科技关联度高的一系列公司，而这种影响将改变这些公司基本面，并最终（先后）反映到公司的股价中。&lt;/p&gt;&lt;p&gt;基于此，该文揭示了一个令人惊讶的实证关系，即&lt;b&gt;目标公司的股票收益率和与其科技关联度相近的公司前期的收益率之间有一种滞后-领先关系。&lt;/b&gt;换句话说，对于任何一个目标公司，使用某种代理指标来计算它和其他公司的科技关联度，然后以该关联度为权重和其他公司的当期收益率就可以计算出一个加权收益率，该收益率对目标公司下一期的收益率有一定的预测性。因此，&lt;b&gt;以科技关联度为权重的加权收益率是一个优秀的 α 因子。这种领衔-滞后关系也可以被称作“科技动量”。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面就来介绍如何构建这个因子。首先需要计算公司之间的科技关联度。为此，Lee et al. (2018) 使用&lt;b&gt;两个公司专利分布之间的 uncentered correlation&lt;/b&gt;（就是计算相关系数的时候&lt;b&gt;省去减均值&lt;/b&gt;的步骤，类似的做法也被 Jaffe 1986 和 Bloom et al. 2013 采用）计算科技关联度：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle\mbox{TECH}_{ijt}=\frac{T_{it}T&#39;_{jt}}{\left(T_{it}T&#39;_{it}\right)^{1/2}(T_{jt}T&#39;_{jt})^{1/2}}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;上式左侧 &lt;equation&gt;\mbox{TECH}_{ijt}&lt;/equation&gt; 代表了公司 i 和 j 在第 t 期的科技关联度；上市右侧的 &lt;equation&gt;T_{it}&lt;/equation&gt; 是一个 427 维的横向量，即 &lt;equation&gt;T_{it} = [T_{it1}, T_{it2}, …, T_{it427}]&lt;/equation&gt; 。427 这个数字源自美国专利商标局（United States Patent and Trademark Office）定义的 427 个科技大类。因此，一个公司的专利分布由它过去五年获取的全部科技专利在这 427 类中的比例决定。举例来说，假如从当前时点计算，某公司过去五年获得了 100 个科技专利，分别属于编号为 1（10 个）, 100（60 个） 和 303（30 个）的三大类，则该公司的专利分布中， &lt;equation&gt;T_{it1} = 10/100 = 0.1&lt;/equation&gt; ， &lt;equation&gt;T_{it100} = 60/100 = 0.6&lt;/equation&gt; ， &lt;equation&gt;T_{it303} = 30/100 = 0.3&lt;/equation&gt; ，而其他大类 k 对应的 T_{itk} 值为 0，这些 &lt;equation&gt;T_{itk}&lt;/equation&gt; 就构成了 t 期该公司的专利分布向量，由此就可以计算不同公司之间的科技关联性 &lt;equation&gt;\mbox{TECH}_{ijt}&lt;/equation&gt; 。&lt;/p&gt;&lt;p&gt;下图来自 Lee et al. (2018)，它展示了两家公司 Regeneron Pharmaceuticals 和 Illumina 在 2002 到 2006 年间科技专利所属类别的情况（绝对数量，未经标准化）。Regeneron 是一家制药公司，而 Illumina 生产生命科学工具并提供遗传分析服务。这俩家公司所处完全不同的行业，且在供应链方面也没有什么联系。但是科技关联性从全新的角度揭示了它们之间的关联 —— 这两家公司在 435 大类（分子和微生物学）方面均有很多专利，它们之间的 TECH_{ijt} 高达 0.71。&lt;b&gt;可见科技关联度可以找到被行业以及上下游产业链忽视的公司之间的关系，Lee et al. (2018) 发现经验数据表明这种关联在选股方面大有可为。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-25d804e356ca80f646af86ea5ef390df_r.jpg&quot; data-rawwidth=&quot;868&quot; data-rawheight=&quot;546&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-25d804e356ca80f646af86ea5ef390df&quot; data-watermark-src=&quot;v2-c74bae787afaa45f61c62cc4b78b75fb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;得到 &lt;equation&gt;\mbox{TECH}_{ijt}&lt;/equation&gt; 之后，利用它作为权重按下式计算加权收益率作为选股因子：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\displaystyle\mbox{TECHRET}_{it}=\frac{\sum_{j\ne i}\mbox{TECH}_{ijt}\times\mbox{RET}_{jt}}{\sum_{j\ne i}\mbox{TECH}_{ijt}}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;上式左侧 &lt;equation&gt;\mbox{TECHRET}_{it}&lt;/equation&gt; 就是公司 i 第 t 期的因子取值；右侧的 &lt;equation&gt;\mbox{RET}_{jt}&lt;/equation&gt; 为公司 j 在 t 期的收益率，所有和 i 不同的公司 j 的收益率以 &lt;equation&gt;\mbox{TECH}_{ijt}&lt;/equation&gt; 为权重加权在一起，构成了选股因子。由于计算科技关联度需要使用到过去五年的专利数，因此每期的候选股票池为在这段时间内至少获得了一个专利的股票（以专利的官方授予日期计算，从而避免了前视偏差）。&lt;/p&gt;&lt;p&gt;值得说明的是，虽然选股因子 &lt;equation&gt;\mbox{TECHRET}_{it}&lt;/equation&gt; 的更新是月频，但是其中的科技关联度 &lt;equation&gt;\mbox{TECH}_{ijt}&lt;/equation&gt; 更新的频率是每年一次，在每年年末使用过去五年的专利数来更新 &lt;equation&gt;\mbox{TECH}_{ijt}&lt;/equation&gt; 。由于收益率 &lt;equation&gt;\mbox{RET}_{jt}&lt;/equation&gt; 是月频收益率，因此最终的因子更新频率是月频。&lt;/p&gt;&lt;p&gt;关于数据的来源和处理方法更详尽的说明请参考 Lee et al. (2018) 中的第二节，这里不再赘述。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 投资组合检验&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了检验 &lt;equation&gt;\mbox{TECHRET}_{it}&lt;/equation&gt; 因子的选股效果，Lee et al. (2018) 首先进行了投资组合检验（portfolio tests）。每个月初，以最新的因子取值将股票池中的股票排序并分成十档，做多分数最高的第一档，做空分数最低的第十档，以此构建一个 L/S 组合，并考察该组合的收益率。L/S 组合的收益率如下表所示（该表是 Lee et al. 2018 中最重要的结果）。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8167d7d6f0ccd1cbfe4982c33ba62bb4_r.jpg&quot; data-rawwidth=&quot;882&quot; data-rawheight=&quot;685&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8167d7d6f0ccd1cbfe4982c33ba62bb4&quot; data-watermark-src=&quot;v2-e66ac1028c22ec933ccceec1996197c2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;先来看看 Panel A。第一列是 L/S 组合相对于无风险收益率的超额收益。按等权重构建的该组合每月可以获得 1.17% 的超额收益；按照市值权重构建的投资组合每月获得 0.69% 的超额收益。Panel A 的第二到第六列汇报了考虑了其他常见的因子后，该 L/S 组合仍然能够获得的超额收益。&lt;/p&gt;&lt;p&gt;以第三列的 3-Factor alpha 为例，它的计算如下：&lt;b&gt;使用 TECHRET 因子的 L/S 组合收益的时间序列和 Fama-French 三因子（Fama and French 1993）的时间序列在时序上回归，得到的截距恰好就是截面上&lt;/b&gt; &lt;b&gt;L/S 无法被三因子解释的超额收益&lt;/b&gt;（这是因为 Fama-French 三个因子本身是投资组合 MKT，SMB，HML 的收益率；需要这方面背景知识的小伙伴请参考&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40984029&quot;&gt;《股票多因子模型的回归检验》&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;其他列考虑的不同因子模型之后获得的超额收益可以类似的解释。其中，4 factor model 是 Fama-French 三因子 + Carhart (1997) 的动量因子，5 factor model 是 Fama and French (2015) 提出的五因子模型，而 6 factor model 是该五因子加上动量因子。结果显示，市场上常见的其他主流因子均无法解释 L/S 获得的超额收益。&lt;/p&gt;&lt;p&gt;上表中 Panel B 展示了使用 4 factor model 对 L/S 组合进行时序回归时，得到的因子载荷。以等权为例，结果显示该组合在市场因子（MKT）上有负的暴露，在 SMB 和 MOM 因子上有正的暴露。这意味着该策略在市场下行、以及小市值和动量股表现好的时候额外有效。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 回归检验&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;除了 portfolio tests 之外，Lee et al. (2018) 还使用 Fama and MacBeth (1973) 进行了&lt;b&gt;截面回归检验&lt;/b&gt;，&lt;b&gt;其目的是为了在控制住其他变量后考察 TECHRET 因子对于股票截面收益差异的解释程度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Fama-MacBeth 回归是在每个时点在截面上用因子载荷和个股的收益率进行回归，从而得到每期各因子的收益率，然后在时序上取平均就得到因子的预期收益率（需要进一步了解 Fama-MacBeth 回归的朋友请参考&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40984029&quot;&gt;《股票多因子模型的回归检验》&lt;/a&gt;）。此外，Lee et al. (2018) 通过 Newey-West 调整求出了因子收益率的 standard error，从而计算出了 Fama-MacBeth t-statistics。下表给出了实证结果。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7f7e94c246bd08000d2a60906086457a_r.jpg&quot; data-rawwidth=&quot;623&quot; data-rawheight=&quot;580&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7f7e94c246bd08000d2a60906086457a&quot; data-watermark-src=&quot;v2-a09a2688f93e8c52303e30822ff1e1ea&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在（1）到（3）列中，被解释变量是股票的收益率 RET。&lt;b&gt;在截面回归中，解释变量是因子载荷。&lt;/b&gt;在这方面的处理上，作者并没有通过时序回归求解因子载荷，而是将股票在各个因子上的取值按其大小映射到 0 到 1 之内的十分位上。比如，如果某一期一个股票在 TECHRET 因子上的取值是所有股票中的前 10%，则它在该因子上的载荷就是 1。&lt;/p&gt;&lt;p&gt;在上表中，除了那些我们熟悉的因子外，其他的因子包括 Gross Profitability (GP)、Asset Growth (AG)、R&amp;amp;D intensity (RD) 以及 INDRET，它是目标公司所在行业的市值加权收益率。结果表明，当控制了这些变量后，TECHRET 因子的预期收益率依然显著大于零（t-statistic 在 4 以上）。&lt;/p&gt;&lt;p&gt;在上表的第（4）列中，作者从 RET 中减去了 INDRET 作为解释变量，从而直接排除行业动量造成的潜在影响。即便如此，Fama-MacBeth 回归结果仍然表明，TECHRET 因子的预期收益率显著大于零，其 t-statistic 高达 6.06。&lt;/p&gt;&lt;p&gt;除了上述控制变量外，Lee et al. (2018) 还考虑了市场中存在的其他可能造成 lead-lag 收益率效应的关联，这其中包括 customer-supplier links（Menzly and Ozbas 2010）以及 standalone-conglomerate firm links（Cohen and Lou 2012）。结果表明，这些已有关联并不能解释新发现的科技关联度。&lt;/p&gt;&lt;p&gt;另一方面，Burt and Hrdlicka (2016) 指出，存在某种关联的公司可能会在一些共同因子上有近似的暴露，导致在评价新因子时出现偏差。为了排除这个影响，Lee et al. (2018) 也在构建 TECHRET 因子时使用了股票的特异性收益率（即收益率减去 4 factor model 解释的部分）。使用根据特异性收益率计算的 TECHRET 因子选股，所构建的 L/S 组合仍然能够获得主流因子无法解释的超额收益（下图）。这也再次说明 TECHRET 和这些主流的因子之间在很大程度上是正交的。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-90c2b31ccf483069fcef0c542f718e76_r.jpg&quot; data-rawwidth=&quot;656&quot; data-rawheight=&quot;601&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-90c2b31ccf483069fcef0c542f718e76&quot; data-watermark-src=&quot;v2-dc22e89205f0e9b39d52903e9428af76&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;除了本小节介绍的这些检验之外，Lee et al. (2018) 中还包括了更多的 robustness tests，由于篇幅的问题就不逐一介绍了，感兴趣的小伙伴请阅读原文。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 内在有效机制&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前文的结果说明 TECHRET 因子在选股方面确实有效，而且它获得的超额收益不能被市场中常见的其他因子解释。本节就来看看它为何有效。&lt;/p&gt;&lt;p&gt;对于超额收益，学术界和业界主流的两种解释是&lt;b&gt;错误定价&lt;/b&gt;和&lt;b&gt;风险补偿&lt;/b&gt;。搞清楚 TECHRET 背后的机制至关重要：错误定价意味着投资者可以通过合理的策略获得潜在的超额收益；而风险补偿则意味着投资者获得的收益是以承担额外风险为代价的。本节和下一节分别考察错误定价和风险补偿这两种解释。&lt;/p&gt;&lt;p&gt;在考察该因子获取的超额收益的可持续性上，作者发现 L/S 投资组合在未来几个月内都可以持续的获得收益（下图）；表明科技动量是一个价格发现的过程，随着投资者逐渐意识到科技关联公司的新息，股价也随之反映完全。&lt;b&gt;这或许说明价格对于与科技有关的基本面消息的吸收是缓慢的，从而导致了错误定价。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b721313f52efb112a503a91f6e05bd14_r.jpg&quot; data-rawwidth=&quot;810&quot; data-rawheight=&quot;536&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b721313f52efb112a503a91f6e05bd14&quot; data-watermark-src=&quot;v2-d012f1cc971abfe4d5abf8bfbcfef46d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;为验证上述猜想，Lee et al. (2018) 研究了以下三个方面：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;科技相关新息（innovation）的性质；&lt;/li&gt;&lt;li&gt;投资者对这类新息的有限注意力（limited attention）；&lt;/li&gt;&lt;li&gt;投资者的套利成本。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在第一方面，实证结果表明，TECHRET 因子的强度和目标公司的 technology intensity 以及 technology specificity（强度和专度）有关。举例来说，在强度方面，R&amp;amp;D 开销大的公司获得的 TECHRET 因子收益更高；在专度方面，该文以专利集中度作为衡量专度的指标并发现专度高的公司获得的 TECHRET 因子收益更高。&lt;/p&gt;&lt;p&gt;Lee et al. (2018) 指出，对于行业应用集中度高的专利类别来说，科技新息被价格反映的速度更慢一些。而上述的结果与这个说法一致。对于科技专度更高的公司，TECHRET 因子包含了更多的该公司的估值信息。此外投资者对于科技专度高的公司的估值变化反应不足。这两种原因导致了较慢的信息扩散过程。&lt;/p&gt;&lt;p&gt;在第二方面，为了检验投资者的 limited attention，作者的猜想是关注度低的公司 —— 特征是市值小、分析师报告和媒体报道更少、机构投资者占比低 —— 可以获得更高的 TECHRET 因子收益率。为此，作者分别构建了 dummy 指标，并进行了回归分析，结果证实了上述猜想。&lt;/p&gt;&lt;p&gt;在最后一方面，作者的假设是那些套利成本高的公司能够获得更高的 TECHRET 因子收益率。使用特异性波动率（Baker and Wurgler 2006, 2007）以及负面新闻（Hong et al. 2000）作为套利成本的代理指标，Lee et al. (2018) 的分析结果和上述猜想一致。对于 limited attention 和套利成本方面的回归分析结果如下表所示。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-29b8f345ebf4ce83d97088ed176f9f4b_r.jpg&quot; data-rawwidth=&quot;721&quot; data-rawheight=&quot;542&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-29b8f345ebf4ce83d97088ed176f9f4b&quot; data-watermark-src=&quot;v2-65ef5d3b9c0b5af2211e2e998d7ad400&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上述结果从科技新息性质、投资者的有限注意力以及套利成本方面证实了价格对与科技类基本面消息的吸收是缓慢的，从而造成了错误定价。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 风险解释站不住脚&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;除了错误定价这种解释外，另一种常见的解释是从风险补偿的角度，即因子之所以获得超额收益是因为它暴露于某种未知的风险。然而 Lee et al. (2018) 的分析说明，这种解释并不成立。&lt;/p&gt;&lt;p&gt;由于“未知”，我们不可能罗列所有潜在的风险然后考察 TECHRET 因子在上面的暴露如何。取而代之，Lee et al. (2018) 从另外四个角度来分析风险补偿说。本文着重介绍其中的两个。&lt;/p&gt;&lt;p&gt;第一个是考察股票在盈余公告期的收益情况，这是一种被学术界普遍认可的方法。它背后的逻辑是，&lt;b&gt;如果某个异象和错误定价有关，则该因子在盈余公告期内应该比其他时间内获得更高的收益，这是因为最新的盈余报告有助于修正投资者之前对该股票的估值错误。而反过来，如果该异象是源自风险补偿，我们将不会观察到上述现象，换句话说，该因子在不同时期（无论是否盈余公告期内）的收益率应该大致相当。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;回归结果（下表）说明，在考虑了一系列必要的控制变量后，盈余公告期内 TECHRET 因子能够获得非盈余公告期内 4 倍以上的收益率，这是风险补偿说完全无法解释的。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e95cc10ef193847af9baf520166a814b_r.jpg&quot; data-rawwidth=&quot;703&quot; data-rawheight=&quot;553&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e95cc10ef193847af9baf520166a814b&quot; data-watermark-src=&quot;v2-5f56f5c338b5976f30337a45fa1d37f7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;第二个角度是 standardized unexpected earnings（SUE，未预期盈余），它是一个非收益率指标，因此不会被对风险的控制不足所影响。Lee et al. (2018) 检验了 TECHRET 能否预测未来的 SUE。由于 SUE 是公司未来现金流的决定因素，如果 TECHRET 能够预测 SUE 则说明前者带来的超额收益和公司基本面的改变相关，而非风险补偿。&lt;/p&gt;&lt;p&gt;实证结果如下表所示，它说明 TECHRET 对 SUE 有统计上显著的预测性。此外，Panel B 的结果表明，当前季度的 TECHRET 对未来三个季度的 SUE 都有显著的预测性，且这种预测性在逐步减弱。这一结果有力的佐证了该因子可能来源于错误定价，而非风险补偿。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e947f0975be0bd600da4c8569d4d95b_r.jpg&quot; data-rawwidth=&quot;623&quot; data-rawheight=&quot;643&quot; data-size=&quot;normal&quot; data-caption=&quot;&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3e947f0975be0bd600da4c8569d4d95b&quot; data-watermark-src=&quot;v2-393380918c73e4c7412bb66a2230b5f0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;此外，Lee et al. (2018) 还指出技术变化风险以及竞争替代风险均无法解释 TECHRET 因子。综合本节和上一节的结果，Lee et al. (2018) 认为，TECHRET 获得超额收益的原因在于人们对科技新息可造成的股价变化反应不足，而非额外的风险补偿。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Lee et al. (2018) 是一篇研究因子的典范。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;以下高度概括一下它的行文逻辑：首先它从世界经济发展造成的公司之间越来越密切的联系出发提出了科技关联度这个新视角，并选择了适当的代理指标（专利分布之间的相关系数）来计算公司之间科技关联度的强弱。为了检验这个因子在解释股票截面预期收益率差异上的作用，该文使用了业界广泛流行的 portfolio tests 和 regression tests 指出该因子确实能够获得超额收益，并通过一系列更为细致的 robustness tests 来确认这一点。该文最后错误定价和风险补偿两个主流角度分析了该因子有效的内在机制，并指出它背后的原理是投资者对于科技新息的反应不足。&lt;/p&gt;&lt;p&gt;我第一次通读该文后大呼过瘾。然而，在受到这个新思路的启发之余，&lt;b&gt;更让我感慨的是海外学术界和业界对于美股研究的这一整套科学的、完全可以复制的体系。&lt;/b&gt;首先是研究美股的数据非常完善（专利数据、股票数据等）；其次是经过几十年来无数学者在顶级期刊上发表的丰硕成果的积淀，一个新的因子被提出后，应该进行哪些 tests、使用哪些主流因子来分析这个新因子、以及如何识别该因子是源自风险补偿还是投资者对它的反应不足等，有大量被反复验证过的文献形成一个科学的分析框架。这种积累不是一朝一夕能形成的，这实在是让人羡慕，也值得我们的学术界和业界学习。&lt;/p&gt;&lt;p&gt;我一直以来的观点是，在寻找 α 的努力中，最重要的是获得新的数据或者是对已有数据的创新用法。与数据比起来，算法先进性的作用相对有限。在这方面，Lee et al. (2018) 的贡献尤为突出，提出了获取 α 的新视角。&lt;/p&gt;&lt;p&gt;这是真正的计量经济学。&lt;/p&gt;&lt;p&gt;这是真正的金融工程。&lt;/p&gt;&lt;p&gt;这是真正为人们理解股票截面预期收益差异而做出的卓越努力。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Baker, M. and J. Wurgler (2006). Investor Sentiment and the Cross-section of Stock Returns. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 61(4), 1645 – 1680.&lt;/li&gt;&lt;li&gt;Baker, M. and J. Wurgler (2007). Investor Sentiment in the Stock Market. &lt;i&gt;Journal of Economic Perspectives&lt;/i&gt;, Vol. 21(2), 129 – 152.&lt;/li&gt;&lt;li&gt;Bloom, N., M. Schankerman, and J. Van Reenen (2013). Identifying Technology Spillovers and Product Market Rivalry. &lt;i&gt;Econometrica&lt;/i&gt;, Vol. 81(4), 1347 – 1393.&lt;/li&gt;&lt;li&gt;Burt, A. and C. M. Hrdlicka (2016). Understanding Network-based Measures of Information Diffusion. Unpublished working paper, University of Washington.&lt;/li&gt;&lt;li&gt;Carhart, M. M. (1997). On Persistence in Mutual Fund Performance. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 52(1), 57 – 82.&lt;/li&gt;&lt;li&gt;Cohen, L. and D. Lou (2012). Complicated Firms. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 104(2), 383 – 400.&lt;/li&gt;&lt;li&gt;Jaffe, A. B. (1986). Technological Opportunity and Spillovers of R&amp;amp;D: Evidence from Firms’ Patents, Profits, and Market Value. &lt;i&gt;American Economic Review&lt;/i&gt;, Vol. 76(5), 984 – 1001.&lt;/li&gt;&lt;li&gt;Fama, E. F. and J. D. MacBeth (1973). Risk, return, and equilibrium: empirical tests. &lt;i&gt;Journal of Political Economy&lt;/i&gt;, Vol. 81(3), 607 – 636.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (1993). Common Risk Factors in the Returns on Stocks and Bonds. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 33(1), 3 – 56.&lt;/li&gt;&lt;li&gt;Fama, E. F. and K. R. French (2015). A Five-Factor Asset Pricing Model. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, Vol. 116(1), 1 – 22.&lt;/li&gt;&lt;li&gt;Lee, C. M. C., S. T. Sun, R. Wang, and R. Zhang (2018). Technological Links and Return Predictability. &lt;i&gt;Journal of Financial Economics&lt;/i&gt;, forthcoming.&lt;/li&gt;&lt;li&gt;Menzly, L. and O. Ozbas (2010). Market Segmentation and Cross-Predictability of Returns. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 65(4), 1555 – 1580.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com/&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-09-18-44781908</guid>
<pubDate>Tue, 18 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>从 CTA 趋势策略的表现看量化投资面临的挑战</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-09-11-44277671.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/44277671&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b98191a9a3d52043d231e018ccdfaac7_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文分析了 CTA 策略近年来的表现，并由此指出量化投资中面临的挑战。在经济存在下行风险的环境下，CTA 策略在未来或大有可为。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年全球经济形势动荡、新兴市场尤甚，中国股市持续下跌探底。在这种背景下，CTA （管理期货）策略的配置价值凸显。在 CTA 策略中，绝大多数都是趋势追踪策略。在下文谈到 CTA 时特指趋势类策略。&lt;/p&gt;&lt;p&gt;其实在今年上半年，CTA 的表现也仅是中规中矩。但是进入 2018 Q3 以来，随着以 PTA 和黑色系为代表的商品期货走出了一波较为流畅的持续上涨行情，加之股市的进一步下跌，此消彼长，使得 CTA 策略脱颖而出。&lt;/p&gt;&lt;p&gt;虽然就 2018 年的前八个月来看，CTA 策略的表现可圈可点（特别是实现了对股票策略的完胜）；但是我们也看到，&lt;b&gt;和几年前（2014 到 2016）CTA 的风光无限相比，其今年的表现其实逊色许多&lt;/b&gt;。此外，持续关注 CTA 策略的小伙伴一定知道，2017 年可谓是 CTA 策略的 nightmare。大部分商品在 2017 年宽幅震荡，但是 CTA 策略却没有什么作为。如此的表现也让人们对“趋势策略是做多波动率”这句话有了新的认识（这句话并不严谨）。&lt;/p&gt;&lt;p&gt;下图是智道管理期货指数（追踪国内 CTA 类私募的整体表现）自 2015 年 以来的表现。不难看出，CTA 策略在 2015 和 2016 年的表现非常优秀，但是到了 2017 年仅仅是在暑期行情中上涨了一波，其他时间都在持续阴跌；而从行业平均而言，CTA 在 2018 年获得的绝对收益也不算高（下图尚未包含今年 7 月中旬开启的一波上涨行情对 CTA 的贡献；在今年前半年，CTA 的表现是非常一般的）。&lt;b&gt;和几年前的大红大紫相比，CTA 在最近两年的表现只能算是差强人意。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0e3746ca6447392b834ecd191bbeee1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;303&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c0e3746ca6447392b834ecd191bbeee1&quot; data-watermark-src=&quot;v2-0790794bd91486f8470f5eef4e785e81&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;类似的现象也出现在海外 CTA 市场。下图展示了 Barclay CTA index 和标普 500 指数自 1980 年以来的走势。Barclay CTA index 是行业中较为认可的 CTA 表现指标，自 2010 年之后，海外的 CTA 平均表现也出现了震荡下行的格局，不如其在 2010 年之前的表现。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8a0ee90703be30442843add97d9eefa4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;388&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8a0ee90703be30442843add97d9eefa4&quot; data-watermark-src=&quot;v2-8010c461308ecd1b6aaca8b850efcedd&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这样的现象促使我们思考：&lt;b&gt;CTA（趋势）策略在这两年怎么了？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文以一个简单的双均线趋势追踪策略为例，简要分析 CTA 趋势追踪策略最近几年在我国商品期货市场上的表现，并&lt;b&gt;探讨市场的变化对量化投资带来的一些挑战。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 双均线趋势追踪策略&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;双均线是利用两个不同周期均线的关系确定开平仓信号、进行交易的策略。双均线系统由一个短周期趋势和一个长周期趋势构成。投资品的大趋势依然由长周期均线捕捉，而短周期均线起到的是择时的作用。计算长、短周期的时间窗口就是双均线策略的参数。&lt;/p&gt;&lt;p&gt;具体的双均线策略如下：&lt;/p&gt;&lt;p&gt;长、短均线的时间窗口分别为 L 和 S 个交易日。在没有头寸时，如果短均线在自下而上穿越长均线则做多；如果短均线自上而下穿越长均线则做空。当持有多头头寸时，如果短均线自上而下穿越长均线则平仓；当持有空头头寸时，如果短均线自下而上穿越长均线则平仓。为了简化讨论，不考虑止损线。&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文实证的目标是在合理的范围内遍历 S 和 L 的取值，并观察以此构建的双均线趋势策略最近几年在我国商品期货市场的表现。&lt;/b&gt;在实证中，S 的取值范围是 1 到 40，搜索步长为 1；L 的取值范围是 S + 1 到 100，搜索步长为 1。实证中使用以下来自国内三大商品交易所的 15 种商品作为投资标的，它们涵盖了有色、化工、农产品以及黑色系四大类别。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1b8eacd1dcc56e0df2fc9dfa8f1661ff_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;430&quot; data-rawheight=&quot;200&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-1b8eacd1dcc56e0df2fc9dfa8f1661ff&quot; data-watermark-src=&quot;v2-db90e774a787de468a7534165959db14&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;为了简化分析，在计算均线以及具体交易时，采用的都是上述商品的合成指数的收盘价。&lt;b&gt;如需实现更精细的实证，在回测交易时应该采用商品的主连数据而非合成指数，但是本文的简化并不定性改变趋势策略的表现。&lt;/b&gt;为了惩罚高换手率策略（S 和 L 的取值比较小、或接近时），假设每次交易的成本是万分之五。最后，回测期为 2010 年 1 月 1 日到 2018 年 9 月 4 日。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 实证分析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于每组给定的 S 和 L，依照上一节的说明构建双均线策略，就可以得到该策略在回测期内的表现，从而计算策略在每一年的收益率。由于我们想观察趋势策略每年的表现变化，因此对于每一个自然年，将不同 S 和 L 取值的策略收益率按照大小绘制成 heatmap 便可一目了然。&lt;/p&gt;&lt;p&gt;下面将逐年展示不同 S 和 L 取值下双均线策略收益率的 heatmap。考虑到我国商品期货市场早期可交易品种较少、且为了关注近几年的变化，下面的 heatmaps 从 2014 年开始。&lt;/p&gt;&lt;p&gt;下图是 2014 年不同参数 S 和 L 组合下双均线收益率的大小。图中纵坐标为 S 的取值、横坐标为 L 的取值，S 和 L 对应的小方块的热图颜色代表了收益率的大小 —— 深红代表高（正）收益、深蓝代表低（负）收益。&lt;b&gt;2014 可谓 CTA 趋势策略的大年&lt;/b&gt;，图中除了一小部分参数组合外（当 S 和 L 都小于 10 时，很少有人会选择这样的参数构建双均线系统），绝大多数 S 和 L 组合构成的双均线策略都能获得非常可观的收益。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ff4902a092e9e5ea476743d3593504b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;665&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9ff4902a092e9e5ea476743d3593504b&quot; data-watermark-src=&quot;v2-58e7da7ad3adca49122ba365d5ebce68&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;进入 2015 年，CTA 趋势策略风光不减。虽然收益率较 2014 有所下降，但绝大多数常见的 S 和 L 组合都可以获得正收益。蓝色部分集中在 S = L 的对角线附近 —— 即长均线周期 L 和短均线周期 S 取值接近 —— 从双均线策略的构建思路出发，很少有人会这么选。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a3bd0a0a6bcb1d0559632bb5e04a8608_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1203&quot; data-rawheight=&quot;665&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a3bd0a0a6bcb1d0559632bb5e04a8608&quot; data-watermark-src=&quot;v2-4e0b2fbda3f6ad3a8d59b9dacb909f3f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;再来看看 2016 年 —— 商品期货扬眉吐气的一年，以黑色系商品为代表，多数商品都迎来了大涨，这也孕育了一大波趋势行情。下图是不同 S 和 L 配对下，双均线策略在 2016 年的收益情况。很明显，蓝色的局部较前两年增多，&lt;b&gt;似乎在传递着某种隐忧 —— 是否趋势策略过热了？&lt;/b&gt;比较 2014 与 2016 的热图，那些 2014 年获得最高收益的参数似乎在 2016 年不够理想。不过好的一方面是，获得正收益的策略的收益很高，相当一部分 S 和 L 组合的策略收益高达 40% 甚至是 60% 以上。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e4018d453612e5c1b5347e7fcd00154b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1206&quot; data-rawheight=&quot;667&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e4018d453612e5c1b5347e7fcd00154b&quot; data-watermark-src=&quot;v2-b21f9ec4e0f70dd308c6a0c50f3d9fe9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;So far so good?&lt;/p&gt;&lt;p&gt;马上进入让 CTA 策略怀疑人生的 2017 年（下图）。趋势仿佛一下子消失了（至少在我们这个简单实证中）。这个大面积蓝色的热图似乎在诉说想要在 2017 年赚钱就应该和趋势对着干。抛开图中靠近 S = L 附近的那一小片红色区域对应的参数，&lt;b&gt;其他能在 2017 年勉强赚钱的参数中 S 的取值都非常小（≤ 10）。这意味着在 2017 年想要依靠趋势赚钱则需要更短的趋势。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0f2408f6a22f6cf738bb01830db6326_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1207&quot; data-rawheight=&quot;667&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d0f2408f6a22f6cf738bb01830db6326&quot; data-watermark-src=&quot;v2-1bba9a585a744f87752662bde839d40c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最后是 2018 年（截至 9 月 4 日）。2018 较 2017 年情况好转，热图中红蓝比例比较正常。但是&lt;b&gt;绝对收益并不高&lt;/b&gt;，大部分 S 和 L 的组合虽然没有亏欠，但也没挣到什么钱。&lt;b&gt;这是否意味着越来越多的策略和资金以趋势追踪的形式涌入商品期货市场，导致市场在趋势方面的非有效性下降了呢？&lt;/b&gt;值得持续关注。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f796349129e61dc01997f3b0ffb1f9e6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1194&quot; data-rawheight=&quot;668&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f796349129e61dc01997f3b0ffb1f9e6&quot; data-watermark-src=&quot;v2-26e164de702ea3adf9e716c522ce42df&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;4 带给量化投资的挑战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上一节上回顾了双均线 CTA 趋势策略在过去五年的表现，下面探讨其表现的变化带给量化投资哪些挑战。&lt;/p&gt;&lt;p&gt;回首过去 5 年，双均线策略在 2017 年的表现对量化策略的构建提出了两个挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如果策略是在 2017 年之前构建的并已经投放到实盘一段时间、且取得了不错的效果，那么这组参数在 2017 年大概率是要亏损的（个别组参数亏损的恐怕还不低），面对这样的表现，我们会问：&lt;b&gt;策略失效了吗？&lt;/b&gt;&lt;/li&gt;&lt;li&gt;站在 2017 年年末这个时点构建双均线趋势策略并用历史数据回测，如果使用 2017 年作为测试集，而使用更早的数据作为训练集，那么大概率会遇到在训练集中有效的参数在样本外完全失效。这就会落入我在&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38256574&quot;&gt;《科学回测中的大学问》&lt;/a&gt;一文中提出的&lt;b&gt;训练集和测试集之纠结。&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对中低频趋势类 CTA 策略而言，一年的亏损表现是非常正常的，我们应尽量客观的看待它。第一个挑战可以从以下几个方面鉴别亏损是源自策略失效还仅仅是暂时不佳表现：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;市场的行为是否发生了变化导致策略失效？&lt;/b&gt;一个资产产生趋势的原因是投资者的 herding 行为，因此它是跨市场的行为。市场可以暂时没有趋势或宽幅震荡，这些会造成 CTA 策略的亏损，但是趋势在今后一定会再次出现的。因此，不太可能是因为市场行为的变化导致策略失效。&lt;/li&gt;&lt;li&gt;&lt;b&gt;策略的（亏损）表现是否在预期之内？&lt;/b&gt;盈亏同源，任何一个策略都不是印钞机。通过历史回测对策略的表现分布有一个合理预期，以此判断策略最新的表现是否在预期之内。&lt;/li&gt;&lt;li&gt;&lt;b&gt;策略构建时是否存在不科学之处？&lt;/b&gt;所有策略都或多或少存在过拟合。过拟合意味着错把历史数据中的噪声当作因果关系来建模，因此回测的表现往往是实盘表现的上限，这意味着实盘外的收益较回测会更低、最大回撤较回测会更大。如果某一年的表现完全不符合预期（且排除了市场问题），那么就要检查构建策略时是否有不科学之处 —— 比如是否单一品种或者单一行业的仓位过重？或者没有充分考虑不同品种之间的相关性，导致相关性过高？（&lt;b&gt;时序动量策略喜欢相关性低的投资品&lt;/b&gt;。）&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;第二个挑战是训练集和测试集的问题。一个经科学回测过的策略应该能够捕捉训练集和测试集数据表现出来的某种市场共性。然而，&lt;b&gt;独立交易数据的匮乏&lt;/b&gt;为实现这个诉求造成了不小困难。交易数据匮乏是针对数据的可交易特征而言。历史数据虽然很长，但满足一个策略假设的样本却十分有限。&lt;/p&gt;&lt;p&gt;本文中双均线策略的结果表明，2017 年的市场中没有出现绝大多数 S 和 L 组合希望的交易特征，造成了它们的亏损。在这种情况下，如果在构建策略时硬把 2017 年当作测试集，一定会不自觉的把策略在测试集中的体现出来的新市场环境反馈到训练过程中，这等价于在整个历史数据中对策略的参数调优了。只要策略交易的市场特征有明确的业务支持而非数据挖掘的产物，那么针对它构建及优化策略参数时，是分别使用训练、测试集，还是使用所有数据来整体优化，并不重要。&lt;/p&gt;&lt;p&gt;再来看看最后一个挑战。下表展示了回测期内净值最高的五组 (S, L) 参数。顺便一提，第二组和第五组的参数很接近，S 和 L 的取值分别是 10 和 20 左右，我猜想市场上有激进的双均线交易者会采取这类的参数，不过这不是本文关注的重点。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e388798bcf364ff123aec1b5f0b0ac7c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;959&quot; data-rawheight=&quot;380&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e388798bcf364ff123aec1b5f0b0ac7c&quot; data-watermark-src=&quot;v2-696f4c144ade3ac03f04b9c791d925b0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们关注的重点是，在这些回测期内净值最高的参数中，2016 年的收益率都非常高。换句话说，&lt;b&gt;一波大行情能够对回测带来很大的不平衡因素，如果以净值作为构建策略时评价参数的标准，则会错误放大这种影响。&lt;/b&gt;因此在参数调优时，不应过度考虑策略的收益率大小，还应考察波动率、最大回撤、最长回撤时间、以及夏普率这些考虑了风险的指标。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;有挑战就有机遇。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文虽然客观的指出了趋势 CTA 策略的表现有所下滑，但是我们对它的未来绝不悲观。我只是想强调，市场在变化，策略的表现也有大小年之分。为此，一个科学的量化体系应该做到定期的检查策略，做到未雨绸缪、防患于未然。最理想的情况是策略不管在什么样的市场行情中都能够取得比较稳定的收益。这绝不容易，这需要我们不断学习、思考，调整策略以顺应市场的变化。&lt;/p&gt;&lt;p&gt;从目前的情况来看，在找到新的增长点之前，中国经济难有大的起色，根据货币宽松程度和财政实施力度，未来存在通胀和通缩两大潜在的经济风险，这对股权市场并非好的增长环境。但对于商品期货而言，因为可以同时做多和做空，不论是通胀压力还是通缩环境，CTA 策略都可以通过捕捉商品价格的趋势赚取收益，成为资本市场上博取风险收益的良好投资品种。在经济存在下行风险的环境下，CTA 策略大有可为。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-09-11-44277671</guid>
<pubDate>Tue, 11 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>用 K-means 聚类做市场状态分析：大阳线之后更危险？</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-09-07-43872533.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43872533&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-98c911a4ee0ae36e6b6712e29a506bec_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;1 无监督聚类&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;无监督学习（unsupervised learning）是机器学习中的三大类问题之一，另外两类分别为有监督学习（supervised learning）和强化学习（reinforcement learning）。&lt;/b&gt;在无监督学习问题中，对于给定的观测数据无需（也没有）已知的响应（response），而是希望分析出观测数据本身的结构。&lt;b&gt;在无监督学习中，聚类（clustering）和降维（dimension reduction）是主要的两大应用场景。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;无监督聚类的目的是将观测点按照它们的特征分成若干个子集——这些子集又称为簇（cluster）——以使得每一簇内的观测点有相似的特性，而不同簇之间的观测点有不同的特性。&lt;/b&gt;聚类分析的算法有很多；其中一个常见且有效的算法是 &lt;b&gt;K-means 聚类&lt;/b&gt;（译作 &lt;b&gt;K-均值聚类&lt;/b&gt;），其中 K 代表簇的个数。&lt;/p&gt;&lt;p&gt;今天我们就来说说 K-means 聚类，它在量化投资领域有很多应用。为了说明这一点，本文除了介绍该算法外，还会以上证指数的价格数据为例说明如何利用该算法进行市场状态监测（regime detection）。&lt;/p&gt;&lt;p&gt;本文的写作参考了 &lt;a href=&quot;http://quantstart.com&quot;&gt;quantstart.com&lt;/a&gt; 上的相关文章，特此声明并致谢（&lt;a href=&quot;https://www.quantstart.com/articles/k-means-clustering-of-daily-ohlc-bar-data&quot;&gt;K-Means Clustering of Daily OHLC Bar Data&lt;/a&gt;）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 K-means 聚类&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;K-means 聚类是一种硬聚类（hard clustering）算法。&lt;/b&gt;所谓硬聚类就是说每一个样本点都必须“非此即彼”的被分到某一个簇中。与硬聚类对应的是&lt;b&gt;软聚类（soft clustering）&lt;/b&gt;。针对每一个样本点，软聚类算法计算该点属于不同簇的概率，这是一种模糊（fuzzy）的概念，它不要求样本点和簇之间“非此即彼”的映射，而是允许样本点以不同的概率所属于不同的簇。&lt;/p&gt;&lt;p&gt;假设 n 维空间中共有 N 个观测数据。在数学上，硬聚类意味着 K 个簇将该 n 维度空间划分为 K 个互斥的区域，每个观测点属于且仅属于这 K 个簇中的某一个。令  代表簇 k，k 属于  ，不同的簇  之间满足如下关系：&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;b&gt;这两个式子说明硬聚类对空间的划分满足 MECE 原则，即 Mutually Exclusive（上面第一个式子）, Collectively Exhaustive（上面第二个式子）。&lt;/b&gt;下图是一个 K-means 聚类的示意图。图中不同的颜色代表着 10 个簇；每一个黑点代表一个观测点。每个簇内的白色叉子代表该簇的质心。这个图的意思是，如果我们有下图中的那些观测点，想采用 K-means 聚类将它们分为 10 个子集，那么就会得到如下的结果。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d91735c031e320c0cef03778f385e33_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;632&quot; data-rawheight=&quot;491&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4d91735c031e320c0cef03778f385e33&quot; data-watermark-src=&quot;v2-cda035ad30ab005a36114aa5dcc1ee2e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;下面来具体说说 K-means 算法。&lt;b&gt;该算法的目标是，对于给定的簇个数 K，找到关于样本空间的最优化分 &lt;/b&gt; &lt;b&gt;，使得簇内差异（within-cluster variation）最小。簇内差异被定义为簇内的每一个点到该簇质心的距离的平方和，因此簇内差异又称为簇内平方和（within-cluster sum of squares）。由于质心代表着均值，这也是 K-means 聚类名字中 mean 一词的含义。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在数学上，该优化问题可以表示为：&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;其中，   代表簇 k 的质心向量，它和观测点一样是 n 维向量。表达式  代表簇 k 内的第 i 个点到质心  的欧氏距离。&lt;/p&gt;&lt;p&gt;在欧几里得空间中，两个 n 维向量    和  的欧氏距离（Euclidean distance）定义如下：&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;对该优化问题求解，就可以得到最优的划分  。&lt;b&gt;不幸的是，寻找该问题的全局解（global optimum）是 NP-hard（简单的理解就是复杂度太高，让计算机硬来也算不出来）。&lt;/b&gt;所幸的是，可以使用启发式算法找到局部解（local optimum）。该启发式算法分为两部，思路如下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一步：随机的将每个观测点划分到一个簇 &lt;/b&gt;k&lt;b&gt;；&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二步：重复本步骤中的过程，直到聚类结果收敛：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;  1. 根据当前的聚类结果，计算每个簇的质心 &lt;/b&gt;  &lt;/p&gt;&lt;p&gt;&lt;b&gt;  2. 根据最新的质心，计算每个观测点到这些质心的欧氏距离，将该点重新划分到距离它最近的质心所处的簇内。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;值得一提的是，局部解十分依赖于求解过程的初始值。&lt;/b&gt;且由于不知道全局解是什么，我们没法证明局部解就是最优的。为了尽可能降低这个问题的影响，可以多次使用该启发式算法找到不同的局部解，然后从它们中间找到最小的，作为最终的解。&lt;/p&gt;&lt;p&gt;在 python 的 sklearn 包里，有实现 K-means 算法的类 sklearn.cluster.KMeans。它的输入参数中，有一个 n_init（默认值为 10），它就决定了求解局部解的次数。该算法会在求出的所有局部解中找到最优的，作为最终的解。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 K-means 聚类算法的不足&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在将 K-means 聚类应用于量化投资之前，有必要知道它的不足。具体来说，特别是针对金融数据，它有以下四点不足之处：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;金融数据信噪比太低，这意味着价格序列中有很多噪声。由于 K-means 是硬聚类，因此每个观测点都被迫分到一个簇中，因此噪声对聚类结果的影响不可忽视。&lt;/li&gt;&lt;li&gt;金融数据中存在异常值（比如黑天鹅事件造成的大跌，或者因为乌龙指造成的价格大幅震荡）。K-means 会把它们当作普通样本处理。因此这些异常值会对聚类结果产生影响。&lt;/li&gt;&lt;li&gt;K-means 对训练集的数据比较敏感。举例来说，如果将历史数据分为两份，分别进行聚类。假如我们知道这两份数据中的观测点 A 和 B 在业务上是相似的。但是，在对这两份数据分别进行聚类分析时，A 和 B 可能会被分配到特性完全不同的两簇中。这说明分类的波动会比较大，即该算法对样本数据敏感。当样本点不足的时候，这个问题尤其严重。&lt;/li&gt;&lt;li&gt;K-means 对 K 的取值（即簇的个数）非常敏感。如果 K 的取值不当，便很难从聚类的结果中得到有益的推断。下一小结的例子就说明这一点。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;b&gt;4 K 的取值至关重要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;聚类分析是为了挖掘观测数据自身的结构。&lt;b&gt;如果我们在事前从业务的角度对数据的结构有一个认知、并以此来选取簇的个数，那么聚类分析的结果将会更有意义。反之，如果我们对待分析的数据一无所知，盲目的选择K的取值，那么得到的很可能是无意义的分析结果。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面通过一个例子说明正确选取 K 值的重要性。&lt;/p&gt;&lt;p&gt;假设我们有&lt;b&gt; 3 个二元正态分布&lt;/b&gt;，它们的均值向量、协方差矩阵分别如下所示：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-08f9e5870e18189eeac44c8cff472579_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;256&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-08f9e5870e18189eeac44c8cff472579&quot; data-watermark-src=&quot;v2-1019e9b1982fa932e17ba87932310170&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;使用这 3 个二元正态分布在二维空间内各随机生成 100 个观测点（即一共有 300 个点），然后使用 K-means 聚类对他们进行划分。由于在这个例子中，我们知道这些点来自 3 个不同的二元正态分布，因此簇数 K 的正确取值应该为 3。为了比较，我们同时考虑 K = 4 的情况。下图展示了 K = 3 和 K = 4 时的 K-means 聚类结果。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21fb2155bac7c57fe27d4208fe681c97_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;558&quot; data-rawheight=&quot;856&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-21fb2155bac7c57fe27d4208fe681c97&quot; data-watermark-src=&quot;v2-5fb19942d7a05cbe24eb50d4564cdab4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当 K = 3 时，这 300 个观测点被分为了 3 簇。它们的质心基本位于 (2, 6)、(8, 7) 以及 (6, 12) 这三个点附近——即这三个二元正态分布的均值点。由于 K = 3 和这些点的内在结构吻合（因为在这个例子中我们知道这些点是来自这 3 个不同的二元正态分布！），所以聚类挖掘出了有效的信息。&lt;/p&gt;&lt;p&gt;当 K = 4 时，这 300 个观测点被分为了 4 簇。比较两个聚类结果可知，来自于均值向量 (2, 6)、协方差矩阵 (2.5, 0; 0, 3.5) 这个二元正态分布的样本点被进一步细分为两个不同的簇（这是因为 K = 4，因此算法必须把所有点分为 4 簇！）。基于这样的结果，我们会认为这两簇是不同的。但是在这里例子中，它们事实上来自同一个分布。&lt;/p&gt;&lt;p&gt;这个例子说明，&lt;b&gt;当 K 的取值不当时，我们有可能从聚类的结果中得出错误的推断。因此，在使用 K-means 聚类之前，如能对待分析的数据有一定的了解，并能从业务的角度判断出合适的簇数 K，将大大提高聚类分析结果的可靠性。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 用 K-means 聚类进行市场状态监测&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节使用一个简单的例子将 K-means 聚类应用于量化投资领域。我们使用上证指数日线的开盘、最高、最低、收盘价（即 OHLC 数据）来描述市场所处的（未知）状态，通过聚类将不同的交易日划分到不同的市场状态中，并在聚类的结果上进行进一步的推断。交易日的时间跨度为过去 5 年（本文写作于 2017 年 7 月，因此实证结果仅到写作之前）。&lt;/p&gt;&lt;p&gt;在这样的设定下，每一个交易日的 OHLC 数据就是一个观测点。&lt;b&gt;为了不同的交易日的价格数据有可比性，有必要进行标准化处理。&lt;/b&gt;为此，使用每日的开盘价对其他三个价格进行标准化，得到 H/O，L/O，C/O，即最高价和开盘价之比、最低价和开盘价之比、以及收盘价和开盘价之比。标准化后，每一个观测点实际上是一个三维向量。&lt;/p&gt;&lt;p&gt;接下来就是确定簇数 K 的取值。在本例中，每一簇便代表了市场的一种状态。从这个角度出发，我们假设 K 的取值为 4 —— 即市场存在 4 种状态。&lt;/p&gt;&lt;p&gt;这里取 4 并没有什么特别的含义，作为读者的你也尽可以发挥想象来解读这个取值。从聚类的结果来看，由于我们是用的是标准化后的 OHLC 数据，这 4 类市场状态对应的基本上是大阳线、大阴线、小阳线和小阴线。&lt;/p&gt;&lt;p&gt;由于观测点都是三维的，因此可以方便的在三维空间画出聚类的结果。以不同颜色表示不同的簇，这 4 簇的聚类结果如下图所示。大部分观测点都围绕在 (1.0, 1.0, 1.0) 附近，它们构成了两簇 —— 小阳线和小阴线；少量的观测点在远离 (1.0, 1.0, 1.0) 的位置，构成另外两簇 —— 大阳线和大阴线。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fa62349d025610cc5447c5f4a4731321_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;982&quot; data-rawheight=&quot;730&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fa62349d025610cc5447c5f4a4731321&quot; data-watermark-src=&quot;v2-931c1e1d1164085712d901d3ded2afe2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如果我们按照簇把每个交易日的 K 线画出来，则可以更清晰的看出簇与簇之间交易日 K 的差异（下图）。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5a35f5c8f587c9652d5537fd90607162_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1206&quot; data-rawheight=&quot;540&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5a35f5c8f587c9652d5537fd90607162&quot; data-watermark-src=&quot;v2-31799ba1b1866344537dd3253e70b076&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;从这个图中可以看出：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一簇中的 K 线大部分都是&lt;b&gt;短的绿色线&lt;/b&gt;，说明这一簇中以&lt;b&gt;小阴线&lt;/b&gt;为主；&lt;/li&gt;&lt;li&gt;第二簇中的 K 线大部分都是&lt;b&gt;长的红色线&lt;/b&gt;，说明这一簇中以&lt;b&gt;大阳线&lt;/b&gt;为主；&lt;/li&gt;&lt;li&gt;第三簇中的 K 线大部分都是&lt;b&gt;长的绿色线&lt;/b&gt;，说明这一簇中以&lt;b&gt;大阴线&lt;/b&gt;为主；&lt;/li&gt;&lt;li&gt;第四簇中的 K 线大部分都是&lt;b&gt;短的红色线&lt;/b&gt;，说明这一簇中以&lt;b&gt;小阳线&lt;/b&gt;为主。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;不过这个结果也清晰的说明，我们的样本是严重的不均衡的，第四簇小阳线内的观测点远超其他三簇。样本严重不均衡对所有的机器学习算法都是一个挑战。&lt;/b&gt;我们会在下面再谈到这个问题。&lt;/p&gt;&lt;p&gt;如果按照时间顺序把每个交易日的市场状态画出来，则得到下图。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-78aa6b5190fc4e5eb54010fef8d71c1b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1075&quot; data-rawheight=&quot;491&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-78aa6b5190fc4e5eb54010fef8d71c1b&quot; data-watermark-src=&quot;v2-5315799e8a1db85521f6f7b3ba2f01a6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们分几个不同的时期来仔细看看。&lt;/p&gt;&lt;p&gt;在 2014 年底牛市启动之前，市场的状态受第一簇（小阴线）主宰，表现出来一个慢慢阴跌的态势。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2a7a4def3c779b3d1c9b7e528229431_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1207&quot; data-rawheight=&quot;544&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a2a7a4def3c779b3d1c9b7e528229431&quot; data-watermark-src=&quot;v2-ccefc14de64937854709b5fdc3aa1846&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在 2014 年底到 2015 年底这个牛熊周期中，在牛市中市场状态由第二簇（大阳线）主宰，而在熊市中市场状态由第三簇（大阴线）主宰。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74cd0378b49832b65782aa3c80edfd95_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1207&quot; data-rawheight=&quot;546&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-74cd0378b49832b65782aa3c80edfd95&quot; data-watermark-src=&quot;v2-61767d920f97a43a08812d948d992f73&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最后，从 2016 年二季度开始，市场状态由第四簇（小阳线）主宰，呈现出慢牛的走势。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ec07847f0ffeec5fc2cb45940d6e8ee0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1205&quot; data-rawheight=&quot;550&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ec07847f0ffeec5fc2cb45940d6e8ee0&quot; data-watermark-src=&quot;v2-a3b1ab16a66b03762a6ff2b770e98d48&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在我们有了每个交易日的状态之后，便可以进行一系列的数据分析，得到进一步的推论。&lt;b&gt;这其中最有效的应该是求出市场状态的转移矩阵，它告诉我们在当前的状态 &lt;/b&gt;&lt;b&gt; 下，下一个交易日市场将处于状态 &lt;/b&gt;  &lt;b&gt; 的条件概率。&lt;/b&gt;这对策略择时和风控会有很大帮助。&lt;/p&gt;&lt;p&gt;基于上面的聚类结果，得到市场状态的转移矩阵如下。其中第    行第    列的数值表示在今天的市场状态为    的条件下，明天市场状态为    的条件概率。对于每一个   ，明天最有可能的状态    被用红色粗体表示出来。这个结果说明，除了大阴线外，在其他三种状态下，下一个交易日最有可能出现的都是小阳线，这和前面提到的样本严重不均衡密切相关。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-55927d112ad5ca3f3f2bb8019bbf610f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;629&quot; data-rawheight=&quot;302&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-55927d112ad5ca3f3f2bb8019bbf610f&quot; data-watermark-src=&quot;v2-1ba8e2074208bcef67563961a849e9d3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;本文的标题提出一个问题“大阳线之后更危险？”。这个问题可以通过这个状态转移矩阵回答。如果今天是大阳线，则下一个交易日是大阴线的&lt;b&gt;条件概率&lt;/b&gt;为 4.2%（第二行、第三列的数值）。让我们再来看看大阴线出现的&lt;b&gt;非条件概率&lt;/b&gt;。在回测的 1207 个交易日中，有 30 个交易日属于第三簇，因此大阴线的非条件概率仅为 2.5%，小于前面这个 4.2% 的条件概率。基于这个结果，我们得出“大阳线之后更危险”的推论。&lt;b&gt;这个结论事实上是符合人的认知的。这是因为无论大涨还是大跌，都意味着波动率的上升；而波动率的上升意味着风险的加大；风险加大意味着大跌的可能性增大。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;假如上述聚类分析的结果是有效的，那么使用这个转移矩阵可以回答很多类似的问题、得到很多有益的推论。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;样本不足和样本不均衡是金融数据的两大特色。&lt;/b&gt;这些对于 K-means 聚类算法在量化投资中的应用提出了严峻的挑战。对于待分析的数据，“如何有效的选取特征？”、“适合的簇数 K 是多少？”，这些都属于算法本身之外的问题，但它们又对算法的分析结果至关重要。比如在上面的例子中，使用 OHLC 数据描述市场状态是否恰当？K = 4 是否有足够的依据？要回答这些问题，自然需要更多的研究。&lt;/p&gt;&lt;p&gt;任何机器学习算法都仅仅是工具。在金融领域，核心的问题不是工具的使用，而是从对市场的理解。唯有理解了市场，才能选择正确的工具。掌握一门算法并不需要很长的时间；但要想深刻理解市场则需要时间的积淀。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-09-07-43872533</guid>
<pubDate>Fri, 07 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>那些年，那些错</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-09-04-43736197.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43736197&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-76a9f52e6363e8489c05a507ee9ef150_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;投资之父 Benjamin Graham 教导我们说“投资者最大的问题、以及他最大的敌人，正是他自己”。本文就来聊聊投资者常犯的错误。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 South Sea Bubble&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;1687 年，著名的物理学家 Isaac Newton（牛顿）在《自然哲学的数学原理》中提出了大名鼎鼎的三大运动定律和万有引力定律。三大运动定律的第一条便是惯性定律（即物体维持运动状态不变），而万有引力则是关于重力。然而，在三十年后的南海泡沫事件中，正是“惯性”（对应 price momentum）和“重力”（对应 market crash）让牛顿爵士亏的血本无归。&lt;/p&gt;&lt;p&gt;South Sea Bubble（南海泡沫事件，以下介绍参考 Wikipedia）是英国在 1720 年发生的经济泡沫，与同年的密西西比泡沫事件及 1637 年的郁金香狂热并称欧洲早期三大经济泡沫。&lt;b&gt;“经济泡沫”一词正是源于南海泡沫事件。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;事件起因源于南海公司（South Sea Company）。该公司于 1711 年西班牙王位继承战争仍然进行时创立，表面上是专营英国与南美洲等地贸易的特许公司，但实际是协助政府融资的私人机构，分担政府因战争而欠下的债务。&lt;/p&gt;&lt;p&gt;南海公司依靠夸大业务前景及进行舞弊从而获得外界看好。1720 年，南海公司更是通过贿赂政府，向国会推出以南海股票换取国债的计划，促使南海公司股票大受追捧。1720 年初，其股价由原本约 120 英镑急升至同年七月的 1000 英镑，&lt;b&gt;全民疯狂炒股&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;然而，市场上随即出现不少“泡沫公司”混水摸鱼，试图趁南海股价上升的同时分一杯羹。为监管这些不法公司的出现，英国国会于 1720 年六月通过 Bubble Act（《泡沫法令》）并于同年八月实施，炒股热潮随之减退，并连带触发南海公司股价急挫，在一个月内暴跌到 200 英镑以下（下图为同期公司股票走势图）。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d1304919aa2b3149e711d46c3ca3808d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;578&quot; data-rawheight=&quot;460&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d1304919aa2b3149e711d46c3ca3808d&quot; data-watermark-src=&quot;v2-e8147cf179bc26aef39d68bc96cfb8e3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;回过头来看，人们不禁会问，谁会傻到买在山尖上？但身处泡沫中，即便理性睿智如牛顿爵士，依然无法安然抽身。下图显示了牛顿在南海泡沫事件中购买股票的情况。他深谙自己提出的动量（大趋势），却忘记了重力（最终仍会要跌落人间），导致血本无归、黯然离场。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2b626b1e55e0dce5a86ee0eef226b033_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;544&quot; data-rawheight=&quot;357&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2b626b1e55e0dce5a86ee0eef226b033&quot; data-watermark-src=&quot;v2-247df87d79a30d481ad157b59f566e77&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;泡沫面前，人人平等。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这样的泡沫多么似曾相识？类似的例子还有很多 —— 美国 2000 年前后的 .com 泡沫，日本的房地产泡沫（鼎盛时东京皇宫的那块地价超过加拿大全国的地价），美国的次贷危机，大 A 股 2015 年的泡沫，前不久的比特币泡沫，举不胜举。&lt;/p&gt;&lt;p&gt;但是泡沫过后人们是否真的吃一堑、长一智？继续往下看。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 “明知故犯”的泡沫&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;根据有效市场假说，价格是投资品基本面信息正确反应。因此有人会说“如果价格受到那个时点的基本面的支撑，那便不是泡沫。而基本面反映的内在价值是很难衡量的，因此说泡沫其实也是很难证实的”。&lt;/p&gt;&lt;p&gt;下面就来看看在已知投资品内在价值的前提下，泡沫是否仍然会发生。&lt;/p&gt;&lt;p&gt;在一堂题为 Behavioral Finance and Investment Strategy 的公开课上，来自 Berkeley Hass 商学院的 Greg LaBlanc 介绍了一个泡沫实验（它由 Gaginalp et al. 2001 提出，本文中介绍的模拟交易结果来自 Berkeley 的本科生）。&lt;/p&gt;&lt;p&gt;该实验的设定如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;某资产的投资期限为 15 期（15 期后，资产的内在价值为 0）；&lt;/li&gt;&lt;li&gt;在每一期，该资产向其拥有者发放股息，股息是一个随机变量，每期股息的期望是 24 美元；&lt;/li&gt;&lt;li&gt;实验开始前，为每位参与者发放一定数量的资金和一定数量的资产；&lt;/li&gt;&lt;li&gt;实验开始后，参与者通过模拟交易系统来进行 bid 和 ask 操作，进行资产的买卖。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;由实验的前两点（期数有限、股息期望已知）可计算出该资产的内在价值。&lt;b&gt;其内在价值等于剩余投资期限内全部股息的期望之和。&lt;/b&gt;举例来说，在第一期交易前，它有 15 期可以交易，每期的期望股息是 24 元，因此它的内在价值是 360（= 24 × 15）元；在第二期交易前，它仅剩 14 期可交易，因此内在价值变为 336（= 24 × 14）元，以此类推。&lt;/p&gt;&lt;p&gt;由于内在价值可知，因此我们预期在模拟交易中不应产生泡沫，交易价格应该和资产的内在价值非常接近。然而，交易结果令人嗔目结舌。下图显示了第一次实验中，这些交易者每一期的交易价格（旁边的数字是交易量）。例如，第一期的成交价约为 75 元（交易量为 7），远远低于资产的内在价值（360 元）。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-230a02c4d53b9a857b73375e77214e29_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;846&quot; data-rawheight=&quot;486&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-230a02c4d53b9a857b73375e77214e29&quot; data-watermark-src=&quot;v2-d4518c21fe3860b9c724ba359c40654d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;随着交易的进行，价格逐渐上升，但仍然低于对应期的基本面价值。终于，在第 6 期的时候，交易价格和基本面价值基本一致。然而，从第 7 期开始，神奇的事情出现了 —— &lt;b&gt;泡沫发生了&lt;/b&gt;。在之后的几期里，狂欢远远没有结束，资产的交易价格持续增长并远超其已知的基本面价值。最终，参与者渐渐意识到资产的剩余内在价值远远不值交易的价格，因此争先出场，导致价格迅速下降，泡沫破灭。&lt;/p&gt;&lt;p&gt;为什么在明知内在价值的前提下依然会产生泡沫呢？是因为这些参与者没有经验吗？为了验证这一点，这些参与者进行了第二次实验。第二次实验中各期的交易价格如下图 X 所示（为了对比，保留了第一次交易的价格序列）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在第二次实验中，依然出现了泡沫。&lt;/b&gt;不过，&lt;b&gt;由于参与者有了一些经验，这次实验中的泡沫比第一次的泡沫在强度（交易价格和基本面价格之差）和持续时间上都减弱了&lt;/b&gt;。这说明经验的提升能够在一定程度上阻止&lt;b&gt;同一批&lt;/b&gt;参与者产生泡沫，这些参与者变得更理性了。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-697a97540d5f44609a078996afd11f75_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;976&quot; data-rawheight=&quot;525&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-697a97540d5f44609a078996afd11f75&quot; data-watermark-src=&quot;v2-a94d1916d7fc66bdb91088cd66b54dd0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最终，这批参与者又进行了第三次实验（下图中圆圈虚线表示）。&lt;b&gt;在这次实验中，完全没有产生泡沫，交易价格在所有 15 期都和基本面价值非常接近。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-00c039df653e28b81c51d5814c9b8244_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;985&quot; data-rawheight=&quot;522&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-00c039df653e28b81c51d5814c9b8244&quot; data-watermark-src=&quot;v2-520b9aef95a2e7764e430e4c2c897b5a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上面的实验结果说明，当&lt;b&gt;同一批&lt;/b&gt;参与者反复经历了&lt;b&gt;同一个&lt;/b&gt;实验、积累了经验后，泡沫消失了。在泡沫面前，最重要的是经验。&lt;/p&gt;&lt;p&gt;上面这句话中有两个非常强的修饰词：&lt;b&gt;经验的建立指的是“同一批”交易者对于“同一个”资产。&lt;/b&gt;在这种情况下，泡沫便不会再发生。但是，如果这两个条件不满足，泡沫依然会发生。在实验中，学者们观察到了如下现象：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如果实验参与者换了一拨人，或者是两拨独立进行过该实验的人被混在一起构成新的交易者进行实验，仍然会出现泡沫；&lt;/li&gt;&lt;li&gt;改变资产的设定（比如投资期限从 15 期改成 20 期、或者改变每期股息的分布）也会造成新的泡沫。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;这样的结果说明在真实的市场中，面对基本面价值难以评估的资产和一代又一代不同的投资者，经验的力量也是渺小的，泡沫注定会再次发生。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那些经历了 .com 泡沫的投资者也许会变得小心并抵触股票投资，但是它们在房地产泡沫和比特币泡沫之前仍然无法免疫。这大概就是人性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 股权溢价之谜&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;聊完了泡沫，我们在聊聊另外一个投资中的大敌：&lt;b&gt;短视损失厌恶（myopic loss aversion）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;1926 年以来，美国股市每年扣除通胀后的平均回报率约为 7%，而政府债券的回报率不足 1%。面对如此巨大的回报率之差，债券投资者的数量却远超股票投资者，造成&lt;b&gt;股权溢价之谜（equity premium puzzle）&lt;/b&gt;。如果将股票的收益率和标准差套入到效用函数中，上述现象的“合理”解释只能是投资者的风险厌恶水平非常高，难以令人信服。&lt;/p&gt;&lt;p&gt;Richard Thaler （Benartzi and Thaler 1995）使用行为经济学先驱 Daniel Kahneman 和 Amos Tversky 提出的 &lt;b&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38526672&quot;&gt;Prospect Theory&lt;/a&gt;（译为前景理论或展望理论）&lt;/b&gt;和他的&lt;b&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38610013&quot;&gt;心理账户理论（Mental Accounting）&lt;/a&gt;&lt;/b&gt;解释了这一现象。&lt;/p&gt;&lt;p&gt;&lt;b&gt;投资者厌恶损失&lt;/b&gt;，且 Prospect Theory 的价值函数指出损失给人造成的效用要强于收益带来的效用。&lt;b&gt;对于投资者来说，亏损的负效用（痛苦）通常是收益的正效用（喜悦）的两倍。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b17ba01cd9ee7fe1e631b7fae9e098d0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;818&quot; data-rawheight=&quot;560&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b17ba01cd9ee7fe1e631b7fae9e098d0&quot; data-watermark-src=&quot;v2-3c28fb2f03b18005d032a5fd60559638&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;此外，心理账户理论的第三部分是关于评估账户的频率。&lt;b&gt;不成熟的、一般的、大多数的投资者倾向于频繁（如果不是每时每刻，那至少也是每天）的查看自己的股票是赚了还是亏了。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;然而股票的短期走势充满着随机性，股价会上下波动。在这种情况下，投资者频繁查看自己的股票账户，上涨只带来一分的快乐，而下跌造成两倍的伤痛，这就造成了短视损失厌恶：&lt;/p&gt;&lt;p&gt;&lt;b&gt;损失厌恶 + 频繁评估心理账户 = 短视损失厌恶&lt;/b&gt;&lt;/p&gt;&lt;p&gt;资产的波动越大，频繁查看账户带来的心理压力越大，这放大了股票的风险给人们的感受。换句话说，这使得它们更加偏好避险资产 —— 债券。这就是为什么那么多人去投资债券，从而解释了股权溢价之谜。&lt;/p&gt;&lt;p&gt;为了证明短视损失厌恶可以解释股权溢价之谜，Thaler et al. (1997) 报告了一系列实验结果。不同的投资者被要求按照不同的频率（每年 8 次、每年 1 次，每 5 年 1 次）在股票和债券之间进行资产配置。调仓频率低的投资者（即每年 1 次和每 5 年 1 次的）将 67% 的资金配置在股票上，33% 的资金配置于债券；而调仓频率高的投资者（每年 8 次）仅仅将 41% 的资金配置在股票上，而将 59% 的资金配置于债券。&lt;b&gt;调仓频率高的投资者容易受到股票高波动以及近期亏损的影响，出现短视损失厌恶。&lt;/b&gt;即便他们知道，长期来看股票的收益会战胜债券，但是仍然陷入短视损失厌恶的误区。在他们的心理账户中独立看待每一次调仓决策，而非在一个更长的时间尺度下把所有决策一起考虑，这导致了这些投资者将更多的资金配置在债券上。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 投资者的无效择时&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在投资中普遍存在的另一个 puzzle 是&lt;b&gt;投资者购买股票或者基金获得的回报往往不如该股票和基金本身的回报高&lt;/b&gt;（Dichev 2007）。&lt;/p&gt;&lt;p&gt;以基金为例，一个基金的回报率（比如年化收益率）是按&lt;b&gt;时间加权（time-weighted）&lt;/b&gt;计算的。比如我们可以计算一个基金过去 5 年或者 10 年的年化收益率。然而，&lt;b&gt;一个投资该基金的投资者获得的收益率则和他的资金何时流入、何时流出、投入量、赎回量等因素有关。&lt;/b&gt;因此，一般称一个投资者的回报率是&lt;b&gt;资金加权的（dollar-weighted）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;我们知道基金的运行有高峰和低谷（回撤期）。如果投资者都是聪明的且能够准确择时，那么他们会在基金表现不好的时候买入，而在基金表现好的时候赎回，这样做能够使投资者获得超过基金本身的回报率。然而结果恰恰相反。&lt;/p&gt;&lt;p&gt;下图展示了在一个主动型公募基金和一个被动的指数基金中，基金本身的收益率（total return）和投资者的收益率（investor return）的对比情况。不难看出，&lt;b&gt;投资期限越长，投资者实际获得的收益率和基金的收益率相差的越多。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-adfd4cd6dce68aa60bf3f74b029f8dcb_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;720&quot; data-rawheight=&quot;564&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-adfd4cd6dce68aa60bf3f74b029f8dcb&quot; data-watermark-src=&quot;v2-fd46ad68ca4e6a78a2b77062cf6a9da0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这个结果说明，&lt;b&gt;投资者们在基金上的择时通常是错误的：由于 performance chasing 而在基金近期表现好的时候买入；由于恐慌在基金表现不好的时候赎回。&lt;/b&gt;高买低卖，造成亏损。跨期越长，犯错的次数越多，因此实际获得的回报越低。&lt;/p&gt;&lt;p&gt;在挑选基金时，真正聪明的投资者考察的应该是一个基金的团队能力和投资理念、基金如何防控风险等核心要素，而非过分注重短期的表现。当然，鉴别这些核心要素并不容易，这使得近期表现这种看得见的指标格外突出，而市面上流行的各大榜单自然也是火上浇了一把油。回想一下，各类型的基金，是否都是在业绩好的时候猛做一波规模呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;同样的问题也出现在因子择时上。&lt;/b&gt;在使用因子选股时，人们倾向于通过因子近期的表现来配置因子。但是，Arnott et al. (2016) 指出因子收益率中包括很大的&lt;b&gt;估值溢价&lt;/b&gt;。他们把由估值上升带来的因子收益率称为环境 α。&lt;b&gt;当剔除了因子估值的变化后，很多因子竟然并不能获得超额收益。&lt;/b&gt;Arnott et al. (2017) 的研究发现&lt;b&gt;选择那些估值处于历史低位的因子（即过去表现的不怎么好的因子）比选择那些过去一段时间过热的因子，能够在未来获得更高的收益。&lt;/b&gt;这解释了为什么按照近期表现来配置因子效果并不好。&lt;/p&gt;&lt;p&gt;世界上最大的公募基金 Vanguard 在介绍它们挑选管理人的时候曾说，对于它们认可的管理人，&lt;b&gt;如果它最近的表现不好，Vanguard 的做法是增加配置的资金而非减少！&lt;/b&gt;这背后的深意是规避本小节提到的投资者常犯的错误择时导致 dollar-weighted 回报率低于 time-weighted 回报率。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;投资之父 Benjamin Graham 曾指出：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;The investor’s chief problem – and even his worst enemy – is likely to be himself.&lt;/i&gt;&lt;br&gt;&lt;i&gt;译：投资者最大的问题、以及他最大的敌人，正是他自己。&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;本文简单介绍了一些投资者常犯的错误，希望能引发各位的思考（另外，从认知偏差角度来说，投资中还有很多其他常见的错误，以后我们找机会再聊）。在这些错误面前，人人平等（想想牛顿）；&lt;b&gt;我们能够做的就是反人性的克制自己，坚决按照策略执行。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Renaissance Technologies 的 James Simons 曾说：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;We slavishly follow the model. You do whatever it says no matter how smart or dumb you think it is.&lt;/i&gt;&lt;br&gt;&lt;i&gt;译：我们完全忠实于模型；不论我们觉着它聪明还是愚蠢，都坚决执行。&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;Investing is simple, but not easy.&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Arnott, R. D., N. Beck, V. Kalesnik, and J. West (2016). How Can &#39;Smart Beta&#39; Go Horribly Wrong? &lt;i&gt;SSRN: https://ssrn.com/abstract=3040949.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;Arnott, R. D., N. Beck, V. Kalesnik (2017). Forecasting Factor and Smart Beta Returns (Hint: History Is Worse than Useless). &lt;i&gt;SSRN: https://ssrn.com/abstract=3040953.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;Benartzi, S. and R. H. Thaler (1995). Myopic Loss Aversion and the Equity Premium Puzzle. &lt;i&gt;The Quarterly Journal of Economics&lt;/i&gt;, Vol. 110(1), 73 – 92.&lt;/li&gt;&lt;li&gt;Caginalp, G., D. Porter, and V. Smith (2001). Financial Bubbles: Excess Cash, Momentum, and Incomplete Information. &lt;i&gt;Journal of Psychology and Financial Markets&lt;/i&gt;, Vol. 2(2), 80 – 99.&lt;/li&gt;&lt;li&gt;Dichev, I. (2007). What are stock investors’ actual historical returns? Evidence from dollar-weighted returns. &lt;i&gt;American Economic Review&lt;/i&gt;, Vol. 97, 386 – 401.&lt;/li&gt;&lt;li&gt;Thaler, R. H., A. Tversky, D. Kahneman and A. Schwartz (1997). The effect of myopia and loss aversion on risk taking: an experimental test. &lt;i&gt;The Quarterly Journal of Economics&lt;/i&gt;, Vol. 122(2), 647 – 661.&lt;/li&gt;&lt;li&gt;http://www.mymoneyblog.com/morningstar-investor-returns-another-reason-why-chasing-past-performance-is-bad.html&lt;/li&gt;&lt;li&gt;https://en.wikipedia.org/wiki/South_Sea_Company&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ERDEozGpV74&quot;&gt;https://www.youtube.com/watch?v=ERDEozGpV74&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-09-04-43736197</guid>
<pubDate>Tue, 04 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>多因子如何玩转加密币？</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-09-02-43545668.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43545668&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-75a1a0a253f1ca4e4ac8bc33dc75573a_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;写在前面&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上周休假去了，公众号和知乎专栏没有更新，下周复工。今天先放一篇之前写的关于加密币的老文。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;今天要谈到的是&lt;b&gt;用多因子的方法投资加密币。&lt;/b&gt;你没听错，用的手段是多因子，作用的对象不是选股而是选加密币！多因子是在股票市场广为使用的选股方法，经过几十年的发展已经变得非常成熟，常见的能够获得超额收益的风险因子（如动量、价值、质量等）早已深入人心（需要背景知识的小伙伴可以参考&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38281562&quot;&gt;《因子投资 —— “被动的”主动投资》&lt;/a&gt;）。而以比特币为代表的&lt;b&gt;数字加密货币（cryptocurrency，简称加密币）&lt;/b&gt;则是一个新兴玩意儿。虽然比特币已经存在了很多年，但其近两年的疯狂上涨以及区块链概念被大肆炒作让比特币以及各种其他加密币真正走进了大众视野。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c302aecd321aa18ed35a9ff0544d6da1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;785&quot; data-rawheight=&quot;357&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c302aecd321aa18ed35a9ff0544d6da1&quot; data-watermark-src=&quot;v2-534960efd4966d684a01f7ef0a167b16&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;成熟、有效的风险因子和非常年轻的加密币市场能碰撞出怎样的火花？加密币市场是否也像股市一样存在可以获取超额收益的风险因子？近期，Hubrich (2017) 这篇文章走进了我们的视野。该文作者使用股票中常见的动量（Momentum）、价值（Value）、以及 Carry 这三个因子对 11 种加密币进行了分析，即&lt;b&gt;多因子选加密币&lt;/b&gt;，说明了这些因子的有效性，读来让人颇为耳目一新。&lt;/p&gt;&lt;p&gt;本文对 Hubrich (2017) 的发现做一个简单的梳理。&lt;/p&gt;&lt;p&gt;在开始之前我想先唠点别的，即我们应该如何客观的看待加密币的这股热潮。面对如此火爆的加密币，市场上大致有三种人：信徒、鄙视者和吃瓜群众。信徒和鄙视者都希望通过自身的言行来影响吃瓜群众对加密币的看法。从自身的利益来看，鄙视者的动机更强。这是因为即便无法说服吃瓜群众，这些靠着加密币大赚特赚的信徒们的收益也不会有多少影响。而对于鄙视者来说，他们无法享受到加密币带来的财富，那就只能希望通过它来获得名望；鄙视者们自认为洞悉了加密币背后的陷阱和虚幻，希望泡沫幻灭以证明他们的先见之明，像拯救苍生的布道高人一样成为吃瓜群众眼中“神一样的存在”。&lt;/p&gt;&lt;p&gt;这两类人大概都过激了。加密币到底是天使还是魔鬼，恐怕现在没人敢下结论。我们能做的是持有开放的心态，尽量客观的看待它，“存在即合理”。Hubrich (2017) 对加密币的看法是：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;我们应该像动物学家一样来看待这种新的金融物种。我们不知道加密币最终会变成一种入侵性很强的害虫还是一种对生态系统的有益补充，但是我们一定可以通过研究它来更深入的理解自然法则。&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;使用风险因子能够获得超额收益就如同金融世界中的自然法则。因此，我们关心的问题是，加密币市场是否能够适应这种法则，或者对这一法则提出新的挑战。&lt;/p&gt;&lt;p&gt;跑偏的有点多，下面言归正传。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 了解加密币市场&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;首先来通过一组数据了解一下加密币市场。在 Hubrich (2017) 的研究中，作者考虑了 11 种加密币：BTC，DASH，DCR，DOGE，ETC，ETH，LTC，PIVX，XEM，XMR 以及 ZEC。每个币种的数据历史、周收益率统计量（考虑到加密币高波动的特性，作者使用周频作为选币、再平衡投资组合的频率）、以及市场统计量汇总于下表。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fa9b1b453c5f689b5a8b86eb2fcd7517_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;956&quot; data-rawheight=&quot;520&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fa9b1b453c5f689b5a8b86eb2fcd7517&quot; data-watermark-src=&quot;v2-f6882e1495275df89468965a6d877289&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们以比特币（BTC）为例解释一下市场统计量。在 Hubrich 分析时，比特币的最新市值约为 70 亿美元，其价格为 4226.06 美元（远低于今天的价格），已挖出的数量约为 1660 万（依照协议，总共为 2100 万）。每天在全世界所有&lt;b&gt;区块上&lt;/b&gt;交易的比特币交易额的（90 日）均值超过 60 亿美元（平均交易次数超过 24 万次）。注意，这个交易额和交易量&lt;b&gt;不包括&lt;/b&gt;在交易所交易的比特币。这些数据说明加密币（特别是比特币、以太币这种“大币种”）每天在区块上的交易相当活跃。最后，每天新挖出来的比特币占已有比特币数量的 0.012%。&lt;/p&gt;&lt;p&gt;在下一节可以看到，作者之所以关心加密币在区块上的交易量以及每天新挖出来的加密币数量占比，是因为他要以此来定义风险因子。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 定义风险因子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Hubrich 考虑了三个因子：&lt;b&gt;Momentum&lt;/b&gt;、&lt;b&gt;Value&lt;/b&gt; 以及 &lt;b&gt;Carry&lt;/b&gt;。至于为什么考虑这三个因子？这里先卖个关子，我们会在本小节的最后说明。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这三个因子都可以在时序上考虑，也可以在截面上考虑。&lt;/b&gt;作者分别考虑了这两种情况，构建了不同的投资组合说明了因子的有效性。本节我们先来看看这些因子是如何定义的；下一节会说明如何在分别从时序和截面的角度使用这些因子来选加密币。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.1 Momentum 因子&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Momentum 即动量因子，是各大类市场中最持久也是最有效的一个因子（当然前提是选对计算动量和持有的周期）。动量因子说的是，前期涨的好的未来还会涨的好；前期跌的多的未来还会跌得多。在构建动量因子的时候，Hubrich 使用了过去 7 天的收益率作为动量因子。&lt;/p&gt;&lt;p&gt;加密币的交易是 24/7 的，一个星期内的 7 天都是交易日，因此在计算周收益率的时候，不好说选择什么时候为起点就更好。在实际计算因子以及构建投资组合时，Hubrich 考虑了以周一到周日这 7 天分别为计算周收益率起点的 7 种情况，并把它们的均值作为因子有效性检验的结果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.2 Value 因子&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Value 即价值因子，它和动量因子的地位相当，也是一个古老而有效的因子。世界上最著名的量化对冲基金 AQR 曾在顶级期刊 Journal of Finance 上发表过一篇题为“Value and Momentum Everywhere（无处不在的价值和动量）”的文章（Asness et al. 2013），足见 Value 因子的重要性。&lt;/p&gt;&lt;p&gt;Value 因子说的是任何一个金融工具都有根据其基本面得到的 fair value，当它的市场价格（market value）高于 fair value 时它的价值被高估；当它的市场价格低于 fair value 时它的价值被低估。我们应该购买价值被低估的（便宜的）投资品而绕开价值被高估的（昂贵的）投资品。&lt;/p&gt;&lt;p&gt;受此影响，Hubrich 也在对加密币的因子研究中试图引入价值因子。但是，很多金融界的 big names 都直言不讳的说加密币就是个泡沫、没有基本面价值。这就尴尬了，没有基本面价值，又怎么来定义价值因子呢？&lt;/p&gt;&lt;p&gt;别担心，学术界最缺乏的就不是创造力。Hubrich 提出了&lt;b&gt;加密币的“基本面”价值体现在了它们的交易价值上。&lt;/b&gt;还记得本文第二节那个表中，我们提到比特币每天在所有区块上的交易额超过 60 亿美元吗？没错，Hubrich 明确指出区块上的交易（transaction）和交易所上的交易（trading）不同，前者是衡量一个加密币价值的有效指标。&lt;b&gt;一个币种在全世界范围内的交易越活跃、交易额越高，说明它的价值越大。&lt;/b&gt;因此，&lt;b&gt;用市值除以区块上的交易值，Hubrich 定义了 Market-to-Transaction-Value（MTV），以此作为加密币的价值因子。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;具体的，Hubrich 使用了每个币种当前的最新市值和其过去 7 个交易日在区块上的平均交易额（美元计价）的比值来计算 MTV。下图是这些加密币的价值因子随时间的变化，它确实呈现均值回复的特性，说明市场时而高估、时而低估这些加密币的“基本面”价值。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2cf8e38ba8c2a6c969f392b255e19510_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;603&quot; data-rawheight=&quot;588&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2cf8e38ba8c2a6c969f392b255e19510&quot; data-watermark-src=&quot;v2-1ef92d69d9264659216bd9e6af9572ea&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;3.3 Carry 因子&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后一个考虑的因子是 Carry。由于我实在想不到特别合适的中文翻译，就让我们姑且就用 Carry 好了，但我保证会把它的定义说清楚。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个资产的 Carry 定义为：当该资产的价格在一定时间内不发生变化时，持有该资产能够获取的收益。&lt;/b&gt;Carry 最早来源于外汇交易，旨在从低利率的市场借入货币，买入高利率市场货币，获取套息收益，即 Carry。后来，更广义的 Carry 被推广到股票、债券以及商品市场之中。&lt;/p&gt;&lt;p&gt;以股票为例，Carry 收益是什么呢？假如我们买入一支股票并一直持有，如果股票的价格不变，那么我们获得的收益率就是该股票的分红。股息率（dividend yield）就是 Carry 收益率，它就是我们的 Carry 因子。顺便说一句，&lt;b&gt;股息率因子是一个非常好使的量化选股因子。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;把 Carry 的定义应用到加密币当中，假设加密币的交易价值不变，它的收益体现在哪里呢？Hubrich 认为&lt;b&gt;加密币的 Carry 收益由它的供需决定。&lt;/b&gt;俗话说，“物以稀为贵”。大多数加密币的发行总数都有个上限且&lt;b&gt;不能随意增发&lt;/b&gt;，因此&lt;b&gt;未来还能被挖出来的币的数量越少，这个币的 Carry 收益率就越高。&lt;/b&gt;因此，Hubrich 使用 7 日内挖出的币的总个数除以该 7 日窗口开始时市场上该币的个数作为 Carry 因子的代理指标，这个比值越高说明 Carry 因子越低。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5c669b16ce4f144ac8435a7eac31b67b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;514&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5c669b16ce4f144ac8435a7eac31b67b&quot; data-watermark-src=&quot;v2-89503e250a7f6f6b21df81e3d8d97e5d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;然而，加密币的紧缩不仅体现在不能随意增发。想象一下这样的情景，Alice 拥有 5 枚比特币。一天她的电脑寿终正寝导致她的私钥丢失，且她没有备份。这意味着这些比特币将永远“死去”。随着时间的推移，像 Alice 一样的人会越来越多，“死去”的比特币（以及其他的加密币）会越来越多，这也将加剧加密币的紧缩，增加其 Carry 收益。显然，加密币的“死去”是非常难以量化的，因此 Hubrich 并没有考虑这方面的影响。&lt;/p&gt;&lt;p&gt;上面分别介绍了 Momentum、Value 和 Carry 因子。Hubrich 选择这三个因子不仅仅因为它们三个在其他市场中太有名了，更是因为它们代表了&lt;b&gt;三个互补的维度&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Momentum：&lt;/b&gt;动量因子考察的是&lt;b&gt;当市场沿着过去的轨迹继续运动时&lt;/b&gt;（即价格上涨的还会涨，价格下跌的还会跌），我们能够获得的收益；&lt;/li&gt;&lt;li&gt;&lt;b&gt;Value：&lt;/b&gt;价值因子考察的是&lt;b&gt;当市场回复到之前的某种均衡状态时&lt;/b&gt;（即价格围绕基本面价值往复运动），我们能够获得收益；&lt;/li&gt;&lt;li&gt;&lt;b&gt;Carry：&lt;/b&gt;Carry 因子考察的是&lt;b&gt;当市场不发生变化时&lt;/b&gt;（即从供需的角度来看，加密币的需求端不发生变化），我们能够获得的收益。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从这个意义上说，以这三个因子为起点，研究因子投资在加密币这个新兴市场中的有效性，是非常合理的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后需要说明的是，在对每个币种各自计算了因子后，必须考虑因子的标准化，否则无法保证因子在跨币种之间的可比性。&lt;/b&gt;以价值因子为例，不同币种的 MTV 可能都不是一个量级，不标准化的话根本没有可比性。 在标准化时，Hubrich 采用了每个币种自身的时序数据计算 Z-score（减去均值再除以标准差）的方式。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 实证结果&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节来介绍用因子选加密币的效果如何。上一节提到 Hubrich 分别考虑了时序和截面两个角度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在时序方面，&lt;/b&gt;每个加密币被独立考虑。在每个调仓节点，对于一个给定的加密币 X 和因子 A，如果 A 当期的取值大于该因子在此节点之前的历史均值，则在因子 A 的投资组合中做多加密币 X，反之则做空加密币 X。&lt;/li&gt;&lt;li&gt;&lt;b&gt;在截面方面，&lt;/b&gt;这些加密币被放在一起比较它们之间的相对强弱关系。在每个调仓节点，对于一个给定的加密币 X 和因子 A，如果 A 当期的取值大于所有加密币的因子 A 在当期取值的均值，则在因子 A 的投资组合中做多加密币 X，反之则做空加密币 X。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上述定义说明，虽然都考虑了多空对冲，但时序策略更接近一个 β 策略，而截面策略更像是一个纯 α 策略。在定性确定每个因子中加密币的多、空之后，还必须选择具体的权重。为此，作者考虑了等权重和按风险加权这两种方法。&lt;/p&gt;&lt;p&gt;由于时序策略的 β 属性，为了说明因子的有效性必须把来自市场的收益率剔除。我们知道过去几年加密币几乎呈现单边上涨行情，因此即便是一个纯多头的买入、持有这 11 个加密币的组合也会有不错的收益。为了说明因子的有效性，Hubrich 构建了纯多头的基准组合，并用基准组合的收益率对这两个策略进行回归。&lt;b&gt;策略的收益率在回归中无法被基准组合的收益率解释的部分就是来自因子的超额收益。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由于有时序 vs 截面两种策略，以及等权 vs 风险加权两种配置方式，我们一共有四个策略。这四个策略的净值如下图所示。&lt;b&gt;作者充分考虑了策略的风险，因此资金量在加密币上的暴露其实非常低，即便如此时序策略仍然获得了可观的收益。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7302908b62547d99e89ce6701d5d7dbc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;628&quot; data-rawheight=&quot;403&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7302908b62547d99e89ce6701d5d7dbc&quot; data-watermark-src=&quot;v2-5d65329e5ce7a8b14427532dd7c0d748&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图中，实线为策略净值、虚线为用基准组合回归后无法解释的超额收益的净值。&lt;b&gt;无论是在时序还是截面策略中，这三个风险因子都发挥了作用，选出的多空加密币组合可以获得跑赢基准的超额收益。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后，Hubrich 将因子的策略组合和基准组合相结合构建了纯多头的策略（因为加密币市场的做空机制也有限），这四个策略加上基准组合之后的表现如下图所示。其中虚线是基准组合净值，实线是因子 + 基准组合的净值曲线。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-411bf705d5af9eeedbc3f18c5efd09e9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;635&quot; data-rawheight=&quot;393&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-411bf705d5af9eeedbc3f18c5efd09e9&quot; data-watermark-src=&quot;v2-62e0ed7f6d06400a1fc018e882089081&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;由于加密币自身的上涨，基准组合的收益率很高。因此因子组合和基准组合两者叠加后，策略的收益率更是进一步提升。不过在文章的最后，Hubrich 也给出“警告”，加密币单边上涨的行情也许在未来无法持续，因此最后这张图中两个策略的叠加效果可能对未来没有太多的借鉴意义。但不可否认的是，以动量、价值和 Carry 这三个因子构建的加密币投资组合战胜了市场。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这两天，全球最大对冲基金桥水的创始人 Ray Dalio 携他的新书《原则》来到中国，掀起了一股 Dalio 热浪。从金融街到陆家嘴，人手一本“黑宝书”、张口闭口就是原则。在接触这本书之前，Dalio（以及桥水）最令我钦佩的是他们在面对市场时求真的态度，他们时时保持着谦逊，孜孜不倦的探究市场的真谛，就像 Dalio 和他的合伙人在介绍桥水著名的全天候策略时写到的那样（如下）。看完《原则》这本书之后，我的这个印象进一步加深：&lt;b&gt;永远怀有开放和包容的心态来追寻市场的真相。&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;找出[投资中的]真相是我们双方的责任。我们[桥水]应该将我们认为正确的观点诚实的表达出来，而你们则应努力地、公开地探究我们的想法，以便我们一起学习什么是正确的。当我们进行了如此高质量的交流之后，我们可以决定真相到底是什么，以及我们应该怎么做。&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;在面对加密币这个新兴市场时，Dalio 和桥水的这种求真的态度非常值得学习。我们无需急于给加密币贴上“天使”或者“魔鬼”的标签，也无需着急“站队”、表明自己对加密币的（过激）立场。一个针对加密币的量化策略在严格控制风险后可以是一个非常好的投资途径。难道就因为它投资的是加密币，而非传统意义的股票、债券、商品、外汇市场，就应该被视为“过度投机”或“无视风险”吗？答案显然是否定的。&lt;/p&gt;&lt;p&gt;在时间面前，人类任何的进程都不过沧海一粟。几十年后，后人自会对加密币的存在作出定论。而当下的我们，应该秉持客观、严谨、求实的态度去探索、学习加密币市场，并争取以此来推动我们对其他市场的理解和认知，这才是一个量化投资践行者应有的态度。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Asness, C. S., T. J. Moskowitz, and Pedersen, L. H. (2013). Value and momentum everywhere. &lt;i&gt;Journal of Finance&lt;/i&gt;, Vol. 68(3), 929 – 985.&lt;/li&gt;&lt;li&gt;Hubrich, S. (2017). Know When to Hodl &#39;Em, Know When to Fodl &#39;Em: An Investigation of Factor Based Investing in the Cryptocurrency Space. &lt;i&gt;SSRN&lt;/i&gt;: https://ssrn.com/abstract=3055498.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-09-02-43545668</guid>
<pubDate>Sun, 02 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>模型复杂度随想</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-08-23-42734509.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42734509&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38a0cdd6cadb8f387d3240e4e928dcb4_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当模型复杂度一样时，人们偏好风险收益特性更高的策略；当风险收益特性一样时，人们偏好模型复杂度更低的策略。各种复杂模型带来的边际超额收益能否 justify 它们的复杂度呢？拭目以待。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一个初入量化投资的分析师经过了一个月的奋斗开发出了一个双均线趋势追踪模型后，兴冲冲的跑来和他的基金经理汇报，于是便有了下面这段对话。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分析师（一脸兴奋）：&lt;/b&gt;我开发出了一个双均线系统，绝对没有数据挖掘，只有计算均线的两个参数，该参数对绝大多数商品期货都有效、适应性极强。&lt;/li&gt;&lt;li&gt;&lt;b&gt;基金经理：&lt;/b&gt;做趋势追踪还有其他的方法，比如时间序列分析、其他技术分析手段、以及机器学习里面的各种复杂算法。你的系统和这些比较过吗？&lt;/li&gt;&lt;li&gt;&lt;b&gt;分析师（心说“一猜你就会问这个”）：&lt;/b&gt;常见的这些方法我都仔细试过了，它们的效果都没有双均线系统好。&lt;/li&gt;&lt;li&gt;&lt;b&gt;基金经理：&lt;/b&gt;……&lt;/li&gt;&lt;li&gt;&lt;b&gt;分析师：&lt;/b&gt;真的！我做了非常详细的对比，逐笔分析了各种不同策略的交易记录，双均线是最好的。&lt;/li&gt;&lt;li&gt;&lt;b&gt;基金经理：从你排除其他策略、挑出双均线系统的那一刻，你就已经过拟合了。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;分析师（一脸迷茫）：&lt;/b&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面这段对话当然是我杜撰的。想通过它表明的观点是，&lt;b&gt;我们将不同的量化技术应用到同样的数据上构建某一类（比如趋势追踪、反转、套利）策略时，最终会挑出来表现最好的量化技术，无论这个技术复杂与否（线性的、非线性的），这个过程本身就是在过拟合。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最终被挑出来的，注定是因为在样本内战胜了其他的。从“超参数”（见&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38256574&quot;&gt;《科学回测中的大学问》&lt;/a&gt;）的意义上说，这个模型难逃 data mining 之嫌，因为&lt;b&gt;它比别的模型更好很可能是因为它对样本数据内的噪音刻画的更精准，而非发现了一些被其他策略忽视到的真实存在于数据之间的因果关系。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;以上这点粗浅的认识当然不是鼓励大家放弃回测中表现好的、使用表现差的量化技术。就我自己有限的经验来看，任何策略都或多或少存在数据挖掘的问题，而这个问题随着模型复杂度的增加更加突出。&lt;/p&gt;&lt;p&gt;今天就简单聊聊模型复杂度。讨论主要从以下两个角度展开：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;模型复杂度和过拟合程度&lt;/b&gt;：定量分析模型复杂度和构建策略时 data mining 的程度。&lt;/li&gt;&lt;li&gt;&lt;b&gt;模型复杂度和损失带来的主观感受&lt;/b&gt;：回答诸如“面对实盘中同等大小 —— 比如 -10% ——的回撤，不同复杂度的模型是否能给我们带来同样的主观感受”这样的问题。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这两个角度的研究都是很大的课题，本文仅仅是做一点抛砖引玉的探讨。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 模型复杂度和过拟合程度&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在构建一个量化投资策略时，一旦确定了模型复杂度，就要进行参数优化。只要是参数优化，无论再怎么小心，都会存在过拟合。本节使用趋势策略阐述&lt;b&gt;在给定的模型复杂度进行参数优化&lt;/b&gt;和&lt;b&gt;过拟合程度&lt;/b&gt;之间的关系。分析流程如下：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7ba6576c5316b73466cbce402fd83d3b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;572&quot; data-rawheight=&quot;582&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7ba6576c5316b73466cbce402fd83d3b&quot; data-watermark-src=&quot;v2-42859f663c812c53adfc14892285035d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;分析中采用的趋势追踪策略是均线多头排列策略。它的定义和模型复杂度介绍如下。&lt;/p&gt;&lt;p&gt;在市场有大趋势的时候，均线一般呈现多头或者空头结构，即不同周期 T 的均线排序和 T 的排序非常一致（比如上涨时，通常有 MA5 &amp;gt; MA15 &amp;gt; MA30）。当投资品从上涨向下跌转换、或由下跌向上涨转换时，短周期均线会先于长周期均线发生变化。在前者发生时，短周期均线开始逐步下穿长周期均线；在后者发生时，短周期均线开始逐步上穿长周期均线。在发生由涨转跌或由跌转涨时，不同周期均线的排序和时间窗口 T 大小的排序关系被打乱，不再完全一致。&lt;/p&gt;&lt;p&gt;&lt;b&gt;使用秩相关系数计算均线排序和时间窗口 T 排序之间的一致性，并使用它择时、构建趋势追踪策略（这里只考虑多头策略）。&lt;/b&gt;当均线多头排列时，均线和 T 之间的秩相关性为 1；当均线空头排列时，均线和 T 之间的秩相关性为 -1。由涨转跌时，短期均线开始下穿，秩相关性从 1 开始下降；由跌转涨时，短期均线开始上穿，秩相关性从 -1 开始上升。由此，可以构建策略如下：&lt;/p&gt;&lt;p&gt;使用给定的均线参数周期，各自计算指数平均，进而计算均线排序和参数排序的秩相关系数。空仓时，如果秩相关系数上穿 -TH 则满仓；满仓时，如果秩相关系数下穿 TH 则空仓。不考虑任何成本。&lt;/p&gt;&lt;p&gt;在这个策略中，模型复杂度由如下两组参数刻画：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;计算均线的周期参数个数；&lt;/li&gt;&lt;li&gt;判断空仓和满仓时，秩相关系数的阈值。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这两组参数各自从不同层面增加了模型的复杂程度。在分析中，它们的取值如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;均线参数的个数从 2 到 5 递增，依次增加模型的复杂度。第一个均线周期取值范围是 10 到 100，步长 10；从第二个均线周期开始，在搜索参数时，其取值范围似是前一个均线的取值与 100 之间，步长 10。此外，允许新加入的均线对策略不产生作用。这保证了随着均线个数增加，求解的空间是递增的，从而保证了最优目标函数的单调性。&lt;/li&gt;&lt;li&gt;在分析时，首先仅考虑均线参数个数造成的影响，因此假设阈值为 TH = 0.5 恒定。之后，为了同时考察阈值对过拟合程度的影响，允许阈值 TH 从 0.1 到 0.9 之间（步长 0.1）选择。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;依照上述描述进行实验，得到的模型复杂度和过拟合程度的关系如下图所示。其中蓝色圆圈表示仅考虑均线参数个数这一种模型复杂度时的情况，而黄色十字表示同时考虑阈值作为模型复杂度的情况。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-94b8a9427d48de4533fcb4960c769797_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;425&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-94b8a9427d48de4533fcb4960c769797&quot; data-watermark-src=&quot;v2-4256bd1c5921955e195c12fe6d86eab5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当我们使用真实的交易数据进行策略的参数优化时，尽管使用了训练集和测试集、考虑了参数平原、从各种业务层面解释了参数的选择，依然无法消除参数优化中过拟合的影响。&lt;b&gt;更不幸的是，对于真实交易数据，由于不知道它其中哪些是因果关系、哪些是噪音，因此我们甚至无法评价参数优化造成的过拟合程度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;然而在上述实验中，由于价格序列由随机游走生成，因此随着实验个数的增加，我们预期它们的基础夏普率均值是 0。这正是使用 random walks 来验证策略的好处，因为它的“正确答案”是已知的 —— &lt;b&gt;一个不存在过拟合的策略在随机游走价格序列上不应该能持续的赚到钱。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这 100 个 random walks 的基础夏普率均值为 -0.03。如果参数优化中没有过拟合，那么策略夏普率均值和基础夏普率均值相差不远。然而，分析的结果远非如此。上图表明，随着参数的增多，模型的过拟合程度（100 个策略夏普率均值于基础家谱率均值之差）也在上升；而随着模型复杂度从多维度的提升（即加入阈值参数），模型的过拟合程度产生了跳变。&lt;/p&gt;&lt;p&gt;&lt;b&gt;上述结果说明模型的过拟合程度随模型的复杂度递增。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 模型复杂度和损失带来的主观感受&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节来看看模型复杂度和策略损失带来的主观感受之间的关系。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38417800&quot;&gt;《追求卓越，但接受交易中的不完美》&lt;/a&gt;一文曾阐述了如下观点：一个策略投放到实盘时最大的敌人是交易者的心理关。&lt;b&gt;这个心理关指的是交易者能否克服实盘中的心理压力从而坚持使用这个策略。&lt;/b&gt;对于任何一个量化投资策略，几乎可以确定的是它在回测中的表现是其在实盘中表现的上限。在实际交易中，价格时刻在波动，充斥着噪音的各路消息以远超过我们能够接受的速度涌来，使人快步踏入行为金融学中的各种认知偏差陷阱、丧失冷静；&lt;b&gt;面对真金白银的亏损，交易者会比想象的更脆弱、更容易怀疑策略的开发中是否存在没有考虑到的问题（对于复杂策略更是如此）、自我动摇想要放弃这个系统 —— 这就是损失带来的主观感受。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当一个策略持续出现回撤，亏损超过回测中最大回撤时，复杂度是否对亏损带给我们的痛苦程度（以及对策略不自信的程度）造成影响呢？&lt;/p&gt;&lt;p&gt;为了回答这个问题，自然要建模。建模的流程如下图所示。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-247d59a129732ccb0917e5b68e0ca542_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;562&quot; data-rawheight=&quot;456&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-247d59a129732ccb0917e5b68e0ca542&quot; data-watermark-src=&quot;v2-4fd21563db72cd2ef48c4f6df54be0a8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这个流程中有三处需要建模：（1）模型复杂度和胜率的关系；（2）胜率和收益率分布均值的关系；（3）模型复杂度和最大回撤与亏损造成的痛苦的关系。下面分别说明。&lt;/p&gt;&lt;p&gt;假设模型复杂度和胜率的关系如下：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;w=w_0+0.003k+0.01\mbox{NL}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中  &lt;equation&gt;w_0&lt;/equation&gt;  是基础胜率（假设等于 0.5）， &lt;equation&gt;k&lt;/equation&gt;  代表模型中参数的个数，NL 为 binary 变量，取值 0 或者 1，代表模型是否为非线性的（NL = 1 表示非线性）。Disclaimer：本模型没有任何 reference，只是我为了得到量化分析结果选用的一个简单模型。&lt;/p&gt;&lt;p&gt;假设单期收益率满足标准差为 1% 的正态分布，均值则和胜率有关。胜率代表着单期收益率大于等于零的概率，因此我们必须选择均值以满足  &lt;equation&gt;\mbox{prob}(r ≥ 0) = w&lt;/equation&gt; 。根据这个关系，可以求出均值为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\mu=-\mbox{ISF}(w)\times\sigma&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中 ISF 表示标准正态分布的 inverse survival function。&lt;/p&gt;&lt;p&gt;得到单期收益率的分布之后，就可以构建任意长度的收益率序列。分析中，我们构建长度为 1000 的序列，以此作为该复杂度下假想策略的收益曲率序列的一个实现，并计算出它的 NAV。有了 NAV 就可以计算出它的最大回撤（max drawdown，MDD）。假设亏损造成的痛苦（记为  &lt;equation&gt;H&lt;/equation&gt; ）和最大回撤以及模型复杂度的关系如下：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;H=e^{(k-1+10\mbox{NL})/C}\times\mbox{MDD}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;上述模型（disclaimer：同样没有任何 reference）说明 &lt;equation&gt;H&lt;/equation&gt; 由两部分组成：模型复杂度和最大回撤。由该模型的表达式可知，在同样的最大回撤下，不同的模型复杂度给人的主观感受是不一样的，&lt;b&gt;模型复杂度非线性的放大了亏损造成的痛苦&lt;/b&gt;。当  &lt;equation&gt;k = 1&lt;/equation&gt; （模型至少有一个参数）且模型为非线性（NL = 0）时， &lt;equation&gt;H&lt;/equation&gt;  的第一项为 1，因此它仅由最大回撤决定。当模型复杂度上升时，对复杂模型的惩罚程度由参数 &lt;equation&gt;C&lt;/equation&gt; （非负实数）控制。 &lt;equation&gt;C&lt;/equation&gt;  越小说明对模型复杂度的惩罚越高（即复杂模型会显著放大最大回撤造成的痛苦程度）。&lt;/p&gt;&lt;p&gt;结合上述胜率和痛苦程度的模型可知，模型复杂度可以增加胜率（hopefully），但它是以提高亏损造成的主观痛苦为代价的。因此，在这二者之间存在一个平衡。&lt;/p&gt;&lt;p&gt;下面来看一些实验结果。对于每一个给定的模型复杂度，随机产生 2000 个长度各为 1000 的收益率序列，并计算它们的最大回撤以及痛苦程度  &lt;equation&gt;H&lt;/equation&gt; ，取这 2000 个实验的均值作为该模型复杂度下损失造成的痛苦程度的度量。&lt;/p&gt;&lt;p&gt;首先考虑线性模型，即 NL = 0 的情况。下面三张图分别显示了  &lt;equation&gt;C&lt;/equation&gt;  取不同数值时，参数个数  &lt;equation&gt;k&lt;/equation&gt;  和  &lt;equation&gt;H&lt;/equation&gt;  的关系：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9693ba67ae9f313c90b56e6cb1283703_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1254&quot; data-rawheight=&quot;330&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9693ba67ae9f313c90b56e6cb1283703&quot; data-watermark-src=&quot;v2-d78bcad440cc4840a5ae4311512ddb98&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当  &lt;equation&gt;C&lt;/equation&gt;  很大时，我们对模型复杂度的惩罚很低，模型复杂度的作用单边体现在提高胜率上。更高的胜率意味着更低的最大回撤，因此随着模型参数的增加，痛苦程度逐渐降低。当  &lt;equation&gt;C&lt;/equation&gt;  很小时，情况正好相反。模型每增加一个参数，造成的痛苦程度非线性急速攀升，大大的抵消掉高胜率造成的低回撤的影响，痛苦程度随模型复杂度单调上升。当 &lt;equation&gt;C&lt;/equation&gt; 取值中规中矩时，从上面中间的图中能够观察到胜率和痛苦程度之间的取舍，在理论上存在最佳的模型复杂度。&lt;/p&gt;&lt;p&gt;当 NL = 1 时，可以观察到和前面类似的结果（下图）。由于在  &lt;equation&gt;H&lt;/equation&gt;  的建模中，我们对 NL 的惩罚较高（系数为 10），因此对于同样的  &lt;equation&gt;C&lt;/equation&gt;  和  &lt;equation&gt;k&lt;/equation&gt; ，NL = 1 比 NL = 0 意味着更大的亏损痛苦。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f5237aec0e48ffa1ab6c29b46865be58_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1268&quot; data-rawheight=&quot;328&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f5237aec0e48ffa1ab6c29b46865be58&quot; data-watermark-src=&quot;v2-b5536ccc4cd78fa458ef9d3a3f100341&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上面的分析都是探索性的，并没有实证数据作为依据（难以找到使用不同模型复杂度策略的投资者并统计它们面对亏损时的不同感受）。我分析的初衷是，&lt;b&gt;在构建投资策略时，任何决定都要在得与失之间取舍。&lt;/b&gt;复杂模型在提高胜率的同时，也一定在某种程度上有它的弊端。从我有限的经验来说，在实盘中出现同样程度的亏损时，复杂的模型比简单的模型更让人不安。&lt;/p&gt;&lt;p&gt;在当下，我们越来越崇尚各种复杂的模型。本小节仅仅希望从一个完全不同的角度来提出一些思考：&lt;b&gt;我们在样本外是否 100% 做好了准备接受复杂模型？交易中存在各种认知偏差，如果我们连最简单的按一根均线做趋势追踪都无法坚决的执行，那又有什么来保证我们在面对实盘亏损时能够坚守复杂模型呢？如果我们不能坚守复杂模型，那么开发复杂模型所付出的心血和努力是否付之东流呢？&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前不久我听了 Vanguard 题为《先锋领航多资产 FOF 策略及外部管理人选聘概览》的报告。感触最深的是当谈到对策略的看法时，先锋的观点是&lt;b&gt;策略的理念一定要简单 —— 能用一句话说清楚策略赚的什么钱，就不要用两句描述；策略的程序一定要可理解、完全透明。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大道至简。&lt;/p&gt;&lt;p&gt;借用老罗的一句话那就是：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;Simplicity is the hidden complexity.&lt;/i&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;当模型复杂度一样时，人们偏好风险收益特性更高的策略；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;当风险收益特性一样时，人们偏好模型复杂度更低的策略。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;各种复杂模型带来的边际超额收益能否 justify 它们的复杂度呢？拭目以待。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原创不易，请保护版权。如需转载，请联系获得授权，并注明出处，谢谢。已委托“维权骑士”(&lt;a href=&quot;http://rightknights.com/&quot;&gt;维权骑士_免费版权监测/版权保护/版权分发&lt;/a&gt;) 为进行维权行动。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-08-23-42734509</guid>
<pubDate>Thu, 23 Aug 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
