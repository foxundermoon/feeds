<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>川流不息</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/</link>
<description>北京量信投资管理有限公司是一家在中国基金业协会备案登记的专业私募基金管理人。本专栏作者石川是量信投资的联合创始人。希望通过这个平台和各位小伙伴分享我们在量化投资领域的知识和心得，共同促进量化投资在中国的发展。</description>
<language>zh-cn</language>
<lastBuildDate>Sat, 23 Jun 2018 14:49:56 +0800</lastBuildDate>
<item>
<title>究竟何为量化投资？</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-22-38368044.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38368044&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bbe37e32fc8ee2c50ba4d8c3a6c4b92b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文作者：高嵩，量信投资联合创始人、CTO&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;量化投资的概念最初由西蒙斯的文艺复兴基金引入公众视野，却始终蒙着一层神秘的面纱。究竟什么是量化投资？如今，若还将量化投资简单的理解为基于数学模型由计算机程序控制的投资，未免太过狭隘。事实上随着近几十年投资学作为一门独立学科高速发展，从定性研究到定量研究是学科发展的必然趋势，数量化的触角已经渗透到投资流程的方方面面，如今可以说是无投资不量化，&lt;b&gt;无量化不投资&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;时至今日，&lt;b&gt;广义的量化投资已经发展成为基于现代科学方法的理论体系、研究方式以及工程系统的总和。&lt;/b&gt;放弃量化投资，无异于放弃了现代科学千百年来积累形成的行之有效的方法论。&lt;/p&gt;&lt;p&gt;早期的科学都是经验的集合。到了近现代，人们对实证经验进行抽象，再辅之以数理推演以及形式逻辑推演，逐步构建了一个相对完整自洽的体系，也就是现代科学。&lt;b&gt;现代科学相较于早期科学，其核心优势就是经过对实证经验的抽象与综合，形成的体系能够去伪存真，获取世界更为本质的规律，对于没有直接观测到的事物进行准确的预测。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;整个投资的历史远较量化投资为长。人们在投资活动中积累了大量的经验，但是直到近几十年，这些经验才被逐渐的抽象归纳，形成可以称之为科学的投资学。基于各种数学模型的量化投资也正是出现在这个阶段。&lt;b&gt;长于各种精确计量的量化投资的兴起只不过是一个学科变得更为成熟的必由之路。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于投资实践经验的抽象与归纳，程序化思维是重要核心。程序化思维并非狭义的“如何把投资方法编写为程序”；而是对于各种投资的实践经验，将其一层层梳理拨开，精准确定每个条件每个环节，确定各个机巧所在，设计各种实验一一验证。这本质是一个思维的过程，是将经验抽象提炼转化为知识的过程。投资经验经过了这个过程，才真正上得了台面，能够指导未来投资实践。&lt;/p&gt;&lt;p&gt;投资经验一旦升华成了知识，就意味着其可检验、可重复，如日升月恒，运转不息。&lt;b&gt;不知疲倦的机器能够最有效的发挥知识的力量，以极低的成本快速扩大规模，遵循由人类长期投资经验抽象而成的知识，不折不扣的进行投资活动。这种投资领域的“工业化大生产”时代正在来临。&lt;/b&gt;&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-22-38368044</guid>
<pubDate>Fri, 22 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>机器学习能否助力风险投资？</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38348236.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38348236&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9376471333ef292e3eb0ac6b57921ffd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;1 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;近几年，以机器学习、特别是深度学习为代表的人工智能（AI）得到了长足的发展，机器学习和人工智能也成为出现在街头巷尾的高频词汇。在&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38348112&quot;&gt;《AI 投资言过其实》&lt;/a&gt;这篇文章中，我们理性的分析了机器学习在二级市场中面对的困难。今天我们把目光放在风险投资（venture capital），看看机器学习能否在一级市场有所作为。&lt;/p&gt;&lt;p&gt;写本文的动机源自我最近读到的一篇来自麻省理工的论文 Hunter and Zaman (2017)。&lt;b&gt;该文提出了一个挑选优秀早期创业公司的量化分析框架，利用机器学习算法进行参数估计以及最优投资组合的构建，从而挑出那些最有可能成功的初创公司（成功的标准是风险投资人因该公司上市或者被收购而退出）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为文章很新（2017 年的），而且将机器学习应用于了一个比较新的场景，读来让人耳目一新，因此希望把它介绍给关注公众号的小伙伴，开阔大家的视野。&lt;b&gt;最重要的是，它在样本外挑出的创业公司的退出成功率高达惊人的 60%！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这篇论文本身非常 technical，因为一些建模的细节问题，我还和作者进行了邮件沟通，确保正确的领会了文章传达的内容。本文将避免涉及太多大数学公式（会有少量必要的），但会不吝篇幅、力争把该分析框架的重点 —— 包括如何构建特征、如何对参数建模求解、以及选取什么样的目标函数 —— 解释清楚。文章最后是关于这个话题的思考。&lt;/p&gt;&lt;p&gt;在介绍这个框架之前，首先来看看相较于二级市场，风险投资为什么更适合机器学习。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 风险投资更适合机器学习&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2016 年，AlphaGo 以无可争议的优势战胜了李世石；2017 年它的升级版更是风卷残云一般战胜了以柯洁为代表的中方各路围棋高手。AI 在围棋领域的大获全胜给了我们很大的启发，一个适合使用机器学习来解决的问题应该包括以下三个性质：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;信息边界明确，状态有限；&lt;/li&gt;&lt;li&gt;所有信息完全公开透明；&lt;/li&gt;&lt;li&gt;有明确的胜负判断标准。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们来看看风险投资是否满足这三个条件。根据百度百科，风险投资的定义如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;风险投资&lt;/b&gt;主要是指向初创企业提供资金支持并取得该公司股份的一种融资方式。风险投资公司为一专业的投资公司，由一群具有科技及财务相关知识与经验的人所组合而成的，经由直接投资被投资公司股权的方式，提供资金给需要资金者（被投资公司）。风投公司的资金大多用于投资新创事业或是未上市企业，并不以经营被投资公司为目的，仅是提供资金及专业上的知识与经验，以协助被投资公司获取更大的利润为目的，所以是一追求长期利润的高风险高报酬事业。&lt;/p&gt;&lt;p&gt;在一个创业公司融资的过程中，通常分为种子轮（seed）、A 轮、B 轮、……、F 轮（一般 IPO 前不超过 F 轮）、最后是 IPO。以 IPO 上市退出无疑会带给投资人最大的收益；在上市无望的情况下，被收购也是一种比较好的退出方式。根据上面的定义，&lt;b&gt;风投的手段是投资有希望的早期创业公司，目的是在退出时为投资人牟取超高额收益。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;从机器学习问题的角度来说，我们需要挖掘初创公司具备的特征与该公司最终能否为投资人带来了丰厚的报酬之间的关系：Y = f(&lt;b&gt;X&lt;/b&gt;)，即回答&lt;b&gt;“什么样的公司能在未来成为独角兽”&lt;/b&gt;这个问题（&lt;b&gt;X&lt;/b&gt; 代表特征向量，Y 代表是否带来了丰厚回报这件事儿）。训练这个模型是一个典型的&lt;b&gt;有监督学习问题&lt;/b&gt;。更重要的是，风险投资比较好的满足上面提到的三个条件：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;一个初创公司是否能够成功大概率受以下几方面的影响：所处的行业是否是风口行业、产品是否有核心竞争力、创始团队是否出色、是否有知名早期投资者扶持。与二级市场投资相比，风险投资问题的边界相对明确且状态有限。&lt;/li&gt;&lt;li&gt;关于初创公司的团队和融资路径数据，虽然还远非尽善尽美，但是也有足够多的数据（包括公开的和可花钱购买的）来建模。在美国，初创公司这方面数据的可得性（availability）可能更高一些，但是在国内也有像鲸准、IT 桔子、铅笔道这样的关于创业团队相关数据的提供方。&lt;/li&gt;&lt;li&gt;对于风投来说，成功的标准比较明确，就是成功退出（包括 IPO 退出或者被收购退出）。更加发散一步，在建模和参数估计时，也可以使用创业公司完成了哪一轮的融资作为判别的依据。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;需要明确说明一下 Hunter and Zaman (2017) 研究的样本对象。&lt;b&gt;该文的样本点仅考虑了 2000 年之后在美国创办的、且从数据库中可以获得其可靠种子轮或 A 轮融资数据的公司；作者关注的是早期融资成功的那些公司中，哪些更有可能最终脱颖而出。&lt;/b&gt;满足上述条件的公司超过 24,000 个。以它们为样本，该文作者使用机器学习算法找到了最有可能在未来成功的创业公司应具备的特质。由于样本中的公司都已完成了种子轮或 A 轮融资，因此&lt;b&gt;早期投资人的背景和能力也成为对公司建模的一个特征维度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面就来说说 Hunter and Zaman (2017) 考虑的特征。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 选择特征&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上一节提到，创业公司的特征可以从以下四个方面考虑：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;行业&lt;/li&gt;&lt;li&gt;产品&lt;/li&gt;&lt;li&gt;领导团队（包括高管和顾问）&lt;/li&gt;&lt;li&gt;早期投资者（首轮融资）的资源和经验&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Hunter and Zaman (2017) 在构建特征时并没有独立考虑产品这个维度（也没有过多的加以说明）。我的猜想可能是行业已经是产品的一个有效代理指标，话句话说，产品和行业维度比较相关。另外的原因就是在产品初期，能客观定量评价它的指标可能非常有限；产品本身太过细分，难以横向比较。事实上，马上我们将看到，Hunter and Zaman (2017) 考虑的行业已经非常细致，这也暗示了无需再进一步考虑产品这个维度了。接下来，分别从行业、领导团队以及早期投资者三个维度介绍特征。这些数据来自 Crunchbase 数据库以及 Linkedin（领英）。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.1 行业&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Hunter and Zaman (2017) 考虑了如下这些行业。当一个创业公司所属于某个行业时，它对应的行业特征取 1，否则为 0。这些行业包括：3D 打印、广告、分析、动画、Apps 应用程序开发、人工智能、汽车、无人驾驶汽车、大数据、生物信息、生物技术、比特币、商业智能、云计算、计算机、计算机视觉、约会交友、开发者 API、电子商务、线上学习、教育、线上虚拟体育、时尚、金融、金融服务、金融科技，健身、GPU、硬件、保健、健康诊断、医院、保险业、互联网、物联网、iOS 开发、生活方式、物流、机器学习、医疗、医疗设备、信息派送、移动通讯、纳米技术、网络安全、开放源码、个人健康、宠物、照片共享、可再生能源、共享出行、机器人、搜索引擎、社交媒体、社交网络、软件、太阳能、体育、交通、视频游戏、虚拟现实和虚拟化。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.2 领导团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;领导团队笼统的包括高管（含创始人）以及顾问。主要考虑的角度包括，团队成员在过去是否有成功的创业经验、团队成员之间工作和教育背景的相似性和互补性、团队和公司所处行业的符合度、以及团队的平均年龄。下面分别说明。&lt;/p&gt;&lt;p&gt;首先，团队成员过去的创业经验包括如下六个指标。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6604bc07d8f69ab2a05cffc5b5edb56a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;720&quot; data-rawheight=&quot;289&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6604bc07d8f69ab2a05cffc5b5edb56a&quot; data-watermark-src=&quot;v2-72e330e156abc00f530535de3c442e7d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其次，利用 Linkedin 的数据，Hunter and Zaman (2017) 抓取了所有领导团队成员在成立/加入本公司之前的工作经历，并从中计算出了如下代表他们工作经验和背景的特征。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20ea7d6ae2dc7abf29aea82a19c149f6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;705&quot; data-rawheight=&quot;256&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-20ea7d6ae2dc7abf29aea82a19c149f6&quot; data-watermark-src=&quot;v2-19257f04ada4b76bbf21be096bd59453&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在计算工作重合度时，Hunter and Zaman (2017) 采用了 Jaccard Index（一种评价两个集合中元素相似度的常见方法）。具体方法为，领导团队成员两两配对，找出他们之前工作单位的交集和并集，用交集中成员的数量除以并集中成员的数量求出 Jaccard Index。这个指标的取值在 0 到 1 之间，是工作重合度的度量，越高说明重合度越高。对于每个配对，都能得到一个 Jaccard Index，然后计算这些 Jaccard Index 的均值和标准差，作为工作重合度的均值和标准差。&lt;/p&gt;&lt;p&gt;在领导团队的教育背景方面，Hunter and Zaman (2017) 考虑了最高学历、是否毕业于名校、以及教育背景重合度等特征。这些特征包括：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-51f1934f47c407022a92a30f1d344fe4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;703&quot; data-rawheight=&quot;357&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-51f1934f47c407022a92a30f1d344fe4&quot; data-watermark-src=&quot;v2-abe4c46fc2c59771a375291055458c6c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在名校的表单中，Hunter and Zaman (2017) 仅考虑了美国的学校（这是个不足？），它们包括：伯克利、布朗大学、加州理工、卡耐基梅隆、哥伦比亚、康奈尔、达特茅斯、杜克大学、哈佛大学、约翰霍普金斯、麻省理工、西北大学、普林斯顿、斯坦福、芝加哥大学、宾夕法尼亚大学、以及耶鲁大学。在计算教育背景重合度时，同样采用的是 Jaccard Index，不再赘述。&lt;/p&gt;&lt;p&gt;对于团队教育背景和公司所处行业的相似性，Hunter and Zaman (2017) 使用了 WordNet 词汇数据库，计算每个领导团队成员学术专业和公司所处行业之间的语义相似度（具体方法是 Palmer-Wu 相似度分数，见 Wu and Palmer 1994）。得到由每个成员计算出的相似度后，取它们的均值作为团队教育背景和公司行业的相似性的度量。&lt;/p&gt;&lt;p&gt;最后一个关于创始团队的指标是在成立该公司时，团队的平均年龄。出于年龄数据不全的考量，作者假设团队成员 18 岁高中毕业、22 岁本科毕业，然后根据他们获得相应学位的年份和公司创办的年份计算出目标年龄。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.3 早期投资者&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在早期投资者这个维度，Hunter and Zaman (2017) 着实花了一番功夫，使用约 83,000 个公司和 48,000 个投资者数据构建了一个公司和投资者关系的动态知识图谱。该图谱随时间变化，对于任意给定的时间点，图谱中的给定节点表示在那个时刻某个投资者投资了某个公司。通过这个图谱，作者计算了两个评价早期投资者能力的指标：&lt;b&gt;投资人的参与度&lt;/b&gt;和&lt;b&gt;投资人的成功率&lt;/b&gt;。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3ceb89aba4196c32013c047644455c24_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;696&quot; data-rawheight=&quot;429&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3ceb89aba4196c32013c047644455c24&quot; data-watermark-src=&quot;v2-8dc0f3f2f2369d8009db42d1e345ca48&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;以上介绍了从行业、团队和早期投资者这三个维度如何构建创业公司的特征。&lt;b&gt;其中的难点在于数据的抓取、数据的清洗（提高数据质量）、以及投资人和公司关系图谱的构建。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 构建参数模型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;有了特征之后，下一步就是要把特征和最终模型学习的目标联系起来。对于选择优秀的初创公司这件事儿，目标应该是什么呢？&lt;/p&gt;&lt;p&gt;我们最终的目标是找到最有希望 IPO 的公司。&lt;b&gt;但是使用上述特征直接映射到创业公司能否 IPO （比如使用逻辑回归）太过简单粗暴了。&lt;/b&gt;下图显示了在 Hunter and Zaman (2017) 的样本中，自 2000 年以来每年新成立的公司的数量以及每年处于各轮融资的公司的数量（从种子轮、A 轮、一直到被收购或者 IPO）。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-158bff9eb19a924296cefb999aae15a3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;860&quot; data-rawheight=&quot;346&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-158bff9eb19a924296cefb999aae15a3&quot; data-watermark-src=&quot;v2-add24f3b269fc8267a9a4e5e42f51192&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;从上面的右图可见，能够最终 IPO 的独角兽公司凤毛麟角。&lt;b&gt;如果仅仅以一个公司是否 IPO 作为标签的话，这样的样本数据是非常不均衡的。&lt;/b&gt;以此来训练分类模型的话，常规的方法会过度的考虑对非 IPO 公司（占绝大多数）分类的准确性，而忽视对少数 IPO 公司的准确性。&lt;/p&gt;&lt;p&gt;从直觉上来看，我们似乎应关心对 IPO 公司预测的准确率，并为此可以牺牲对该类预测的召回率，以及对非 IPO 公司预测的精度。但是不要忘记，IPO 的回报是非常高的 —— 不夸张的说，早期 VC 投 100 个公司，有一个能够最终 IPO 就足够覆盖其他 99 个失败造成的损失并给他带来丰厚的收益了。这样的收益特性称为 top-heavy payoff structure。基于此，我们似乎更应该关注对 IPO 公司分类的召回率。&lt;/p&gt;&lt;p&gt;无论如何，直接以是否 IPO 作为标签来训练一个有监督分类问题是过于简化了。更合理的建模思路应该是什么呢？从业务上来考虑，一个创业公司在成功的历经各轮融资后，它的估值是在逐步提升的。因此，&lt;b&gt;使用创业公司的特征来对它估值的变化建模似乎是一条可行并合理的路径。&lt;/b&gt;Hunter and Zaman (2017) 正是这么做的。&lt;/p&gt;&lt;p&gt;Hunter and Zaman (2017) 假设&lt;b&gt;一个公司的估值&lt;/b&gt; V(t) &lt;b&gt;随时间的变化可以由一个布朗运动描述&lt;/b&gt;，该布朗运动的漂移率和扩散率同样为时间 t 的函数，分别为 μ(t) 和 σ(t)。假设在成立时，公司的估值为 0，即 V(0) = 0，随着时间的推移，V(t) 按布朗运动波动。进一步假设不同的融资轮对应不同的估值阈值，当 V(t) 超过某轮阈值就意味着该公司成功完成该轮融资。&lt;b&gt;经过这样的假设，一个公司每完成新一轮融资所需要的时间就是这个布朗运动的 first passage time（首达时间）。&lt;/b&gt;在进一步的数学假设下，作者给出了布朗运动首达时间的概率分布函数 f 以及累计分布函数 F（公式本身太“感人”了，因此我们仅仅给出它们的数学符号，具体表达式就不列出来了，感兴趣的读者请参考原文）：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-82e4e3bf72e63d88052302a2feffad3b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;439&quot; data-rawheight=&quot;94&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-82e4e3bf72e63d88052302a2feffad3b&quot; data-watermark-src=&quot;v2-a5c45041ede57e2ac57dd78c3df46bb7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其中 t_0 表示下一轮融资的起始时间、α 表示估值 V(t) 需要达到的阈值。结合创业公司的融资数据，作者观察到了如下特征，并将它们用于对 μ(t) 和 σ(t) 的建模中：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;大多数成功的创业公司在早期几轮融资中的间隔时间大致相同，这说明我们可以假设在一段时间内，μ(t) 和 σ(t) 保持不变；&lt;/li&gt;&lt;li&gt;很多公司虽然在前几轮融资成功，但是随着时间的推移，越来越多的不免走向失败，无法继续获得融资。这意味着当过一个公司发展了几年后，布朗运动的漂移率开始下降；&lt;/li&gt;&lt;li&gt;随着时间进一步推移，一个公司能够成功（IPO 或者被收购）的可能性越来越低（说明其估值 V(t) 到达某个极限，很难继续增长），这意味着 μ(t) 和 σ(t) 将随着 t 的增大趋近于 0。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;考虑到这些特性，Hunter and Zaman (2017) 对 μ(t) 和 σ(t) 的表达式总结如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2f99ced0be7c40558d6d3ef8291ea130_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;581&quot; data-rawheight=&quot;134&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2f99ced0be7c40558d6d3ef8291ea130&quot; data-watermark-src=&quot;v2-3650fb7e7589a2fec6268ff25274189f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这表明当 t ≤ ν 时，μ(t) 和 σ(t) 为常数；而当 t ＞ ν 时，μ(t) 和 σ(t) 按指数衰减。ν、τ、μ_0 及 σ_0 需要根据训练集数据得到，其中 ν 和 τ 的取值对所有公司相同，而 μ_0 及 σ_0 是每个公司特有的参数。&lt;b&gt;用什么来决定每个公司的&lt;/b&gt; μ_0 &lt;b&gt;和&lt;/b&gt; σ_0 &lt;b&gt;呢？你一定已经猜到了：公司的特征！&lt;/b&gt;如此一来，公司特征就和上述布朗运动有机的结合起来了。&lt;/p&gt;&lt;p&gt;对于 μ_0 和 σ_0，分别考虑两组参数向量 &lt;b&gt;β&lt;/b&gt; 和 &lt;b&gt;γ&lt;/b&gt;，并令 μ_0 和 σ_0 是特征向量 &lt;b&gt;X&lt;/b&gt;以 &lt;b&gt;β&lt;/b&gt; 和 &lt;b&gt;γ&lt;/b&gt; 分别为权重的线性组合：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7341b56b6c9933ba95a138bb74ed46ad_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;478&quot; data-rawheight=&quot;118&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7341b56b6c9933ba95a138bb74ed46ad&quot; data-watermark-src=&quot;v2-def05cf8587e73f5703de2a3aaf3d873&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;此外，Hunter and Zaman (2017) 认为&lt;b&gt;外部环境的改变会影响公司特征对于公司能否成功的重要性。&lt;/b&gt;为此，他们假设同年成立的公司共享一组 &lt;b&gt;β&lt;/b&gt;，但不同年份之间 &lt;b&gt;β&lt;/b&gt;向量是不同的（当然不同年的 &lt;b&gt;β&lt;/b&gt; 之间是不独立的）。对于给定年份，所有在该年成立的创业公司使用该年的 &lt;b&gt;β&lt;/b&gt; 向量和自身的特征向量 &lt;b&gt;X&lt;/b&gt; 来求解漂移率 μ_0。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最终需要根据训练集来估计的参数包括 β 和 γ，以及用来描述漂移率和扩散率随时间变化结构的&lt;/b&gt; ν &lt;b&gt;和&lt;/b&gt; τ。对于给定的参数，可以求出描述公司估值变化的布朗运动的漂移率和扩散率，即 μ(t) 和 σ(t)，从而计算出估值 V(t) 到达各轮融资阈值的首达时间的概率分布；有了这个概率分布便能求出每个创业公司在个给定的时间内是否能成功完成指定轮融资的概率。&lt;b&gt;在参数估计中，目标函数就是最大化所有训练集样本点各轮融资发生的概率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了计算概率，需要给定各轮融资的阈值。Hunter and Zaman (2017) 将这些阈值作为模型的超参数直接给定，但他们也强调模型对融资阈值的选择并不敏感。由于在模型中融资阈值对所有公司都一样，因此它们仅对 &lt;b&gt;β&lt;/b&gt; 和 &lt;b&gt;γ&lt;/b&gt; 参数的大小起缩放（scaling）作用，并不影响特征和目标函数之间的内在关系。&lt;/p&gt;&lt;p&gt;由于目标函数太复杂，作者采用了 Broyden-Fletcher-Goldfarb-Shanno 算法（一种求解无约束非线性优化问题的迭代算法，见 Yuan 1991），它能比传统的梯度法更快的找到最优解。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 构建最优投资组合&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过上述参数模型，作者构建了公司特征和公司估值 V 变化之间的关系。但到了这一步还没结束，仅仅有了这个关系，我们只能大致知道哪个公司可能更有希望获得融资。&lt;b&gt;为了从成千上万的创业公司中找出独角兽，我们最关心的是每个创业公司最终能够在有限时间内实现 IPO 的概率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有了首达时间的概率分布函数 F 和模型的参数，很容易通过下式求出任何公司 i 最终 IPO 的概率，记为 p_i（其中 H 为实现 IPO 所需要的阈值）：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f164ae1be5a0e786908dc2625e7c3db8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;445&quot; data-rawheight=&quot;51&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;有了每个公司成功的概率 p_i，那么 VC 是不是只需要将有限的资金投入给成功概率最高的那些公司就可以了呢？答案并非那么简单。假设一共有 m 个创业公司，由于资金有限制，VC 需要从中选出 k 个，&lt;b&gt;目标是这 k 个里面至少有一个最终会 IPO。&lt;/b&gt;这个问题类似背包问题（knapsack problem）或集合覆盖问题（set covering problem），其目标函数可以写成：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b715c3247c622f5be51860e817bc152d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;477&quot; data-rawheight=&quot;89&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b715c3247c622f5be51860e817bc152d&quot; data-watermark-src=&quot;v2-f15369f2653469a6ddd59a68cc22fa59&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其中 [m] = {1, 2, …, m} 构成了所有公司的集合，S 是 [m] 的子集、大小为 k，E_i 代表公司 i 成功 IPO（其概率为 p_i）。由于我们希望至少有一个 IPO 成功，因此只需要将不同的 E_i 求交集。U(S) 就是选出的 k 个公司中，至少有一个 IPO 成功的概率，所以我们希望最大化 U(S)。&lt;/p&gt;&lt;p&gt;这个问题是 HP-hard，难以求解。但是，该问题具备一些不错的数学性质使得贪心算法（greedy）可以找到不错的次优解。&lt;b&gt;使用贪心算法，每一轮从所有剩余公司中选择一个，选出来的应该是能够最大化目标函数的边际增长，直到&lt;/b&gt; k &lt;b&gt;轮后，一共选择&lt;/b&gt; k &lt;b&gt;个公司构成&lt;/b&gt; S&lt;b&gt;。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果令 S_G 和 S_W 分别表示贪心算法的解和全局最优解，那么可以证明，目标函数的准确性是有&lt;b&gt;下界&lt;/b&gt;的：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1122d775890e8f78828cfbf6b3511b7e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;426&quot; data-rawheight=&quot;76&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-1122d775890e8f78828cfbf6b3511b7e&quot; data-watermark-src=&quot;v2-c6e5022bcaf90b7daa6ca5d856220a70&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当 E_i 之间独立时 S_G 和 S_W 完全一致。在实际的求解中，Hunter and Zaman (2017) 假设公司之间能否 IPO 是独立的。利用独立性可以把目标函数表示成 p_i 的形式（p_i 是公司 i 成功 IPO 的概率）：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2594b8bebee93f6a233f9b8bef3d656a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;473&quot; data-rawheight=&quot;167&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2594b8bebee93f6a233f9b8bef3d656a&quot; data-watermark-src=&quot;v2-6668e21798164e5c97caafabfaf188c1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最后需要指出的一点是，在上一节的建模中，作者令系数 &lt;b&gt;β&lt;/b&gt; 随时间变化。因此在计算目标函数 U(S) 的时候必须考虑 &lt;b&gt;β&lt;/b&gt; 的变化引入的随机性。这意味着 U(S) 实际是关于 &lt;b&gt;β&lt;/b&gt; 的期望，即我们最终要最大化的是&lt;b&gt;按照 β 的概率分布计算出来的至少有一家创业公司成功 IPO 的期望概率&lt;/b&gt;：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b671fd2cd8d9d10e3b8d3894e10fbc94_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;703&quot; data-rawheight=&quot;321&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b671fd2cd8d9d10e3b8d3894e10fbc94&quot; data-watermark-src=&quot;v2-0a2de732be7343a7ecfe47256ae382bf&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这个期望可以使用蒙特卡洛积分求解。这就是这个量化风投框架的全部内容。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 量化效果&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Hunter and Zaman (2017) 使用 2000 到 2010 年的数据作为训练集，之后的数据作为测试集，检验了他们提出的量化框架。通过在训练集上训练模型，他们得到了每个公司估值布朗运动的漂移率 μ_0 和扩散率 σ_0。将所有公司按照其最高的融资轮次分组，并考察每组中公司的 μ_0 和 σ_0 的中位数有：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dc1ed1467198cf1ad6bf38124137c5dd_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;611&quot; data-rawheight=&quot;456&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-dc1ed1467198cf1ad6bf38124137c5dd&quot; data-watermark-src=&quot;v2-496b06bd76ff320b9c0e064441d834bd&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;观察这张图可以得到如下启发：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;表现较差的创业公司（最高融资轮止步于种子轮或者 A 轮）通常有较低的漂移率；&lt;/li&gt;&lt;li&gt;表现一般的创业公司（最高融资轮为 B 到 F 轮）通常有较高的漂移率，但是较低的扩散率；&lt;/li&gt;&lt;li&gt;表现最好的公司（以 IPO 或者被收购退出）的漂移率仅仅是一般水平，但是却有很大的扩散率。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;这似乎说明足够大的扩散率是成功的必要条件。&lt;/b&gt;这让我们自然的提出下一个问题：什么样的公司特征可能带来比较大的扩散率（和漂移率）？&lt;/p&gt;&lt;p&gt;作者给出了 2010 年对漂移率产生最大影响的五个行业和非行业特征及它们的系数（别忘了 &lt;b&gt;β&lt;/b&gt; 每年是变的），以及对扩散率产生最大影响的五个行业和非行业特征及它们的系数：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-28c9a6294bc1bdc8b1b83e0c9af6102e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;673&quot; data-rawheight=&quot;414&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-28c9a6294bc1bdc8b1b83e0c9af6102e&quot; data-watermark-src=&quot;v2-fa62465a20bf3e785275f4e11ffd68b3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;从行业的角度来说，在 2010 年，影响漂移率的五大行业是线上学习、共享出行、开源、云计算以及生物信息学；影响扩散率的五大行业是社交媒体、信息派送、社交网络、APPs 应用程序开发以及云计算。这意味着这些行业的想象空间（波动）比较大。&lt;/p&gt;&lt;p&gt;从非行业特征角度来说，无论是对于漂移率还是扩散率，&lt;b&gt;最重要的特征就是创始团队的经验，特别是管理团队成员是否在成立本公司之前有过成功的创业经历。&lt;/b&gt;除此之外，&lt;b&gt;教育背景（是否毕业于名校），和早期投资者过往的成功率（maximum acquisition fraction）也尤为重要。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据训练模型和最优投资组合的优化函数，作者分别在 2011 年和 2012 年构建了两个投资组合，每个里面包含 10 个创业公司。这两个组合如下表所示，其中第二列为到 2016 年底每个公司最终的融资或退出情况，第三列为模型预测的退出概率 p_i，第四列为组合中依次加入每个公司之后目标函数 U(S) 的变化。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-46af32068f5d7256d0ff570bd15ff7a8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1030&quot; data-rawheight=&quot;663&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-46af32068f5d7256d0ff570bd15ff7a8&quot; data-watermark-src=&quot;v2-edaac68097da19ee7e83ed568fd6fa87&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;结果显示，在 2011 年选出来的 10 个公司中，有 6 个如今已经成功退出了（包括 1 个 IPO 和 5 个被收购）；在 2012 年选出的 10 个公司中，有 4 个已经退出了（均是被收购）。这可以说是&lt;b&gt;令人称奇&lt;/b&gt;的结果了。&lt;/p&gt;&lt;p&gt;为了横向比较，Hunter and Zaman (2017) 把他们的模型和顶级 VC 以及一个基准模型比较。基准模型采用了 ordered logistic regression 算法，它使用每个公司最高的融资轮作为标签，进行有监督分类。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8781f46298bcecda715244970b3aa89_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;458&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f8781f46298bcecda715244970b3aa89&quot; data-watermark-src=&quot;v2-ac5307b86c99554f7aa36e6b80a6a928&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图中，左侧的为 2011 年的结果，右侧为 2012 年的结果。横坐标表示所投公司数量，纵坐标为成功退出公司的数量。其中红线和蓝线为基于 Hunter and Zaman (2017) 框架的两个版本的模型的结果，它们的成功率远超基准模型以及顶级 VC；在 2011 年的组合中，当投资个数增加时，基准模型 ordered logistic regression 也取得了不错的效果，但是当投资的创业公司较少时，Hunter and Zaman (2017) 的框架仍然是最出色的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7 启发与思考&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;终于把这个框架介绍完了，首先的感受是“给跪了”。Hunter 和 Zaman 在这个量化风险投资框架中集成了大量的机器学习和数学优化算法。对它们的梳理如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从创业公司数据库（如作者采用的 Crunchbase）和 Linkedin 抓取创业公司和创业者、投资人的数据；从行业、团队、早期投资人三个维度构建特征；这其中运用了知识图谱的构建以及语义分析等技术；&lt;/li&gt;&lt;li&gt;使用带漂移率和扩散率的布朗运动来建模创业公司估值的变化，以最大化训练集中所有公司各轮融资发生的概率为目标训练模型参数，这是一个有监督学习问题，求解时采用了 BFGS 算法；&lt;/li&gt;&lt;li&gt;根据模型的参数，使用布朗运动首达时间的概率分布计算出每个公司实现 IPO 的概率。&lt;/li&gt;&lt;li&gt;使用贪心算法和蒙特卡洛积分求解公司选取最优化问题，最优化的目标是最大化选出来的公司中至少有一个能够实现 IPO 的概率。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;一个优秀的风险投资公司必备的两点是一套科学的方法论（来洞察投资热点和评估创业团队），和丰富的资源（无论是募资能力还是社会资源）。&lt;/b&gt;没有前者，它找不到好的项目；没有后者，好的项目不找它。&lt;b&gt;本文介绍的这个量化框架可以是这套科学方法论的有利助力。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为什么这么说呢？因为哪怕是抛开该框架在样本外的预测效果而言，它通过训练集建模得到的参数就能给 VC 们带来很多非常有帮助的启发，这其中包括&lt;b&gt;对热点行业的追踪&lt;/b&gt;以及&lt;b&gt;对优秀创业公司必备的特征的精准定位&lt;/b&gt;。比如，通过模型的参数可以找出时下最热门的行业，并指出一个创业公司想要成功必备的特质是创始人的工作经历和教育背景 —— 资本尤其青睐连续创业者。这些发现和国内很多顶级 VC 的“投的是人，而不是项目”的理念不谋而合。&lt;/p&gt;&lt;p&gt;当然在现阶段，纯量化的风投框架无法解决一个风投公司的资源问题。换句话说，一个量化型风投基金如果没人脉没资源、没有足够的募资能力，那即便是它找到了最具成功潜质的公司，也很难得到股权投资的机会。但是对于那些已在市场中站稳脚跟的 VC 们，掌握一套量化的科学评估体系（无论是对行业还是对创业公司） —— 即便该体系没有本文介绍的这么复杂 —— 也都是大有裨益的。&lt;b&gt;该体系一定会在当下的风投界为这些 VC 们赢得一定的 edge。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果有一天，机器学习（或更广义的，人工智能）真的在投资界大有作为，那么一级市场的 VC 们恐怕会比二级市场的基金经理们率先“沦陷”，而“干掉”他们的正是他们扶持起来的这些人工智能领域的独角兽们。&lt;/p&gt;&lt;p&gt;犹未可知。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Hunter, D. and T. Zaman (2017). &lt;i&gt;Picking winners: a framework for venture capital investment.&lt;/i&gt; Working paper, Sloan School of Management, Massachusetts Institute of Technology.&lt;/li&gt;&lt;li&gt;Wu, Z. and M. Palmer (1994). Verbs semantics and lexical selection. In &lt;i&gt;Proceedings of the 32th annual meeting on association for computational linguistics&lt;/i&gt;, 133 – 138.&lt;/li&gt;&lt;li&gt;Yuan, Y.X. (1991). A modified BFGS algorithm for unconstrained optimization. &lt;i&gt;IMA Journal of Numerical Analysis&lt;/i&gt;, Vol. 11(3), 325 – 332.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/LkQ6IjTE02msrXBB9xE8 (二维码自动识别)&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38348236</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>AI 投资言过其实</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38348112.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38348112&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a31b89ae9d91c70faa557b52b9ac23ee_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;转一篇我的合伙人高老板关于 AI 投资的文章。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 狂热的 AI 浪潮&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;近几年随着深度学习算法的出现，人工智能（AI）技术的热潮在全球各领域铺展开来。之前一些计算机处理起来非常困难的任务，依赖深度学习算法，得到了很好的解决。在很多特定数据集、特定任务中，计算机已经达到甚至超过了人类的水平。AlphaGo 在围棋上击败人类把这波浪潮推向了一个新的高峰，人们纷纷对于 AI 的发展无比乐观，似乎很快 AI 就要全面取代人类。&lt;/p&gt;&lt;p&gt;这狂热的一幕在 AI 历史上已经出现过几次，早在上世纪 60 年代，AI 刚刚被提出时，乐观的从业者就认为 AI 将很快在国际象棋和语言翻译中击败人类。90 年代深蓝在国际象棋中击败了人类，日前 AlphaGo 又拿下了更为复杂的围棋，但语言翻译到目前为止 AI 仍然与人类有较大差距。&lt;/p&gt;&lt;p&gt;现在 AI 的旋风又刮到了投资领域，AI 投资进入市场，颇有联合收割机进场割韭菜之势。AI 是否真的如此神奇？事实上目前以深度学习为代表的 AI 技术还有着非常大的局限性，AI 的一些核心问题仍未解决，AI 未来的路还很长。而&lt;b&gt;投资任务的复杂性远远超出了目前 AI 能够很好处理的范围。&lt;/b&gt;现阶段说 AI 投资将要甚至已经击败了人类，有些言过其实了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 AI 擅长的任务&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为什么棋类游戏最先被 AI 攻克？我们来看&lt;b&gt;棋类游戏&lt;/b&gt;的特点：&lt;b&gt;1、信息边界明确，状态有限；2、所有信息完全公开透明；3、游戏在有限步内结束，有明确的胜负判断标准。&lt;/b&gt;这几点造成了棋类游戏的的整个状态空间是有限确定的。以围棋为例，每个交叉点上无非就是黑子/白子/空三种状态，再加上整个局面轮黑棋或白棋先行，满打满算一共也就 3^361 × 2 种局面，之外的任何信息都对策略没有影响。就是一只猪，把每个局面最优着法记下来，也成了围棋之神。当然，以目前的技术列出围棋的全部局面是不可想象的，但是计算机相较于人的长处正是海量数据的存储与高速运算。因此计算机在棋类游戏中击败人类就不足为奇了。&lt;/p&gt;&lt;p&gt;再看&lt;b&gt;投资领域&lt;/b&gt;，与围棋相比在上述几个特点上都显著的更为复杂。与围棋的全部信息都在棋盘之中相比，对于投资你&lt;b&gt;很难预先确定整个问题的信息边界&lt;/b&gt;。这对于现阶段的 AI 已经构成了天大的挑战。现在的 AI 从技术以及形态上显然无法像人类一样主动去现实世界探索信息，那么如果让 AI 去投资，整个系统的输入是什么？哪些信息是相关的哪些信息是无关的？对于投资这种开放性问题，大千世界的任何信息都有可能会对决策产生影响，信息量巨大而信噪比极低。AI 不可能获取到一切有可能有意义的信息，从目前常见的做法来看，除了各类报表数据，无非就是接入互联网，从新闻以及舆论中挖掘一些有意义的信息。但这远非投资需要了解的全部，反而引入了大量的垃圾噪音。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f290aed03e8c4a62c1bbe2cc77f90e93_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;570&quot; data-rawheight=&quot;210&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f290aed03e8c4a62c1bbe2cc77f90e93&quot; data-watermark-src=&quot;v2-e147f1df61bcfa82f55f707ddef1cfb3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 1 投资任务的信息范围&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;如上图所示，&lt;b&gt;AI 能够使用的信息实际只是现实世界全部信息一小部分，其中还包含了大量的无用噪音甚至是虚假、错误信息&lt;/b&gt;。在这样的数据基础上，无论使用多么先进的算法，也无异于盲人摸象，难以获得令人满意的结果。&lt;/p&gt;&lt;p&gt;另外棋类游戏有确定的结束标志，存在明确的胜负标准，这也对 AI 的学习提供了极大的便利。最新的 AlphaGo Zero 版本正是依赖于此，让程序从 0 开始，不断的自我对弈以提升棋力。其背后唯一的逻辑很简单：一盘下完了，赢棋方的着法总是比输棋方走得好。这其实是一类非常特殊的问题。深入分析一下，围棋 AI 希望尽可能的提高棋力，而对弈胜负正是棋力真实客观的外在量化标准，可以直接测量、反馈。作为 AI 只需要不断地追求胜利即可，这个量化目标与根本目的是完全一致的。同样的事情放在投资上就不那么显然了。选出中国平安的策略比较厉害？还是选出贵州茅台的策略比较厉害？我们希望尽可能的提高 AI 的投资能力，但是这个&lt;b&gt;投资能力缺乏一个明确的可量化评测标准&lt;/b&gt;。我们只能利用唯一的历史数据，使用类似“近十年的投资信息比率”、“近五年的收益率”等代理指标。但是我们应当清醒的认识到，这些简单指标均无法完全准确的代表投资能力。过于片面的追求这些指标的优化，还容易陷入过拟合的风险。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 深度学习算法的局限&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;目前取得重大进展的以深度学习为代表的 AI 技术，本质上还是基于数据的统计，是一种高维空间的模式识别。&lt;/b&gt;这使得 AI 无法“理解”任务内容，在 AI 看来所有的任务都是寻找 f 使得 f(X) -&amp;gt; Y 的过程。这样AI的效果将极其依赖于给定的输入 X 与输出 Y。前面两节已经提到，在投资任务中，输入 X 中包含了大量的垃圾信息，又将很多真正有意义的信息排除在外；输出 Y 又不易准确量化评价。&lt;b&gt;对于人类来说，存在大量的领域背景知识，可以轻松的滤掉“显而易见”的无用或错误信息。但是现阶段技术下，这种领域背景知识很难迁移到 AI 中&lt;/b&gt;。AI 将对所有信息一视同仁，努力在其中发现模式，而这种模式将完全不同于人类的思维和理解方式，对于人类来说几乎是一个黑箱。这等于 AI 放弃了人类文明千百年来的持续积淀，仅通过目前人类给他划定的一部分信息，采用不同于人类的方式自学成才。对于围棋来说，棋盘上的信息是完全的，人类的所有领域知识积累都可以从棋盘上推演得到，人类的知识显得“多余”了。但&lt;b&gt;对于投资来说，涉及的信息无法穷尽，此时放弃人类知识就是非常危险的。&lt;/b&gt;那些人类闭着眼都不会踩到、甚至根本无法意识到其存在的坑，都很可能就会让 AI 阴沟里翻船。更何况现在的 AI 对于针对性构建的恶意样本还非常脆弱，一旦被人恶意利用，后果不堪设想。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d72995d86f84f847db2eca8d42784670_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;730&quot; data-rawheight=&quot;306&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d72995d86f84f847db2eca8d42784670&quot; data-watermark-src=&quot;v2-491e0ca99f88f1c5ab48ff1a65ea643c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 2 针对性构建的恶意样本&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;同时，现阶段的 AI 投资还面临一个重大挑战就是数据匮乏。&lt;/b&gt;从基于统计的机器学习开始，到现在的深度卷积神经网络，对于复杂的问题采取了使用海量数据学习以暴制暴的方式。AlphaGo 对弈了数百万盘围棋，达到了人类的水平。而一个人类棋手从学棋开始至达到职业水平的对弈数连 AlphaGo 的零头都不到。在这一点上，目前的 AI 与人类的思维方式还有着显著的差别。AlphaGo 击败了人类也不意味着机器就比人更聪明。&lt;/p&gt;&lt;p&gt;&lt;b&gt;人类的优势是对复杂数据进行高层次的抽象，大道至简；而深度学习算法则是充分发挥机器的优势，以量取胜。&lt;/b&gt;这使得人类能够从少量的样本中总结出深层次的简单规律，并利用这些规律做出各种预测；而 AI 在目前阶段无法做到这一点。观察到苹果落地，牛顿总结出是因为地球的引力，据此发展出万有引力定律；爱因斯坦总结出是因为地球质量造成时空弯曲，据此发展出广义相对论。他们都通过少量（相对 AI 的训练数据规模）的观察准确的抽象出了高层次的一些规律。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在小样本上的学习能力、深层次规律的抽象泛化能力，人类远远强过 AI。&lt;/b&gt;如果巴菲特是 AI，他可能需要看过 100 万家“可口可乐”公司的成功，才能在实际中选出可口可乐。但很可惜，可口可乐公司只有一个，历史也只有一次。对于 AI 来说，这样的学习数据实在是太少了。现阶段的 AI 算法，如果学习数据太少，会非常轻易的陷入过拟合的陷阱 —— AI 记住了所有的学习数据，而非其中真正能够持久生效的一些深层规律。&lt;b&gt;从投资到计量经济学，都注定了只有唯一的历史数据可以学习，时间持续流逝，环境不断变化，你也无法控制同样的环境反复的实验验证。&lt;/b&gt;此时就要求必须能够从这少量的甚至是唯一的样本中总结规律。现在 AI 言必称大数据，而爱因斯坦 100 年前没有任何实际的观测，通过“零数据”就预言了引力波的存在，直到 100 年后的今天才被实际观测到，这种能力现阶段的 AI 是无法企及的。专家们早已注意到了机器学习过于依赖样本的局限性，小样本学习的问题已经被推到 AI 领域前沿，但迄今未出现像深度学习算法这样的重大突破。目前 AI 仍然无法脱离模式识别的范畴，我们离实现真正的智能还有很长的路要走。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 AI 投资路在何方&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前 AI 在投资上也并非无用武之地。尽管整个投资任务对于 AI 来说过于宽泛复杂了，但 AI 在一些特定的具体领域任务上足以与人类媲美，已经证明了其巨大价值。&lt;b&gt;AI 的长处在于大量繁杂数据的高速处理，而人类的长处在于化繁为简，达到更高的抽象层次。人类和机器具备各自独特的优势而又能够有效互补。&lt;/b&gt;对于投资来说，AI 可以作为工具，帮助人类去高效的完成一些特定环节。我们仍然应当以人类投资的成功经验为基础，在其中一些特定环节上由 AI 替代人类高效完成。目前我们关注研究的重点不应当是 AI 如何替代人类做投资，而是如何作为工具帮助人类更高效更好的进行投资。将 AI 引入投资领域的商业本质仍然是效率的优化，是时间、成本、质量之间的平衡。&lt;b&gt;AI 的引入能够大幅降低低端人力成本，提高企业投资业务处理能力，从而获得更高的边际效益。&lt;/b&gt;作为专业投资者应当拥抱这种变革，但不应对 AI 有不切实际的期望，更不应当把 AI 作为噱头，勉强蹭热度。只有深入的理解 AI 技术，才能了解 AI 的优势与局限，让 AI 为投资发挥其最大的效能。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38348112</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>因子投资指数化实证</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38340466.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38340466&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b69cc06f353e7c2874c7f15876232355_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;1 前言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38281562&quot;&gt;《因子投资——“被动的”主动投资》&lt;/a&gt;系统阐述了如何基于能在长期获得溢价的风险因子来构建投资组合，即因子投资的概念。因子投资的核心是在给定的市场中构建具有可投资性的投资组合。如果不能做到这一点，那么因子投资仅仅是经济学家们的数学游戏，而无法（从获取超额收益的角度）为投资实践带来真正的作用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;可投资性是指投资组合中股票的仓位是否合理，该组合的换手率和交易成本是否实际，进入该组合的股票是否有足够的流动性、该投资组合能承担的资金量（即投资组合的容量）是否足够大等。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因子投资的实践者需通过排序或者优化，来从备选的股票中选出股票并构建出满足可投资性约束的投资组合。投资者通过持有该投资组合并在有新的基本面数据出现后按照同样的规则调仓，以期获得该因子对应的风险溢价。&lt;/p&gt;&lt;p&gt;今天，我们就以成长因子为例，来看看因子投资在我国股市是否有落地的可能。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 实验准备&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们的股票候选池为中证 500 的成分股。构建因子投资组合的频率为月频，即每月月底使用当时最新的因子暴露，来构建成长因子的投资组合。换句话说，在实证中，我们按月进行调仓。在时间维度上，我们使用从 2013 年 6 月到 2016 年 11 月三年半的月频数据。&lt;/p&gt;&lt;p&gt;在构建具有可投资性的投资组合时，我们采取求解如下形式的带约束条件的最优化问题：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9484a44453457733dc5ebd657f149b4d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;406&quot; data-rawheight=&quot;225&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9484a44453457733dc5ebd657f149b4d&quot; data-watermark-src=&quot;v2-ebb8f18032d49338e48af3e86343a91c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其中，w 是待求的股票权重的向量；X 是股票在目标因子，即成长因子上当期的暴露；V 是股票收益率之间的协方差矩阵；a 是一个给定的系数。&lt;b&gt;约束条件方面，我们考虑了虑纯多头组合（这是因为个股无法做空）；满额投资；单只股票的权重上限 2%（这保证我们的组合中至少会有 50 支股票，这么做的目的是尽量分散个股的特异性风险，即个股无法被因子解释的风险）；涨跌停股票的买卖限制；以及对其他行业和风格因子的暴露尽量低（这是因为我们想捕捉的是成长因子本身带来的风险溢价）。该优化问题的目标函数为最大化投资组合在成长因子上的暴露，以此来捕捉该因子带来的超额收益。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实证中考虑的其他因子包括 28 个申万一级行业和除成长因子外的其他 10 类风格因子。这些风格因子是： EP 因子、BP 因子、流动性因子、规模因子、非线性规模因子、Beta 因子、残差波动率因子、动量因子、反转因子和杠杆因子。&lt;/p&gt;&lt;p&gt;此外，为求解这个优化问题，一个核心的输入数据是个股的协方差矩阵。由于股票池有 500 支成分股，因此它们的协方差矩阵有约 125000 个参数需要估计。&lt;b&gt;直接通过个股的收益率历史样本数据直接求该协方差矩阵会造成极大的误差。为此，我们采用多因子模型来求解该协方差矩阵。&lt;/b&gt;在我们的多因子模型中，我们考虑了上述 28 个行业因子，11 个风格因子以及 1 个国家因子。具体的方法不在本文的介绍范围之内，故略去。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 结果分析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在我们之前的实证中，曾经使用 Barra 的纯因子模型构建过成长因子投资组合。该组合在回测期内获得持续的超额收益的（下图）。在本次实证中，我们想看看加入各种可投资性的约束后，获得的成长因子投资组合是否仍然给我们带来超额收益。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-39d50e17ea59ac1a060188707cfe1008_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;786&quot; data-rawheight=&quot;284&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-39d50e17ea59ac1a060188707cfe1008&quot; data-watermark-src=&quot;v2-1b0d5f578a6cff3535ac60d533be0f9e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;下图显示了回测期内中证 500 指数和我们的成长因子投资组合的净值走势比较。不出意外，围绕成长因子构建的投资组合大幅跑赢了市场。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-618784903d254b88535e83669b6cdfac_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;550&quot; data-rawheight=&quot;404&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-618784903d254b88535e83669b6cdfac&quot; data-watermark-src=&quot;v2-a19beadce81b9aa43d916e80a9bdc1cf&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;由于我们构建的额是纯多头组合，因此该组合显然对市场有不可避免的暴露，这便解释了为什么成长因子的投资组合也随市场有着同步的上下波动。&lt;/b&gt;为了更好的衡量该投资组合捕捉超额收益的能力，我们来看看它相对市场的净值走势（下图）。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2d278906b09f48a4078af7d5c97b295f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;555&quot; data-rawheight=&quot;407&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2d278906b09f48a4078af7d5c97b295f&quot; data-watermark-src=&quot;v2-e124c1d54ef62bfe0c676ccb46fa8881&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;成长因子投资组合相对于市场有着稳健的超额收益。其累计净值在回测期内穿越市场的牛熊，稳健向上。这条相对收益的净值曲线可以获得 9.1% 的年化超额收益；以月收益率计算的最大回撤为 3%。&lt;/b&gt;这说明如果能够通过做空中证 500 指数来对冲市场风险，那么依靠成长因子便可以获得如上图所示的稳定收益。&lt;/p&gt;&lt;p&gt;当然，现在股指期货的交易量有着非常严格的限制，因此能靠卖空股指期货来对冲的资金量非常有限。如果未来股指期货限制放宽的政策可以继续出台，那么必将为因子投资在国内的发展带来积极的影响。&lt;/p&gt;&lt;p&gt;最后，我们想说明的是，本次实证是我们将因子投资从理论转化为实践的初探。在实验中，我们并没有考虑所有可投资性的约束条件，比如我们就没有特别限制相邻两次调仓之间的换手率（从结果来看，回测期内每次调仓的平均单边换手率为 31%）。&lt;/p&gt;&lt;p&gt;此外，一旦在实践中尝试按照数学优化的结果来建仓，势必也会遇到不同的问题，造成一定的误差，这些也会影响投资组合的收益率。这是在实践中必须考虑的问题。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38340466</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>多个因子配置实证</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38340204.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38340204&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1331b06d10258675d59775bcbec531dd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;1 多个优秀的风险因子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;因子投资（factor investing）是近几年来的发达市场的新趋势。而随着国内股指期货的松绑和投资者逐渐变得理性和成熟，因子投资在 A 股一定也会有更美好的前景。我们之前对 A 股市场做了一些多因子实证。本文将重点讨论&lt;b&gt;如何有效的将多个优秀的风险因子配置在一起&lt;/b&gt;，使它们优势互补、得到收益风险比更佳的投资组合。本文假设读者已经熟悉我们之前的文章&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38281562&quot;&gt;《因子投资——“被动的”主动投资》&lt;/a&gt;以及&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38340466&quot;&gt;《因子投资指数化实证》&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我们的研究发现存在五类风险因子，围绕它们构建的具备可投资性的纯多头投资组合在回测中可以获得相对于基准指数的超额收益。&lt;b&gt;这五类因子是：流动性因子、规模因子、成长因子、估值因子以及反转因子。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;以中证 500 指数为基准，使用其成分股构建的这五类风险因子的投资组合的超额收益在过去近 7 年的净值曲线如下图所示，它们都取得了比基准指数本身更高的回报。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-164c867db26b4be6f4ea632ae155ea47_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;548&quot; data-rawheight=&quot;404&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-164c867db26b4be6f4ea632ae155ea47&quot; data-watermark-src=&quot;v2-e0340bc18e55024365cde71b9cf0c379&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;更具体的，针对这五类风险因子相对于基准指数的&lt;b&gt;超额收益&lt;/b&gt;，计算它们的年化收益率、最大回撤、平均回撤、以及夏普率。结果总结于下表。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4c5d1c257ee43d849d0022398c816646_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;527&quot; data-rawheight=&quot;191&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4c5d1c257ee43d849d0022398c816646&quot; data-watermark-src=&quot;v2-60b17824dcbde2dd6eade10738126f3b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;虽然上述每一个风险因子本身都有着跑赢基准指数的不俗表现，但它们的投资组合的收益率之间&lt;b&gt;相关性较低&lt;/b&gt;（下图）。&lt;b&gt;这说明因子的表现存在周期性，在不同的时期有些因子会比其他因子更出众。&lt;/b&gt;这使我们不禁发问：&lt;b&gt;能否把这五类因子的投资组合通过某种策略配置在一起，得到一个收益风险比更优的多因子配置组合呢（如更高的夏普率）？&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6189657122e5689dc0bdd3d592be79fb_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;508&quot; data-rawheight=&quot;390&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6189657122e5689dc0bdd3d592be79fb&quot; data-watermark-src=&quot;v2-b912adcec2ebc36892add8b5b9e9ba43&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;本期数据解码投资就来研究研究如何将不同的风险因子配置在一起。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 实验准备&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们以中证 500 指数的成分股作为候选池构建这五类风险因子的&lt;b&gt;纯多头&lt;/b&gt;因子投资组合，按月调仓，回测区间为 2009 年 6 月到 2017 年 2 月。在回测期间内的每一个月，我们都有这五类因子的绝对收益率以及相对中证 500 的相对收益率。&lt;b&gt;在构建单因子的投资组合时采用数学优化的方法，既注重投资组合在目标因子上的暴露又强调投资组合的可投资性&lt;/b&gt;，具体的介绍可以参阅&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38340466&quot;&gt;《因子投资指数化实证》&lt;/a&gt;。有了单一因子的收益率序列后，就可以使用不同的策略把它们配置在一起了。&lt;/p&gt;&lt;p&gt;在实证中，考虑五种策略来将这五些因子配置在一起。&lt;b&gt;这五个策略包括：简单多样化、波动率倒数、跟踪误差倒数、风险平价以及趋势追踪。&lt;/b&gt;它们的业务含义、实现方法以及相应的数学公式总结于下表。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6059a41f099049f9e5250dd1520f063f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;701&quot; data-rawheight=&quot;668&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6059a41f099049f9e5250dd1520f063f&quot; data-watermark-src=&quot;v2-6f564c35ccef7b367930ad7b1e1c2fc0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;显然，简单多样化是将多个因子组合在一起的最简单、直接的方法。它不对因子未来的表现做预期，在任何时候都以等权来配置这些因子。因此它是一个&lt;b&gt;被动的且静态的&lt;/b&gt;配置方法。&lt;/p&gt;&lt;p&gt;相比于简单多样化，其他四种配置方法都需要结合使用者的&lt;b&gt;主观判断&lt;/b&gt;。它们都是从不同方面考虑因子在过去一段时间的表现，从而对未来产生判断，并以此来&lt;b&gt;动态的&lt;/b&gt;配置因子在下一个配置周期的权重。在实证中，用于评判因子过去表现的策略包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;波动率倒数：&lt;/b&gt;这里关注的是因子&lt;b&gt;绝对收益率&lt;/b&gt;（而非对基准指数的相对收益率）的波动率，认为在过去波动率低的在将来会有更高的收益风险比。&lt;/li&gt;&lt;li&gt;&lt;b&gt;追踪误差倒数：&lt;/b&gt;跟踪误差是因子相对于基准指数的&lt;b&gt;相对收益&lt;/b&gt;的波动率，认为在过去跟踪误差低的在将来会有更高的收益风险比。&lt;/li&gt;&lt;li&gt;&lt;b&gt;风险平价：&lt;/b&gt;从风险的角度来实现多样化，要求单一因子对最终投资组合的边际风险贡献相同。在考虑风险时，我们考虑的是因子的&lt;b&gt;绝对收益率&lt;/b&gt;的波动，而非其相对基准指数的相对收益率的波动。&lt;/li&gt;&lt;li&gt;&lt;b&gt;趋势追踪：&lt;/b&gt;考察因子近期风险收益的综合表现，认为因子表现的趋势会延续，即过去好的在未来也会好。计算风险和收益时，使用因子相对基准指数的&lt;b&gt;相对收益率&lt;/b&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对所有这些需要通过计算过去一段时间表现而决定当期因子权重的策略，考察当前时点之前 12 个月内因子的表现。因此，这五种配置策略的实际回测区间要晚于构建因子收益率的回测区间 12 个月；配置策略的回测区间从 2010 年 6 月到 2017 年 2 月。&lt;/p&gt;&lt;p&gt;通过实证想要回答以下几个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;将相关性的因子配置在一起到底能否得到收益风险比更高的投资组合；&lt;/li&gt;&lt;li&gt;纯粹被动的简单多样化策略是否足够优秀；&lt;/li&gt;&lt;li&gt;加入主观判断的另外四种策略相对于被动的简单多样化到底能否取得更好的配置结果。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;b&gt;3 结果分析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;使用这五种策略分别把这些风险因子相对中证 500 指数的相对收益进行配置，以此构建出五个策略的净值曲线，如下图所示。令人意外的而是，它们的效果非常接近。&lt;b&gt;进一步考察可以发现，简单多样化、波动率倒数、以及风险平价三种方法的效果很类似；而追踪误差倒数和因子趋势这两种方法的效果接近，但它们较另外三种方法稍差一些。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07af3bb8b328206863152f57eef3db09_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;546&quot; data-rawheight=&quot;403&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-07af3bb8b328206863152f57eef3db09&quot; data-watermark-src=&quot;v2-19162c29b88ccb4f6098d6ab962bef44&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;为了解释这种结果，&lt;b&gt;一个合理的猜测是这五种配置策略对因子配置的权重十分接近&lt;/b&gt;。下面是这些策略下，因子权重在回测期间变化的堆积图（stack plots）。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7cf39d72896c44b344cf13daf8755921_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;538&quot; data-rawheight=&quot;397&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7cf39d72896c44b344cf13daf8755921&quot; data-watermark-src=&quot;v2-ad0568b1d1b0722fa18f097c06c48b6d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-37189b997147f067a9db6d6067e96579_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;542&quot; data-rawheight=&quot;393&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-37189b997147f067a9db6d6067e96579&quot; data-watermark-src=&quot;v2-897f65f04cc81bf10bfd688219f7bc66&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-23e843d1e80f8d208a65f445fc9aea0f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;541&quot; data-rawheight=&quot;397&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-23e843d1e80f8d208a65f445fc9aea0f&quot; data-watermark-src=&quot;v2-7dd79118019eb99d306b17dd750ffb7b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-394f0484bb46183f1a8073be2ebd7f03_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;543&quot; data-rawheight=&quot;394&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-394f0484bb46183f1a8073be2ebd7f03&quot; data-watermark-src=&quot;v2-d869aa74d14db7733f9be4275be25ff6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dcdfad0c9b66c55660ef68106cb9b985_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;536&quot; data-rawheight=&quot;395&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-dcdfad0c9b66c55660ef68106cb9b985&quot; data-watermark-src=&quot;v2-cd635772a82cc68ab0b37e74b0e1a43b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;简单多样化策略无需多言。所有因子在回测期间等权配置，每个因子的权重为 0.2 恒定。其次，再来看看按照绝对收益率波动率的倒数以及风险平价这两种策略得到的权重。在这两种方法下，因子的权重虽然随时间略有波动，但波动幅度非常小，整体效果与简单多样化非常接近，这解释了为什么它们的净值曲线和简单多样化策略的净值曲线非常接近。&lt;/p&gt;&lt;p&gt;最后来看看根据相对收益率的追踪误差倒数以及趋势追踪策略得到的因子权重。乍一看，在这两种策略中因子的权重随时间变化的非常剧烈。但从本文第一节所示的五种因子的相对收益率表现来看，绿色代表的规模因子以及红色代表的成长因子效果最好。这两个因子在组合中的总权重一定程度上决定了组合的收益情况。对于这两个策略，这两个因子的总权重在整个回测区间基本也都在 40% 到 50% 之间，因此它们的净值走势和其它三种也非常接近。&lt;/p&gt;&lt;p&gt;&lt;b&gt;说完了表象，我们来谈谈本质。上面的结果到底意味着什么？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;波动率的倒数配置策略与风险平价策略关注的都是因子&lt;b&gt;绝对收益率&lt;/b&gt;的波动。反观跟踪误差倒数策略以及趋势追踪策略，它们考量的均为因子&lt;b&gt;相对收益率&lt;/b&gt;的相关指标。&lt;b&gt;在构建单因子的投资组合时，我们在满足可投资性的前提下尽量的追逐投资组合在目标因子上的暴露；高的因子暴露意味着高的主动管理波动，即较大的跟踪误差。&lt;/b&gt;此外，&lt;b&gt;因子的表现存在周期性&lt;/b&gt;，在过去一段时间表现优秀的因子可能在未来就不那么突出。&lt;b&gt;基于相对收益率波动计算权重进行配置在自身波动较大的基础上又引入了因子表现不稳定这方面的误差&lt;/b&gt;，造成因子权重的变化非常剧烈，以及净值表现不敌基于因子绝对收益率波动配置的效果。&lt;/p&gt;&lt;p&gt;再来看看将多个因子配置在一起是否能够获得比单因子的收益风险比更高的组合。如下图所示，&lt;b&gt;五种配置方法都有效的较低了最大回撤，并显著提高了夏普率&lt;/b&gt;。很显然，&lt;b&gt;将多个因子配置在一起获得了更高的收益风险比&lt;/b&gt;。这个结果回答了本文第二节提出的第一个问题。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c12c6f2097e7c50ca99375fd1c299d25_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;562&quot; data-rawheight=&quot;382&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c12c6f2097e7c50ca99375fd1c299d25&quot; data-watermark-src=&quot;v2-b21b132dca331e30997677061c5e33eb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们来回答文本第二节提出的后两个问题。首先可以看到，&lt;b&gt;纯粹被动的、静态的、不带有任何主观判断的简单多样化策略取得了非常好的配置效果&lt;/b&gt;。它的年化收益率在五种策略中排名第二，且最大回撤和平均回撤均最小，夏普率较波动率倒数和风险平价策略不相上下。这两种方法虽然通过主动判断提高了夏普率，但是改观非常有限。需要指出的是，在本实验中，我们没有特别重点的考察不同配置策略下换手率的差异程度。经验表明，带有主观判断的配置策略会造成因子权重的波动，这是不利于降低换手率的。从这个角度来看，&lt;b&gt;波动率倒数和风险平价策略对于夏普率的提高不一定能覆盖潜在的更高的交易成本&lt;/b&gt;。综合考虑我们认为简单多样化策略就足够优秀，可以胜任配置多个因子的重任。&lt;/p&gt;&lt;p&gt;最后，下图比较了简单多样化策略的净值曲线和五个风险因子净值曲线，通过将多个因子配置在一起，净值曲线变得更加平滑。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-91eda40b77ce4c8d4767dcaeffb811e4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;556&quot; data-rawheight=&quot;406&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-91eda40b77ce4c8d4767dcaeffb811e4&quot; data-watermark-src=&quot;v2-6290019679da778c8c9b7cc8036d1451&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;4 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文以中证 500 指数的成分股为例，通过近 7 年的回测数据，比较了五种将多个风险因子配置在一起的策略。结果发现简单多样化是一种非常简单有效的策略，可以取得优秀的配置效果。当然，一些更复杂的动态配置方法，如风险平价以及基于波动率倒数的配置策略对于进一步提高夏普率有帮助，但是能否覆盖潜在高换手率带来的额外交易成本还有待进一步考察。&lt;/p&gt;&lt;p&gt;在投资实践中，如何配置多个因子完全取决于投资经理的自身判断。简单多样化策略赋予所有因子相同的权重且保持不变，它是一个纯被动且静态策略。其他策略则都加入了投资经理对因子效果的主观判断。如果投资经理对自己的判断和能力有信心，那么完全有可能通过动态配置取得更好的结果。当然，这绝不会很容易；至少从实证来看，四种常用的主观动态配置策略都无法有效的击败简单多样化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38340204</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>写给你的金融时间序列分析：应用篇</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38322638.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38322638&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b6857d5c1547296ce043d03ec060d3d1_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;1 书接前文&lt;/b&gt;&lt;/p&gt;&lt;p&gt;《写给你的金融时间序列分析》系列想通过一系列文章使读者&lt;b&gt;了解金融时间序列的特点、熟悉金融时间序列分析的目的、并使用线性但实用的时间序列分析模型对投资品收益率进行预测并以此制定量化投资策略。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在本系列之前的三篇文章中，我们以对收益率建模为目标，按部就班的解释了为实现这个目标所需要的每一块“积木”。作为回顾，这三篇文章的结构为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38320827&quot;&gt;基础篇&lt;/a&gt;：&lt;/b&gt;介绍金融时间序列的特性和进行金融时间序列分析的目的；解释时间序列分析中的核心概念：自相关性。&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38321845&quot;&gt;初级篇&lt;/a&gt;：&lt;/b&gt;说明时间序列建模的过程；介绍时间序列分析中的最基本模型：白噪声和随机游走。&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38322333&quot;&gt;进阶篇&lt;/a&gt;：&lt;/b&gt;介绍时间序列分析中常用的线性模型：自回归模型、滑动平均模型、以及自回归滑动平均模型。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文是系列的最后一篇：应用篇。我们将利用 ARMA 对上证指数收益率序列建模，并以此产生交易信号、构建投资策略，以此展示时间序列分析在量化投资领域的应用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 对时间序列模型预测的正确预期&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过本系列之前的文章的介绍，我们已经知道，时间序列建模的目的是挖掘收益率序列的内在“特性”（自相关性），并在“该特性可以在未来重复”的假设下，对未来的收益率做判断。&lt;b&gt;如果我们想要根据这个收益率预测来构建交易信号&lt;/b&gt;——比如如果预测的收益率为正则买入；如果预测的收益率为负则空仓（因为不容易做空）——&lt;b&gt;那么就必须要对时间序列模型的预测效果有正确的认识。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;来看一个例子。下图是上证指数在 2017 年 4 月 24 日（含）之前 20 个交易日的收益率（注：为了建模，我们当然可以也应该使用更长的历史数据；这里为了绘图清晰仅显示 20 个历史交易日的数据）。那么一个时间序列模型对下一个交易日，即 2017 年 4 月 25 日，的收益率预测会是多少呢？该预测值会接近图中的点 1、2、3 或者 4 吗？&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-086cf99f06989d368312b9557555a1a2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;693&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-086cf99f06989d368312b9557555a1a2&quot; data-watermark-src=&quot;v2-9ff8e7bb9f4a38e653bf05809a14230f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;也许你已经注意到了，我故意挑选的这 4 个点都满足一个条件，就是她们的绝对值都大于 0.5%（其中 1 和 4 两个点的绝对值都高于 1%）。&lt;b&gt;±0.5% 或者 ±1% 的日收益率对于上证指数可以算是正常的取值，因此我们是否应该预期时间序列模型的预测值也有类似的量级呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;事实上，如果我们用 1 年的历史数据来构建 ARMA 模型，并对 2017 年 4 月 25 日的收益率预测时，得到的预测值和它的 95% 的置信区间如下图所示（下图中，模型同时对 2017 年 4 月 25 日之后的 5 个交易日进行预测）。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ffdfadb0a15cd85c0670bc89f74d62a0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;747&quot; data-rawheight=&quot;592&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ffdfadb0a15cd85c0670bc89f74d62a0&quot; data-watermark-src=&quot;v2-12c4a295335a4e7c2b679278713d42f6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;可以看到，收益率的预测值实际上非常接近 0%，远没有到达 ±0.5% 或者 ±1% 的量级。且它的 95% 的置信区间非常宽。这样的结果说明：&lt;/p&gt;&lt;p&gt;&lt;b&gt;当我们用较长的一段历史数据来对时间序列建模时，序列的内在自相关性相对于随机噪声来说非常微弱。模型能够解释的收益率的波动较随机噪声的波动来说微乎其微（上图中绿色的样本内拟合收益率和蓝色的实际收益率之间的残差很大很好的说明了这一点）。这样的结果就是，模型对于收益率的预测的绝对值将会非常接近 0，且该预测值的标准差会很大，造成很宽的置信区间。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果用白话来解释上面这一大段话那就是：&lt;b&gt;如果使用太长的历史数据建模，则序列中表现出来的自相关性非常微弱，时间序列建模“然并卵”。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;既然太长不行，那我们来看看少用点数据建模又如何。假如我们仅仅使用 10 个历史收益率数据建模，则预测结果如下：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-008743f844d1f655f7a863d9d80b413b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;773&quot; data-rawheight=&quot;567&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-008743f844d1f655f7a863d9d80b413b&quot; data-watermark-src=&quot;v2-879f90aebf8ac1f648a69d47ec0b0dbb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这会我们看到，数据少了以后，拟合收益率和实际收益率更加接近；而预测出来的收益率似乎在量级上也更加符合我们 ±0.5% 或者 ±1% 的预期。但是，&lt;b&gt;对于这种预测结果我们敢相信吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;当我们用很短的一段历史数据来对时间序列建模时，几乎“确定、一定以及肯定”的会发生过拟合。事实上，上面的模型是一个带有常数项的 AR(4) 模型，相当于用 10 个历史数据来确定 5 个模型的参数。过拟合的结果是，模型过分解读了样本内的随机扰动，以至于它对样本外数据的预测准确性会非常差（该模型在样本外有很大的方差）。我们无法肯定该模型捕捉到了多少收益率内在的特征，但可以肯定的是它刻画了样本内的很多无效噪声。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果用白话来解释上面这一大段话那就是：&lt;b&gt;如果使用太短的历史数据建模，则模型会过度关注样本内的随机扰动，因此时间序列建模依然“然并卵”。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;归根结底，ARMA 模型是一个统计建模的方法。因此和所有统计模型一样，它在预测的时候既有偏差又有方差。此外，收益率序列中含有大量的随机扰动，且频率越高扰动越强&lt;/b&gt;（比如日内高频数据比日数据的噪声更大；日数据比周数据的噪声更大）。这也为预测本身带来了巨大的困难。因此，在使用时有正确的预期就非常重要。&lt;/p&gt;&lt;p&gt;上面的分析说明，由于收益率的特殊性（特别是我们研究的 A 股收益率的特殊性），使用太长或者太短的数据建模都没什么太大的作用。但是，只要预期正确，这些困难仍然不妨碍我们来尝试一下。下面我们就用 ARMA 模型来为上证指数构建一个投资策略。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 基于 ARMA 模型的投资策略&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们的投资标的为上证指数。回测期为 2013 年 7 月 19 日到 2017 年 4 月 24 日。基于时间序列建模的交易策略如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于每一个交易日，使用之前的 60 个历史日收益率（相当于 3 个月）滚动构建 ARMA 模型，并对该日的收益率预测。在选择模型参数时，ARMA 的阶数 p 和 q 的取值范围均为 1 到 4，并根据 AIC 准则确定最优参数。如果收益率预测为正则在下一个交易日持仓；反之则空仓。不考虑交易成本。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上述策略在回测期的净值和上证指数自身的净值比较如下图所示：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-41b7f28c127f773a0b6b8fc089570139_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;605&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-41b7f28c127f773a0b6b8fc089570139&quot; data-watermark-src=&quot;v2-0d0af20481e487383029092925362661&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;净值曲线的具体参数如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7ab4bbccdc7a634df727f3fa56ff9d44_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;502&quot; data-rawheight=&quot;273&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7ab4bbccdc7a634df727f3fa56ff9d44&quot; data-watermark-src=&quot;v2-f0391d17106f49c7186c0a34dc0d3fa8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;从结果上看，基于 ARMA 建模的策略似乎还不错：它较上证指数本身取得了更高的收益和更低的回撤，因此有更高的夏普率（当然，这部分“得益于”我们没有考虑交易成本）。从净值曲线图上不难发现 ARMA 模型对收益率的预测满足以下几点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;预测较好的捕捉到了 2014 年底到 2015 年中旬的大牛市；&lt;/li&gt;&lt;li&gt;预测一定程度的躲过了 2015 年下半年开始到 2016 年初的几波下跌；&lt;/li&gt;&lt;li&gt;从 2016 年 3 月份开始，ARMA 模型的走势和基准指数接近。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;从 ARMA 的参数上不难解释出现上面结果的原因。下图是 ARMA 模型中的常数项随时间的变化。较 AR 或者 MA 部分的贡献，常数项（收益率的漂移率）的量级对收益率的预测贡献更大。显然，ARMA 模型在牛市时有显著为正的常数项，而在熊市的时候有显著为负的常数项。而自 2016 年 3 月开始，常数项接近 0 但是大部分时间仍然为证，这样的结果就是策略在大比例的时间中会持有上证指数，因此策略在这个时期的走势和指数接近。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-53788e6b31a22b7b0ccaef167388b55e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;608&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-53788e6b31a22b7b0ccaef167388b55e&quot; data-watermark-src=&quot;v2-9bf09a9cb22d7298c855c3074ec689b3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;股灾 n.0 之后，随着监管的加强，除去随机扰动之后的收益率再难呈现大牛大熊市时的那种大幅波动。具有中国特色的 A 股生生变成了具有美国特色的美股（长期有一个正的小幅漂移率，此外就是随机扰动）。由于监管的变化，我国的股市已经悄然发生了结构性变化（regime change）。如果 A 股以后维持这种走势，那么最好的策略也许就是（量化）选股，即便是没有对冲的纯多头选股也大有可为。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 充满希望？长回测期内再看 ARMA 模型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面的结果也许让人感到时间序列分析在量化投资中是充满希望的。但正如本文第二节说明的那样，时间序列分析有其自身存在的问题，且股票的收益率（尤其是高频的收益率）预测这件事本身几乎没有什么规律可循。&lt;/p&gt;&lt;p&gt;如果我们将回测期从过去 4 年拉长到过去 11 年（即考虑过去的两个牛熊周期），结果会怎样的？下图是策略和基准指数的净值曲线。策略可谓令人大跌眼镜。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c87fde736af4a2e4cae911c8e78c2f60_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;598&quot; data-rawheight=&quot;416&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c87fde736af4a2e4cae911c8e78c2f60&quot; data-watermark-src=&quot;v2-c70e5bce77cf875cb80ffed7238fca6d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在回测期内，在尚未考虑交易成本的前提下，策略就远远地跑输了指数。我们当然不能草草的下结论说 ARMA 模型没有用。但是这个结果也清楚的告诉我们，&lt;b&gt;如果想使用模型对收益率建模，我们必须对投资品和模型本身都非常了解，这样才能将二者较好的结合在一起、使模型尽可能的反应投资品的特点。如果仅仅是胡乱的尝试参数，结果往往是徒劳的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为系列的最终章，本文介绍了如何应用 ARMA 模型对上证指数收益率进行预测，并以此产生交易信号、构建交易策略。在上一篇最后，我们提出了这样一个问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;时间序列分析到底是纸上谈兵还是实战利器？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;也许通过本文中简单的实证我们仍然无法确切的回答这个问题。但是，相信通过今天的文章，你能对时间序列建模的预测效果有一个正确的预期，这对于进一步使用预测结果至关重要。我们看到，在过去 4 年的回测期内，ARMA 模型还是取得了不错的结果。更进一步的，即便时间序列模型的预测的准确性不足以使它被独立的用于产生交易信号，它所传达的信息也能够为我们理解投资品本身提供一些启发。&lt;/p&gt;&lt;p&gt;此外，我们当然可以尝试使用更高级的时间序列分析模型，比如用 ARMA 模型预测收益率并结合 GARCH 模型预测收益率波动率。这会取得比单纯的使用 ARMA 模型更加优异的效果。在海外，有人使用 ARMA + GARCH 模型对标普 500 建模并取得了不错的效果（当然那和美股自身的长期慢牛且在股灾时又可以做空有一定关系）。虽然困难重重，但是新模型的提出为我们对收益率建模提供了更广阔的空间和前所未有的可能。&lt;/p&gt;&lt;p&gt;正如这世上没有完美的模型一样，交易中也没有常胜的策略。我们要做的是找到适合自己投资标的以及符合自己交易风格的策略。努力提升交易水平的过程，也正是我们拓宽知识面、历练心性、提高人生修为的过程。&lt;/p&gt;&lt;p&gt;（全系列完）&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38322638</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>写给你的金融时间序列分析：进阶篇</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38322333.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38322333&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-86b33eecc5932c52ce58de801fa2b0ed_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;1 书接前文&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本系列的前两篇——&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38320827&quot;&gt;基础篇&lt;/a&gt;和&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38321845&quot;&gt;初级篇&lt;/a&gt;——分别介绍了金融时间序列分析的核心以及时间序列建模中最简单的模型：白噪声和随机游走。在金融时间序列研究的对象中，投资品的收益率无疑是最重要的一个。挖掘收益率序列的自相关性是金融时间序列的核心内容。无论对于个股还是指数，它们的收益率序列都表现着一定的自相关性。前面的文章说明，白噪声模型假设了时间序列各观测点之间的独立性、无法捕捉收益率序列的自相关性，因此使用白噪声来对投资品收益率建模是不妥的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果投资品收益率真的是个白噪声，那么我们就靠扔硬币猜涨跌就行了。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文为系列的第三篇——进阶篇。&lt;b&gt;我们将介绍时间序列分析中最常用的线性模型：自回归模型、滑动平均模型，以及它们二者结合的自回归滑动平均模型。&lt;/b&gt;在下文中我们将看到，自回归和滑动平均模型这两个模型都从某种程度上符合交易者对收益率变化的理解，因此它们都能刻画出收益率序列中的某种自相关性。&lt;/p&gt;&lt;p&gt;首先来看自回归模型。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 自回归模型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于 A 股的收益率，人们往往有这样的感受：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在大牛市的时候，股票天天涨（每个交易日的收益率都是正的、鲜有回调），万民欢腾；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;在大熊市的时候，股票日日跌（每个交易日的收益率都是负的、拒绝反弹），戾气冲天；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;在震荡市的时候，股票时涨时跌，一买就跌，一卖就涨，颇有价格在某个区间内震荡、收益率呈现均值回复之意。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些感受给我们的启发是，收益率序列的前后观测点之间往往不是独立的，而是以某种自相关性联系在一起。因此，一个很自然的问题就是：&lt;b&gt;能不能用过去的收益率序列对未来的收益率建模？答案是肯定的。这便引出了自回归模型（autoregressive model）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;数学上，满足如下关系的时间序列｛r_t｝被称为一个 p 阶的自回归模型，记为 AR(p) 模型：&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21bf48d50303bde96a513ea0a643a42d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;516&quot; data-rawheight=&quot;144&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-21bf48d50303bde96a513ea0a643a42d&quot; data-watermark-src=&quot;v2-7bb739325cb43b42a587edb27a80d3ee&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;这是一个典型的线性回归模型。它和传统线性回归的不同之处在于自变量是序列自身（历史观测值），而非其他变量，这就是自回归中“自”的由来。&lt;/b&gt;另外，p 阶的意思是模型使用当前时刻 t 之前的 p 个观测值作为自变量对 r_t 建模。这个模型的含义是，r_t 可以表达为 t 时刻之前的 p 个收益率观测值的线性组合以及一个 t 时刻的随机误差 w_t。&lt;/p&gt;&lt;p&gt;&lt;b&gt;p 的取值可以是任何一个正整数，因此最简单的自回归模型就是 AR(1) 模型（p = 1）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在上面这个定义中，我们没有考虑截距项。如果截距项对于待研究的时间序列是必要的，则可以在上面的公式右侧加入一个常数项 c。&lt;/p&gt;&lt;p&gt;&lt;b&gt;另外需要特别说明的是，自回归模型不一定都满足平稳性。&lt;/b&gt;举一个最简单的例子，本系列初级篇介绍的随机游走模型其实就是一个 1 阶自回归模型，满足：x_t = x_[t-1] + w_t。由于 x_t 的方差是时间 t 的函数，因此该序列不满足平稳性。&lt;/p&gt;&lt;p&gt;对于一个 p 阶自回归模型，由它的回归系数 α_i 可以写出它的&lt;b&gt;特征方程（characteristic equation）&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;1-\alpha_1x-\alpha_2x^2-\cdots-\alpha_px^p=0&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;它是一个 p 次多项式，有 p 个解，其中可能既包括实数解又包括复数解；这 p 个解的倒数称为该方程的&lt;b&gt;特征根（characteristic roots）&lt;/b&gt;。&lt;b&gt;自回归模型平稳性要求模型特征方程的所有特征根的模都小于 1。&lt;/b&gt;在上面的随机游走例子中，该模型的特征方程为 1 - x = 0，它的特征根为 1。由于它不满足模小于 1 这个条件，因此该模型不满足平稳性。&lt;/p&gt;&lt;p&gt;对于一个满足平稳性、且假设没有截距项的 p 阶自回归模型，它的均值显然为 0（如果有截距项的话，该时间序列的均值就是 c）；它的不同间隔 k 的自协方差 γ_k 和自相关系数 ρ_k 可以表达为如下的递归方程，又称为 Yule-Walker equations：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4d57f7e4f8c2afc5567c4b09b9915410_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;494&quot; data-rawheight=&quot;199&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4d57f7e4f8c2afc5567c4b09b9915410&quot; data-watermark-src=&quot;v2-1ec9bcabfad91e804b7374c663791350&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在实际中，想要使用自回归模型对收益率建模，必须确定模型的阶数 p。这一点将在本文的第 5 节讨论。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 滑动平均模型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;滑动平均（moving average）模型是另一个常见的线性时间序列模型。&lt;/b&gt;在自回归模型中，我们将收益率 r_t 看作是给定阶数 p 下历史收益率序列的线性组合。&lt;b&gt;与自回归模型不同，滑动平均模型将收益率 r_t 看作是历史白噪声的线性组合。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这听起来也许有些费解。但它背后的逻辑也符合人们的认知。以美股指数（比如标准普尔 500 指数）为例，它给我们的印象是它的收益率有一个微弱的但是大于零的漂移率（drift），形成一个常年慢牛的走势。除了这个 drift 项之外，它的收益率呈不规则的波动。在这种背景下，自回归模型仿佛不是那么好用。&lt;b&gt;而滑动平均模型则是对漂移率之外“随机噪声”建模，它把这些噪声理解为不同时刻出现的影响收益率的新息或者冲击（shocks）。通过对“噪声”建模来预测当前时刻 t 的“噪声”，再和漂移率结合，作为 t 时刻的收益率预测。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;数学上，满足如下关系的时间序列｛r_t｝被称为一个 q 阶的滑动平均模型（为了简化表达式，我们假设漂移率项为 0，即该模型不考虑截距项），记为 MA(q) 模型：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;equation&gt;r_t=\omega_t+\beta_1\omega_{t-1}+\beta_2\omega_{t-2}+\cdots+\beta_q\omega_{t-q}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;&lt;b&gt;与自回归模型不同，滑动平均模型一定满足平稳性。&lt;/b&gt;它的序列均值为 0（如果考虑截距项，则可以在上式右侧加入一个常数 c 代表漂移率，这时序列均值变为 c）。它的各间隔 k 的自相关系数满足：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a440f234ed1a6910f1c68d983cef297d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;533&quot; data-rawheight=&quot;225&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a440f234ed1a6910f1c68d983cef297d&quot; data-watermark-src=&quot;v2-fb7f07de12a74140bba5a01036412309&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其中 β_0 = 1。同样，我们将在第 5 节中介绍如何选择滑动平均模型的阶数 q。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 自回归滑动平均模型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面两节分别讨论了自回归和滑动平均模型。前者用收益率的历史对未来收益率做预测，它背后的逻辑是捕捉市场参与者的有效性（或者非有效性）造成的市场的动量或者反转效应；而后者对噪声建模，其逻辑为突发信息对收益率将会造成冲击（比如上市公司超出预期的财报或者内部交易丑闻等）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;将一个 p 阶的自回归模型和一个 q 阶的滑动平均模型组合在一起，便得到了一个阶数为 (p,q) 的自回归滑动平均模型（autoregressive moving average model），它将 AR 和 MA 模型的优势互补起来。&lt;/b&gt;由于 AR 和 MA 模型都是线性模型，因此它俩的线性组合，即 ARMA 模型，也是线性模型。&lt;/p&gt;&lt;p&gt;&lt;b&gt;数学上，满足如下关系的时间序列｛r_t｝被称为一个阶数为 (p,q) 的自回归滑动平均模型（为了简化表达式，假设模型中的不含常数项），记为 ARMA(p,q) 模型：&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e5958a94b785e506a0eb6592fa2395dc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;592&quot; data-rawheight=&quot;89&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;相比较单一的 AR 或者 MA 模型，ARMA 模型拥有更多的参数。因此它出现过拟合的危险就更高。&lt;/b&gt;虽然它能够捕捉到两个单一模型各自所代表的时间序列自回归性，但是在确定阶数 p 和 q 的时候，我们应时刻谨记，防止过拟合。&lt;/p&gt;&lt;p&gt;下面就来看看如何利用&lt;b&gt;信息量准则（information criterion）和残差自相关检验可以被用来确定 AR、MA 以及 ARMA 模型的阶数。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 确定模型的阶数&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在实际中使用 AR、MA 或 ARMA 模型对收益率建模，必须确定模型的阶数 p 以及 q。显然，p 或者 q 越大，则模型的参数越多，越有可能捕捉到时间序列中不同间隔 k 的自相关性。但是，参数太多的话容易造成过拟合。因此在选择阶数时，&lt;b&gt;必须同时考虑拟合的准确性和防止过拟合。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;在确定模型阶数时，常用的工具是使用信息量准则，包括赤池信息量准则（Akaike information criterion，简称 AIC，由日本统计学家赤池弘次创立）以及贝叶斯信息量准则（Bayesian information criterion，简称 BIC）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;这两个信息量准则的目的都是寻找可以最好地解释数据但包含最少自由参数的模型。它们均使用模型的似然函数、参数个数以及观测点个数来构建一个标量函数，以此作为评价模型好坏的标准。它们的区别是标量函数的表达式有所不同。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;令 L、k、n 表示模型的似然函数，则 AIC 和 BIC 的定义分别为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\begin{array}{rll} \mbox{AIC}&amp;amp;=&amp;amp;-2\ln(L)+2k\\ \mbox{BIC}&amp;amp;=&amp;amp;-2\ln(L)+k\ln(n)\\ \end{array}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;&lt;b&gt;从定义可知，AIC 和 BIC 都由两部分组成：第一部分衡量模型的拟合度，第二部分是对参数个数的惩罚（防止过拟合）。当一个模型能够很好的解释（样本内）数据时，它的似然函数很大，因此第一项 -2ln(L) 就会越小；如果模型的参数越少，则第二项也越少。所以 AIC 和 BIC 总是越小越好。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;随着模型阶数 p 和 q 的增多，模型对样本内的数据的解释程度越来越高，即 -2ln(L) 变小。但是解释度的提高是以参数增多（过拟合风险增大）为代价，因此 2k 或者 kln(n) 增大。所以 AIC 和 BIC 是在这两者之间做权衡。最终选出的最佳参数 p* 和 q* 可以使它们对应的 AIC 或者 BIC 比其他任何参数 p 和 q 对应的 AIC 或者 BIC 更小。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;值得说明的是，AIC 和 BIC 的表达式虽然长得差不多，但是还是有细微的差别。因此在实际中，有可能 AIC 对应的最优阶数（即使得 AIC 最小）和 BIC 对应的最优阶数（即使得 BIC 最小）略有差别。具体选择哪个信息量准则则取决于使用者自身。&lt;/p&gt;&lt;p&gt;当我们使用 AIC 或者 BIC 确定模型的最优阶数之后，便可以对时间序列建模。但是，我们仍然需要检验该模型是否很好的捕捉了时间序列的自相关性。在本系列反复强调过，如果一个模型和原时间序列的残差满足白噪声，那么该模型就是合适的。因此，我们只需要检验残差序列是否在任何间隔 k 上呈现出统计意义上显著的自相关性。在这方面，Ljung–Box 检验是一个很好的方法，&lt;b&gt;它同时检验残差序列各间隔的自相关系数是否显著的不为 0。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Ljung–Box 检验构建了一个满足卡方分布（chi-squared distribution）的统计量，然后计算它出现的概率，以此来判断是否可以在给定的显著性水平下拒绝原假设。这里不再赘述，感兴趣的读者可参阅相关资料。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 利用 AR、MA 以及 ARMA 对上证指数收益率建模&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节中，我们利用上面介绍的 AR、MA 以及 ARMA 对上证指数的对数收益率建模。实验考虑 2012 年 4 月 24 日到 2017 年 4 月 24 日这五年之中上证指数的日收益率。在确定模型阶数时，在给定的 p、q 参数区间内使用不同的参数取值建模，并采用 AIC 准则进行参数选择，在建模时让保留常数项。p 和 q 的区间分别为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;AR 模型：p 的取值范围为 1 到 5；&lt;/li&gt;&lt;li&gt;MA 模型：q 的取值范围为 1 到 5；&lt;/li&gt;&lt;li&gt;ARMA 模型：p 和 q 的取值范围为 1 到 5。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首先来看 AR 模型。根据 AIC 准则，最优的阶数 p* = 4，此时 AIC = -7305.31。使用 Ljung-Box 检验原始对数收益率序列和 AR(4) 模型的残差是否在 20 以内的间隔上有任何自相关性，统计量的 p-value 为 0.005132，说明我们可以在 1% 的显著性水平下拒绝原假设。这意味着残差中存在相关性。事实上，这可以从残差序列的相关图中看到，它说明&lt;b&gt;残差序列在间隔 k 等于 6、8、13 和 19 时仍然有 AR(4) 模型未捕捉到的自相关性&lt;/b&gt;。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eef6ae91c7369c1f7573c1c0a24f4be9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;592&quot; data-rawheight=&quot;437&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-eef6ae91c7369c1f7573c1c0a24f4be9&quot; data-watermark-src=&quot;v2-af984a0d81f33fac875868cb148a34cf&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;再来看看 MA 模型。根据 AIC 准则，最优的阶数同样为 q* = 4，此时 AIC = -7302.70。使用 Ljung-Box 检验原始对数收益率序列和 MA(4) 模型的残差是否在 20 以内的间隔上有任何自相关性，统计量的 p-value 为 0.001371。同样，我们可以在 1% 的显著性水平下拒绝原假设。从下面的残差相关图不难发现，与 AR(4) 模型类似，&lt;b&gt;MA(4) 模型的残差序列在间隔 k 等于 6、8、13 和 19 时仍然有模型未捕捉到的自相关性&lt;/b&gt;。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e3e0151cb236be1f38119a7446a7a53_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;594&quot; data-rawheight=&quot;436&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2e3e0151cb236be1f38119a7446a7a53&quot; data-watermark-src=&quot;v2-ed74eb63bf9f40febc759cecb0845392&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;最后来看看 ARMA 模型。根据 AIC 准则，最优的阶数为 p*=5，q* = 4，此时 AIC = -7330.43。使用 Ljung-Box 检验原始对数收益率序列和 ARMA(5,4) 模型的残差是否在 20 以内的间隔上有任何自相关性，统计量的 p-value 为 0.103462。&lt;b&gt;这说明我们不能在 10% 的显著性水平下拒绝原假设。&lt;/b&gt;它意味着间隔 20 以内，该模型的残差序列没有统计上显著的自相关。从残差序列的相关图中看到，虽然当 k = 12 和 14 时自相关系数超过了 95% 置信区间，但我们无法从统计上否定它们可能是来自随机误差。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c71b61ace13f1230ab2ec2e5bba3c0a8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;596&quot; data-rawheight=&quot;435&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c71b61ace13f1230ab2ec2e5bba3c0a8&quot; data-watermark-src=&quot;v2-073ad2612306970951405ce7ff7c212e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;从残差的自相关性分析来看，ARMA 模型比 AR 和 MA 模型单独使用更有效的捕捉了收益率序列中的自相关性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7 最终章预告&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;众所周知，投资品的收益率序列具有一个属性称为波动聚类（volatility clustering）。&lt;/b&gt;这意味着收益率的波动率是随时间变化的（它是对收益率序列的二阶平稳性假设的直接挑战），这种波动率行为的术语称为&lt;b&gt;条件异方差（conditional heteroskedasticity）&lt;/b&gt;。&lt;b&gt;本文介绍的 AR，MA 和 ARMA 模型均是不条件异方差模型；它们不考虑波动聚类&lt;/b&gt;（事实上，上一节中采用这些模型对过去 5 年上证指数对数收益率建模时，我们看到这些模型无法解释 k 较大时的自相关性，这说明收益率存在长记忆性，这就和波动聚类有关）。为了定量的描述这种特性，我们需要更加复杂的模型。&lt;/p&gt;&lt;p&gt;针对波动率的特性，我们实际上是对收益率的平方直接建模。这时，可以使用自回归条件异方差（Autoregressive Conditional Heteroskedastic，又称 ARCH）模型和广义自回归条件异方差（Generalized Autoregressive Conditional Heteroskedastic，又称 GARCH）模型。(G)ARCH 模型是定量金融中应用广泛，主要用于预测风险。&lt;/p&gt;&lt;p&gt;(G)ARCH 模型主要解决收益率的波动率不恒定的问题。我们在此指出它是为了让读者意识到这一点。但是作为本系列所追求的目标，我们将不会更进一步的深入探讨 (G)ARCH 模型。当然，波动聚类仍然是一个必须要面对的问题，因此在实证中，我们将使用滚动窗口，通过对在每个窗口中的一段收益率序列建模来规避掉波动聚类这个问题，即假设在每一小段窗口内的收益率序列是平稳的。&lt;/p&gt;&lt;p&gt;下一篇文章将是本系列的最终章，它将介绍如何应用 ARMA 模型对上证指数收益率进行预测，并以此产生交易信号、构建交易策略。对于收益率的预测，&lt;b&gt;时间序列分析到底是纸上谈兵还是实战利器？&lt;/b&gt;我们将在下篇见分晓。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38322333</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>写给你的金融时间序列分析：初级篇</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38321845.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38321845&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c36007c2ff692a2f0417ccd5af535bd9_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;1 前文回顾&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前文——&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38320827&quot;&gt;《写给你的金融时间序列分析：基础篇》&lt;/a&gt;——介绍了金融时间序列的核心特性：自相关性；说明&lt;b&gt;金融时间序列分析的核心正是挖掘该时间序列中的自相关性&lt;/b&gt;。一个优秀的模型应该能够有效的刻画原始时间序列中不同间隔的自相关性；而衡量一个模型是否适合原始时间序列的标准正是考察原始值和拟合值之间的残差序列是否近似的为白噪声。&lt;/p&gt;&lt;p&gt;本篇是系列的第二篇，初级篇。白噪声正是本文的内容之一，它是时间序列分析中最基本的模型。在它的基础上延伸出的另一个基本模型便是随机游走。通常，白噪声和随机游走被认为是用来分别描述投资品收益率和价格的最简单模型。我们稍后会看到，对于收益率来说（特别是股指的收益率），白噪声模型并不有效。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 时间序列建模&lt;/b&gt;&lt;/h2&gt;&lt;blockquote&gt;&lt;i&gt;&lt;b&gt;本质上说讲，时间序列模型是一个可以“解释”时间序列中的自相关性的数学模型。&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;能够解释时间序列的自相关性在量化投资领域意义重大：&lt;/p&gt;&lt;p&gt;&lt;b&gt;我们假设金融时间序列（比如投资品的收益率）存在未知的自相关性（当然也伴随着噪声），而这种自相关性体现了该时间序列某种内在的特性（比如趋势、或者均值回复），而这种内在特性是可以延续的（至少在未来短时间内）。因此，我们希望通过对历史数据的拟合找到一个合适的模型，使得它能最大程度的解释该时间序列表现出来的自相关性。基于未来会重复历史的假设，我们在统计上预期这种自相关性存在于未来的序列中，由于这个模型考虑了这种自相关性，因此它将会帮助我们来预测未来。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;时间序列分析为我们研究投资品收益率的行为提供了有力的统计学框架。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在投资中，对收益率的预测显然是非常有用的。如果我们能够预测投资品的涨跌，那么就能基于此构建一个交易策略；如果我们能够预测收益率的波动率，那么就可以进行风险管理（因此我们对时间序列的二阶统计量——如方差——同样感兴趣）。&lt;/p&gt;&lt;p&gt;假设原始时间序列为｛y_t｝，模型拟合出来的序列为｛p_t｝，则残差序列｛e_t｝定义为原始序列和拟合序列的差值：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;e_t=y_t-p_t&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;&lt;b&gt;如果模型很好的捕捉了原始时间序列的自相关性，那么残差序列｛e_t｝应该近似的为白噪声，对任何非零间隔 k，该残差序列的自相关系数 ρ_k 都应该在统计意义上不显著的偏离 0。&lt;/b&gt;当然，这仅仅是我们说该模型是个优秀模型的充分条件，因为一个好模型最关键的还是能产生赚钱的交易信号。因此，&lt;b&gt;模型的检验最终还要看它在样本外预测的准确性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;时间序列建模的过程可以总结如下：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7735442ad0d39a144274baed58223094_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;576&quot; data-rawheight=&quot;559&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7735442ad0d39a144274baed58223094&quot; data-watermark-src=&quot;v2-ce7f17e114f9ec387aec4514b0e653cf&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于一个时间序列，我们总是希望首先画出它的相关图来看看它存在什么样的自相关性。基于对其自相关性的认知，第二步则是选择合适的模型，比如 AR、MA 或者 ARMA 模型，甚至于更高级对波动率建模的 GARCH 模型等。选定模型后，接下来便需要优化模型的参数，以使其尽可能解释时间序列的自相关性。在这一步，我们通过对残差进行自相关性分析来判断模型是否合适。在这方面，Ljung–Box 检验是一个很好的方法，它同时检验给残差序列各间隔的自相关系数是否显著的不为 0。在选定模型参数之后，仍需定量评价该模型在样本外预测的准确性。毕竟，对于样本内的数据，错误的&lt;b&gt;过拟合&lt;/b&gt;总会得到“优秀”的模型，但它们往往对样本外数据的预测效果很差。因此，只有样本外预测的准确性才能客观的评价模型的好坏。如果模型的准确性较差，这说明该模型存在缺陷，无法充分捕捉原序列的自相关性。这时必须考虑更换模型。这就构成了上述步骤的反馈回路，直到最终找到一个既能解释原时间序列自相关性，又能在样本外有不错的准确性的模型。之后，该模型将被用来产生交易型号并构建量化投资策略。&lt;/p&gt;&lt;p&gt;接下来我们就来介绍一个最简单的时间序列模型：白噪声。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 白噪声&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文第一节指出，对于收益率来说，&lt;b&gt;白噪声（white noise）&lt;/b&gt;并不是一个十分有效的模型。那么为什么我们还要研究它呢？这是因为它有一个重要的特性，即&lt;b&gt;序列不相关：一个白噪声序列中的每一个点都独立的来自某个未知的分布，它们满足独立同分布（independent and identically distributed）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;一个（离散）白噪声的定义如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;考虑时间序列｛w_t：t = 1, …, n｝。如果该序列的成分 w_t 满足均值为 0，方差 σ^2，且对于任意的 k ≥ 1，自相关系数 ρ_k 均为 0，则称该时间序列为一个离散的白噪声。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面的定义并没有假设 w_t 来自正态分布。事实上，白噪声对分布没有要求。&lt;b&gt;当 w_t 来自正态分布时，该序列又称为高斯白噪声（Gaussian white noise）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据白噪声的定义，&lt;b&gt;一个白噪声序列显然满足平稳性要求&lt;/b&gt;。它的均值和二阶统计量为： &lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cd4f0135f493fecc681dc13bac688e05_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;410&quot; data-rawheight=&quot;139&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-cd4f0135f493fecc681dc13bac688e05&quot; data-watermark-src=&quot;v2-f8fef613e29a3d3b60279c1ffcc312a9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们已经多次强调，当一个模型很好的捕捉了原始时间序列的自相关性，它的残差序列就应该没有任何（统计意义上显著的）自相关性了。换句话说，一个优秀模型的残差序列应该（近似）为一个白噪声。&lt;b&gt;因此，使用白噪声序列的性质可以帮助我们确认我们的残差序列中没有任何相关性了，一旦残差序列没有相关性便意味着模型是原始时间序列的一个良好的拟合。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在白噪声模型中，唯一的参数就是方差 σ^2。这个参数可以通过历史数据估计得到。在本系列的第一篇文章中，我们曾给出了一个白噪声序列的相关图（如下），该序列由标准正态分布生成（因此为高斯白噪声），共 500 个观测值。可以看到，对图中显示的间隔 k 的取值，对所有 k ≥ 1 均有自相关系数在统计上等于 0。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f0f9ea4e7ae4fc5091dc863859dc098f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;540&quot; data-rawheight=&quot;399&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f0f9ea4e7ae4fc5091dc863859dc098f&quot; data-watermark-src=&quot;v2-ec166fd61b51fac2f231f2299a3fda60&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;4 随机游走&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;将白噪声模型进行一步延伸，便得到&lt;b&gt;随机游走（random walk）&lt;/b&gt;模型，它的定义如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于时间序列｛x_t｝，如果它满足 x_t = x_[t-1] + w_t，其中 w_t 是一个均值为 0、方差为 σ^2 的白噪声，则序列｛x_t｝为一个随机游走。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由定义可知，在任意 t 时刻的 x_t 都是不超过 t 时刻的所有历史白噪声序列的总和，即：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;x_t=w_t+w_{t-1}+w_{t-2}+\cdots+w_{0}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;随机游走的序列均值和方差为：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f0673ef0462bdc263eca3565bfc462d9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;543&quot; data-rawheight=&quot;150&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f0673ef0462bdc263eca3565bfc462d9&quot; data-watermark-src=&quot;v2-a8cd2cff65c160c11b54c32db07270ae&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;虽然均值不随时间 t 改变，但是由于方差是 t 的函数，因此随机游走不满足稳定性。随着 t 的增加，x_t 的方差增大，说明其波动性不断增加。&lt;/b&gt;对于任意给定的 k，通过以下推导给得出随机游走的自协方差：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ca669393e65bec23de9253d20fbfcd2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;553&quot; data-rawheight=&quot;252&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4ca669393e65bec23de9253d20fbfcd2&quot; data-watermark-src=&quot;v2-28a8340b87fb5a8e137c701d2e0dcd8f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上述推导中使用了独立随机变量的方差可加性。有了自协方差和方差，便可以方便的求出随机游走的自相关函数：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1f53c08421c0880ed7b5f7c6309a5542_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;443&quot; data-rawheight=&quot;245&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-1f53c08421c0880ed7b5f7c6309a5542&quot; data-watermark-src=&quot;v2-fa16c36d218d15a955ea7b37d63766f7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;显然，自相关系数既是时间 t 又是间隔 k 的函数。&lt;b&gt;ρ 的表达式说明，对于一个足够长的随机游走时间序列（t 很大），当考察的自相关间隔 k 很小时，自相关系数近似为 1。&lt;/b&gt;这是随机游走的一个非常重要的特性，不熟悉它往往容易造成不必要的错误。&lt;/p&gt;&lt;p&gt;举个例子。我们通常假设股价的对数收益率符合正态分布，因此股价对数是一个布朗运动（随机游走的一种特殊形式）。&lt;b&gt;如果当前的（对数）股价是 x_t，由随机游走的特性可知，t + 1 时刻的股价的条件期望为 E[x_[t+1] | x_t] = x_t，即我们对下一时点的股价的最好的猜测就是当前的价格。随机游走是一个鞅（martingale）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;假如我们有一个预测股价的模型，而该模型就是用 t 时刻的股价作为对 t + 1 时刻的股价的预测，则该模型的预测值和实际值之间的相关系数就等于股价序列的间隔为 1 的自相关系数。如果股价近似的为随机游走，那么由它的性质可知，间隔为 1 的自相关系数非常接近 1。因此我们的股价预测模型——用今天的价格作为明天的价格的预测——的预测值和实际值之间的相关系数也非常接近 1。这会给我们造成错觉：这个模型相当准确。&lt;b&gt;不幸的是，这个模型猜测的收益率在任何时刻都为 0，因此它对于我们构建交易信号毫无作用。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我看到过无数的学术论文（大多是硕士论文）中，针对投资品价格本身构建&lt;b&gt;自回归&lt;/b&gt;模型。&lt;b&gt;独立变量就包括历史价格&lt;/b&gt;，用它们和其他一些基本面或宏观经济数据来预测下一个交易日的股价。从上面的分析可知，这样的模型将会“精准的毫无用处”，因为回归模型中历史价格的系数之和将会非常接近 1。&lt;/p&gt;&lt;p&gt;&lt;b&gt;任何价格序列的自回归模型都是耍流氓。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;利用本文第三节例子中的白噪声序列，便可以构建一个人工随机游走序列的例子。它的轨迹如下图所示。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-75f9555df40653243c77bbb5c5c86a1c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;527&quot; data-rawheight=&quot;377&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-75f9555df40653243c77bbb5c5c86a1c&quot; data-watermark-src=&quot;v2-d00bb34a735f2cd19f94ff1eea78a8b7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;不出意外，当间隔 k 相对于时间序列的长度很小时，它的自相关系数（下图）非常接近 1，这源自随机游走的性质。不要忘了，随机游走是对股价的对数建模。因此，这种自相关性对于基于收益率预测的投资策略并没有帮助。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff634765b5dd49baac3ceff6c33626e9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;538&quot; data-rawheight=&quot;392&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ff634765b5dd49baac3ceff6c33626e9&quot; data-watermark-src=&quot;v2-11dcefdcbec6d3d2d69765e24f7bc281&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;事实上，如果（对数）股价严格的符合随机游走，那么该时间序列的方差将会随时间线性增长。&lt;/b&gt;这说明，长期来看它将呈现出巨大的波动。下图为来自同一个分布的 15 条随机游走的轨迹。随着时间的推进，这些轨迹上对应观测值的波动越来越大，充分的展现出随机性。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6e01afedc8b41a638b198e182ee710d7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;682&quot; data-rawheight=&quot;621&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6e01afedc8b41a638b198e182ee710d7&quot; data-watermark-src=&quot;v2-9e770247f73cc010e027d10e7826a843&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;5 用白噪声对收益率建模&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如果股票的对数收益率为白噪声，那么它的自相关系数应该在任何非零的间隔上都在统计意义上等于零。下面我们就来看看真实的股票收益率是否满足这一点。为此，考虑一支个股（万科）和一个股指（上证指数）。&lt;/p&gt;&lt;p&gt;以日频为例，通过交易日的复盘后收盘价可以算出对数收益率：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;r_t=\ln x_t-\ln x_{t-1}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;首先来看看万科，当考察期为过去 10 年时，万科的对数收益率的相关图为：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3b083e3b1c91bca2ef7b91c5f13e710f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;612&quot; data-rawheight=&quot;454&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3b083e3b1c91bca2ef7b91c5f13e710f&quot; data-watermark-src=&quot;v2-a2e6dae65be9ea2b79e228394c855779&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图指出，在间隔为 2 和 4 时，该收益率序列表现出了统计意义上显著的相关性。当然，由于图中的蓝色区域仅仅是 95% 的置信区间，因此仅仅根据随机性也很可能出现在一个或者两个间隔上的自相关系数处于置信区间之外的情况。因此，根据上面的结果，我们并不能一定就说白噪声不是万科收益率的一个适当的模型。&lt;/p&gt;&lt;p&gt;如果我们把考察的窗口缩短到过去 5 年，则万科的对数日收益率序列的相关图变为：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e43b1f56ff4ca5dcd1d8bc99aba4de1d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;613&quot; data-rawheight=&quot;454&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e43b1f56ff4ca5dcd1d8bc99aba4de1d&quot; data-watermark-src=&quot;v2-f64f2bd815f5035a80ea9e5a0579f95c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当 k = 1，2，3，4 以及 14 的时候，自相关系数都超过了置信区间，即在 5% 的显著性水平下不为零。&lt;b&gt;我们无法再无视这样的结果而把它们都归结于随机性。&lt;/b&gt;该相关图清晰地说明白噪声不能有效的解释收益率序列中的自相关性。&lt;/p&gt;&lt;p&gt;对于上证指数，这种结论则更加明显。&lt;b&gt;无论是考察 10 年还是 5 年的窗口，上证指数的对数收益率均在不同的间隔上表现出了显著的自相关（下图），且它比个股的自相关性更加显著。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-af83eb2f9ea25544e0f3a07a69105bb1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;618&quot; data-rawheight=&quot;447&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-af83eb2f9ea25544e0f3a07a69105bb1&quot; data-watermark-src=&quot;v2-11d0cecb10707c96294b92975ceb9bed&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c384709c9442c142f50a4c8f82454d37_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;605&quot; data-rawheight=&quot;442&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c384709c9442c142f50a4c8f82454d37&quot; data-watermark-src=&quot;v2-26a1ec0b127c6b6bf0dd2b9d3232eeb1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;这个结果说明上证指数的对数收益率序列无法用白噪声来建模。更有意思的是，当 k 较小或者较大时，上证指数的收益率均表现出了自相关性，这说明它既有短记忆又有长记忆。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 下文预告&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文的分析引出如下的结论：&lt;/p&gt;&lt;p&gt;&lt;b&gt;无论对于个股或是指数，它们的收益率序列中都存在某种自相关性，不满足白噪声模型。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因此，我们必须考虑更加高级的时间序列模型来对自相关性建模。在这方面，自回归模型（AR）和滑动平均模型（MA），以及它们二者的组合——自回归滑动平均模型（ARMA）——都是非常有力的工具。它们将是本系列下一篇的内容。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38321845</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>写给你的金融时间序列分析：基础篇</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38320827.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38320827&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c05d4ce3b1c6c65ab4587cc1f8020589_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;1 前言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;时间序列分析（time series analysis）是量化投资中的一门基本技术。时间序列是指在一定时间内按时间顺序测量的某个变量的取值序列。&lt;/b&gt;比如变量是股票价格，那么它随时间的变化就是一个时间序列；同样的，如果变量是股票的收益率，则它随时间的变化也是一个时间序列。&lt;b&gt;时间序列分析就是使用统计的手段对这个序列的过去进行分析，以此对该变量的变化特性建模、并对未来进行预测。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;时间序列分析试图通过研究过去来预测未来。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;时间序列分析在工程学、经济学、气象学、金融学等众多领域有着广泛的应用。在金融学领域，介绍时间序列分析的优秀书籍层出不穷。其中最家喻户晓之一的要数美国芝加哥大学商学院 Ruey S. Tsay 教授撰写的金融时间序列分析——Analysis of Financial Time Series（下图，该书也同时有中文版）。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-457ea66abae152c0d2252d36a3f28ca8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;562&quot; data-rawheight=&quot;350&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-457ea66abae152c0d2252d36a3f28ca8&quot; data-watermark-src=&quot;v2-9b18503e0c8817d941e8d615c655f728&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;金融时间序列分析要求使用者具备一定的高等数学知识。特别是其中一些高级的模型，如分析波动率的 ARCH/GARCH 模型、极值理论、连续随机过程、状态空间模型等都对使用者的数学水平有着极高的要求。因此，在很多人眼中，金融时间序列分析无疑带着厚厚的面纱，令人望而却步。&lt;/p&gt;&lt;p&gt;然而，如果学习的目的是为&lt;b&gt;了解金融时间序列的特点、熟悉金融时间序列分析的目的、并使用线性但非常实用的模型（比如 ARMA 模型）对金融时间序列进行预测并以此制定量化策略&lt;/b&gt;，那么只要具备简单的统计学基础，就完全能够实现这些目标。&lt;/p&gt;&lt;p&gt;出于这个目的，从本周开始，量化核武研究这个专题下将推出四篇文章，深入浅出的介绍金融时间序列分析的相关知识。该系列不会涉及上面提到的那些高级模型；相反的，&lt;b&gt;本系列以对股票收益率建模并构建投资策略为目标，按部就班的把实现这个目标所需要的每一块“积木”清晰地呈献给读者&lt;/b&gt;。这四篇文章的结构为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;基础篇（本文）：&lt;/b&gt;介绍金融时间序列的特性和进行金融时间序列分析的目的；解释时间序列分析中的核心概念：序列相关性（又称自相关性）。&lt;/li&gt;&lt;li&gt;&lt;b&gt;初级篇：&lt;/b&gt;说明时间序列建模的过程；介绍时间序列分析中的最基本模型：白噪声和随机游走。&lt;/li&gt;&lt;li&gt;&lt;b&gt;进阶篇：&lt;/b&gt;介绍时间序列分析中常用的线性模型：AR、MA、ARMA等。&lt;/li&gt;&lt;li&gt;&lt;b&gt;应用篇：&lt;/b&gt;利用 ARMA 对上证指数收益率序列建模，并以此产生交易信号、构建投资策略，以此展示时间序列分析在量化投资领域的应用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;本系列文章会避免过多罗列晦涩难懂的大数学（但会涉及必要的数学知识），希望带你走入金融时间序列分析的大门，为你今后学习更高级的模型奠定一些基础。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是写给你的金融时间序列分析。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 金融时间序列分析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了避免下文中涉及的概念过于抽象，我们假设本文讨论的金融时间序列为&lt;b&gt;投资品的收益率序列&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;金融时间序列分析考虑的是金融变量（比如投资品收益率）随时间演变的理论和实践。任何金融时间序列都包含不确定因素，因此统计学的理论和方法在金融时间序列分析中至关重要。金融资产的时间序列常被看作是未知随机变量序列随时间变化的一个实现。通常假设该随机变量序列仅在时间轴上的离散点有定义，则该随机变量序列就是一个离散随机过程。比如股票的日收益率就是离散的时间序列。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在量化投资领域，我们的目标是通过统计手段对投资品的收益率这个时间序列建模，以此推断序列中不同交易日的收益率之间有无任何特征，以此来预测未来的收益率并产生交易信号。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个时间序列可能存在的特征包括以下几种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;趋势：&lt;/b&gt;趋势是时间序列在某一方向上持续运动（比如牛市时股市每天都在上涨，股票收益率持续为正；熊市时股市每天都在下跌，股票收益率持续为负）。趋势经常出现在金融时间序列中，特别是大宗商品价格；许多商品交易顾问（CTA）基金在他们的交易算法中都使用了复杂的趋势识别模型。&lt;/li&gt;&lt;li&gt;&lt;b&gt;季节变化：&lt;/b&gt;许多时间序列中包含季节变化。在金融领域，我们经常看到商品价格的季节性变化，特别是那些与生长季节或温度变化有关的商品，比如天然气。&lt;/li&gt;&lt;li&gt;&lt;b&gt;序列相关性：金融时间序列的一个最重要特征是序列相关性（serial correlation），又称为自相关性（autocorrelation）。&lt;/b&gt;以投资品的收益率序列为例，我们会经常观察到一段时间内的收益率之间存在正相关或者负相关。此外，波动聚类（volatility clustering）也是一种序列相关性，它意味着高波动的阶段往往伴随着高波动的阶段出现、低波动的阶段往往伴随着低波动的阶段出现，这在量化投资中尤为重要。比如下图为 2001 年到 2017 年上证指数日收益率的标准差，从中可以清晰的看到波动聚类。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-966ea84da2969a847b5c97da07be3282_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;552&quot; data-rawheight=&quot;370&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-966ea84da2969a847b5c97da07be3282&quot; data-watermark-src=&quot;v2-5cb19fcfe5ed5c79e52d4e9142062c2f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;随机噪声：&lt;/b&gt;它是时间序列中除去趋势、季节变化和自相关性之后的剩余随机扰动。由于时间序列存在不确定性，随机噪声总是夹杂在时间序列中，致使时间序列表现出某种震荡式的无规律运动。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;量化投资的交易者的目标是利用统计建模来识别金融时间序列中潜在的趋势、季节变化和序列相关性。&lt;/b&gt;利用一个好的模型，金融时间序列分析的主要应用包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;预测未来：&lt;/b&gt;为了成功交易，我们需要在&lt;b&gt;统计上&lt;/b&gt;“准确”预测未来的投资品价格或者收益率。&lt;/li&gt;&lt;li&gt;&lt;b&gt;序列模拟：&lt;/b&gt;一旦发现了金融时间序列的统计特征，我们可以使用它们来模拟时间序列并进行场景分析。这对于估计交易次数、期望交易成本、期望收益率至关重要，从而最终定量的计算一个策略或者投资组合的风险分布和盈利水平。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上文说到，金融时间序列的关系中，最重要的当属自相关性。这是因为我们很容易从一个时间序列中识别出趋势以及季节变换。当除去这些关系后，剩下的时间序列往往看来十分随机。然而对于金融时间序列，比如投资品的收益率，看似随机的时间序列中往往存在着惊人的自相关。&lt;b&gt;对自相关建模并加以利用能够大幅提高交易信号的准确性。&lt;/b&gt;配对交易的均值回复策略就是这么一个例子。均值回复策略利用一对投资品价差序列的&lt;b&gt;负相关性&lt;/b&gt;进行投资，产生做多或者做空的交易信号，实现盈利。&lt;/p&gt;&lt;p&gt;&lt;b&gt;金融时间序列分析的核心就是挖掘该时间序列中的自相关性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文的下面几节就来介绍如何计算时间序列的自相关性。为此，首先来看两个基础概念：协方差和相关系数。之后会谈及时间序列的稳定性，它是时间序列分析的一个必要前提。最后介绍时间序列的自相关性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 协方差和相关系数&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节介绍概率论中的基础概念：协方差和相关系数。熟悉它们的读者可跳过。&lt;/p&gt;&lt;p&gt;假设两个随机变量 X 和 Y 满足未知的概率分布（可以是同分布也可以是不同的分布）。E[] 为求解数学期望的运算符。X 和 Y 的&lt;b&gt;总体协方差（population covariance）&lt;/b&gt;为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\mbox{Cov}(X,Y)=\mbox{E}[(X-\mu_X)(Y-\mu_Y)]&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中，μ_X 和 μ_Y 分别为 X 和 Y 的&lt;b&gt;总体均值（population mean）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;协方差告诉我们两个随机变量是如何一起移动的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在实际中，由于总体的概率分布未知，我们只能通过 X 和 Y 的观测值来计算&lt;b&gt;样本均值（sample mean）&lt;/b&gt;。假设我们各有 X 和 Y 的观测值 n 个，则它们的&lt;b&gt;样本协方差（sample covariance）&lt;/b&gt;为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar X)(Y_i-\bar Y)&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中， &lt;equation&gt;\bar X&lt;/equation&gt; 和 &lt;equation&gt;\bar Y&lt;/equation&gt; 为 X 和 Y 的样本均值。上面公式中右侧之所以除以 n - 1 而非 n 的原因是，这么做可以保证样本协方差是（未知）总体协方差的一个&lt;b&gt;无偏估计（unbiased estimator）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;假设我们随机生成两个随机变量 X 和 Y 的序列，它们的散点图如下。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a45acbf734df887c7aba5ff0f07986e8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;539&quot; data-rawheight=&quot;384&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a45acbf734df887c7aba5ff0f07986e8&quot; data-watermark-src=&quot;v2-39063d76fb8de39aacecc5789e93bb09&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;按照上面的公式，X 和 Y 的样本协方差为 893.215203。它有什么意义呢？在回答这个问题之前，让我们再来看另外两个变量，我们称之为 X100 和 Y100。它们分别定义为 X100 = 100 * X 和 Y100 = 100 * Y。可见，它们仅仅是 X 和 Y 各乘以 100 得到的。X100 和 Y100 的样本协方差为 8932152.03，这是 X 和 Y 的协方差的 10000 倍。&lt;b&gt;然而，如果仅仅因此就得出 X100 和 Y100 的相关性高于 X 和 Y 的相关性就大错特错了。&lt;/b&gt;事实上，由于 X100 和 Y100 是由 X 和 Y 分别乘以 100 得到的，因此它们之间的相关性显然和 X 与 Y 的相关性相同。&lt;/p&gt;&lt;p&gt;上面这个例子说明使用协方差衡量变量相关性的&lt;b&gt;致命缺点：协方差是有量纲的，因此它的大小受随机变量本身波动范围的影响&lt;/b&gt;。在上个例子中，当两个随机变量的波动范围扩大 100 倍后，它们的协方差扩大了 10000 倍。因此，人们希望使用某个和协方差有关，但是又是&lt;b&gt;无量纲&lt;/b&gt;的测量来描述两个随机变量的相关性。&lt;b&gt;最简单的做法就是用变量自身的波动对协方差进行标准化。相关系数（correlation 或者 correlation coefficient）便由此得来。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;令 ρ 表示 X 和 Y 的&lt;b&gt;总体相关系数（population correlation）&lt;/b&gt;，它的定义为：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\rho(X,Y)=\frac{\mbox{E}[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X\sigma_Y}=\frac{\mbox{Cov}(X,Y)}{\sigma_X\sigma_Y}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中 &lt;equation&gt;\sigma_X&lt;/equation&gt; 和 &lt;equation&gt;\sigma_Y&lt;/equation&gt; 分别为 X 和 Y 的&lt;b&gt;总体标准差（population standard deviation）&lt;/b&gt;。通过使用 X 和 Y 的标准差对它们的协方差归一化，ρ 的取值范围在 -1 到 +1 之间，即 [-1, +1]：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;ρ(X, Y) = 1 表示 X 和 Y 之间存在确切的线性正相关；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;ρ(X, Y) = 0 表示 X 和 Y 之间不存在任何线性相关性；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;ρ(X, Y) = -1 表示 X 和 Y 之间存在确切的线性负相关。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得一提的是，&lt;b&gt;相关系数仅仅刻画 X 和 Y 之间的线性相关性；它不描述它们之间的（任何）非线性关系&lt;/b&gt;。在实际中，由于总体的概率分布未知，我们只能通过 X 和 Y 的观测值来计算 X 和 Y 的&lt;b&gt;样本相关系数（sample correlation）&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\hat\rho(X,Y)=\frac{\sum_{i=1}^n(X_i-\bar X)(Y_i-\bar Y)}{\sqrt{\sum_{i=1}^n(X_i-\bar X)^2\sum_{i=1}^n(Y_i-\bar Y)^2}}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;在上面的例子中，无论考虑 X 和 Y 还是 X100 和 Y100（即无论如何缩放 X 和 Y），它们的相关系数都是 0.894655，这和我们的预期相符。由于这个数值非常接近 1，它意味着 X 和 Y 之间存在很强的线性正相关。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 时间序列的平稳性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;平稳性（stationarity）是时间序列分析的基础。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了通俗的理解平稳性，来看下面这个类比（这是我能想到的最好的例子）。假如某股票的日收益率由转轮盘赌决定：转到不同数字就对应不同的收益率。在每个时刻 t，我们都转同一个轮盘赌并确定收益率 r_t。只要这个轮盘不变，那么对于所有的 t，r_t 的概率分布都是一样的、不随时间变化。这样的时间序列 ｛r_t｝ 就是（严格）平稳的。如果从某个时刻 t’ 开始，轮盘发生了变化（比如轮盘上面的数字变多了），那么显然从 t ≥ t’ 开始，r_t 的分布就便随之发生变化，因此时间序列 ｛r_t｝ 就不是平稳的。&lt;/p&gt;&lt;p&gt;在数学上，时间序列的&lt;b&gt;严平稳（strictly stationary）&lt;/b&gt;有着更精确的定义：它要求时间序列中任意给定长度的两段子序列都满足相同的联合分布。&lt;b&gt;这是一个很强的条件，在实际中几乎不可能被满足。&lt;/b&gt;因此我们还有&lt;b&gt;弱平稳（weakly stationary）&lt;/b&gt;的定义&lt;b&gt;，它要求时间序列满足均值平稳性（stationary in mean）和二阶平稳性（secondary order stationary）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;如果一个时间序列 ｛r_t｝ 满足以下两个条件，则它是弱平稳的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;对于所有的时刻 t，有 E[r_t] = μ，其中 μ 是一个常数。&lt;/li&gt;&lt;li&gt;对于所有的时刻 t 和任意的间隔 k，r_t 和 r_(t-k) 的协方差 σ(r_t, r_(t-k)) = γ_k，其中 γ_k 与时间 t 无关，它仅仅依赖于间隔 k。特别的，当 k = 0 时，这个特性意味着 σ(r_t, r_t) —— r_t 的方差 —— 不随时间变化，等于一个与时间 t 无关的常数 γ_0，这称为&lt;b&gt;方差平稳性（stationary in variance）&lt;/b&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;弱平稳假设对于分析投资品收益率至关重要。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了解释这一点，来看一个例子。假设我们想知道 2017 年 5 月 16 日这天上证指数收益率的均值是多少，而我们的猜想是它来自一个未知的分布。也许你会马上说“查一下 Wind 不就知道了？上证指数那天的收益率是 0.74%”。注意，&lt;b&gt;0.74% 这个数值仅仅是那天上证指数未知收益率分布的一个实现（realization）&lt;/b&gt;！它不是均值，因此从时间序列分析的角度来说仅仅知道 0.74% 远远不够。&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于一般的未知概率分布，只要通过进行大量重复性实验，就可以有足够多的独立观测点来进行统计推断（计算均值和方差这些统计量）。&lt;/b&gt;按照这个思路，我们必须把 2017 年 5 月 16 日这一天经历许多遍，得到许多个那天的收益率观测值，然后用这些观测值计算出收益率的均值。&lt;b&gt;不幸的是，历史只发生一次，时间也一去不复返，我们只能实实在在的经历一遍 2017 年 5 月 16 日，只能得到一个收益率的观测点，即 0.74%。因此这个方法对于金融数据是行不通的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;然而，如果我们假设上证指数的收益率序列满足弱平稳，就柳暗花明了。根据弱平稳假设，上证指数的日收益率序列&lt;/b&gt; &lt;b&gt;｛r_t｝ 的均值是一个与时间无关的常数，即 E[r_t] = μ。这样便可以利用一段时间的历史数据来计算出日收益率的均值。&lt;/b&gt;比如我们可以对上证指数在 2017 年交易日的日收益率序列取平均，把它作为对总体均值 μ 的一个估计。根据弱平稳性，该平均值也正是 2017 年 5 月 16 日的收益率均值。&lt;/p&gt;&lt;p&gt;同样的道理，在弱平稳的假设下，可以根据历史数据方便的对时间序列的诸多统计量进行推断。&lt;b&gt;在金融文献中，也通常假定投资品收益率序列是弱平稳的。只要有足够多的历史数据，这个假定可以用实证方法验证。比如，我们可以把数据分成若干个子集，并分别计算每个子集的统计量，然后通过统计的手段检验这些来自不同子集的统计量的一致性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;需要说明的是，即便是弱平稳性，有时金融数据也无法满足。回想第二节中那个上证指数日收益率标准差的图，它清晰的说明，在 2001 到 2017 年之间，标准差是随时间变化的。这意味着在这段时间内，收益率序列不满足二阶平稳性。对于此，我们可以通过更复杂的非线性模型对波动率建模（比如 GARCH），又或者可以把时间段细分为更短的区间，使得在每个小区间内的收益率序列尽量满足弱平稳性。&lt;/p&gt;&lt;p&gt;有了上一节和本节的内容做铺垫，下面我们就可以聊聊时间序列的自相关性了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 自相关性和自相关函数&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;假设我们有弱平稳的投资品收益率序列 ｛r_t｝。自相关性考察的是 t 时刻的收益率 r_t 和距当前任意间隔 k 时刻的收益率 r_(t-k) 之间的线性相依关系（k 的取值是所有 ≥ 0 的整数）。由于 r_t 和 r_(t-k) 来自同一个时间序列，因此我们将第三节中的相关系数的概念应用到 r_t 和 r_(t-k) 上，便推广出自相关系数（autocorrelation）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;定义：r_t 和 r_(t-k) 的相关系数称为&lt;/b&gt; &lt;b&gt;r_t 的间隔为 k 的自相关系数。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在弱平稳假设下，这个间隔为 k 的自相关系数与时间 t 无关，而仅仅与间隔 k 有关，由 ρ_k 表示。由第三节中介绍的相关系数的定义可知：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\rho_k=\frac{\mbox{Cov}(r_t,r_{t-k})}{\sigma_{r_t}\sigma_{r_{t-k}}}=\frac{\mbox{Cov}(r_t,r_{t-k})}{\sigma_{r_t}\sigma_{r_t}}=\frac{\gamma_k}{\gamma_0}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;上面的推导中用到了弱平稳的性质，即协方差和方差平稳性（换句话说，二阶平稳性）。从这个定义不难看出，当 k = 0 时有：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\rho_0=\frac{\gamma_0}{\gamma_0}=1&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;这表示 r_t 的间隔为 0 的自相关系数恒定为 1。此外，ρ_k 还有如下的性质：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\rho_k=\rho_{-k}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;&lt;equation&gt;-1\le\rho_k\le 1&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;和第三节一样，上面定义的 ρ_k 是总体的统计特性。实际中，我们仍然只能通过有限的样本数据来计算样本的统计特性。令 ζ_k 为与 ρ_k 对应的样本统计量，则有：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\begin{array}{rll} \zeta_k&amp;amp;=&amp;amp;\displaystyle\frac{c_k}{c_0}\\ c_k&amp;amp;=&amp;amp;\displaystyle\frac{1}{n}\sum_{t=1}^{n-k}(r_t-\bar r)(r_{t+k}-\bar r) \end{array}&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;上式中，c_k 是 r_t 的&lt;b&gt;间隔为 k 的样本自协方差（sample autocovariance of lag k）&lt;/b&gt;；ζ_k 为 r_t 的&lt;b&gt;间隔为 k 的样本自相关系数（sample autocorrelation of lag k）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果把 ζ_k 看作是 k 的方程，则它通常被称为样本自相关方程（sample autocorrelation function；同样的，ρ_k 为总体自相关方程），它刻画了时间序列的重要特性。利用相关图（correlogram）可以清晰地看到 ζ_k 是如何随间隔 k 变化的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下图为两个假想时间序列的相关图。它们呈现出完全不同结构的自相关性。事实上，第一个相关图的时间序列存在明显的趋势；而第二个相关图的时间序列存在明显的周期性。这两个例子说明相关图可以告诉我们很多时间序列的内在特性。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-05204d0d5aa568ce8514db304105053f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;472&quot; data-rawheight=&quot;640&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-05204d0d5aa568ce8514db304105053f&quot; data-watermark-src=&quot;v2-33238f9a1f34b8fa472270a9e6b3180d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;金融时间序列的相关图虽然远没有这两个假象序列的相关图这么有结构，&lt;b&gt;但相关图在我们对时间序列建模时至关重要&lt;/b&gt;。之前已经说过，金融时间序列，特别是收益率序列，最重要的特性是一些不容易被发现的自相关性。（通常股票的收益率序列没有季节性或者明显的趋势性；即便是弱趋势也可以由自相关性反应。）因此，拿来一个收益率序列，&lt;b&gt;只要画出相关图，就可以检测该序列在任何间隔 k 有无统计上显著的自相关性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;对金融时间序列建模，最重要的就是挖掘出该序列中的不同间隔 k 的自相关性。相关图可以帮助我们判断模型是否合适。&lt;/b&gt;这是因为金融时间序列的特征中往往包括相关性和随机噪声。&lt;b&gt;如果模型很好的捕捉了自相关性，那么原始时间序列与模型拟合的时间序列之间的残差应该近似的等于随机噪声。&lt;/b&gt;残差序列自然也是一个时间序列，因此可以对它画出相关图。&lt;b&gt;一个标准随机噪声的自相关满足 ρ_0 = 1 以及 ρ_k = 0, k = 1, 2, 3, …，即对于任意不为 0 的间隔，随机噪声的自相关均为 0。&lt;/b&gt;下图为一个随机噪声的相关图（我们是用标准正态分布构造了有 500 个点的随机噪声序列）：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f0f9ea4e7ae4fc5091dc863859dc098f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;540&quot; data-rawheight=&quot;399&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f0f9ea4e7ae4fc5091dc863859dc098f&quot; data-watermark-src=&quot;v2-ec166fd61b51fac2f231f2299a3fda60&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;关于这个图：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;显然，间隔为 0 的自相关系数为 1；&lt;/li&gt;&lt;li&gt;对于任意的 k ≥ 1，蓝色的阴影区域为 95% 的置信区间。因此，自相关系数只要没有超过蓝色阴影区域，我们就无法在 5% 的显著性水平下拒绝原假设（原假设为间隔为 k 的自相关系数为 0）。上图的结果说明当 k 不为 0 时，随机噪声的自相关系数为 0。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;因此，在评价对金融时间序列的建模是否合适时，我们首先找到原始时间序列和它的拟合序列之间的残差序列；然后只要画出这个&lt;b&gt;残差序列&lt;/b&gt;的相关图就可以看到它是否含有任何模型未考虑的额外自相关性：&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果残差的相关图和上面这个图相似，则可以认为残差是一个随机噪声，而模型已经很好的捕捉了原始时间序列中的自相关性；&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果残差的相关图体现了额外的自相关性，它们将为我们改进已有的模型提供依据，因为这些额外的自相关说明已有模型没有考虑原始时间序列在某些特定间隔上的自相关。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6 下文预告&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为金融时间序列分析系列的开篇，本文介绍金融时间序列的特性和进行金融时间序列分析的目的；并解释时间序列分析中的核心概念：自相关性。对金融时间序列建模的核心就是捕捉该序列中不同间隔上的自相关性。相关图可以清晰地刻画任何一个时间序列在不同间隔的自相关性。&lt;/p&gt;&lt;p&gt;在下一篇中，我们将会从最简单的白噪声和随机游走出发，说明它们无法有效刻画投资品收益率序列中体现出来的自相关性。这会促使我们提出更高级的模型，包括 AR，MA，以及 ARMA。这些模型背后的理论是什么？如何正确的挑选模型的参数以构建最适当的模型？这些将会在本系列后面几篇文章中探讨。&lt;/p&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38320827</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>你用因子，他也用因子；你没赚钱，他却赚钱了</title>
<link>https://henix.github.io/feeds/zhuanlan.mitcshi/2018-06-21-38315648.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38315648&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67adbe2287a0c3f9e831b7678533b3e0_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;0 引言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前些天，有个小伙伴问了这么一个问题：&lt;b&gt;现在量化选股因子泛滥，大家都用同样的数据做同样的测试，最后也得出相似的结论，导致很多策略同质化。这个问题量信怎么看？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;今天这篇文章就来回答这个问题。&lt;/p&gt;&lt;p&gt;首先，&lt;b&gt;一个因子能够挣钱是因为市场在该因子方面存在非有效性。&lt;/b&gt;用的人越多，市场在那方面越有效，导致因子的效果越差。但就现阶段而言就说市场在哪个因子上已经完全有效为时尚早。事实上，由于 A 股市场中噪声投资者的高度参与感，市场仍远不够有效。&lt;/p&gt;&lt;p&gt;拿我们熟悉的价值投资来说，价值投资有效的直接原因不是相关因子的额外风险溢价补偿（事实上，价值投资构建的投资组合风险较市场往往更低），而是由于噪音投资者的存在（见&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38278868&quot;&gt;《写在当越来越多人谈论价值投资时》&lt;/a&gt;），这是不会消失的，所以它会持续有效。&lt;/p&gt;&lt;p&gt;在因子仍将会有效这个大前提下，我想更系统的谈谈第二个方面：&lt;b&gt;同样是使用主流的因子（比如价值、动量、质量等），有的人赚钱了，有的人却没赚钱。虽然是同质化的策略，但因子在靠谱的基金经理手里能发挥最大的效果，而在不靠谱的基金经理手里则变得非常平庸。&lt;/b&gt;这里面的门道又在哪呢？&lt;/p&gt;&lt;p&gt;答案很简单：&lt;b&gt;细节决定成败。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着量化选股的普及，市面上出现了很多优秀的回测平台，能够快速的测试选股因子是否有效。然而，无论测试再怎么方便快捷，一旦真要实盘时，会有一些不得不面对的问题：每个因子应该选多少股票？不同因子如何取舍？股票之间的仓位如何确定？调仓频率如何选取？交易时如何降低成本？等等。因子投资的成败取决于能否很好的应对这些问题。&lt;/p&gt;&lt;p&gt;本文旨探讨在因子投资实践中必须考虑的细节问题。需要说明的是，这里面的某些问题并没有标准答案、不同的选择和投资者的风险偏好有关。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1 细节一：选择合适的代理指标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;在确定风格因子后，首先要决定的就是找到合适的代理指标。&lt;/b&gt;我们以价值（value）因子为例说明这个问题。&lt;/p&gt;&lt;p&gt;&lt;i&gt;顺便提一句，现如今我们提到价值投资的时候，由于巴菲特精神深入人心，往往指的是“好公司”+“便宜”。&lt;b&gt;但是，最初的价值投资就是买便宜的。便宜的定义就是公司每单位市值的基本面价值更高，而不在乎基本面的好坏，这叫做 pure value。&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;当我们使用价值这个因子来选股时，必须通过具体的指标来对股票的便宜程度排名。这就是选择因子的代理指标。在衡量便宜方面，有很多常见的 multiples（见下面的小贴士），比如 P/E，P/B，EV/EBIT 等。&lt;/p&gt;&lt;p&gt;&lt;i&gt;在英文的资料中涉及价值因子的指标时，multiple 是个非常常见的词汇，因此拿出来解释一下，方便小伙伴们以后阅读英文文献。multiple 一词是倍数的意思，顾名思义，指的是两个指标相除。按照惯例，一般分子上指标的数值要大于分母上指标的数值。比如市盈率 P/E，它就是每股股价和每股 earnings 的比值，这就是一个 multiple；而 EV（Enterprise Value）和 EBIT（earnings before interest and taxes）的比值也是一个 multiple。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;面对同一因子的多个代理指标时，我们可以选择回测时效果最好的那个，也可以使用多个指标同时选股。&lt;b&gt;单一指标可能由于财报数据的不准确而产生噪声&lt;/b&gt;；使用多个指标可以避免这个问题。从实证来看，选择多个指标通常能提高该因子的选股效果（但这不是绝对的）。不过，由于同一因子的不同指标之间相关度较高，因此也没有必要选择太多的指标。&lt;/p&gt;&lt;p&gt;以中证 500 为例，使用 P/B 和 EV/EBIT 两个指标作为价值因子选股。简单回测的效果如下表所示。无论是从策略的风险收益特征，还是因子本身的 IC 和 IR 来看，同时使用两个因子都优于单一因子。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f2e1c06279266a9d25804ecb7726bd7e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;716&quot; data-rawheight=&quot;296&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f2e1c06279266a9d25804ecb7726bd7e&quot; data-watermark-src=&quot;v2-0500a279ed5f9c6a7674e771d368765e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当然，同时使用多个代理指标虽然提高了效果，但我们也会问这里面是否有数据挖掘的成分呢？在这方面，著名的量化投资基金 AQR 告诉我们，使用多个指标并不是一种因子激增（因此没有数据挖掘问题），而是提高因子健壮性的一种方法，因为无论哪个单一指标都无法完美的代表我们的目标因子。&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;It is important to note that using multiple measures is not a form of factor proliferation, which can lead to concerns about data mining; instead, using additional measures leads to a more robust version of the ideas behind the factors as there isn’t a single, perfect definition of each style.&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;这种处理类似于机器学习中的集合学习算法，它和随机森林以及 AdaBoost 算法比单一的决策树算法分类效果更好有异曲同工之妙。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 细节二：构建因子投资组合&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在使用因子选股、构建投资组合时，&lt;b&gt;因子暴露程度&lt;/b&gt;和&lt;b&gt;可投资性&lt;/b&gt;是必须考虑的两个因素，然而高的因子暴露是通过牺牲可投资性得到的，我们必须在二者之间取舍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;可投资性是指投资组合中股票的仓位是否合理，该组合的换手率和交易成本是否实际，进入该组合的股票是否有足够的流动性、该投资组合能承担的资金量（即投资组合的容量）是否足够大等。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面的金字塔图描绘了五种构建因子投资组合的方法。&lt;b&gt;自下而上，它们的因子暴露越来越高，而可投资性却越来越低。&lt;/b&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38281562&quot;&gt;《因子投资 —— “被动的”主动投资》&lt;/a&gt;曾对这五种方法进行了详细的阐述，本文只是简要说明一下。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4b811afb1e05f32acb4e0334c5591dc5_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;856&quot; data-rawheight=&quot;488&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4b811afb1e05f32acb4e0334c5591dc5&quot; data-watermark-src=&quot;v2-3aa9026b1907b057cceacfa275db92fb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在金字塔底部是市场组合，由所有股票按市值加权构成。我们认为市场组合中因子的暴露为零。往上移动是高容量因子组合 —— 这里的容量是就该组合中股票支撑的资金容量而言。该组合不剔除任何股票，但是它们的权重不再由市值决定，而是由股票在该因子上的暴露决定。较市场组合而言，该组合在目标因子上有更高的暴露。继续往上是高暴露组合，它会剔除部分因子暴露度低的个股而集中于剩下那些因子暴露度更高的股票，使得组合的因子暴露度更高，但牺牲了一定的可投资性。&lt;b&gt;这三种组合都是纯多头组合。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最上面两类指的是 Fama-French 三因子模型中的多空构建方法以及 Barra 的纯因子组合（见&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38280638&quot;&gt;《正确理解 Barra 的纯因子模型》&lt;/a&gt;），它们更多的都是为了评价因子的效果。这两种组合都是多空组合，由于做空的限制，它们的可投资性比较差。尤其是 Barra 的纯因子组合，它在构建时没有考虑任何可投资性的限制，但它在风险管理中有着非常重要的作用，在本文的第六节还会提到它。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在因子投资实务中，通常的做法是根据个股在因子上的排序选出一小部分在该因子上暴露高的个股，构建一个投资组合。这种做法相当于上述金字塔中的高暴露组合法。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在选择股票时，值得考量的标准除了股票在该因子上的强弱外，还包括股票的市值（只有大市值才能支持大的资金容量）、所属的行业等因素（想要尽量分散行业从而规避行业特有的风险），目的是尽量构建一个行业中性且投资性高的组合。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这种方法简单、透明、逻辑清晰，然而它不容易控制指数对其他风格因子的暴露。&lt;/b&gt;比如我们针对价值因子构建的可投资性高的投资组合难免也会在其他因子上有一定的暴露。&lt;b&gt;如果我们观察到因子的投资组合表现不佳，这可能不是因为该因子失效造成的，而是由该组合在其他因子上的暴露带来的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 细节三：多个因子如何选股？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;因子投资中通常使用多个风格因子，而非单一因子。这就引发了一个问题，多个因子如何选股？这时通常有两种做法：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;每个因子独立选，然后把选出来的股票放在一起。这个方法称为 portfolio mix。&lt;/li&gt;&lt;li&gt;使用所有因子给股票打分，每个股票得到一个总分，然后按照总分的高低选择。该方法称作 integrated approach。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;这两种方法并无一定谁对谁错。但它们可能会选出完全不同的结果。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;考虑下面这个假想的例子，它使用价值因子和盈利因子选股，股票池中的股票在每个因子上的打分从好到坏被分为 A、B、C、D 四挡。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3397a18f48f62f695d3a0911c725a284_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;561&quot; data-rawheight=&quot;339&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3397a18f48f62f695d3a0911c725a284&quot; data-watermark-src=&quot;v2-ad136159ffa630ffd63251eedb0c1b80&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当我们使用 portfolio mix（单个因子独立选股）时，对于价值（盈利）因子，会把所有在该因子上得分为 A 的股票选出来然后放在一起。&lt;b&gt;该方法不看每支股票的综合实力，而更在乎它们是否有“偏科”（在特定因子上暴露高）。&lt;/b&gt;按此种方法，我们会选出落入上图中蓝色和黄色格子里的那些股票。&lt;/p&gt;&lt;p&gt;另一方面，当使用 integrated approach（多个因子综合打分）时，只有股票在这些因子上的表现都不错时，才会被选入（比如在两个因子上的得分都不低于 B）。&lt;b&gt;该方法考察的是每支股票的综合实力，它会惩罚“偏科”选手。&lt;/b&gt;使用此方法，我们会选出落入上图中蓝色和红色格子里的股票。&lt;/p&gt;&lt;p&gt;重申一遍：&lt;b&gt;这两种方法并无一定谁对谁错。&lt;/b&gt;取舍的角度是到底想通过因子投资实现什么样的目标，以及策略的收益风险比和交易成本。以价值投资为例，它要求股票既满足盈利高又要便宜，因此在盈利和价值两个因子上都要表现突出，这时可以选择的是 integrated approach。而如果我们的目标并不是传统的价值投资，而只是希望把投资组合尽可能的暴露在盈利和价值这两个风格因子之上，那么 portfolio mix 这种方法未尝不是一个更好的选择。&lt;/p&gt;&lt;p&gt;在下一节，我们将会谈到多个因子的配置问题。&lt;b&gt;风格因子投资的范畴远远超过用因子法执行价值投资。&lt;/b&gt;在风格因子投资领域，有很多优秀的因子，对它们的（主动）配置格外重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 细节四：因子择时和因子配置&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以中证 500 的成分股为选股池，构建下列五个风格因子的纯多头组合：流动性因子、规模因子、成长因子、价值因子、反转因子。这五个投资组合相对中证 500 的&lt;b&gt;超额收益&lt;/b&gt;的风险收益特性如下。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f4a7b74bfb34f3bd8c45bc9f4a764fbf_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;663&quot; data-rawheight=&quot;219&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f4a7b74bfb34f3bd8c45bc9f4a764fbf&quot; data-watermark-src=&quot;v2-95b0c3d5ba8597e25c930cd91dc72e87&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;除了自身的优异表现外，这些因子之间的相关性也很低（下图）：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b83574b261d7be497e78dcfd8f11317_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;630&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3b83574b261d7be497e78dcfd8f11317&quot; data-watermark-src=&quot;v2-b0fbe9dcedee36cfd6af5a153e1df6eb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如同配置股票一样，&lt;b&gt;配置因子&lt;/b&gt;也是量化投资中的一个重要课题。&lt;b&gt;它希望把相关性低的多个因子通过某种方式配置在一起，得到一个收益风险比更优的多因子配置组合。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;常见因子配置方法包括：简单多样化、波动率倒数、跟踪误差倒数、风险平价以及趋势追踪。它们的业务含义、实现方法以及相应的数学公式如下表所示。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8228a51cca0b9f5600174c9faba1f281_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;761&quot; data-rawheight=&quot;715&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8228a51cca0b9f5600174c9faba1f281&quot; data-watermark-src=&quot;v2-ef540d1f4b17c0986402ade427b7c690&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;除了简单多样化这种被动的静态配置方法外，其他四种配置方法都需要结合投资者的&lt;b&gt;主观判断&lt;/b&gt;。它们从不同方面考虑因子在过去一段时间的表现，从而判断因子未来的表现，以此&lt;b&gt;动态&lt;/b&gt;的配置因子在下一个配置周期的权重。&lt;/p&gt;&lt;p&gt;上述五种配置方法的效果如下图所示。&lt;b&gt;可以看到，被动的简单多样化就非常优秀。而其他四中主动配置方法并没有带来显著的提高（有两种方法甚至不如简单多样化）。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4a3a2ab3f63d3628c51394f2425192e7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;673&quot; data-rawheight=&quot;225&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4a3a2ab3f63d3628c51394f2425192e7&quot; data-watermark-src=&quot;v2-f82bf70d3b353786236103148dd5c6fd&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于简单多样化来说，每个因子的权重为 0.2 恒定。而在按照绝对收益率波动率的倒数以及风险平价这两种方法下，因子的权重虽然随着时间的推移略有波动，但是波动幅度非常小，整体效果与简单多样化非常接近，因此这两种方法的配置效果和简单多样化接近。&lt;/p&gt;&lt;p&gt;波动率的倒数配置策略与风险平价策略关注的都是因子&lt;b&gt;绝对收益率&lt;/b&gt;的波动。反观跟踪误差倒数策略，它考量的是因子&lt;b&gt;相对收益率&lt;/b&gt;的相关指标。在构建每个因子的投资组合时，我们在满足可投资性的前提下尽量的追逐投资组合在目标因子上的暴露；高的因子暴露意味着高的主动管理波动，即较大的跟踪误差。&lt;b&gt;较大的跟踪误差对因子的配置效果造成了负面的影响。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后来看看趋势追踪法。随着因子投资越来越流行，投资者在选择因子时往往看中的是因子最近的表现 —— 选择那些最近几年收益率高的因子。对业绩的追逐造成大量资金涌入过去有效的因子，从而大幅&lt;b&gt;提高了该因子的估值&lt;/b&gt;。这么做造成了两个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;因子估值提升使得因子收益率被高估，容易使人们对因子的效果产生错误的预期。在任何理性投资中，哪怕一个标的再好，我们都不应该不计成本的买入。&lt;/li&gt;&lt;li&gt; 历史数据及经济规律表明，估值满足均值回归。一旦在过去表现过热的因子的估值回归，那么就会大大降低它在未来的收益率。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Arnott et al (2016) 指出因子收益率中包括很大的&lt;b&gt;估值溢价（valuation premium）&lt;/b&gt;。他们把由估值上升带来的因子收益率称为环境 α。&lt;b&gt;当剔除了因子估值的变化后，很多因子竟然并不能获得超额收益。&lt;/b&gt;Arnott et al. (2017) 的研究发现&lt;b&gt;选择那些估值处于历史低位的因子（即过去表现的不怎么好的因子）比选择那些过去一段时间过热的因子，能够在未来获得更高的收益。&lt;/b&gt;这解释了为什么按照趋势追踪来配置因子效果并不好。&lt;/p&gt;&lt;p&gt;使用哪个因子是个因子择时问题；如何将资产分配到不同因子上是个因子配置问题。在实际投资中，任何主观的择时、配置方法都会比简单多样化这种被动方法带来更多的主动误差；这增加了交易难度、并有可能提高换手率、增加交易成本。从这个意义上说，被动的简单多样化足够优秀，可以胜任配置多个因子的重任。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 细节五：调仓频率和交易&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在确定了使用的因子和如何根据因子挑选股票之后，紧接着的环节就是交易了。&lt;b&gt;交易涉及调仓的频率以及交易日内买卖如何成交。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在调仓频率方面，可以采用定期（每隔固定的一段时间）和每日调仓。从大量实证经验来看，如果把调仓的粒度（周期）定为大于 1 个交易日，即&lt;b&gt;不是每天调仓，那么策略的回测效果受实际的调仓日期影响较大（因为在一些特定的日期能恰好选出一些特别优秀的股票，而在其他日期却没选出）。&lt;/b&gt;这一方面自然说明如此的多因子策略是有问题的（对输入太敏感），但同时也说明这种较低调仓周期也有自身的问题。&lt;/p&gt;&lt;p&gt;虽然财务因子的变化频率很低、只有当新的财报被披露时才会更新，但是对于和价格有关的因子，比如价值因子或者规模因子，由于价格每天都会变化，它们的数值也会频繁变化。每天刷新因子、重新选股可以保证及时的根据最新因子取值。但是每天都调仓可能造成过高的换手率。下图为在某个使用因子法执行的价值投资策略中，在每天更新因子并调仓的前提下，持股个数和年化换手率的关系。可以看到，当持股个数过少时（≤ 5 支），该策略的换手率非常高。当持股个数在 10 以上时，策略的换手率就比较稳定了（注：上述 10 这个数字和具体实证有关，不同的投资者应根据自己的多因子策略来寻找换手率稳定时持股个数的最小阈值）。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5185e3e6f8d16a2f565d36cdbb826b6c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;768&quot; data-rawheight=&quot;479&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5185e3e6f8d16a2f565d36cdbb826b6c&quot; data-watermark-src=&quot;v2-e0c247c0125a9257667d1b10091d8273&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;除了换手率之外，每天交易需要交易者承受更大的心理压力。在当前的 A 股市场，自动化交易的限制还比较大，更多的是靠人来交易。人类的情绪、认知偏差等弱点不可避免的会给策略带来难以评估的不确定性，尤其是在交易频率高的时候。华尔街的前辈在谈及人对量化投资策略的影响时指出：&lt;b&gt;严格由机器执行得到的效果是量化策略的上限而非下限，任何人为的干预从长期来看都只能削弱策略的表现。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;选股个数太少的另外一个问题是风险无法充分分散。&lt;/b&gt;因子投资看中的是一揽子股票在风格因子上的共性。如果仅选择太少的股票，则和这个初衷背道而驰，而更多的是暴露在这些个股的特异性收益率上。此外，如果个股太少，会导致我们把资金重仓在几支个股上面。一旦持仓中的个别股票发生了较大的亏损，这会给交易者造成巨大的心理压力。&lt;/p&gt;&lt;p&gt;交易中的第二个问题是交易的执行，它涉及的是在交易日应该如何交易来减少滑点和交易费用。&lt;b&gt;对因子选股来说，通常的做法是在 T 日收盘后，根据最新的价格和财务数据计算出最新的股票仓单，然后在 T + 1 日择机交易。&lt;/b&gt;那么我们是否应该 T + 1 日开盘交易？收盘交易？或者固定时点（比如上午 10 点）交易？亦或是按照 TWAP（时间平均）交易？一般来说，市场的成交量在交易日内呈现 U 型 —— 在开盘和收盘波动较大，因此滑点较高。&lt;/p&gt;&lt;p&gt;下图显示了某个因子选股策略根据 T + 1 日不同价格交易的效果（均假设千一的单边交易费用）。从收益率和夏普率来看，开盘价效果 &amp;gt; 10 点价格效果 &amp;gt; 中午收盘价效果 &amp;gt; 日均价效果 &amp;gt; 收盘价效果（这个结果也是和多因子策略有关的，并不一定对所有策略都是开盘交易效果最好）。在实际中，由于开盘波动率较高，因此需要考虑额外的滑点造成的冲击。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-adfc3ba7c0a5567b7f0031e6b0be1001_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;756&quot; data-rawheight=&quot;204&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-adfc3ba7c0a5567b7f0031e6b0be1001&quot; data-watermark-src=&quot;v2-e1a44f8a2bb87d02bd616ef54235fdc9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;6 细节六：风险管理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文讨论的最后一个细节是&lt;b&gt;风险管理&lt;/b&gt;。&lt;b&gt;在市场状态发生转换时会造成风格因子失效。然而，更加困难的是想要判断出一个因子有效或者失效需要较长的周期。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;比如规模因子在 2016 年之前一直有效（挑小市值），而在 2016 年之后则失效了。但我们之所以说它失效，是因为站在两年后的 2018 年回顾过去两年小市值的表现时发现了基于该因子的策略是持续下跌的。但显然在现实中，历经两年实打实的亏损（而且还亏的很惨）才得出因子失效的结论是很痛苦的。&lt;/p&gt;&lt;p&gt;前文提到，为了构建具有可投资性高的因子投资组合，该组合一定不可避免的在其他风格因子上有暴露。它们会对最终的选股带来额外的风险。&lt;b&gt;我们应该定期评测投资组合在不同风格因子上的动态暴露，进行风险归因和业绩归因。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为此，Barra 的纯因子模型闪亮登场。纯因子模型是从数学角度出发构建的完美暴露于单一风格因子的投资组合，它虽然几乎不具备任何可投资性，但是在风险归因上具有重要作用。将选股投资组合的收益率在时序上用这些纯因子组合的收益率进行回归，就可以分析出选股投资组合的收益和风险成分中由哪些风格因子组成。&lt;/p&gt;&lt;p&gt;对于风险来说，Davis and Menchero (2010) 指出：&lt;/p&gt;&lt;p&gt;&lt;b&gt;σ = Exposure × Volatility × Correlation&lt;/b&gt;&lt;/p&gt;&lt;p&gt;它的具体表现为下面这个数学关系：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;\sigma(R)=\sum_m x_m\sigma(r_m)\rho(r_m,R)&lt;/equation&gt; &lt;/p&gt;&lt;p&gt;其中 σ(R) 是选股投资组合收益率的标准差，而等式右侧的三要素分别为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Exposure（暴露）：&lt;/b&gt;即 x_m，它衡量投资组合对每个风格因子的暴露大小。在风险归因时，不仅应该考虑我们自己选定的风格因子，还应该考虑其他常见的风格因子，因为选股组合会不可避免的暴露在它们上面。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Volatility（波动性）：&lt;/b&gt;即 σ(r_m)，它代表的是第 m 个风格因子收益率 r_m 的标准差。由于投资组合是暴露在不同的风格因子中，那么风格因子收益率的波动越大，它对投资组合的风险的贡献程度也越大。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Correlation（相关性）：&lt;/b&gt;即 ρ(r_m, R)，它是风格因子 m 和选股投资组合收益率之间的相关系数。这种相关性越高，投资组合收益率受风格因子影响的确定性越显著。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;定期对选股投资组合做风险归因有助于判断不理想的选股结果是来自选定的风格因子本身（比如风格切换了，风格因子赚不到钱了），还是因为投资组合暴露在其他的因子上造成的。对于后一种情况，则需要考虑重新构建投资组合从而尽量降低其在不必要因子上的暴露。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7 结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文抛砖引玉，介绍了一些在因子投资实践中必须要考虑的细节。不可否认，在大家都没有独门数据的今天，因子投资变得越来越同质化。但是，只要市场是非有效的，因子就还会有效，而因子投资的关键在于执行时对各种细节的精确处理。在这方面，量化投资无疑有着巨大的优势。&lt;/p&gt;&lt;p&gt;量化投资基金 AQR 针对因子投资中的这些问题也展开过相应的讨论，并把通过良好执行而真正实现因子投资收益的这个过程称为&lt;b&gt;“craftsmanship alpha（手艺 alpha）”&lt;/b&gt;，意思是只有那些专注于做好每个细节的优秀基金经理才能把因子投资在理论上的超额收益转换成现实。&lt;/p&gt;&lt;p&gt;虽然在这些细节中并不总是有一定正确或者错误的决策，但靠谱的基金经理应该能够为自己的选择辩护并深谙每个决策对于投资收益和风险的影响。在这方面，基于经济原则和经验证据的细节处理决策将在大概率上为因子投资带来更好的结果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;The devil is in the details.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Arnott, R. D., N. Beck, V. Kalesnik, and J. West (2016). How Can &#39;Smart Beta&#39; Go Horribly Wrong?&lt;i&gt; SSRN: https://ssrn.com/abstract=3040949.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;Arnott, R. D., N. Beck, V. Kalesnik (2017). Forecasting Factor and Smart Beta Returns (Hint: History Is Worse than Useless). &lt;i&gt;SSRN: https://ssrn.com/abstract=3040953.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;Davis, B. and J. Menchero (2010). &lt;i&gt;Risk Contribution is Exposure times Volatility times Correlation.&lt;/i&gt; Technical Report. MSCI Barra Research.&lt;/li&gt;&lt;/ul&gt;</description>
<author>石川</author>
<guid isPermaLink="false">2018-06-21-38315648</guid>
<pubDate>Thu, 21 Jun 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
