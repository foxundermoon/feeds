<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>机器之心</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/</link>
<description>专业的人工智能媒体和产业服务平台</description>
<language>zh-cn</language>
<lastBuildDate>Sat, 03 Mar 2018 06:47:08 +0800</lastBuildDate>
<item>
<title>资源 | 像「花书」一样排版：Ian Goodfellow「亲授」的高级LaTex教程</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-02-1000000618_503254864.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzv9bjkZ*ecJ1BC-prhfNgifZ9Z1-3yIrguu4wDtQJZATD5CTblkcYp2B24Q0kt2CgPU1eCx3E-qb688KCx4oovs=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 从可视化到新模型：纵览深度学习的视觉可解释性                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-02&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;border-width: initial;border-style: initial;border-color: currentcolor;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;span style=&quot;max-width: 100%;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;张拳石、朱松纯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：乾树、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在本篇论文中，来自 UCLA 的研究人员就目前有关理解神经网络表征和用可解释/分离式表征学习神经网络的研究进行了一次调查。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本文将研究范围圈定到以下六个研究方向：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络中间层的 CNN 特征可视化。这些方法主要是合成图像，使预训练的 CNN 中的给定神经元的得分最大化，或者用卷积层的 feature maps 反推出输入图。详细内容请看第二节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 表征的诊断。相关的研究涉及为不同的物体类别诊断 CNN 的特征空间，或揭露卷积层的潜在的表征缺陷。详细内容见第三节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;「模式混合」的分离式表征编码在 CNN 的每个滤波器中。这方面的研究主要用于解卷积层的复合表征以及网络表征可视化。详细内容见第四节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;构建可解释的模型。我们在第五节讨论了可解释的 CNN 模型 [Zhang et al., 2017c]，胶囊网络 capsule network）[Sabour et al., 2017]，可解释的 R-CNNs [Wu et al., 2017]，以及 InfoGAN [Chen et al., 2016]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过人机交互进行语义级的由中到尾的学习。CNN 表征的正确的语义解可以进一步实现弱监督下的神经网络的「由中到尾」学习。第七节介绍了一些通过人机交互来学习新模型的方法 [Zhang et al., 2017b] 以及通过有限的人机交互实现积极有效的问答游戏 [Zhang et al., 2017a]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;综上，CNN 表征可视化是探讨网络表征的最直接的方法。网络可视化还为许多诊断 CNN 表征的方法提供了技术基础。预训练的 CNN 的特征的分离式表征以及对可解释的网络表征的学习给最先进的算法带来了更大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Visual Interpretability for Deep Learning: a Survey&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29365079365079366&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylevYsuGDQOhez15ibSzAvjfc2b16s3pI0pSFRgVpCQ3VDk2YrEVLllvmw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1008&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(123, 12, 0);&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文地址：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;&quot;&gt;https://arxiv.org/abs/1802.00614&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：本篇论文回顾了目前有关理解神经网络表征和用可解释/分离式中间层表征学习神经网络的新兴方向的研究。尽管深度神经网络在不同的任务中取得了不俗的表现，但是它的可解释性一直是深度神经网络的阿克琉斯之踵。当前，深度神经网络获得了很高的鉴别力，同时它也想黑匣子一样难以解释。我们相信良好的模型可解释性或许会帮助研究人员突破深度学习的瓶颈，例如，从很少的注释中学习，通过人机交互进行语义级别的学习，以及 debug 网络的语义表征。在本文中，我们重点关注卷积神经网络（CNN），并重新审视 CNN 表征的可视化，预训练 CNN 表征的诊断方法，预训练 CNN 表征的分离方法，CNN 的分离式表征学习，以及基于模型可解释性的从中到尾的学习。最后，我们将探讨可解释的人工智能的发展趋势。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;2 CNN 表征的可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将 CNN 滤波器可视化是探索隐藏在神经元内的视觉模式的最直接方式。网络可视化已经有了各种各样的可视化方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，基于梯度的方法是网络可视化的主流方法 [Zeiler and Fergus, 2014; Mahendran and Vedaldi, 2015; Simonyan et al., 2013; Springenberg et al., 2015]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;其次，上卷积网络 [Dosovitskiy and Brox, 2016] 是另一种典型 CNN 表征可视化技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3 CNN 表征的诊断方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;一些方法超出了 CNN 的可视化和 CNN 表示诊断的范畴，以获得对 CNN 中编码的特征的启发式理解。我们将所有相关研究大致分为以下五个方面。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第一个研究方向是从全局角度分析 CNN 特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第二个研究方向是提取通过网络直接输出为标签/属性的图像区域，以解释标签/属性的 CNN 表征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 特征空间中易受影响点的估计也是网络表征诊断的热门方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第四个研究方向是基于网络特征空间的分析来细化网络表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3241590214067278&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleYtpWnQspaMHg1Husw6JsEAgZQhRN635pMDEETTfvXMaxUBianC7ibV9Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;654&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1 ：CNN 中的偏置的表征 [Zhang et al., 2018b]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4 将 CNN 表征解构成说明图和决策树&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4501510574018127&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleEux4ywfYgFQs85nZVCk85CefMS9Oksica4zwFw7kQWdIeh28jqficgmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;662&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 2 ：不同的输入图像获得的滤波器的 Feature maps [Zhang et al., 2018a]。为了可视化 feature map，该方法将 feature map 中激活单元的感受野映射到图像平面。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4955223880597015&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylesaMu82nu0cHthM5cbUYMXbC6aRYPRkFDOOGCjqYcZmXmNjAyGk5Vbw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 3 ：说明图 [Zhang et al., 2018a]。说明图表示隐藏在 CNN 的卷积层中的知识层次。预训练的 CNN 中的每个滤波器可以由对象的不同部分得到。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5194274028629857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleF9NZ2L3oQibWKhKJNXibdcVxIeSlJKrcf2u9EFxzcdOnicuGI7sv1bnUQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;978&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 5：模式热点图 [Zhang et al., 2018a]。热点图将具有最高推断得分的说明图的第 L 层中排名前 50％的模式的空间分布可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8403614457831325&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleCbOkibJ2M80bTz6Uc69M2280zBTbMIeCdHTOPckS0Bx4AvkAOdyeRPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;664&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 7：语义级 CNN 预测解释的决策树 [Zhang et al., 2018c]。CNN 学习在顶层的卷积层中运用分离式表征进行目标分类，其中每个过滤器代表一个特定的对象部分。决策树以由粗到精的方式编码隐藏在 CNN 全连接层内的各种决策模式。给定一张输入图像，决策树推断出一个解析树（红线）来定量分析 CNN 预测的基本原理，即物体的哪些部分（或滤波器）用于预测以及该部分（或滤波器）对预测有多大贡献。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;5 用可解释/分离式表征学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29375&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyle1kT2TlmBGkwQmkxJ56kqtErpHiaibgma8iahvC5axkzukahNVnfJzfvgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 10：上层卷积层的可解释滤波器的可视化图 [Zhang et al., 2017c]。我们使用 [Zhou et al., 2015] 来估计 feature map 中激活感受野的图像分辨率以可视化过滤器的语义信息。可解释的 CNN 通常在其顶部的卷积层中对动物的头部模式进行编码以便于分类。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;6 网络可解释性的评估标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7970588235294118&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleFrzlYn4yEfnnGzFX2FfFdjQzOT2MnF36BRZC1IMWDUMBkVM2fmCsaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;680&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 13：与或图在预训练的 CNN 上衍生为语义分支 [Zhang et al., 2017a]。AOG 将特定的 CNN 单元与某些图像区域相关联。红线表示解析图。&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;7 由中到尾学习的网络可解释性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.31044776119403&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleNougLFf4y6SAIIIBj8fiaLCb4oGf24ytw0PWa1sjzBnC8muAMgJ6QAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 14：QA 过程的图示 [Zhang et al., 2017a]。（上）该方法选择不可解释的对象进行分类。（下）每个目标对象的问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;73764431&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-02-1000000618_503254864</guid>
<pubDate>Fri, 02 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>业界 | 实时替换视频背景：谷歌展示全新移动端分割技术</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-02-1000000618_503254850.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzv9bjkZ*ecJ1BC-prhfNgiekARo9PWwoEBoFKhYcmnbqvYjZqebRGlK6c*LCNiLnGrMOFgyGO6r0Y7we9gp-EYY=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 从可视化到新模型：纵览深度学习的视觉可解释性                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-02&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;border-width: initial;border-style: initial;border-color: currentcolor;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;span style=&quot;max-width: 100%;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;张拳石、朱松纯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：乾树、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在本篇论文中，来自 UCLA 的研究人员就目前有关理解神经网络表征和用可解释/分离式表征学习神经网络的研究进行了一次调查。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本文将研究范围圈定到以下六个研究方向：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络中间层的 CNN 特征可视化。这些方法主要是合成图像，使预训练的 CNN 中的给定神经元的得分最大化，或者用卷积层的 feature maps 反推出输入图。详细内容请看第二节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 表征的诊断。相关的研究涉及为不同的物体类别诊断 CNN 的特征空间，或揭露卷积层的潜在的表征缺陷。详细内容见第三节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;「模式混合」的分离式表征编码在 CNN 的每个滤波器中。这方面的研究主要用于解卷积层的复合表征以及网络表征可视化。详细内容见第四节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;构建可解释的模型。我们在第五节讨论了可解释的 CNN 模型 [Zhang et al., 2017c]，胶囊网络 capsule network）[Sabour et al., 2017]，可解释的 R-CNNs [Wu et al., 2017]，以及 InfoGAN [Chen et al., 2016]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过人机交互进行语义级的由中到尾的学习。CNN 表征的正确的语义解可以进一步实现弱监督下的神经网络的「由中到尾」学习。第七节介绍了一些通过人机交互来学习新模型的方法 [Zhang et al., 2017b] 以及通过有限的人机交互实现积极有效的问答游戏 [Zhang et al., 2017a]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;综上，CNN 表征可视化是探讨网络表征的最直接的方法。网络可视化还为许多诊断 CNN 表征的方法提供了技术基础。预训练的 CNN 的特征的分离式表征以及对可解释的网络表征的学习给最先进的算法带来了更大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Visual Interpretability for Deep Learning: a Survey&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29365079365079366&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylevYsuGDQOhez15ibSzAvjfc2b16s3pI0pSFRgVpCQ3VDk2YrEVLllvmw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1008&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(123, 12, 0);&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文地址：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;&quot;&gt;https://arxiv.org/abs/1802.00614&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：本篇论文回顾了目前有关理解神经网络表征和用可解释/分离式中间层表征学习神经网络的新兴方向的研究。尽管深度神经网络在不同的任务中取得了不俗的表现，但是它的可解释性一直是深度神经网络的阿克琉斯之踵。当前，深度神经网络获得了很高的鉴别力，同时它也想黑匣子一样难以解释。我们相信良好的模型可解释性或许会帮助研究人员突破深度学习的瓶颈，例如，从很少的注释中学习，通过人机交互进行语义级别的学习，以及 debug 网络的语义表征。在本文中，我们重点关注卷积神经网络（CNN），并重新审视 CNN 表征的可视化，预训练 CNN 表征的诊断方法，预训练 CNN 表征的分离方法，CNN 的分离式表征学习，以及基于模型可解释性的从中到尾的学习。最后，我们将探讨可解释的人工智能的发展趋势。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;2 CNN 表征的可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将 CNN 滤波器可视化是探索隐藏在神经元内的视觉模式的最直接方式。网络可视化已经有了各种各样的可视化方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，基于梯度的方法是网络可视化的主流方法 [Zeiler and Fergus, 2014; Mahendran and Vedaldi, 2015; Simonyan et al., 2013; Springenberg et al., 2015]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;其次，上卷积网络 [Dosovitskiy and Brox, 2016] 是另一种典型 CNN 表征可视化技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3 CNN 表征的诊断方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;一些方法超出了 CNN 的可视化和 CNN 表示诊断的范畴，以获得对 CNN 中编码的特征的启发式理解。我们将所有相关研究大致分为以下五个方面。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第一个研究方向是从全局角度分析 CNN 特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第二个研究方向是提取通过网络直接输出为标签/属性的图像区域，以解释标签/属性的 CNN 表征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 特征空间中易受影响点的估计也是网络表征诊断的热门方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第四个研究方向是基于网络特征空间的分析来细化网络表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3241590214067278&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleYtpWnQspaMHg1Husw6JsEAgZQhRN635pMDEETTfvXMaxUBianC7ibV9Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;654&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1 ：CNN 中的偏置的表征 [Zhang et al., 2018b]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4 将 CNN 表征解构成说明图和决策树&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4501510574018127&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleEux4ywfYgFQs85nZVCk85CefMS9Oksica4zwFw7kQWdIeh28jqficgmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;662&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 2 ：不同的输入图像获得的滤波器的 Feature maps [Zhang et al., 2018a]。为了可视化 feature map，该方法将 feature map 中激活单元的感受野映射到图像平面。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4955223880597015&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylesaMu82nu0cHthM5cbUYMXbC6aRYPRkFDOOGCjqYcZmXmNjAyGk5Vbw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 3 ：说明图 [Zhang et al., 2018a]。说明图表示隐藏在 CNN 的卷积层中的知识层次。预训练的 CNN 中的每个滤波器可以由对象的不同部分得到。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5194274028629857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleF9NZ2L3oQibWKhKJNXibdcVxIeSlJKrcf2u9EFxzcdOnicuGI7sv1bnUQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;978&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 5：模式热点图 [Zhang et al., 2018a]。热点图将具有最高推断得分的说明图的第 L 层中排名前 50％的模式的空间分布可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8403614457831325&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleCbOkibJ2M80bTz6Uc69M2280zBTbMIeCdHTOPckS0Bx4AvkAOdyeRPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;664&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 7：语义级 CNN 预测解释的决策树 [Zhang et al., 2018c]。CNN 学习在顶层的卷积层中运用分离式表征进行目标分类，其中每个过滤器代表一个特定的对象部分。决策树以由粗到精的方式编码隐藏在 CNN 全连接层内的各种决策模式。给定一张输入图像，决策树推断出一个解析树（红线）来定量分析 CNN 预测的基本原理，即物体的哪些部分（或滤波器）用于预测以及该部分（或滤波器）对预测有多大贡献。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;5 用可解释/分离式表征学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29375&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyle1kT2TlmBGkwQmkxJ56kqtErpHiaibgma8iahvC5axkzukahNVnfJzfvgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 10：上层卷积层的可解释滤波器的可视化图 [Zhang et al., 2017c]。我们使用 [Zhou et al., 2015] 来估计 feature map 中激活感受野的图像分辨率以可视化过滤器的语义信息。可解释的 CNN 通常在其顶部的卷积层中对动物的头部模式进行编码以便于分类。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;6 网络可解释性的评估标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7970588235294118&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleFrzlYn4yEfnnGzFX2FfFdjQzOT2MnF36BRZC1IMWDUMBkVM2fmCsaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;680&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 13：与或图在预训练的 CNN 上衍生为语义分支 [Zhang et al., 2017a]。AOG 将特定的 CNN 单元与某些图像区域相关联。红线表示解析图。&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;7 由中到尾学习的网络可解释性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.31044776119403&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleNougLFf4y6SAIIIBj8fiaLCb4oGf24ytw0PWa1sjzBnC8muAMgJ6QAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 14：QA 过程的图示 [Zhang et al., 2017a]。（上）该方法选择不可解释的对象进行分类。（下）每个目标对象的问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;420476458&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-02-1000000618_503254850</guid>
<pubDate>Fri, 02 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>学界 | 从可视化到新模型：纵览深度学习的视觉可解释性</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-02-1000000618_503254839.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzv9bjkZ*ecJ1BC-prhfNgidh4ELLUuKqw3OPV1A4khWlf3rWufCc6ogUtPRevHrkcdhsfM1HsMFF9ZE6u*TiJb0=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 从可视化到新模型：纵览深度学习的视觉可解释性                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-02&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;border-width: initial;border-style: initial;border-color: currentcolor;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;span style=&quot;max-width: 100%;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;张拳石、朱松纯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：乾树、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在本篇论文中，来自 UCLA 的研究人员就目前有关理解神经网络表征和用可解释/分离式表征学习神经网络的研究进行了一次调查。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本文将研究范围圈定到以下六个研究方向：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络中间层的 CNN 特征可视化。这些方法主要是合成图像，使预训练的 CNN 中的给定神经元的得分最大化，或者用卷积层的 feature maps 反推出输入图。详细内容请看第二节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 表征的诊断。相关的研究涉及为不同的物体类别诊断 CNN 的特征空间，或揭露卷积层的潜在的表征缺陷。详细内容见第三节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;「模式混合」的分离式表征编码在 CNN 的每个滤波器中。这方面的研究主要用于解卷积层的复合表征以及网络表征可视化。详细内容见第四节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;构建可解释的模型。我们在第五节讨论了可解释的 CNN 模型 [Zhang et al., 2017c]，胶囊网络 capsule network）[Sabour et al., 2017]，可解释的 R-CNNs [Wu et al., 2017]，以及 InfoGAN [Chen et al., 2016]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过人机交互进行语义级的由中到尾的学习。CNN 表征的正确的语义解可以进一步实现弱监督下的神经网络的「由中到尾」学习。第七节介绍了一些通过人机交互来学习新模型的方法 [Zhang et al., 2017b] 以及通过有限的人机交互实现积极有效的问答游戏 [Zhang et al., 2017a]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;综上，CNN 表征可视化是探讨网络表征的最直接的方法。网络可视化还为许多诊断 CNN 表征的方法提供了技术基础。预训练的 CNN 的特征的分离式表征以及对可解释的网络表征的学习给最先进的算法带来了更大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Visual Interpretability for Deep Learning: a Survey&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29365079365079366&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylevYsuGDQOhez15ibSzAvjfc2b16s3pI0pSFRgVpCQ3VDk2YrEVLllvmw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1008&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(123, 12, 0);&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文地址：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;&quot;&gt;https://arxiv.org/abs/1802.00614&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：本篇论文回顾了目前有关理解神经网络表征和用可解释/分离式中间层表征学习神经网络的新兴方向的研究。尽管深度神经网络在不同的任务中取得了不俗的表现，但是它的可解释性一直是深度神经网络的阿克琉斯之踵。当前，深度神经网络获得了很高的鉴别力，同时它也想黑匣子一样难以解释。我们相信良好的模型可解释性或许会帮助研究人员突破深度学习的瓶颈，例如，从很少的注释中学习，通过人机交互进行语义级别的学习，以及 debug 网络的语义表征。在本文中，我们重点关注卷积神经网络（CNN），并重新审视 CNN 表征的可视化，预训练 CNN 表征的诊断方法，预训练 CNN 表征的分离方法，CNN 的分离式表征学习，以及基于模型可解释性的从中到尾的学习。最后，我们将探讨可解释的人工智能的发展趋势。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;2 CNN 表征的可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将 CNN 滤波器可视化是探索隐藏在神经元内的视觉模式的最直接方式。网络可视化已经有了各种各样的可视化方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，基于梯度的方法是网络可视化的主流方法 [Zeiler and Fergus, 2014; Mahendran and Vedaldi, 2015; Simonyan et al., 2013; Springenberg et al., 2015]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;其次，上卷积网络 [Dosovitskiy and Brox, 2016] 是另一种典型 CNN 表征可视化技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3 CNN 表征的诊断方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;一些方法超出了 CNN 的可视化和 CNN 表示诊断的范畴，以获得对 CNN 中编码的特征的启发式理解。我们将所有相关研究大致分为以下五个方面。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第一个研究方向是从全局角度分析 CNN 特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第二个研究方向是提取通过网络直接输出为标签/属性的图像区域，以解释标签/属性的 CNN 表征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 特征空间中易受影响点的估计也是网络表征诊断的热门方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第四个研究方向是基于网络特征空间的分析来细化网络表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3241590214067278&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleYtpWnQspaMHg1Husw6JsEAgZQhRN635pMDEETTfvXMaxUBianC7ibV9Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;654&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1 ：CNN 中的偏置的表征 [Zhang et al., 2018b]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4 将 CNN 表征解构成说明图和决策树&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4501510574018127&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleEux4ywfYgFQs85nZVCk85CefMS9Oksica4zwFw7kQWdIeh28jqficgmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;662&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 2 ：不同的输入图像获得的滤波器的 Feature maps [Zhang et al., 2018a]。为了可视化 feature map，该方法将 feature map 中激活单元的感受野映射到图像平面。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4955223880597015&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylesaMu82nu0cHthM5cbUYMXbC6aRYPRkFDOOGCjqYcZmXmNjAyGk5Vbw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 3 ：说明图 [Zhang et al., 2018a]。说明图表示隐藏在 CNN 的卷积层中的知识层次。预训练的 CNN 中的每个滤波器可以由对象的不同部分得到。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5194274028629857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleF9NZ2L3oQibWKhKJNXibdcVxIeSlJKrcf2u9EFxzcdOnicuGI7sv1bnUQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;978&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 5：模式热点图 [Zhang et al., 2018a]。热点图将具有最高推断得分的说明图的第 L 层中排名前 50％的模式的空间分布可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8403614457831325&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleCbOkibJ2M80bTz6Uc69M2280zBTbMIeCdHTOPckS0Bx4AvkAOdyeRPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;664&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 7：语义级 CNN 预测解释的决策树 [Zhang et al., 2018c]。CNN 学习在顶层的卷积层中运用分离式表征进行目标分类，其中每个过滤器代表一个特定的对象部分。决策树以由粗到精的方式编码隐藏在 CNN 全连接层内的各种决策模式。给定一张输入图像，决策树推断出一个解析树（红线）来定量分析 CNN 预测的基本原理，即物体的哪些部分（或滤波器）用于预测以及该部分（或滤波器）对预测有多大贡献。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;5 用可解释/分离式表征学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29375&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyle1kT2TlmBGkwQmkxJ56kqtErpHiaibgma8iahvC5axkzukahNVnfJzfvgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 10：上层卷积层的可解释滤波器的可视化图 [Zhang et al., 2017c]。我们使用 [Zhou et al., 2015] 来估计 feature map 中激活感受野的图像分辨率以可视化过滤器的语义信息。可解释的 CNN 通常在其顶部的卷积层中对动物的头部模式进行编码以便于分类。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;6 网络可解释性的评估标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7970588235294118&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleFrzlYn4yEfnnGzFX2FfFdjQzOT2MnF36BRZC1IMWDUMBkVM2fmCsaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;680&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 13：与或图在预训练的 CNN 上衍生为语义分支 [Zhang et al., 2017a]。AOG 将特定的 CNN 单元与某些图像区域相关联。红线表示解析图。&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;7 由中到尾学习的网络可解释性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.31044776119403&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleNougLFf4y6SAIIIBj8fiaLCb4oGf24ytw0PWa1sjzBnC8muAMgJ6QAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 14：QA 过程的图示 [Zhang et al., 2017a]。（上）该方法选择不可解释的对象进行分类。（下）每个目标对象的问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;2004009842&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-02-1000000618_503254839</guid>
<pubDate>Fri, 02 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>教程 | 22分钟直冲Kaggle竞赛第二名！一文教你做到</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-02-1000000618_503254837.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzv9bjkZ*ecJ1BC-prhfNgie-BKITZvQyZz*7F8DAbxon3MuCL03Pe1axw08wuXKn2RlEKXSzvS2HtQRImBO6MXs=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 从可视化到新模型：纵览深度学习的视觉可解释性                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-02&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;border-width: initial;border-style: initial;border-color: currentcolor;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;span style=&quot;max-width: 100%;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;张拳石、朱松纯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：乾树、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在本篇论文中，来自 UCLA 的研究人员就目前有关理解神经网络表征和用可解释/分离式表征学习神经网络的研究进行了一次调查。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本文将研究范围圈定到以下六个研究方向：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络中间层的 CNN 特征可视化。这些方法主要是合成图像，使预训练的 CNN 中的给定神经元的得分最大化，或者用卷积层的 feature maps 反推出输入图。详细内容请看第二节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 表征的诊断。相关的研究涉及为不同的物体类别诊断 CNN 的特征空间，或揭露卷积层的潜在的表征缺陷。详细内容见第三节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;「模式混合」的分离式表征编码在 CNN 的每个滤波器中。这方面的研究主要用于解卷积层的复合表征以及网络表征可视化。详细内容见第四节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;构建可解释的模型。我们在第五节讨论了可解释的 CNN 模型 [Zhang et al., 2017c]，胶囊网络 capsule network）[Sabour et al., 2017]，可解释的 R-CNNs [Wu et al., 2017]，以及 InfoGAN [Chen et al., 2016]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过人机交互进行语义级的由中到尾的学习。CNN 表征的正确的语义解可以进一步实现弱监督下的神经网络的「由中到尾」学习。第七节介绍了一些通过人机交互来学习新模型的方法 [Zhang et al., 2017b] 以及通过有限的人机交互实现积极有效的问答游戏 [Zhang et al., 2017a]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;综上，CNN 表征可视化是探讨网络表征的最直接的方法。网络可视化还为许多诊断 CNN 表征的方法提供了技术基础。预训练的 CNN 的特征的分离式表征以及对可解释的网络表征的学习给最先进的算法带来了更大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Visual Interpretability for Deep Learning: a Survey&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29365079365079366&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylevYsuGDQOhez15ibSzAvjfc2b16s3pI0pSFRgVpCQ3VDk2YrEVLllvmw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1008&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(123, 12, 0);&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文地址：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;&quot;&gt;https://arxiv.org/abs/1802.00614&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：本篇论文回顾了目前有关理解神经网络表征和用可解释/分离式中间层表征学习神经网络的新兴方向的研究。尽管深度神经网络在不同的任务中取得了不俗的表现，但是它的可解释性一直是深度神经网络的阿克琉斯之踵。当前，深度神经网络获得了很高的鉴别力，同时它也想黑匣子一样难以解释。我们相信良好的模型可解释性或许会帮助研究人员突破深度学习的瓶颈，例如，从很少的注释中学习，通过人机交互进行语义级别的学习，以及 debug 网络的语义表征。在本文中，我们重点关注卷积神经网络（CNN），并重新审视 CNN 表征的可视化，预训练 CNN 表征的诊断方法，预训练 CNN 表征的分离方法，CNN 的分离式表征学习，以及基于模型可解释性的从中到尾的学习。最后，我们将探讨可解释的人工智能的发展趋势。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;2 CNN 表征的可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将 CNN 滤波器可视化是探索隐藏在神经元内的视觉模式的最直接方式。网络可视化已经有了各种各样的可视化方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，基于梯度的方法是网络可视化的主流方法 [Zeiler and Fergus, 2014; Mahendran and Vedaldi, 2015; Simonyan et al., 2013; Springenberg et al., 2015]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;其次，上卷积网络 [Dosovitskiy and Brox, 2016] 是另一种典型 CNN 表征可视化技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3 CNN 表征的诊断方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;一些方法超出了 CNN 的可视化和 CNN 表示诊断的范畴，以获得对 CNN 中编码的特征的启发式理解。我们将所有相关研究大致分为以下五个方面。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第一个研究方向是从全局角度分析 CNN 特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第二个研究方向是提取通过网络直接输出为标签/属性的图像区域，以解释标签/属性的 CNN 表征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 特征空间中易受影响点的估计也是网络表征诊断的热门方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第四个研究方向是基于网络特征空间的分析来细化网络表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3241590214067278&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleYtpWnQspaMHg1Husw6JsEAgZQhRN635pMDEETTfvXMaxUBianC7ibV9Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;654&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1 ：CNN 中的偏置的表征 [Zhang et al., 2018b]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4 将 CNN 表征解构成说明图和决策树&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4501510574018127&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleEux4ywfYgFQs85nZVCk85CefMS9Oksica4zwFw7kQWdIeh28jqficgmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;662&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 2 ：不同的输入图像获得的滤波器的 Feature maps [Zhang et al., 2018a]。为了可视化 feature map，该方法将 feature map 中激活单元的感受野映射到图像平面。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4955223880597015&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylesaMu82nu0cHthM5cbUYMXbC6aRYPRkFDOOGCjqYcZmXmNjAyGk5Vbw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 3 ：说明图 [Zhang et al., 2018a]。说明图表示隐藏在 CNN 的卷积层中的知识层次。预训练的 CNN 中的每个滤波器可以由对象的不同部分得到。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5194274028629857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleF9NZ2L3oQibWKhKJNXibdcVxIeSlJKrcf2u9EFxzcdOnicuGI7sv1bnUQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;978&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 5：模式热点图 [Zhang et al., 2018a]。热点图将具有最高推断得分的说明图的第 L 层中排名前 50％的模式的空间分布可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8403614457831325&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleCbOkibJ2M80bTz6Uc69M2280zBTbMIeCdHTOPckS0Bx4AvkAOdyeRPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;664&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 7：语义级 CNN 预测解释的决策树 [Zhang et al., 2018c]。CNN 学习在顶层的卷积层中运用分离式表征进行目标分类，其中每个过滤器代表一个特定的对象部分。决策树以由粗到精的方式编码隐藏在 CNN 全连接层内的各种决策模式。给定一张输入图像，决策树推断出一个解析树（红线）来定量分析 CNN 预测的基本原理，即物体的哪些部分（或滤波器）用于预测以及该部分（或滤波器）对预测有多大贡献。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;5 用可解释/分离式表征学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29375&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyle1kT2TlmBGkwQmkxJ56kqtErpHiaibgma8iahvC5axkzukahNVnfJzfvgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 10：上层卷积层的可解释滤波器的可视化图 [Zhang et al., 2017c]。我们使用 [Zhou et al., 2015] 来估计 feature map 中激活感受野的图像分辨率以可视化过滤器的语义信息。可解释的 CNN 通常在其顶部的卷积层中对动物的头部模式进行编码以便于分类。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;6 网络可解释性的评估标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7970588235294118&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleFrzlYn4yEfnnGzFX2FfFdjQzOT2MnF36BRZC1IMWDUMBkVM2fmCsaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;680&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 13：与或图在预训练的 CNN 上衍生为语义分支 [Zhang et al., 2017a]。AOG 将特定的 CNN 单元与某些图像区域相关联。红线表示解析图。&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;7 由中到尾学习的网络可解释性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.31044776119403&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleNougLFf4y6SAIIIBj8fiaLCb4oGf24ytw0PWa1sjzBnC8muAMgJ6QAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 14：QA 过程的图示 [Zhang et al., 2017a]。（上）该方法选择不可解释的对象进行分类。（下）每个目标对象的问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;705662792&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-02-1000000618_503254837</guid>
<pubDate>Fri, 02 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>NumPy能力大评估：这里有70道测试题</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-02-1000000618.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzv9bjkZ*ecJ1BC-prhfNgifBK94t8NkTUd2xS09tUCz3FHXwYGFQQQuqv-CuCHfSXkypk5qEY6sxfpKvJubvnkc=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 从可视化到新模型：纵览深度学习的视觉可解释性                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-02&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;border-width: initial;border-style: initial;border-color: currentcolor;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;span style=&quot;max-width: 100%;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;张拳石、朱松纯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：乾树、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在本篇论文中，来自 UCLA 的研究人员就目前有关理解神经网络表征和用可解释/分离式表征学习神经网络的研究进行了一次调查。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本文将研究范围圈定到以下六个研究方向：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络中间层的 CNN 特征可视化。这些方法主要是合成图像，使预训练的 CNN 中的给定神经元的得分最大化，或者用卷积层的 feature maps 反推出输入图。详细内容请看第二节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 表征的诊断。相关的研究涉及为不同的物体类别诊断 CNN 的特征空间，或揭露卷积层的潜在的表征缺陷。详细内容见第三节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;「模式混合」的分离式表征编码在 CNN 的每个滤波器中。这方面的研究主要用于解卷积层的复合表征以及网络表征可视化。详细内容见第四节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;构建可解释的模型。我们在第五节讨论了可解释的 CNN 模型 [Zhang et al., 2017c]，胶囊网络 capsule network）[Sabour et al., 2017]，可解释的 R-CNNs [Wu et al., 2017]，以及 InfoGAN [Chen et al., 2016]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过人机交互进行语义级的由中到尾的学习。CNN 表征的正确的语义解可以进一步实现弱监督下的神经网络的「由中到尾」学习。第七节介绍了一些通过人机交互来学习新模型的方法 [Zhang et al., 2017b] 以及通过有限的人机交互实现积极有效的问答游戏 [Zhang et al., 2017a]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;综上，CNN 表征可视化是探讨网络表征的最直接的方法。网络可视化还为许多诊断 CNN 表征的方法提供了技术基础。预训练的 CNN 的特征的分离式表征以及对可解释的网络表征的学习给最先进的算法带来了更大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Visual Interpretability for Deep Learning: a Survey&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29365079365079366&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylevYsuGDQOhez15ibSzAvjfc2b16s3pI0pSFRgVpCQ3VDk2YrEVLllvmw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1008&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(123, 12, 0);&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文地址：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;&quot;&gt;https://arxiv.org/abs/1802.00614&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-decoration: underline;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：本篇论文回顾了目前有关理解神经网络表征和用可解释/分离式中间层表征学习神经网络的新兴方向的研究。尽管深度神经网络在不同的任务中取得了不俗的表现，但是它的可解释性一直是深度神经网络的阿克琉斯之踵。当前，深度神经网络获得了很高的鉴别力，同时它也想黑匣子一样难以解释。我们相信良好的模型可解释性或许会帮助研究人员突破深度学习的瓶颈，例如，从很少的注释中学习，通过人机交互进行语义级别的学习，以及 debug 网络的语义表征。在本文中，我们重点关注卷积神经网络（CNN），并重新审视 CNN 表征的可视化，预训练 CNN 表征的诊断方法，预训练 CNN 表征的分离方法，CNN 的分离式表征学习，以及基于模型可解释性的从中到尾的学习。最后，我们将探讨可解释的人工智能的发展趋势。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;2 CNN 表征的可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将 CNN 滤波器可视化是探索隐藏在神经元内的视觉模式的最直接方式。网络可视化已经有了各种各样的可视化方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，基于梯度的方法是网络可视化的主流方法 [Zeiler and Fergus, 2014; Mahendran and Vedaldi, 2015; Simonyan et al., 2013; Springenberg et al., 2015]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;其次，上卷积网络 [Dosovitskiy and Brox, 2016] 是另一种典型 CNN 表征可视化技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3 CNN 表征的诊断方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;一些方法超出了 CNN 的可视化和 CNN 表示诊断的范畴，以获得对 CNN 中编码的特征的启发式理解。我们将所有相关研究大致分为以下五个方面。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第一个研究方向是从全局角度分析 CNN 特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第二个研究方向是提取通过网络直接输出为标签/属性的图像区域，以解释标签/属性的 CNN 表征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;CNN 特征空间中易受影响点的估计也是网络表征诊断的热门方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;第四个研究方向是基于网络特征空间的分析来细化网络表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3241590214067278&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleYtpWnQspaMHg1Husw6JsEAgZQhRN635pMDEETTfvXMaxUBianC7ibV9Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;654&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1 ：CNN 中的偏置的表征 [Zhang et al., 2018b]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4 将 CNN 表征解构成说明图和决策树&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4501510574018127&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleEux4ywfYgFQs85nZVCk85CefMS9Oksica4zwFw7kQWdIeh28jqficgmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;662&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 2 ：不同的输入图像获得的滤波器的 Feature maps [Zhang et al., 2018a]。为了可视化 feature map，该方法将 feature map 中激活单元的感受野映射到图像平面。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4955223880597015&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPylesaMu82nu0cHthM5cbUYMXbC6aRYPRkFDOOGCjqYcZmXmNjAyGk5Vbw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 3 ：说明图 [Zhang et al., 2018a]。说明图表示隐藏在 CNN 的卷积层中的知识层次。预训练的 CNN 中的每个滤波器可以由对象的不同部分得到。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5194274028629857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleF9NZ2L3oQibWKhKJNXibdcVxIeSlJKrcf2u9EFxzcdOnicuGI7sv1bnUQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;978&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 5：模式热点图 [Zhang et al., 2018a]。热点图将具有最高推断得分的说明图的第 L 层中排名前 50％的模式的空间分布可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8403614457831325&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleCbOkibJ2M80bTz6Uc69M2280zBTbMIeCdHTOPckS0Bx4AvkAOdyeRPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;664&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 7：语义级 CNN 预测解释的决策树 [Zhang et al., 2018c]。CNN 学习在顶层的卷积层中运用分离式表征进行目标分类，其中每个过滤器代表一个特定的对象部分。决策树以由粗到精的方式编码隐藏在 CNN 全连接层内的各种决策模式。给定一张输入图像，决策树推断出一个解析树（红线）来定量分析 CNN 预测的基本原理，即物体的哪些部分（或滤波器）用于预测以及该部分（或滤波器）对预测有多大贡献。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;5 用可解释/分离式表征学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.29375&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyle1kT2TlmBGkwQmkxJ56kqtErpHiaibgma8iahvC5axkzukahNVnfJzfvgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 10：上层卷积层的可解释滤波器的可视化图 [Zhang et al., 2017c]。我们使用 [Zhou et al., 2015] 来估计 feature map 中激活感受野的图像分辨率以可视化过滤器的语义信息。可解释的 CNN 通常在其顶部的卷积层中对动物的头部模式进行编码以便于分类。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;6 网络可解释性的评估标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7970588235294118&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleFrzlYn4yEfnnGzFX2FfFdjQzOT2MnF36BRZC1IMWDUMBkVM2fmCsaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;680&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 13：与或图在预训练的 CNN 上衍生为语义分支 [Zhang et al., 2017a]。AOG 将特定的 CNN 单元与某些图像区域相关联。红线表示解析图。&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;7 由中到尾学习的网络可解释性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.31044776119403&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8SJtb0yTicXrcAOexKoPyleNougLFf4y6SAIIIBj8fiaLCb4oGf24ytw0PWa1sjzBnC8muAMgJ6QAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;670&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 14：QA 过程的图示 [Zhang et al., 2017a]。（上）该方法选择不可解释的对象进行分类。（下）每个目标对象的问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;610102388&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-02-1000000618</guid>
<pubDate>Fri, 02 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>入门 | 奇异值分解简介：从原理到基础机器学习应用</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-01-1000000617_503254786.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzu-s8thnkv0ZvxuIUkZlpuVQYe0h-r3bOMh3a42B*6mIXliFuE7X7N8AyaMtz7h*4GyP5jrmVugIq3oGa3oii7g=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 华中科技大学提出多向文本检测方法：基于角定位与区域分割                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-01&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;font-size: 14px;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;font-size: 16px;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Pengyuan Lyu等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Nurhachu Null、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在计算机视觉的应用场景里，对图像中的文本进行准确识别是重要而相对困难的任务。来自华中科技大学的研究者们近日提出了一种全新的多项文本检测方法，大幅提高了机器学习的识别准确度。该研究已被即将于 6 月 18 日在美国盐湖城举行的 CVPR 2018 大会接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;最近，由于现实世界应用（如产品搜索 [4]，图像检索 [19]，以及自动驾驶）需求的增长，从自然场景图像中提取文本信息的研究正变得越来越流行。场景文本检测（Scene text detection）在各种文本读取系统中起着重要的作用 [34, 10, 47, 5, 20, 13, 7, 25]，它的目标是在自然图像中定位出文本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;由于外部因素和内部因素，场景文本检测具有一定的挑战性。外部因素源自环境，例如噪声、模糊和遮挡，它们也是一般目标检测中存在的主要问题。内部因素是由场景文本的属性和变化引起的。与一般目标检测相比，场景文本检测更加复杂，因为：1）场景文本可能以任意方向存在于自然图像中，因此边界框可能是旋转的矩形或者四边形；2）场景文本边界框的长宽比变化比较大；3）因为场景文本的形式可能是字符、单词或者文本行的形式，所以在定位边界的时候算法可能会发生混淆。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2679640718562874&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdldJS5T3Bz1YlDhRXsOsbtDtHbG0bomWGGudZz3E5GCFN2OwZHPPoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;668&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 1. 顶行和底行中的图像分别是左上角、右上角、右下角和左下角的预测角点和位置敏感图。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在过去几年中，随着一般目标检测和语义分割的快速发展，场景文本检测得到了广泛的研究 [10, 5, 49, 20, 43, 52, 39, 42]，并且在最近取得了明显的进展。基于一般目标检测和语义分割模型，几个精心设计的模型使得文本检测能够更加准确地进行。这些文本检测器可以被划分为两个分支。第一个分支以一般目标检测器（SSD [30]，YOLO [37] 和 DenseBox [18]）为基础，例如 TextBoxes [27]，FCRN [14] 以及 EAST [53] 等，它们直接预测候选的边界框。子二个分支以语义分割为基础，例如 [52] 和 [50]，它们生成分割映射，然后通过后处理生成最终的文本边界框。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;与前面的方法不同，来自华中科技大学的研究人员结合了目标检测和语义分割的思想，并将它们以一种可替代的方式进行了应用。新研究的动机主要来源于两方面的观察：1）不管矩形的大小如何、长宽比如何、方向如何，它都可以由角点决定；2）区域分割图可以提供有效的文本位置信息。所以，我们可以首先检测文本的角点（左上角、右上角、右下角和左下角）（如图 1 所示），而不是直接检测文本边界框。此外，我们预测位置敏感分割图（如图 1 所示），而不是像 [52] 和 [50] 中提到的文本/非文本图。最后，我们再通过角点进行采样和分组，以生成候选边界框，并通过分割信息消除不合理的边框。新的方法的处理流程如图 2 所示：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2807570977917981&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUBhcrZOokHnNXNZ2hibhIJicIBSdVhISedu9j8labCjmy5hMmoaAdVCuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1268&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 2. 方法概览。给定一幅图像，网络通过角点检测和位置敏感语义分割输出角点。然后通过对角点进行采样和分组得到候选的边框。最后，通过分割图对候选边框进行打分，并使用非极大抑制（NMS）对边框进行抑制。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法的关键优势如下：1）因为我们是通过对角点进行采样和分组来检测场景文本的，所以新的方法能够处理任意方向的文本；2）因为我们检测的是角点，而不是边界框，所以新的方法可以自然地避免边框比较大的问题；3）因为使用了位置敏感分割，所以无论是字符、单词，还是文本行，我们都能够较好地分割文本实例；4）在新方法中，候选边框的边界是由角点决定的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;研究人员在来自公共基准测试集上的水平文本、定向文本、长定向文本以及多语言文本中验证了该方法的有效性。结果显示新提出的算法在准确率和速度方面均有优势。具体而言，新方法在 ICDAR2015 [22] 上的 F-Measures 分别为 84.3 %、81.5 % 和 72.4 %，这显著优于现有的方法。此外，新方法在效率上也很有竞争力。它每秒可以处理 10.4 张以上的图像 ( 512×512 )。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;该研究的主要贡献有四个方面：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;（1）提出了一种融合目标检测和分割思想的场景文本检测器，这个场景文本检测器可以以端到端的方式进行训练和测试。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 2 ) 在位置敏感 ROI 池化 [ 9] 的基础上，提出了一种旋转的位置敏感 ROI 平均池化层，可以处理任意方向的请求。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 3 ) 新提出的方法可以同时处理多方向场景文本中的诸多挑战（如旋转、宽高比变化、非常闭合的实例）。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 4 ) 新方法在精度和效率上均取得了较好或有竞争力的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法所用的网络全部是卷积神经网络，它扮演着特征提取器、角检测和位置敏感分割的角色。网络结构如图 3 所示。给定一张图片，网络会生成候选的角点和分割图。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4623574144486692&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdRCoiaOVWZnGRW3JSWZ2J6ibMKBAJVS2WPGibCwRjicca269yxtiacWKBnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1315&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 3. 网络结构。网络包含三个部分：主干网络，角点检测器和位置敏感图预测器。主干网络来自于 DSSD [ 11 ]。角检测器是基于多特征层（紫色的模块）建立的。位置敏感分割预测器与角检测器共享了一些特征（紫色的模块）。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2733433734939759&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUyHibcY1faf7G8AF1yzGpeHKSAHe5G6WG7XOvN0rPicvnOicicoicXiayfRYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1328&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 6. 检测结果的一些示例。从左到右依次是： ICDAR2015, ICDAR2013, MSRA-TD500, MLT, COCO-Text。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.541374474053296&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUSNaw0MXxgxpWbZibfuIp27W8Z3brwjvyMIU3zOTGCGMn2fbITOf1j5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;713&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4. MSRA-TD500 上的测试结果。有†表示的模型不基于 VGG16。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1002906976744187&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUDgP7Qoh4V4BcIuHLo99re7HlKxOawibLMnrJlJXsMPPwIJibjI8Dpg9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 6. COCO-Text 上的测试结果。∗代表多尺度。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.277577505407354&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUpxuHVrFibdKc5cf4vFDfyAdShZ1D6oic6OOlrY7nMq9so91PTiaSv4pTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1387&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.08948&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此前基于深度学习的场景文本检测方法可以被粗略地分为两大类别。第一类将场景文本识别视作一种一般的目标检测问题，这类方法遵循一般目标检测的范式，通过回归文本框来定位场景文本，但是会受到任意方向和较大变化的长宽比的场景文本的困扰。第二类将文本区域进行直接分割，但是大都需要复杂的后处理过程。在这篇论文中，我们提出了一种能将这两类方法的思想进行结合，同时能够避免它们各自弱点的新方法。我们提出了通过定位文本边界框的角点，并在相对位置分割文本区域来检测场景文本的方法。在推理阶段，候选边框通过对角点的采样和分组得到，候选边框进一步通过分割图进行打分，然后使用非极大值抑制（NMS）方法对边框进行抑制。与之前的方法相比，我们的方法能够自然地处理长定向文本，并且不需要复杂的后处理过程。在 ICDAR2013、ICDAR2015、MSRA-TD500、MLT 和 COCO-Text 上的实验证明我们提出的方法能够在准确率和效率方面同时达到更好或者更具竞争力的结果。基于 VGG16，我们的方法在 ICDAR2015 上实现了 84.3% 的 F-measure，在 MSRA-TD500 上达到了 81.5% 的 F-measure。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUw76FPPYDhVFpChU29twtHB3yicHUYYznJR6fia4GfdLjjNscGb03x2Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;height: 20px;width: 39px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1352759726&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-01-1000000617_503254786</guid>
<pubDate>Thu, 01 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>CVPR 2018 | 华中科技大学提出多向文本检测方法：基于角定位与区域分割</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-01-1000000617_503254759.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzu-s8thnkv0ZvxuIUkZlpuXaYMvt4HLg6kFclvfti*dra3bSFoWb03Pt0tDKtgccD2waOhuPVwsucDj0S7PfZ5g=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 华中科技大学提出多向文本检测方法：基于角定位与区域分割                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-01&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;font-size: 14px;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;font-size: 16px;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Pengyuan Lyu等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Nurhachu Null、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在计算机视觉的应用场景里，对图像中的文本进行准确识别是重要而相对困难的任务。来自华中科技大学的研究者们近日提出了一种全新的多项文本检测方法，大幅提高了机器学习的识别准确度。该研究已被即将于 6 月 18 日在美国盐湖城举行的 CVPR 2018 大会接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;最近，由于现实世界应用（如产品搜索 [4]，图像检索 [19]，以及自动驾驶）需求的增长，从自然场景图像中提取文本信息的研究正变得越来越流行。场景文本检测（Scene text detection）在各种文本读取系统中起着重要的作用 [34, 10, 47, 5, 20, 13, 7, 25]，它的目标是在自然图像中定位出文本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;由于外部因素和内部因素，场景文本检测具有一定的挑战性。外部因素源自环境，例如噪声、模糊和遮挡，它们也是一般目标检测中存在的主要问题。内部因素是由场景文本的属性和变化引起的。与一般目标检测相比，场景文本检测更加复杂，因为：1）场景文本可能以任意方向存在于自然图像中，因此边界框可能是旋转的矩形或者四边形；2）场景文本边界框的长宽比变化比较大；3）因为场景文本的形式可能是字符、单词或者文本行的形式，所以在定位边界的时候算法可能会发生混淆。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2679640718562874&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdldJS5T3Bz1YlDhRXsOsbtDtHbG0bomWGGudZz3E5GCFN2OwZHPPoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;668&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 1. 顶行和底行中的图像分别是左上角、右上角、右下角和左下角的预测角点和位置敏感图。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在过去几年中，随着一般目标检测和语义分割的快速发展，场景文本检测得到了广泛的研究 [10, 5, 49, 20, 43, 52, 39, 42]，并且在最近取得了明显的进展。基于一般目标检测和语义分割模型，几个精心设计的模型使得文本检测能够更加准确地进行。这些文本检测器可以被划分为两个分支。第一个分支以一般目标检测器（SSD [30]，YOLO [37] 和 DenseBox [18]）为基础，例如 TextBoxes [27]，FCRN [14] 以及 EAST [53] 等，它们直接预测候选的边界框。子二个分支以语义分割为基础，例如 [52] 和 [50]，它们生成分割映射，然后通过后处理生成最终的文本边界框。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;与前面的方法不同，来自华中科技大学的研究人员结合了目标检测和语义分割的思想，并将它们以一种可替代的方式进行了应用。新研究的动机主要来源于两方面的观察：1）不管矩形的大小如何、长宽比如何、方向如何，它都可以由角点决定；2）区域分割图可以提供有效的文本位置信息。所以，我们可以首先检测文本的角点（左上角、右上角、右下角和左下角）（如图 1 所示），而不是直接检测文本边界框。此外，我们预测位置敏感分割图（如图 1 所示），而不是像 [52] 和 [50] 中提到的文本/非文本图。最后，我们再通过角点进行采样和分组，以生成候选边界框，并通过分割信息消除不合理的边框。新的方法的处理流程如图 2 所示：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2807570977917981&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUBhcrZOokHnNXNZ2hibhIJicIBSdVhISedu9j8labCjmy5hMmoaAdVCuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1268&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 2. 方法概览。给定一幅图像，网络通过角点检测和位置敏感语义分割输出角点。然后通过对角点进行采样和分组得到候选的边框。最后，通过分割图对候选边框进行打分，并使用非极大抑制（NMS）对边框进行抑制。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法的关键优势如下：1）因为我们是通过对角点进行采样和分组来检测场景文本的，所以新的方法能够处理任意方向的文本；2）因为我们检测的是角点，而不是边界框，所以新的方法可以自然地避免边框比较大的问题；3）因为使用了位置敏感分割，所以无论是字符、单词，还是文本行，我们都能够较好地分割文本实例；4）在新方法中，候选边框的边界是由角点决定的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;研究人员在来自公共基准测试集上的水平文本、定向文本、长定向文本以及多语言文本中验证了该方法的有效性。结果显示新提出的算法在准确率和速度方面均有优势。具体而言，新方法在 ICDAR2015 [22] 上的 F-Measures 分别为 84.3 %、81.5 % 和 72.4 %，这显著优于现有的方法。此外，新方法在效率上也很有竞争力。它每秒可以处理 10.4 张以上的图像 ( 512×512 )。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;该研究的主要贡献有四个方面：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;（1）提出了一种融合目标检测和分割思想的场景文本检测器，这个场景文本检测器可以以端到端的方式进行训练和测试。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 2 ) 在位置敏感 ROI 池化 [ 9] 的基础上，提出了一种旋转的位置敏感 ROI 平均池化层，可以处理任意方向的请求。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 3 ) 新提出的方法可以同时处理多方向场景文本中的诸多挑战（如旋转、宽高比变化、非常闭合的实例）。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 4 ) 新方法在精度和效率上均取得了较好或有竞争力的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法所用的网络全部是卷积神经网络，它扮演着特征提取器、角检测和位置敏感分割的角色。网络结构如图 3 所示。给定一张图片，网络会生成候选的角点和分割图。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4623574144486692&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdRCoiaOVWZnGRW3JSWZ2J6ibMKBAJVS2WPGibCwRjicca269yxtiacWKBnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1315&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 3. 网络结构。网络包含三个部分：主干网络，角点检测器和位置敏感图预测器。主干网络来自于 DSSD [ 11 ]。角检测器是基于多特征层（紫色的模块）建立的。位置敏感分割预测器与角检测器共享了一些特征（紫色的模块）。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2733433734939759&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUyHibcY1faf7G8AF1yzGpeHKSAHe5G6WG7XOvN0rPicvnOicicoicXiayfRYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1328&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 6. 检测结果的一些示例。从左到右依次是： ICDAR2015, ICDAR2013, MSRA-TD500, MLT, COCO-Text。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.541374474053296&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUSNaw0MXxgxpWbZibfuIp27W8Z3brwjvyMIU3zOTGCGMn2fbITOf1j5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;713&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4. MSRA-TD500 上的测试结果。有†表示的模型不基于 VGG16。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1002906976744187&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUDgP7Qoh4V4BcIuHLo99re7HlKxOawibLMnrJlJXsMPPwIJibjI8Dpg9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 6. COCO-Text 上的测试结果。∗代表多尺度。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.277577505407354&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUpxuHVrFibdKc5cf4vFDfyAdShZ1D6oic6OOlrY7nMq9so91PTiaSv4pTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1387&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.08948&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此前基于深度学习的场景文本检测方法可以被粗略地分为两大类别。第一类将场景文本识别视作一种一般的目标检测问题，这类方法遵循一般目标检测的范式，通过回归文本框来定位场景文本，但是会受到任意方向和较大变化的长宽比的场景文本的困扰。第二类将文本区域进行直接分割，但是大都需要复杂的后处理过程。在这篇论文中，我们提出了一种能将这两类方法的思想进行结合，同时能够避免它们各自弱点的新方法。我们提出了通过定位文本边界框的角点，并在相对位置分割文本区域来检测场景文本的方法。在推理阶段，候选边框通过对角点的采样和分组得到，候选边框进一步通过分割图进行打分，然后使用非极大值抑制（NMS）方法对边框进行抑制。与之前的方法相比，我们的方法能够自然地处理长定向文本，并且不需要复杂的后处理过程。在 ICDAR2013、ICDAR2015、MSRA-TD500、MLT 和 COCO-Text 上的实验证明我们提出的方法能够在准确率和效率方面同时达到更好或者更具竞争力的结果。基于 VGG16，我们的方法在 ICDAR2015 上实现了 84.3% 的 F-measure，在 MSRA-TD500 上达到了 81.5% 的 F-measure。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUw76FPPYDhVFpChU29twtHB3yicHUYYznJR6fia4GfdLjjNscGb03x2Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;height: 20px;width: 39px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1026077246&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-01-1000000617_503254759</guid>
<pubDate>Thu, 01 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>教程 | 如何理解KL散度的不对称性</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-01-1000000617_503254745.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzu-s8thnkv0ZvxuIUkZlpuUls04WqwG74Im0OoD2OC65S3rNTo4dtQuayvy1wuOrCGOwZWgofJ00xWUS2pvIQ88=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 华中科技大学提出多向文本检测方法：基于角定位与区域分割                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-01&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;font-size: 14px;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;font-size: 16px;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Pengyuan Lyu等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Nurhachu Null、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在计算机视觉的应用场景里，对图像中的文本进行准确识别是重要而相对困难的任务。来自华中科技大学的研究者们近日提出了一种全新的多项文本检测方法，大幅提高了机器学习的识别准确度。该研究已被即将于 6 月 18 日在美国盐湖城举行的 CVPR 2018 大会接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;最近，由于现实世界应用（如产品搜索 [4]，图像检索 [19]，以及自动驾驶）需求的增长，从自然场景图像中提取文本信息的研究正变得越来越流行。场景文本检测（Scene text detection）在各种文本读取系统中起着重要的作用 [34, 10, 47, 5, 20, 13, 7, 25]，它的目标是在自然图像中定位出文本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;由于外部因素和内部因素，场景文本检测具有一定的挑战性。外部因素源自环境，例如噪声、模糊和遮挡，它们也是一般目标检测中存在的主要问题。内部因素是由场景文本的属性和变化引起的。与一般目标检测相比，场景文本检测更加复杂，因为：1）场景文本可能以任意方向存在于自然图像中，因此边界框可能是旋转的矩形或者四边形；2）场景文本边界框的长宽比变化比较大；3）因为场景文本的形式可能是字符、单词或者文本行的形式，所以在定位边界的时候算法可能会发生混淆。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2679640718562874&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdldJS5T3Bz1YlDhRXsOsbtDtHbG0bomWGGudZz3E5GCFN2OwZHPPoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;668&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 1. 顶行和底行中的图像分别是左上角、右上角、右下角和左下角的预测角点和位置敏感图。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在过去几年中，随着一般目标检测和语义分割的快速发展，场景文本检测得到了广泛的研究 [10, 5, 49, 20, 43, 52, 39, 42]，并且在最近取得了明显的进展。基于一般目标检测和语义分割模型，几个精心设计的模型使得文本检测能够更加准确地进行。这些文本检测器可以被划分为两个分支。第一个分支以一般目标检测器（SSD [30]，YOLO [37] 和 DenseBox [18]）为基础，例如 TextBoxes [27]，FCRN [14] 以及 EAST [53] 等，它们直接预测候选的边界框。子二个分支以语义分割为基础，例如 [52] 和 [50]，它们生成分割映射，然后通过后处理生成最终的文本边界框。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;与前面的方法不同，来自华中科技大学的研究人员结合了目标检测和语义分割的思想，并将它们以一种可替代的方式进行了应用。新研究的动机主要来源于两方面的观察：1）不管矩形的大小如何、长宽比如何、方向如何，它都可以由角点决定；2）区域分割图可以提供有效的文本位置信息。所以，我们可以首先检测文本的角点（左上角、右上角、右下角和左下角）（如图 1 所示），而不是直接检测文本边界框。此外，我们预测位置敏感分割图（如图 1 所示），而不是像 [52] 和 [50] 中提到的文本/非文本图。最后，我们再通过角点进行采样和分组，以生成候选边界框，并通过分割信息消除不合理的边框。新的方法的处理流程如图 2 所示：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2807570977917981&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUBhcrZOokHnNXNZ2hibhIJicIBSdVhISedu9j8labCjmy5hMmoaAdVCuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1268&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 2. 方法概览。给定一幅图像，网络通过角点检测和位置敏感语义分割输出角点。然后通过对角点进行采样和分组得到候选的边框。最后，通过分割图对候选边框进行打分，并使用非极大抑制（NMS）对边框进行抑制。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法的关键优势如下：1）因为我们是通过对角点进行采样和分组来检测场景文本的，所以新的方法能够处理任意方向的文本；2）因为我们检测的是角点，而不是边界框，所以新的方法可以自然地避免边框比较大的问题；3）因为使用了位置敏感分割，所以无论是字符、单词，还是文本行，我们都能够较好地分割文本实例；4）在新方法中，候选边框的边界是由角点决定的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;研究人员在来自公共基准测试集上的水平文本、定向文本、长定向文本以及多语言文本中验证了该方法的有效性。结果显示新提出的算法在准确率和速度方面均有优势。具体而言，新方法在 ICDAR2015 [22] 上的 F-Measures 分别为 84.3 %、81.5 % 和 72.4 %，这显著优于现有的方法。此外，新方法在效率上也很有竞争力。它每秒可以处理 10.4 张以上的图像 ( 512×512 )。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;该研究的主要贡献有四个方面：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;（1）提出了一种融合目标检测和分割思想的场景文本检测器，这个场景文本检测器可以以端到端的方式进行训练和测试。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 2 ) 在位置敏感 ROI 池化 [ 9] 的基础上，提出了一种旋转的位置敏感 ROI 平均池化层，可以处理任意方向的请求。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 3 ) 新提出的方法可以同时处理多方向场景文本中的诸多挑战（如旋转、宽高比变化、非常闭合的实例）。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 4 ) 新方法在精度和效率上均取得了较好或有竞争力的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法所用的网络全部是卷积神经网络，它扮演着特征提取器、角检测和位置敏感分割的角色。网络结构如图 3 所示。给定一张图片，网络会生成候选的角点和分割图。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4623574144486692&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdRCoiaOVWZnGRW3JSWZ2J6ibMKBAJVS2WPGibCwRjicca269yxtiacWKBnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1315&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 3. 网络结构。网络包含三个部分：主干网络，角点检测器和位置敏感图预测器。主干网络来自于 DSSD [ 11 ]。角检测器是基于多特征层（紫色的模块）建立的。位置敏感分割预测器与角检测器共享了一些特征（紫色的模块）。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2733433734939759&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUyHibcY1faf7G8AF1yzGpeHKSAHe5G6WG7XOvN0rPicvnOicicoicXiayfRYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1328&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 6. 检测结果的一些示例。从左到右依次是： ICDAR2015, ICDAR2013, MSRA-TD500, MLT, COCO-Text。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.541374474053296&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUSNaw0MXxgxpWbZibfuIp27W8Z3brwjvyMIU3zOTGCGMn2fbITOf1j5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;713&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4. MSRA-TD500 上的测试结果。有†表示的模型不基于 VGG16。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1002906976744187&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUDgP7Qoh4V4BcIuHLo99re7HlKxOawibLMnrJlJXsMPPwIJibjI8Dpg9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 6. COCO-Text 上的测试结果。∗代表多尺度。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.277577505407354&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUpxuHVrFibdKc5cf4vFDfyAdShZ1D6oic6OOlrY7nMq9so91PTiaSv4pTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1387&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.08948&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此前基于深度学习的场景文本检测方法可以被粗略地分为两大类别。第一类将场景文本识别视作一种一般的目标检测问题，这类方法遵循一般目标检测的范式，通过回归文本框来定位场景文本，但是会受到任意方向和较大变化的长宽比的场景文本的困扰。第二类将文本区域进行直接分割，但是大都需要复杂的后处理过程。在这篇论文中，我们提出了一种能将这两类方法的思想进行结合，同时能够避免它们各自弱点的新方法。我们提出了通过定位文本边界框的角点，并在相对位置分割文本区域来检测场景文本的方法。在推理阶段，候选边框通过对角点的采样和分组得到，候选边框进一步通过分割图进行打分，然后使用非极大值抑制（NMS）方法对边框进行抑制。与之前的方法相比，我们的方法能够自然地处理长定向文本，并且不需要复杂的后处理过程。在 ICDAR2013、ICDAR2015、MSRA-TD500、MLT 和 COCO-Text 上的实验证明我们提出的方法能够在准确率和效率方面同时达到更好或者更具竞争力的结果。基于 VGG16，我们的方法在 ICDAR2015 上实现了 84.3% 的 F-measure，在 MSRA-TD500 上达到了 81.5% 的 F-measure。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUw76FPPYDhVFpChU29twtHB3yicHUYYznJR6fia4GfdLjjNscGb03x2Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;height: 20px;width: 39px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1708889299&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author>邱陆陆</author>
<guid isPermaLink="false">2018-03-01-1000000617_503254745</guid>
<pubDate>Thu, 01 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>学习了！谷歌今日上线基于TensorFlow的机器学习速成课程（中文版）</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-01-1000000617.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDzu-s8thnkv0ZvxuIUkZlpuVSJePOwkvJyGSD6Znnw7m9UuAAupd0i9-6hy58rWy0EU-crFeF8I1APJkkqoVqeTs=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 华中科技大学提出多向文本检测方法：基于角定位与区域分割                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-01&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;font-size: 14px;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;font-size: 16px;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Pengyuan Lyu等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Nurhachu Null、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style=&quot;white-space: normal;&quot;&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;在计算机视觉的应用场景里，对图像中的文本进行准确识别是重要而相对困难的任务。来自华中科技大学的研究者们近日提出了一种全新的多项文本检测方法，大幅提高了机器学习的识别准确度。该研究已被即将于 6 月 18 日在美国盐湖城举行的 CVPR 2018 大会接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;最近，由于现实世界应用（如产品搜索 [4]，图像检索 [19]，以及自动驾驶）需求的增长，从自然场景图像中提取文本信息的研究正变得越来越流行。场景文本检测（Scene text detection）在各种文本读取系统中起着重要的作用 [34, 10, 47, 5, 20, 13, 7, 25]，它的目标是在自然图像中定位出文本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;由于外部因素和内部因素，场景文本检测具有一定的挑战性。外部因素源自环境，例如噪声、模糊和遮挡，它们也是一般目标检测中存在的主要问题。内部因素是由场景文本的属性和变化引起的。与一般目标检测相比，场景文本检测更加复杂，因为：1）场景文本可能以任意方向存在于自然图像中，因此边界框可能是旋转的矩形或者四边形；2）场景文本边界框的长宽比变化比较大；3）因为场景文本的形式可能是字符、单词或者文本行的形式，所以在定位边界的时候算法可能会发生混淆。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2679640718562874&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdldJS5T3Bz1YlDhRXsOsbtDtHbG0bomWGGudZz3E5GCFN2OwZHPPoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;668&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 1. 顶行和底行中的图像分别是左上角、右上角、右下角和左下角的预测角点和位置敏感图。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在过去几年中，随着一般目标检测和语义分割的快速发展，场景文本检测得到了广泛的研究 [10, 5, 49, 20, 43, 52, 39, 42]，并且在最近取得了明显的进展。基于一般目标检测和语义分割模型，几个精心设计的模型使得文本检测能够更加准确地进行。这些文本检测器可以被划分为两个分支。第一个分支以一般目标检测器（SSD [30]，YOLO [37] 和 DenseBox [18]）为基础，例如 TextBoxes [27]，FCRN [14] 以及 EAST [53] 等，它们直接预测候选的边界框。子二个分支以语义分割为基础，例如 [52] 和 [50]，它们生成分割映射，然后通过后处理生成最终的文本边界框。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;与前面的方法不同，来自华中科技大学的研究人员结合了目标检测和语义分割的思想，并将它们以一种可替代的方式进行了应用。新研究的动机主要来源于两方面的观察：1）不管矩形的大小如何、长宽比如何、方向如何，它都可以由角点决定；2）区域分割图可以提供有效的文本位置信息。所以，我们可以首先检测文本的角点（左上角、右上角、右下角和左下角）（如图 1 所示），而不是直接检测文本边界框。此外，我们预测位置敏感分割图（如图 1 所示），而不是像 [52] 和 [50] 中提到的文本/非文本图。最后，我们再通过角点进行采样和分组，以生成候选边界框，并通过分割信息消除不合理的边框。新的方法的处理流程如图 2 所示：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2807570977917981&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUBhcrZOokHnNXNZ2hibhIJicIBSdVhISedu9j8labCjmy5hMmoaAdVCuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1268&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 2. 方法概览。给定一幅图像，网络通过角点检测和位置敏感语义分割输出角点。然后通过对角点进行采样和分组得到候选的边框。最后，通过分割图对候选边框进行打分，并使用非极大抑制（NMS）对边框进行抑制。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法的关键优势如下：1）因为我们是通过对角点进行采样和分组来检测场景文本的，所以新的方法能够处理任意方向的文本；2）因为我们检测的是角点，而不是边界框，所以新的方法可以自然地避免边框比较大的问题；3）因为使用了位置敏感分割，所以无论是字符、单词，还是文本行，我们都能够较好地分割文本实例；4）在新方法中，候选边框的边界是由角点决定的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;研究人员在来自公共基准测试集上的水平文本、定向文本、长定向文本以及多语言文本中验证了该方法的有效性。结果显示新提出的算法在准确率和速度方面均有优势。具体而言，新方法在 ICDAR2015 [22] 上的 F-Measures 分别为 84.3 %、81.5 % 和 72.4 %，这显著优于现有的方法。此外，新方法在效率上也很有竞争力。它每秒可以处理 10.4 张以上的图像 ( 512×512 )。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;该研究的主要贡献有四个方面：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;（1）提出了一种融合目标检测和分割思想的场景文本检测器，这个场景文本检测器可以以端到端的方式进行训练和测试。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 2 ) 在位置敏感 ROI 池化 [ 9] 的基础上，提出了一种旋转的位置敏感 ROI 平均池化层，可以处理任意方向的请求。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 3 ) 新提出的方法可以同时处理多方向场景文本中的诸多挑战（如旋转、宽高比变化、非常闭合的实例）。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;( 4 ) 新方法在精度和效率上均取得了较好或有竞争力的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;新方法所用的网络全部是卷积神经网络，它扮演着特征提取器、角检测和位置敏感分割的角色。网络结构如图 3 所示。给定一张图片，网络会生成候选的角点和分割图。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4623574144486692&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUdRCoiaOVWZnGRW3JSWZ2J6ibMKBAJVS2WPGibCwRjicca269yxtiacWKBnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1315&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 3. 网络结构。网络包含三个部分：主干网络，角点检测器和位置敏感图预测器。主干网络来自于 DSSD [ 11 ]。角检测器是基于多特征层（紫色的模块）建立的。位置敏感分割预测器与角检测器共享了一些特征（紫色的模块）。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2733433734939759&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUyHibcY1faf7G8AF1yzGpeHKSAHe5G6WG7XOvN0rPicvnOicicoicXiayfRYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1328&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;图 6. 检测结果的一些示例。从左到右依次是： ICDAR2015, ICDAR2013, MSRA-TD500, MLT, COCO-Text。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.541374474053296&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUSNaw0MXxgxpWbZibfuIp27W8Z3brwjvyMIU3zOTGCGMn2fbITOf1j5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;713&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4. MSRA-TD500 上的测试结果。有†表示的模型不基于 VGG16。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1002906976744187&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUDgP7Qoh4V4BcIuHLo99re7HlKxOawibLMnrJlJXsMPPwIJibjI8Dpg9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 6. COCO-Text 上的测试结果。∗代表多尺度。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.277577505407354&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUpxuHVrFibdKc5cf4vFDfyAdShZ1D6oic6OOlrY7nMq9so91PTiaSv4pTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1387&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.08948&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;：&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此前基于深度学习的场景文本检测方法可以被粗略地分为两大类别。第一类将场景文本识别视作一种一般的目标检测问题，这类方法遵循一般目标检测的范式，通过回归文本框来定位场景文本，但是会受到任意方向和较大变化的长宽比的场景文本的困扰。第二类将文本区域进行直接分割，但是大都需要复杂的后处理过程。在这篇论文中，我们提出了一种能将这两类方法的思想进行结合，同时能够避免它们各自弱点的新方法。我们提出了通过定位文本边界框的角点，并在相对位置分割文本区域来检测场景文本的方法。在推理阶段，候选边框通过对角点的采样和分组得到，候选边框进一步通过分割图进行打分，然后使用非极大值抑制（NMS）方法对边框进行抑制。与之前的方法相比，我们的方法能够自然地处理长定向文本，并且不需要复杂的后处理过程。在 ICDAR2013、ICDAR2015、MSRA-TD500、MLT 和 COCO-Text 上的实验证明我们提出的方法能够在准确率和效率方面同时达到更好或者更具竞争力的结果。基于 VGG16，我们的方法在 ICDAR2015 上实现了 84.3% 的 F-measure，在 MSRA-TD500 上达到了 81.5% 的 F-measure。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pK4cARk8Ptr10LfzaDRkUw76FPPYDhVFpChU29twtHB3yicHUYYznJR6fia4GfdLjjNscGb03x2Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;height: 20px;width: 39px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;2089188092&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author>思源</author>
<guid isPermaLink="false">2018-03-01-1000000617</guid>
<pubDate>Thu, 01 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>业界 | 前微软城市计算负责人郑宇出任京东金融首席数据科学家</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-28-1000000616_503254748.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520030828&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=iPELhTSTRmK0MYt*xkDLzwoKP8gO6hd2Zr2gW*CGW8gTC1sXUolY0EqXWNexrLWX89GW-arwJP-S3HEVfMuDznfyrpBVTpHfOhtez4DdC8cOmJF9y7Slytp7UJenrit7lrUhL9eXBNQxgE8Feq-L0A05WfPGgptG4ztCV4NZxp0=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-28&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;max-width: 100%;font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Matthew Sotoudeh等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：路雪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，英特尔的研究者提出新型深度神经网络压缩技术 DeepThin，适合移动端设备，性能优于其他压缩技术。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：DeepThin: A Self-Compressing Library for Deep Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28087167070217917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15LvOapOzFkq9vSWuJ4kRIFgz80UYn2wMMvfGnufYWSm49U2Wng3E55A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.06944&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：随着业界在移动设备上部署越来越大、越来越复杂的神经网络，这些设备的内存和计算资源所面临的压力也越来越大。深度压缩（或深度神经网络权重矩阵压缩）技术为此类场景扩展了应用资源。现有的压缩方法无法高效压缩模型，压缩 1-2% 都比较困难。我们开发了一种新的压缩技术 DeepThin，该技术基于低秩分解领域的现有研究。我们将秩分解和向近似函数添加非线性的重塑过程结合起来，从而识别和打破由低秩近似造成的人工约束。我们将 DeepThin 部署为一个与 TensorFlow 相整合的 plug-gable 库，使用户无缝压缩不同粒度的模型。我们在两个顶尖的声学模型 TFKaldi 和 ZXC DeepSpeech 上评估 DeepThin，将其与之前的压缩方法（剪枝、HashNet 和秩分解）、实证有限研究方法和手动调整模型进行了对比。在 TFKaldi 上，DeepThin 网络的词错率（WER）在几乎所有测试压缩率情况下优于其他方法，平均优于秩分解 60%，优于剪枝 57%，优于等大小的手动调整网络 23%，优于计算成本高昂的 HashNet 6%。在 DeepSpeech 上，DeepThin 压缩网络比所有其他压缩方法的测试损失都低，优于秩分解 28%，优于剪枝 27%，优于手动调整同样大小网络 20%，优于 HashNet 12%。DeepThin 还使推断速度提升了 2 倍到 14 倍，提升幅度取决于压缩率和平台缓存大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;1 引言和动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近年来，机器学习算法越来越广泛地应用于消费者产品中，如个人助手中的语音识别。这些算法依赖于大型权重矩阵将网络中的不同节点之间的关系进行编码。完美情况下，这些算法将直接在客户端设备上运行，如 Amazon Echo [20] 和 Google Home [14]。&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;不过，此类设备通常是移动、低功耗设备，因此运行此类对内存、性能和能耗有很高要求的算法并不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了解决该问题，很多开发者致力于在高性能云服务器上执行推断模型，和在客户端和服务器之间传输模型输入和输出。但是，该解决方案带来了很多问题，如高昂的运算成本、移动网络上的大量数据迁移、用户隐私担忧，以及延迟增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期研究调查了可将模型压缩至能够在客户端设备上直接高效执行的方法。此类压缩方法必须在基本不影响预测准确率、运行时性能或工程时间量的前提下降低模型空间需求。我们的研究基于低秩分解领域的现有研究，我们开发了一种新型压缩方法和 DeepThin 库，该方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;使用辅助中间矩阵和高效的重新布局操作，解决了机器学习模型参数极低秩矩阵分解的基础对称性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;整合了流行和常用的 TensorFlow 框架，使用户无缝压缩不同粒度的模型。我们在该库中实现了之前的压缩技术，以对比不同压缩方法的准确率损失。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在同样大小的网络上，比其他压缩方法的准确率更高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在我们基于 MKL [11] 的自定义 C++ TensorFlow 操作帮助下，实验证明其推断性能加速比未压缩的模型提高 2 倍到 14 倍。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3. DeepThin 压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;标准的深度神经网络包含一系列有序连接的层级（layer），输入数据依次通过各层直到获得想要的输出。每个层计算先前层输出与当前层权重矩阵之间的矩阵乘积。在计算完矩阵乘积之后，将结果加上偏置项并馈送到非线性激活函数而得到输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对有时间依赖性的数据，可使用循环神经网络。尽管有很多不同类型的 RNN，但它们都涉及一种包含若干（通常 3 或 4）类似于上述计算步骤的模型。这样的模型要比寻常的 DNN 更具参数效率，但仍旧需要特别大的权重矩阵来获得优秀的准确率，因此它们可以从压缩方法中得到巨大收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对视觉数据而言，卷积神经网络从输入数据中学习到滤波器组（权重），来提取常见特征。每层的正向传播步骤都类似于上面描述的层运算。在此论文中，我们重点放在了 RNN 和前馈 DNN。然而，把 DeepThin 压缩方法应用到 CNN 也没有任何基础限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在该研究中，我们将该压缩方法单独应用到每层的权重矩阵。具备非线性激活函数 a、权重 W、偏置项 B 的单个层可定义为：Y = a(X.W + B) (1)，其中 W 和 B 是必须存储在该网络内的可学习参数。B 的大小与 W 相比可以忽略不计，因此这里我们只考虑 W 参数的压缩（不过我们在评估中也压缩偏置项）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;DeepThin 架构可压缩任意存储大型权重矩阵（如公式 1 中的 W）的模型，不过准确率会有些微损失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.6998158379373849&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM155ia6Ftg3eHMibBYIUKQUZSSgJxYS2cyRJv53LAfFM0TULWsZGMNQ6rIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;543&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 权重矩阵的低秩分解：随着 r 变小，重构矩阵的行和列对应地实现缩放。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.339652448657188&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15HUZs34HwTWRupBpq635qlqMeABNNEWa5cmazodeEZoAT44GTycloCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 2. 打破分解创建的人工结构约束。该变换具备两个可学习参数：低秩因子 X^f 和 W^f。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;6 准确率结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19978517722878625&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15lv0k63lcOEwfJpkZo4Act0ibeCZicneVUaR3fm3pA8onmx2rzrIrAdpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;931&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 1. 与其他四种压缩方法相比，DeepThin 的平均提升。TFKaldi 数值是关于词错率下降，DeepSpeech 数值是关于测试误差减少。这里，我们看到不同的压缩方法在不同的数据集上各有偏重，而 DeepThin 在几乎所有测试情况中打败了其他压缩方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;7 性能结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5651282051282052&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15oViceFUtfiaic85pq66Fe3pUQqzjpqff3dHaIyYxSibibkteiaofIanCkic3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;975&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 2. TFKaldi 和 DeepSpeech 上，DeepThin 模型在不同压缩大小和机器情况中的执行速度对比。不同机器之间的压缩大小略有不同，但是准确程度在 0.0001 以内。所有结果都以比未压缩的基线模型速度「X faster」的形式呈现。我们发现最大的提升来自缓存较小的平台，使用 DeepThin 可持续降低所有测试配置中的执行时间，使之更适合延迟和电量使用比较重要的环境。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1435818873&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-28-1000000616_503254748</guid>
<pubDate>Wed, 28 Feb 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
