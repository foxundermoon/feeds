<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>机器之心</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/</link>
<description>专业的人工智能媒体和产业服务平台</description>
<language>zh-cn</language>
<lastBuildDate>Sun, 25 Feb 2018 22:20:11 +0800</lastBuildDate>
<item>
<title>专访 | 这位「计算」的信徒，要用机器智能塑造城市的未来</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-25-1000000613_503254602.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QNex6w2cpGii-Sc5rYKv7YdBH1IbXL6xXH9areixO6rFgMRqtmDqItO0g*4zvZ1bzYK8TmqDCU4maZ*qSNzsk3s=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 美国东北大学提出MoNet，使用紧密池化缓解特征高维问题                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-25&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Mengran Gou等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#7f7f7f;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;参与：路雪、黄小天、邱陆陆&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，来自美国东北大学和美国信息科学研究所的研究者联合发布论文《MoNet: Moments Embedding Network》，提出 MoNet 网络，使用新型子矩阵平方根层，在双线性池化之前执行矩阵归一化，结合紧凑池化在不损害性能的前提下大幅降低维度，其性能优于 G^2DeNet。目前该论文已被 CVPR 2018 接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将图像的局部表示嵌入成既具有代表性、又不受轻微噪声影响的特征，是很多计算机视觉任务中的重要一步。在深度卷积神经网络（CNN）成功之前，研究人员使用手动的连续独立步骤解决该问题。典型包括 HOG、SIFT、协方差描述子、VLAD、Fisher 向量和双线性池化。尽管 CNN 是端到端地训练的，但是它们可以被看作两部分：卷积层负责特征提取步骤，后面的全连接层是编码步骤。现在已有多项研究探索用卷积嵌入方法替换全连接层，无论训练采用两段式还是端到端方式。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.42020497803806733&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmvMNsNgWiasNhqbbpicrlnCoqFibkKiaibFXFnk14lg29Hk4WHEU4OAoibBkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;表 1. 不同神经网络的二阶统计信息对比。双线性 CNN（BCNN）仅具备二阶信息，没有使用矩阵归一化。改进后的 BCNN（iBCNN）和 G^2DeNet 都利用了矩阵归一化，但是都受制于高维度，因为它们需要计算一个很大的池化矩阵的平方根。本论文提出的 MoNet，在新型子矩阵平方根层（sub-matrix square-root layer）的帮助下，可以直接归一化局部特征，同时，通过使用紧凑池化（compact pooling）替代全双线性池化，可以大幅降低最后的表示维度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;双线性 CNN 由 Lin et al. 首次提出，旨在池化不同空间位置的二阶统计信息。双线性池化已被证明在多项任务中有用，包括细粒度图像分类、大规模图像识别、分割、视觉问答、人脸识别和艺术风格重建。Wang et al. 提出，使用高斯嵌入层纳入一阶信息。实践证明，归一化方法对这些 CNN 的性能也很重要。研究者提出了两种归一化方法用于双线性池化矩阵：对于&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26804123711340205&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmIv8wV7uXPraeJPlvkshhwiaazwhmh3xydme9KmCOCFRYwhmNIVK1smQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;97&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;其中&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.24260355029585798&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmneqxl8gzn6yyyh0qKvEQSkCDox4RZ6pQ00arEhQmUs3Xic13KuxsWrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;169&quot; style=&quot;text-align: justify;width: 86px;height: 21px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;表示局部特征，一方面，由于 M 是正定对称矩阵（SPD），Ionescu et al. 提出使用矩阵对数（matrix-logarithm）来将 SPD 矩阵从黎曼流行映射到欧氏空间，即&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1065989847715736&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmibx05VUdEiaxZdaEJ9l5kWMH8pl8GPbyJjjFA2LqMhqibUxWctNdX3Uwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;197&quot; style=&quot;&quot;&gt;   &lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;（&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.21951219512195122&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjhcBa9z5Z1BfO87HzKYdo6iczdTPaEA7LtaKPQq0VgghYxPYnwrwB3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;123&quot; style=&quot;text-align: justify;width: 104px;height: 23px;&quot;&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;另一方面，Wang et al. 提出矩阵方幂（matrix-power）方法，将 M 非线性地扩展到&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5324675324675324&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUm2aSsVKzOupaDicRPvsEPYoEX9EdmbbnLklzDTEmTHSJxwwNsvKKfNTQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;154&quot; style=&quot;width: 41px;height: 22px;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2857142857142857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmfRgEsj3LZKNTdZ0FC7QvWLdDW9UUjAqxcKAUniadaznJgYAxq0jjF7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;84&quot; style=&quot;width: 67px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;。两项研究中，矩阵方幂的性能和数值稳定性都优于矩阵对数。此外，Li et al. 对矩阵方幂归一化在解决通用大规模图像识别问题上的优秀性能提供了理论支持。因此，本论文提出将矩阵方幂正则化整合进 MoNet 架构中。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.296140350877193&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmoWuqW8TSS8Th6haTicebW0FUgmnPmX84vfHIGG8Et6DgGT1iaNmfP8ibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1425&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 论文提出的 MoNet 架构图示。该架构使用论文提出的子矩阵平方根层，这使得在双线性池化之前执行矩阵归一化或进一步使用紧凑池化，在不损害性能的前提下大幅降低维度成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;上述特征编码的一个重要缺陷是编码后特征的维度极高。由于张量相乘，最后的特征维度是&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9555555555555556&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjvyyNHVZFia9BI9icwCFCAM65wRibKEO1vGl6D1XDkf0ZibgSbDiaibJUQ3g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;90&quot; style=&quot;width: 25px;height: 24px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;，其中 C 是最后一个卷积层的特征通道数。即使在 C 相对较低的情况下，如 VGG16 中，C = 512，最后特征的维度也超过 260K。该问题可通过随机投影（random projection）、张量速写（tensor sketching）和低秩属性来缓解。但是，由于矩阵方幂归一化层应用在池化矩阵 M 上，因此很难结合矩阵归一化和紧凑池化来同时达到更好的性能和更低的最后特征维度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本论文使用同质填充局部特征（homogeneous padded local feature）的张量积重写了 G^2DeNet 的方程，使之对齐 BCNN 架构，以使高斯嵌入操作和双线性池化解耦合。本论文没有特别关注双线性池化矩阵 M，而是推导出子矩阵平方根层，对（非）同质局部特征上直接执行矩阵方幂归一化。在新型子矩阵平方根层的帮助下，研究者利用紧凑池化逼近张量积，同时使维度更低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;本论文的贡献有以下三方面：&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用实证矩矩阵（moment matrix）结合 G^2DeNet 和双线性池化 CNN，并将高斯嵌入与双线性池化解耦合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;提出新型子矩阵平方根层，在双线性池化层之前直接对特征执行归一化处理，从而利用紧凑池化降低表示的维度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用矩阵反向传播推导出子矩阵平方根层的梯度，这样 MoNet 架构可以进行协同优化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;MoNet&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;MoNet 网络的架构概述如上述图 1 所示。在本节中，我们将详述每个模块的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对于输入图像 I，ReLU X 之后最后一个卷积层的输出由整个空间位置 i = 1, 2, . . . , n 上的局部特征 x_i 组成。接着，我们将其映射到齐次坐标，方法是添加额外的值为 1 的维度，并把所有元素除以&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8181818181818182&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmdmcOu9Bru2qB3WDyib7EJKUXgyCVKWSZMUALxic5cY7BXoQibHRATZibibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;44&quot; style=&quot;width: 23px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。之后，应用一个适当的子矩阵平方根归一化。最后，使用一个紧密双线性池化层池化整个空间位置中所有 n 个特征，并在最后的全连接层之前进行逐元素的平方根正则化和&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9565217391304348&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmcxqFIcZkqn5GVceA9AHQjVVPEKChN29CMGH78ibPT7CaTUiauH4ianGhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;46&quot; style=&quot;width: 23px;height: 22px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;归一化。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.34215500945179583&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmJnV8wjh1OavicwGOYCKcM5ibyaiauAymvFLZbiauaOxjJGMHYj7PoMxVyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1058&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4：细粒度分类上的实验结果。双线性和 TS 分别表征全双线性池化和 Tensor Sketch 紧密池化。每栏中的最佳表现标为红色。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：MoNet: Moments Embedding Network&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.27570921985815605&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmPhiaiayqk3GBraEVdNvw1LmSo0sNKYngJu2Db3CmshD3xhSITmGKg9sg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1128&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.07303&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期双线性池化作为一种特征编码层被提出，可在深度网络的卷积层之后使用，提升在多个视觉任务中的表现。与传统的全局平均池化层或全连接层相比，双线性池化以平移不变式的形式收集二阶信息。但是，这一池化层家族的一个严重弊端是其维度爆炸。为解决这一问题，已探索了紧密的近似池化方法。另外，最近成果表明，通过矩阵归一化来调整不稳定的较高阶信息可获得显著的性能提升。然而，紧密池化与矩阵归一化的结合至今未被探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本论文中，我们通过实证矩矩阵结合了双线性池化层与全局高斯嵌入层。此外，我们提出一个全新的子矩阵平方根层，借助此层，可以直接归一化卷积层的输出，并通过现成的紧密池化方法来缓解维度问题。我们在三个广泛使用的细粒度分类数据集上进行了实验，实验表明，我们提出的 MoNet 架构相比 G^2DeNet 架构有着更好的表现。与紧密池化技术结合使用时，本方法可以用维度数降低了 96% 的编码特征获得可比的表现。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmWrcc4I5avU7mZ7JTgSYJrKTAiapiaLbcpfEo30prFbwRaklvyHPK8w5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 46px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;991171337&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author>刘燕</author>
<guid isPermaLink="false">2018-02-25-1000000613_503254602</guid>
<pubDate>Sun, 25 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>CVPR 2018 | 美国东北大学提出MoNet，使用紧密池化缓解特征高维问题</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-25-1000000613_503254594.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QNex6w2cpGii-Sc5rYKv7Yflu52H0D*bpKrGeIz3HRGnW03xEcUjoHoH*71dLuUCkcHDVkOF3gGCF7nxEbdIE6c=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 美国东北大学提出MoNet，使用紧密池化缓解特征高维问题                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-25&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Mengran Gou等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#7f7f7f;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;参与：路雪、黄小天、邱陆陆&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，来自美国东北大学和美国信息科学研究所的研究者联合发布论文《MoNet: Moments Embedding Network》，提出 MoNet 网络，使用新型子矩阵平方根层，在双线性池化之前执行矩阵归一化，结合紧凑池化在不损害性能的前提下大幅降低维度，其性能优于 G^2DeNet。目前该论文已被 CVPR 2018 接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将图像的局部表示嵌入成既具有代表性、又不受轻微噪声影响的特征，是很多计算机视觉任务中的重要一步。在深度卷积神经网络（CNN）成功之前，研究人员使用手动的连续独立步骤解决该问题。典型包括 HOG、SIFT、协方差描述子、VLAD、Fisher 向量和双线性池化。尽管 CNN 是端到端地训练的，但是它们可以被看作两部分：卷积层负责特征提取步骤，后面的全连接层是编码步骤。现在已有多项研究探索用卷积嵌入方法替换全连接层，无论训练采用两段式还是端到端方式。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.42020497803806733&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmvMNsNgWiasNhqbbpicrlnCoqFibkKiaibFXFnk14lg29Hk4WHEU4OAoibBkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;表 1. 不同神经网络的二阶统计信息对比。双线性 CNN（BCNN）仅具备二阶信息，没有使用矩阵归一化。改进后的 BCNN（iBCNN）和 G^2DeNet 都利用了矩阵归一化，但是都受制于高维度，因为它们需要计算一个很大的池化矩阵的平方根。本论文提出的 MoNet，在新型子矩阵平方根层（sub-matrix square-root layer）的帮助下，可以直接归一化局部特征，同时，通过使用紧凑池化（compact pooling）替代全双线性池化，可以大幅降低最后的表示维度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;双线性 CNN 由 Lin et al. 首次提出，旨在池化不同空间位置的二阶统计信息。双线性池化已被证明在多项任务中有用，包括细粒度图像分类、大规模图像识别、分割、视觉问答、人脸识别和艺术风格重建。Wang et al. 提出，使用高斯嵌入层纳入一阶信息。实践证明，归一化方法对这些 CNN 的性能也很重要。研究者提出了两种归一化方法用于双线性池化矩阵：对于&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26804123711340205&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmIv8wV7uXPraeJPlvkshhwiaazwhmh3xydme9KmCOCFRYwhmNIVK1smQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;97&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;其中&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.24260355029585798&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmneqxl8gzn6yyyh0qKvEQSkCDox4RZ6pQ00arEhQmUs3Xic13KuxsWrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;169&quot; style=&quot;text-align: justify;width: 86px;height: 21px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;表示局部特征，一方面，由于 M 是正定对称矩阵（SPD），Ionescu et al. 提出使用矩阵对数（matrix-logarithm）来将 SPD 矩阵从黎曼流行映射到欧氏空间，即&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1065989847715736&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmibx05VUdEiaxZdaEJ9l5kWMH8pl8GPbyJjjFA2LqMhqibUxWctNdX3Uwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;197&quot; style=&quot;&quot;&gt;   &lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;（&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.21951219512195122&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjhcBa9z5Z1BfO87HzKYdo6iczdTPaEA7LtaKPQq0VgghYxPYnwrwB3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;123&quot; style=&quot;text-align: justify;width: 104px;height: 23px;&quot;&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;另一方面，Wang et al. 提出矩阵方幂（matrix-power）方法，将 M 非线性地扩展到&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5324675324675324&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUm2aSsVKzOupaDicRPvsEPYoEX9EdmbbnLklzDTEmTHSJxwwNsvKKfNTQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;154&quot; style=&quot;width: 41px;height: 22px;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2857142857142857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmfRgEsj3LZKNTdZ0FC7QvWLdDW9UUjAqxcKAUniadaznJgYAxq0jjF7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;84&quot; style=&quot;width: 67px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;。两项研究中，矩阵方幂的性能和数值稳定性都优于矩阵对数。此外，Li et al. 对矩阵方幂归一化在解决通用大规模图像识别问题上的优秀性能提供了理论支持。因此，本论文提出将矩阵方幂正则化整合进 MoNet 架构中。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.296140350877193&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmoWuqW8TSS8Th6haTicebW0FUgmnPmX84vfHIGG8Et6DgGT1iaNmfP8ibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1425&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 论文提出的 MoNet 架构图示。该架构使用论文提出的子矩阵平方根层，这使得在双线性池化之前执行矩阵归一化或进一步使用紧凑池化，在不损害性能的前提下大幅降低维度成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;上述特征编码的一个重要缺陷是编码后特征的维度极高。由于张量相乘，最后的特征维度是&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9555555555555556&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjvyyNHVZFia9BI9icwCFCAM65wRibKEO1vGl6D1XDkf0ZibgSbDiaibJUQ3g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;90&quot; style=&quot;width: 25px;height: 24px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;，其中 C 是最后一个卷积层的特征通道数。即使在 C 相对较低的情况下，如 VGG16 中，C = 512，最后特征的维度也超过 260K。该问题可通过随机投影（random projection）、张量速写（tensor sketching）和低秩属性来缓解。但是，由于矩阵方幂归一化层应用在池化矩阵 M 上，因此很难结合矩阵归一化和紧凑池化来同时达到更好的性能和更低的最后特征维度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本论文使用同质填充局部特征（homogeneous padded local feature）的张量积重写了 G^2DeNet 的方程，使之对齐 BCNN 架构，以使高斯嵌入操作和双线性池化解耦合。本论文没有特别关注双线性池化矩阵 M，而是推导出子矩阵平方根层，对（非）同质局部特征上直接执行矩阵方幂归一化。在新型子矩阵平方根层的帮助下，研究者利用紧凑池化逼近张量积，同时使维度更低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;本论文的贡献有以下三方面：&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用实证矩矩阵（moment matrix）结合 G^2DeNet 和双线性池化 CNN，并将高斯嵌入与双线性池化解耦合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;提出新型子矩阵平方根层，在双线性池化层之前直接对特征执行归一化处理，从而利用紧凑池化降低表示的维度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用矩阵反向传播推导出子矩阵平方根层的梯度，这样 MoNet 架构可以进行协同优化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;MoNet&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;MoNet 网络的架构概述如上述图 1 所示。在本节中，我们将详述每个模块的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对于输入图像 I，ReLU X 之后最后一个卷积层的输出由整个空间位置 i = 1, 2, . . . , n 上的局部特征 x_i 组成。接着，我们将其映射到齐次坐标，方法是添加额外的值为 1 的维度，并把所有元素除以&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8181818181818182&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmdmcOu9Bru2qB3WDyib7EJKUXgyCVKWSZMUALxic5cY7BXoQibHRATZibibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;44&quot; style=&quot;width: 23px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。之后，应用一个适当的子矩阵平方根归一化。最后，使用一个紧密双线性池化层池化整个空间位置中所有 n 个特征，并在最后的全连接层之前进行逐元素的平方根正则化和&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9565217391304348&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmcxqFIcZkqn5GVceA9AHQjVVPEKChN29CMGH78ibPT7CaTUiauH4ianGhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;46&quot; style=&quot;width: 23px;height: 22px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;归一化。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.34215500945179583&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmJnV8wjh1OavicwGOYCKcM5ibyaiauAymvFLZbiauaOxjJGMHYj7PoMxVyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1058&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4：细粒度分类上的实验结果。双线性和 TS 分别表征全双线性池化和 Tensor Sketch 紧密池化。每栏中的最佳表现标为红色。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：MoNet: Moments Embedding Network&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.27570921985815605&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmPhiaiayqk3GBraEVdNvw1LmSo0sNKYngJu2Db3CmshD3xhSITmGKg9sg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1128&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.07303&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期双线性池化作为一种特征编码层被提出，可在深度网络的卷积层之后使用，提升在多个视觉任务中的表现。与传统的全局平均池化层或全连接层相比，双线性池化以平移不变式的形式收集二阶信息。但是，这一池化层家族的一个严重弊端是其维度爆炸。为解决这一问题，已探索了紧密的近似池化方法。另外，最近成果表明，通过矩阵归一化来调整不稳定的较高阶信息可获得显著的性能提升。然而，紧密池化与矩阵归一化的结合至今未被探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本论文中，我们通过实证矩矩阵结合了双线性池化层与全局高斯嵌入层。此外，我们提出一个全新的子矩阵平方根层，借助此层，可以直接归一化卷积层的输出，并通过现成的紧密池化方法来缓解维度问题。我们在三个广泛使用的细粒度分类数据集上进行了实验，实验表明，我们提出的 MoNet 架构相比 G^2DeNet 架构有着更好的表现。与紧密池化技术结合使用时，本方法可以用维度数降低了 96% 的编码特征获得可比的表现。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmWrcc4I5avU7mZ7JTgSYJrKTAiapiaLbcpfEo30prFbwRaklvyHPK8w5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 46px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;500498229&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-25-1000000613_503254594</guid>
<pubDate>Sun, 25 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>教程 | 通过Python实现马尔科夫链蒙特卡罗方法的入门级应用</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-25-1000000613_503254579.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QNex6w2cpGii-Sc5rYKv7Yfq9t9ZgErKOdSz9DZFQupryFU1mdvJtSTYxlV5u806HEH1HgucwUNjNwvbDJQ2LXk=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 美国东北大学提出MoNet，使用紧密池化缓解特征高维问题                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-25&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Mengran Gou等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#7f7f7f;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;参与：路雪、黄小天、邱陆陆&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，来自美国东北大学和美国信息科学研究所的研究者联合发布论文《MoNet: Moments Embedding Network》，提出 MoNet 网络，使用新型子矩阵平方根层，在双线性池化之前执行矩阵归一化，结合紧凑池化在不损害性能的前提下大幅降低维度，其性能优于 G^2DeNet。目前该论文已被 CVPR 2018 接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将图像的局部表示嵌入成既具有代表性、又不受轻微噪声影响的特征，是很多计算机视觉任务中的重要一步。在深度卷积神经网络（CNN）成功之前，研究人员使用手动的连续独立步骤解决该问题。典型包括 HOG、SIFT、协方差描述子、VLAD、Fisher 向量和双线性池化。尽管 CNN 是端到端地训练的，但是它们可以被看作两部分：卷积层负责特征提取步骤，后面的全连接层是编码步骤。现在已有多项研究探索用卷积嵌入方法替换全连接层，无论训练采用两段式还是端到端方式。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.42020497803806733&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmvMNsNgWiasNhqbbpicrlnCoqFibkKiaibFXFnk14lg29Hk4WHEU4OAoibBkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;表 1. 不同神经网络的二阶统计信息对比。双线性 CNN（BCNN）仅具备二阶信息，没有使用矩阵归一化。改进后的 BCNN（iBCNN）和 G^2DeNet 都利用了矩阵归一化，但是都受制于高维度，因为它们需要计算一个很大的池化矩阵的平方根。本论文提出的 MoNet，在新型子矩阵平方根层（sub-matrix square-root layer）的帮助下，可以直接归一化局部特征，同时，通过使用紧凑池化（compact pooling）替代全双线性池化，可以大幅降低最后的表示维度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;双线性 CNN 由 Lin et al. 首次提出，旨在池化不同空间位置的二阶统计信息。双线性池化已被证明在多项任务中有用，包括细粒度图像分类、大规模图像识别、分割、视觉问答、人脸识别和艺术风格重建。Wang et al. 提出，使用高斯嵌入层纳入一阶信息。实践证明，归一化方法对这些 CNN 的性能也很重要。研究者提出了两种归一化方法用于双线性池化矩阵：对于&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26804123711340205&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmIv8wV7uXPraeJPlvkshhwiaazwhmh3xydme9KmCOCFRYwhmNIVK1smQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;97&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;其中&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.24260355029585798&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmneqxl8gzn6yyyh0qKvEQSkCDox4RZ6pQ00arEhQmUs3Xic13KuxsWrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;169&quot; style=&quot;text-align: justify;width: 86px;height: 21px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;表示局部特征，一方面，由于 M 是正定对称矩阵（SPD），Ionescu et al. 提出使用矩阵对数（matrix-logarithm）来将 SPD 矩阵从黎曼流行映射到欧氏空间，即&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1065989847715736&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmibx05VUdEiaxZdaEJ9l5kWMH8pl8GPbyJjjFA2LqMhqibUxWctNdX3Uwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;197&quot; style=&quot;&quot;&gt;   &lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;（&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.21951219512195122&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjhcBa9z5Z1BfO87HzKYdo6iczdTPaEA7LtaKPQq0VgghYxPYnwrwB3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;123&quot; style=&quot;text-align: justify;width: 104px;height: 23px;&quot;&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;另一方面，Wang et al. 提出矩阵方幂（matrix-power）方法，将 M 非线性地扩展到&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5324675324675324&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUm2aSsVKzOupaDicRPvsEPYoEX9EdmbbnLklzDTEmTHSJxwwNsvKKfNTQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;154&quot; style=&quot;width: 41px;height: 22px;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2857142857142857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmfRgEsj3LZKNTdZ0FC7QvWLdDW9UUjAqxcKAUniadaznJgYAxq0jjF7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;84&quot; style=&quot;width: 67px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;。两项研究中，矩阵方幂的性能和数值稳定性都优于矩阵对数。此外，Li et al. 对矩阵方幂归一化在解决通用大规模图像识别问题上的优秀性能提供了理论支持。因此，本论文提出将矩阵方幂正则化整合进 MoNet 架构中。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.296140350877193&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmoWuqW8TSS8Th6haTicebW0FUgmnPmX84vfHIGG8Et6DgGT1iaNmfP8ibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1425&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 论文提出的 MoNet 架构图示。该架构使用论文提出的子矩阵平方根层，这使得在双线性池化之前执行矩阵归一化或进一步使用紧凑池化，在不损害性能的前提下大幅降低维度成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;上述特征编码的一个重要缺陷是编码后特征的维度极高。由于张量相乘，最后的特征维度是&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9555555555555556&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjvyyNHVZFia9BI9icwCFCAM65wRibKEO1vGl6D1XDkf0ZibgSbDiaibJUQ3g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;90&quot; style=&quot;width: 25px;height: 24px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;，其中 C 是最后一个卷积层的特征通道数。即使在 C 相对较低的情况下，如 VGG16 中，C = 512，最后特征的维度也超过 260K。该问题可通过随机投影（random projection）、张量速写（tensor sketching）和低秩属性来缓解。但是，由于矩阵方幂归一化层应用在池化矩阵 M 上，因此很难结合矩阵归一化和紧凑池化来同时达到更好的性能和更低的最后特征维度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本论文使用同质填充局部特征（homogeneous padded local feature）的张量积重写了 G^2DeNet 的方程，使之对齐 BCNN 架构，以使高斯嵌入操作和双线性池化解耦合。本论文没有特别关注双线性池化矩阵 M，而是推导出子矩阵平方根层，对（非）同质局部特征上直接执行矩阵方幂归一化。在新型子矩阵平方根层的帮助下，研究者利用紧凑池化逼近张量积，同时使维度更低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;本论文的贡献有以下三方面：&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用实证矩矩阵（moment matrix）结合 G^2DeNet 和双线性池化 CNN，并将高斯嵌入与双线性池化解耦合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;提出新型子矩阵平方根层，在双线性池化层之前直接对特征执行归一化处理，从而利用紧凑池化降低表示的维度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用矩阵反向传播推导出子矩阵平方根层的梯度，这样 MoNet 架构可以进行协同优化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;MoNet&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;MoNet 网络的架构概述如上述图 1 所示。在本节中，我们将详述每个模块的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对于输入图像 I，ReLU X 之后最后一个卷积层的输出由整个空间位置 i = 1, 2, . . . , n 上的局部特征 x_i 组成。接着，我们将其映射到齐次坐标，方法是添加额外的值为 1 的维度，并把所有元素除以&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8181818181818182&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmdmcOu9Bru2qB3WDyib7EJKUXgyCVKWSZMUALxic5cY7BXoQibHRATZibibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;44&quot; style=&quot;width: 23px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。之后，应用一个适当的子矩阵平方根归一化。最后，使用一个紧密双线性池化层池化整个空间位置中所有 n 个特征，并在最后的全连接层之前进行逐元素的平方根正则化和&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9565217391304348&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmcxqFIcZkqn5GVceA9AHQjVVPEKChN29CMGH78ibPT7CaTUiauH4ianGhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;46&quot; style=&quot;width: 23px;height: 22px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;归一化。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.34215500945179583&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmJnV8wjh1OavicwGOYCKcM5ibyaiauAymvFLZbiauaOxjJGMHYj7PoMxVyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1058&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4：细粒度分类上的实验结果。双线性和 TS 分别表征全双线性池化和 Tensor Sketch 紧密池化。每栏中的最佳表现标为红色。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：MoNet: Moments Embedding Network&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.27570921985815605&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmPhiaiayqk3GBraEVdNvw1LmSo0sNKYngJu2Db3CmshD3xhSITmGKg9sg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1128&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.07303&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期双线性池化作为一种特征编码层被提出，可在深度网络的卷积层之后使用，提升在多个视觉任务中的表现。与传统的全局平均池化层或全连接层相比，双线性池化以平移不变式的形式收集二阶信息。但是，这一池化层家族的一个严重弊端是其维度爆炸。为解决这一问题，已探索了紧密的近似池化方法。另外，最近成果表明，通过矩阵归一化来调整不稳定的较高阶信息可获得显著的性能提升。然而，紧密池化与矩阵归一化的结合至今未被探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本论文中，我们通过实证矩矩阵结合了双线性池化层与全局高斯嵌入层。此外，我们提出一个全新的子矩阵平方根层，借助此层，可以直接归一化卷积层的输出，并通过现成的紧密池化方法来缓解维度问题。我们在三个广泛使用的细粒度分类数据集上进行了实验，实验表明，我们提出的 MoNet 架构相比 G^2DeNet 架构有着更好的表现。与紧密池化技术结合使用时，本方法可以用维度数降低了 96% 的编码特征获得可比的表现。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmWrcc4I5avU7mZ7JTgSYJrKTAiapiaLbcpfEo30prFbwRaklvyHPK8w5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 46px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;858191980&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-25-1000000613_503254579</guid>
<pubDate>Sun, 25 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>从数学到实现，全面回顾高斯过程中的函数最优化</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-25-1000000613.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QNex6w2cpGii-Sc5rYKv7YedRE2zWet6uM-pXbzIkQ5xCsoy7b*4m0AzX0Eq8Xe-7W63efCYlLtSSypvzz5feuU=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 美国东北大学提出MoNet，使用紧密池化缓解特征高维问题                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-25&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Mengran Gou等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#7f7f7f;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;参与：路雪、黄小天、邱陆陆&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，来自美国东北大学和美国信息科学研究所的研究者联合发布论文《MoNet: Moments Embedding Network》，提出 MoNet 网络，使用新型子矩阵平方根层，在双线性池化之前执行矩阵归一化，结合紧凑池化在不损害性能的前提下大幅降低维度，其性能优于 G^2DeNet。目前该论文已被 CVPR 2018 接收。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将图像的局部表示嵌入成既具有代表性、又不受轻微噪声影响的特征，是很多计算机视觉任务中的重要一步。在深度卷积神经网络（CNN）成功之前，研究人员使用手动的连续独立步骤解决该问题。典型包括 HOG、SIFT、协方差描述子、VLAD、Fisher 向量和双线性池化。尽管 CNN 是端到端地训练的，但是它们可以被看作两部分：卷积层负责特征提取步骤，后面的全连接层是编码步骤。现在已有多项研究探索用卷积嵌入方法替换全连接层，无论训练采用两段式还是端到端方式。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.42020497803806733&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmvMNsNgWiasNhqbbpicrlnCoqFibkKiaibFXFnk14lg29Hk4WHEU4OAoibBkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;表 1. 不同神经网络的二阶统计信息对比。双线性 CNN（BCNN）仅具备二阶信息，没有使用矩阵归一化。改进后的 BCNN（iBCNN）和 G^2DeNet 都利用了矩阵归一化，但是都受制于高维度，因为它们需要计算一个很大的池化矩阵的平方根。本论文提出的 MoNet，在新型子矩阵平方根层（sub-matrix square-root layer）的帮助下，可以直接归一化局部特征，同时，通过使用紧凑池化（compact pooling）替代全双线性池化，可以大幅降低最后的表示维度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;双线性 CNN 由 Lin et al. 首次提出，旨在池化不同空间位置的二阶统计信息。双线性池化已被证明在多项任务中有用，包括细粒度图像分类、大规模图像识别、分割、视觉问答、人脸识别和艺术风格重建。Wang et al. 提出，使用高斯嵌入层纳入一阶信息。实践证明，归一化方法对这些 CNN 的性能也很重要。研究者提出了两种归一化方法用于双线性池化矩阵：对于&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26804123711340205&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmIv8wV7uXPraeJPlvkshhwiaazwhmh3xydme9KmCOCFRYwhmNIVK1smQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;97&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;其中&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.24260355029585798&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmneqxl8gzn6yyyh0qKvEQSkCDox4RZ6pQ00arEhQmUs3Xic13KuxsWrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;169&quot; style=&quot;text-align: justify;width: 86px;height: 21px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;表示局部特征，一方面，由于 M 是正定对称矩阵（SPD），Ionescu et al. 提出使用矩阵对数（matrix-logarithm）来将 SPD 矩阵从黎曼流行映射到欧氏空间，即&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1065989847715736&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmibx05VUdEiaxZdaEJ9l5kWMH8pl8GPbyJjjFA2LqMhqibUxWctNdX3Uwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;197&quot; style=&quot;&quot;&gt;   &lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;（&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.21951219512195122&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjhcBa9z5Z1BfO87HzKYdo6iczdTPaEA7LtaKPQq0VgghYxPYnwrwB3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;123&quot; style=&quot;text-align: justify;width: 104px;height: 23px;&quot;&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-align: justify;font-size: 14px;&quot;&gt;另一方面，Wang et al. 提出矩阵方幂（matrix-power）方法，将 M 非线性地扩展到&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5324675324675324&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUm2aSsVKzOupaDicRPvsEPYoEX9EdmbbnLklzDTEmTHSJxwwNsvKKfNTQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;154&quot; style=&quot;width: 41px;height: 22px;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2857142857142857&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmfRgEsj3LZKNTdZ0FC7QvWLdDW9UUjAqxcKAUniadaznJgYAxq0jjF7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;84&quot; style=&quot;width: 67px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;。两项研究中，矩阵方幂的性能和数值稳定性都优于矩阵对数。此外，Li et al. 对矩阵方幂归一化在解决通用大规模图像识别问题上的优秀性能提供了理论支持。因此，本论文提出将矩阵方幂正则化整合进 MoNet 架构中。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.296140350877193&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmoWuqW8TSS8Th6haTicebW0FUgmnPmX84vfHIGG8Et6DgGT1iaNmfP8ibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1425&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 论文提出的 MoNet 架构图示。该架构使用论文提出的子矩阵平方根层，这使得在双线性池化之前执行矩阵归一化或进一步使用紧凑池化，在不损害性能的前提下大幅降低维度成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;上述特征编码的一个重要缺陷是编码后特征的维度极高。由于张量相乘，最后的特征维度是&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9555555555555556&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmjvyyNHVZFia9BI9icwCFCAM65wRibKEO1vGl6D1XDkf0ZibgSbDiaibJUQ3g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;90&quot; style=&quot;width: 25px;height: 24px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;，其中 C 是最后一个卷积层的特征通道数。即使在 C 相对较低的情况下，如 VGG16 中，C = 512，最后特征的维度也超过 260K。该问题可通过随机投影（random projection）、张量速写（tensor sketching）和低秩属性来缓解。但是，由于矩阵方幂归一化层应用在池化矩阵 M 上，因此很难结合矩阵归一化和紧凑池化来同时达到更好的性能和更低的最后特征维度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;本论文使用同质填充局部特征（homogeneous padded local feature）的张量积重写了 G^2DeNet 的方程，使之对齐 BCNN 架构，以使高斯嵌入操作和双线性池化解耦合。本论文没有特别关注双线性池化矩阵 M，而是推导出子矩阵平方根层，对（非）同质局部特征上直接执行矩阵方幂归一化。在新型子矩阵平方根层的帮助下，研究者利用紧凑池化逼近张量积，同时使维度更低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;本论文的贡献有以下三方面：&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用实证矩矩阵（moment matrix）结合 G^2DeNet 和双线性池化 CNN，并将高斯嵌入与双线性池化解耦合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;提出新型子矩阵平方根层，在双线性池化层之前直接对特征执行归一化处理，从而利用紧凑池化降低表示的维度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;利用矩阵反向传播推导出子矩阵平方根层的梯度，这样 MoNet 架构可以进行协同优化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;MoNet&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;MoNet 网络的架构概述如上述图 1 所示。在本节中，我们将详述每个模块的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对于输入图像 I，ReLU X 之后最后一个卷积层的输出由整个空间位置 i = 1, 2, . . . , n 上的局部特征 x_i 组成。接着，我们将其映射到齐次坐标，方法是添加额外的值为 1 的维度，并把所有元素除以&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8181818181818182&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmdmcOu9Bru2qB3WDyib7EJKUXgyCVKWSZMUALxic5cY7BXoQibHRATZibibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;44&quot; style=&quot;width: 23px;height: 19px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。之后，应用一个适当的子矩阵平方根归一化。最后，使用一个紧密双线性池化层池化整个空间位置中所有 n 个特征，并在最后的全连接层之前进行逐元素的平方根正则化和&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9565217391304348&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmcxqFIcZkqn5GVceA9AHQjVVPEKChN29CMGH78ibPT7CaTUiauH4ianGhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;46&quot; style=&quot;width: 23px;height: 22px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;归一化。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.34215500945179583&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmJnV8wjh1OavicwGOYCKcM5ibyaiauAymvFLZbiauaOxjJGMHYj7PoMxVyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1058&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;表 4：细粒度分类上的实验结果。双线性和 TS 分别表征全双线性池化和 Tensor Sketch 紧密池化。每栏中的最佳表现标为红色。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：MoNet: Moments Embedding Network&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.27570921985815605&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmPhiaiayqk3GBraEVdNvw1LmSo0sNKYngJu2Db3CmshD3xhSITmGKg9sg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1128&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.07303&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期双线性池化作为一种特征编码层被提出，可在深度网络的卷积层之后使用，提升在多个视觉任务中的表现。与传统的全局平均池化层或全连接层相比，双线性池化以平移不变式的形式收集二阶信息。但是，这一池化层家族的一个严重弊端是其维度爆炸。为解决这一问题，已探索了紧密的近似池化方法。另外，最近成果表明，通过矩阵归一化来调整不稳定的较高阶信息可获得显著的性能提升。然而，紧密池化与矩阵归一化的结合至今未被探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本论文中，我们通过实证矩矩阵结合了双线性池化层与全局高斯嵌入层。此外，我们提出一个全新的子矩阵平方根层，借助此层，可以直接归一化卷积层的输出，并通过现成的紧密池化方法来缓解维度问题。我们在三个广泛使用的细粒度分类数据集上进行了实验，实验表明，我们提出的 MoNet 架构相比 G^2DeNet 架构有着更好的表现。与紧密池化技术结合使用时，本方法可以用维度数降低了 96% 的编码特征获得可比的表现。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW99CnJMuNInq8ayvFdiaduUmWrcc4I5avU7mZ7JTgSYJrKTAiapiaLbcpfEo30prFbwRaklvyHPK8w5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 46px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;881632328&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-25-1000000613</guid>
<pubDate>Sun, 25 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>深度 | 让机器思考与互相理解：DeepMind提出机器心智理论神经网络ToMnet</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-24-1000000612_503254560.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QAoNFMtkLGSPSQ2J1Abpeo77kMRrMy87DiBEaFcIYEhQDX5C3nNpMHKbvl9TRXpEFyy2BBiwjQ0oL8IgPYTkkCM=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    AAAI 2018 | 腾讯AI Lab现场陈述论文：训练L1稀疏模型的象限性消极下降算法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-24&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心发布&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);font-size: 12px;&quot;&gt;&lt;strong&gt;演讲者：&lt;span style=&quot;color: rgb(136, 136, 136);text-align: justify;font-size: 12px;&quot;&gt;王倪剑桥&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;腾讯 AI Lab 共有 12 篇论文入选在美国新奥尔良举行的国际人工智能领域顶级学术会议 AAAI 2018。腾讯技术工程官方号独家编译了论文《训练 L1 稀疏模型的象限性消极下降算法》(Training L1-Regularized Models with Orthant-Wise Passive Descent Algorithms)，该论文被 AAAI 2018 录用为现场陈述论文 (Oral Presentation)，由腾讯 AI Lab 独立完成，王倪剑桥为论文唯一作者。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1704.07987&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.23314606741573032&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2UAF9HpZdt2Wkjh1bmknwOr7C5BbppzVp1dk2IhOogB37EOF3EMbNww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1068&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;中文概要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;L1 范数正则模型是一种常用的高维数据的分析方法。对于现代大规模互联网数据上的该模型，研究其优化算法可以提高其收敛速度，进而在有限时间内显著其模型准确率，或者降低对服务器资源的依赖。经典的随机梯度下降 (SGD) 虽然可以适用于神经网络等多种模型，但对于 L1 范数不可导性并不适用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本文中，我们提出了一种新的随机优化方法，随机象限性消极下降算法 (OPDA)。本算法的出发点是 L1 范数函数在任何一个象限内是连续可导的，因此，模型的参数在每一次更新之后被投影到上一次迭代时所在的象限。我们使用随机方差缩减梯度 (SVRG) 方法产生梯度方向，并结合伪牛顿法 (Quasi-Newton) 来使用损失函数的二阶信息。我们提出了一种新的象限投影方法，使得该算法收敛于一个更加稀疏的最优点。我们在理论上证明了，在强凸和光滑的损失函数上，该算法可以线性收敛。在 RCV1 等典型稀疏数据集上，我们测试了不同参数下 L1/L2 范数约束 Logistic 回归下该算法性能，其结果显著超越了已有的线性收敛算法 Proximal-SVRG，并且在卷积神经网络 (CNN) 的实验上超越 Proximal-SGD 等算法，证明了该算法在凸函数和非凸函数上均有很好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;演讲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;大家好，我是王倪剑桥，来自腾讯 AI Lab。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6100478468899522&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2IiaiccFyf1eqibTED0DMstqGeWbz3oYavLdvG5AjBVG86PF43x9QtDBlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;引言：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学习稀疏表征一直都是一个非常重要的数据分析任务。比如说，在生物学领域，为了对单个个体进行基因分析，常常涉及到数百万个基因，然而其中真正对某任务，比如帮助预测某种稀有癌症，有用的基因片段并不多。在金融序列预测和网络广告等领域，也有很多数据数量甚至比数据维度还小的情况。这本身是一个病态 (ill-condition) 的问题，然而如果对解有一个稀疏先验的话，问题则是可解的。通信领域的压缩感知中的核心部分也是如何高效求解稀疏模型。目前，这些方法包括 Lasso (Robert Tibshirani), Dantzig Selector (Emmanuel Candes, Terrence Tao), OMP (Joel A. Tropp, Tong Zhang), FoBa (Tong Zhang) 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，我们给一个直观的例子，为什么 L1 范数正则项（绝对值的和）适用于求解稀疏模型。下图中，蓝色区域是约束内的可行解区域，左边是 L1 范数球（norm ball），右边是 L2 范数球，红色圈是均方损失函数（average-of-square-loss）的等高线。这些球和等高线之间的交点是模型的解。我们可以看到 L1 正则化模型的解接近 Y 轴，这意味着其 X 维元素更接近于 0。这是一个简单的例子，可以看出来 L1 正则项比 L2 正则项更适合于学习稀疏模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7707317073170732&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2QAG5fcR7g1nZ4IAza0F5BZVkjoiaFKgtpngP8IDXJwvtaX1fzicjAgqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们可以把大部分问题统一为最小化一个正则化函数 P(x)= F(x)+R(x)，其中 F(x) 是 N 个损失函数的平均，其中每个都依赖于一个数据样本，R 是 L1 正则项。我们还假设每个损失函数都满足二次可导 (twice differentiable)、强凸 (strongly-convex) 和光滑 (smooth)。由于该 L1 范数是不可导的（在零点），目前最通用的优化方法是近端方法 (proximal method)，通过迭代式地采取梯度下降步骤，然后在当前点上优化一个 proximal 问题。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7527010804321729&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2VZmAGYbLIUn5Uia7QxAxyuyFghIlskE8Uoq6mZsOdVrUVHLKPkdk8fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;相关文献介绍：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们的主要参考方法是象限性伪牛顿法 (OWL-QN: Galen Andrew, Jianfeng Gao)，这种方法基于 L-BFGS (Jorge Nocedal)，一种最常用的伪牛顿法。该方法 OWL-QN 将更新后的参数限制在一个特定的象限内，因为在每个单个象限中，其绝对值函数实际上是可微分的。OWL-QN 的一个关键创新点与在零点的次梯度 (subgradient) 有关。这里 L1 正则项 R(x) 的次梯度既可以是正λ，也可以是负 λ，那么如何选择次梯度会影响收敛速度。以下面大括号内第三个分支为例：我们研究的是当前点 X 的第 i 维 X_i，和梯度 V_i。如果 X_i 等于 0 且 X_i 加上 λ 为负，那么该次梯度就设为 V_i 加上正 λ，因为在减去这个次梯度之后，X_i 将会是一个正值，那么 R(x) 的次梯度将仍然为正 λ，这会使 L1 范数的次梯度在一次迭代中保持一致。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539203860072377&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2a6toxQiaoUTiczsjSTQ6jco4UO7SiaGKUk1tQb41FkxQX3W2hvTAjyFPg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了处理大规模互联网数据，研究者提出了很多用于加速训练过程的优化方法，比如随机梯度下降法 (SGD)。但是，SGD 通常需要衰减步长才能收敛，而且它的收敛率是次线性的 (sublinear)。近期出现了 SVRG (Rie Johnson, Tong Zhang) 和 SAGA (Aaron Defazio, Francis Bach) 等一些随机方差缩减方法，可以无需降低步长就能收敛，而且可以在光滑和强凸的模型上实现线性收敛率 (linear convergence rate)。在 SGD 方法中，第 k 步的下降方向 v_k 是在该数据集的一个随机子集 S_k 上进行评估的。在 SVRG 方法中，我们需要周期性地在一些参考点（比如 tilde-X）上计算一个准确梯度。这个准确梯度构成了 SVRG 的 v_k 的第三项，然后我们必须通过在 tilde-X 上减去一个随机梯度（这是在同一子集 S_k 上计算的）来平衡它的期望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7535885167464115&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2xoXrW705kktPQiaI1t6ibHfNj9PQ2vn1ROQ8sSzEuhmUZk1oAF2w60Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;受 SVRG 和 OWL-QN 的启发，我们开发了一种针对 L1 正则化模型的随机优化方法。在第一步时，我们计算损失函数 F(x) 的 SVRG，然后我们使用来自 OWL-QN 的思想来计算一个参考方向，尽量使下降方向以在一次迭代后维持同一个象限。而我们的实际下降方向 V_k 是用这里的第三个等式计算的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.749400479616307&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2fF6PreGCOBUgf25HN01ZymqWI96PJ7l70PYsVfcNT3wGOYz7LURZ2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;现在我们可以计算解前进的方向了。我们可以通过计算当前点上的 Hessian 矩阵或估计近似的 Hessian 矩阵（伪牛顿法）来使用该损失函数的二阶信息，从而加速其收敛。然后我们可以通过在当前点附近的 Taylor 二次展开来计算最优下降方向 D_k。如果我们使用 L-BFGS，我们可以绕开耗时的矩阵求逆运算，只通过快速的矩阵向量乘法就可以做到。我们也可以直接将 V_k 分配给 D_k，这样就是一个典型的一阶方法。在这个步骤之后，方向 D_k 的象限必须与参考方向保持一致，这意味着：如果 D_k 的某些维度与参考方向的符号不同，它们就必须被分配为 0，我们将这个对齐后的版本记为 P_k。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7612121212121212&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2cNFibURJ2YuouXqB1bLCfhbrUS9vbZA8mibSlvbDMeYcgJiadpQrqibatA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;除了对齐参考，上述计算梯度并没有涉及到 L1 正则化 R(x) 的偏导数，因为我们要避免对随机梯度的引入额外方差。为了使解是稀疏的，我们提出了一种全新的对齐算子来激励零元素。这个算子作用在 X,Y 两个元素上，如果 X 和 Y 符号不同或 X 的绝对值小于一个阈值，就强制 X 为零。通过这个对齐算子，每次在我们完成了之前的计算之后，我们就检查下一个点是否与当前点在同一个象限，如果不在，下一个点的某些维度就会被强制为零。在这一步之后，显然 X_k 的更多维度应该为零，而不是绝对值很小的非零值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7490996398559424&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2b3q9qRstQiadKLZ50sckvtandmzYwYNyI6PwkTibDo1FdnTmia4d7eJTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;收敛性分析：在这篇论文中，我们证明在平滑性和强凸性的假设下，我们的方法将以一个线性速率收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7621359223300971&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2lldvfuryvFlzbdUbMHJL5SY9MbrzYnG7HorEPEblRdVcXuouFSxbQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了进行可视化，我们在这张图中绘制了在一个简单的二维合成函数的优化轨迹。我们的方法 OPDA 用红线标识，作为基准的 Proximal-Gradient Descent 算法用蓝线标识。在迭代了同样多次数之后，我们看到 OPDA 用更快的速度收敛到了等高线中更低的区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7619047619047619&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2Rx2yIBc1BgohFzPS7KvNN8xBal8zYibWpoLGyHzSzlprHxBPSYGtveQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;819&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在凸函数上的实验：我们还使用 L2/L1 regularized Logistic 回归上进行了一些实验。在这一部分，我们将我们的方法与一个线性收敛算法 Prox-SVRG (Lin Xiao, Tong Zhang) 进行了比较。在这张图中，Y 轴表示解的次优性 (suboptimality)，即当前目标函数与最小值之间的间隔；X 轴表示完整扫过数据集的次数。我们发现使用不同的步长以及 L2 和 L1 正则化系数时，OPDA 的速度稳定地超越了 Prox-SVRG 算法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539015606242497&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ST95OPvOSHfvz2taBQKcA81HwwnxBoqGibiccybHZMjx8LU5d6CCeWgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6020408163265306&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2N9V6ia3ncOYia7mpIias4IZASGCYHiaxedytdaas5m5TMknPesYI1ZwsHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1078&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在深度学习上的实验：我们使用 L1 正则化稀疏卷积神经网络 (sparse-CNN) 进行了实验，以表明我们的方法在非凸函数的有效性。下图中红线表示我们的方法，蓝线表示近端 SVRG。我们测试了不同规模的 L1 正则化。我们看到 OPDA 收敛速度比近 Prox-SGD 更快。而且在 L1 正则项更强的情况下，这种差异更大。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7547846889952153&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ia2GiaT9kCxWhLBP9kbict7ZUX8Ztn8da7lNIJtMzJdEpPJ6890XaY0rA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出的 OPDA 算法可以适用于快速优化 L1 正则的稀疏模型。实际上，由于我们的方法的象限性本质，下降方向和更新后的点的许多维度都会在对齐过程中被强制变为零，这会使等效步长变小很多；但是，在同等步长条件下，我们方法的速度仍然远远快于近端方法。这证明我们提出的对齐算子确实能将方向调校得更好，使其整体框架更为有效，而且在每次迭代中所需额外运算量接近可以忽略不计。 &lt;span style=&quot;color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);&quot;&gt; &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKczlUNeEAmUicw7MXcFnte6PhPpD5AHeEVvqImFdQz3ziaXsDmtjAp2icXupgXc6j3OpGl8dvHEicvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);white-space: normal;font-size: 16px;text-align: justify;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 51px !important;&quot; width=&quot;43px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3654970760233918&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9cWqUGib1I8LicEna2GCqsE2zaRCjXkkQxUj4xSMwic51nHPBia7CbbDHcJTkShoT3z4RZCh1v4KPYGA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1026&quot; width=&quot;auto&quot; style=&quot;font-size: 16px;white-space: normal;color: rgb(62, 62, 62);text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: auto !important;&quot;&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1276491573&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;a class=&quot;media_tool_meta meta_primary&quot; id=&quot;js_view_source&quot; href=&quot;##&quot;&gt;阅读原文&lt;/a&gt;
                                &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;https://mp.weixin.qq.com/mp/homepage?__biz=MzA3MzI4MjgzMw==&amp;amp;hid=11&amp;amp;sn=a2c8b0d29b504f0b5c30cd6c86eb34d7#wechat_redirect&quot; target=&quot;_blank&quot;&gt;阅读原文&lt;/a&gt;
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-24-1000000612_503254560</guid>
<pubDate>Sat, 24 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>前沿 | 剧本自动生成电影：杜克大学提出AI视频生成新方法</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-24-1000000612_503254558.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QAoNFMtkLGSPSQ2J1Abpeo6HfjgeEW*E6teHYB756SYoN1fH0yN8gwpS9xYn*hd4uqeSv1zef17I0bwjOEk3HaA=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    AAAI 2018 | 腾讯AI Lab现场陈述论文：训练L1稀疏模型的象限性消极下降算法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-24&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心发布&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);font-size: 12px;&quot;&gt;&lt;strong&gt;演讲者：&lt;span style=&quot;color: rgb(136, 136, 136);text-align: justify;font-size: 12px;&quot;&gt;王倪剑桥&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;腾讯 AI Lab 共有 12 篇论文入选在美国新奥尔良举行的国际人工智能领域顶级学术会议 AAAI 2018。腾讯技术工程官方号独家编译了论文《训练 L1 稀疏模型的象限性消极下降算法》(Training L1-Regularized Models with Orthant-Wise Passive Descent Algorithms)，该论文被 AAAI 2018 录用为现场陈述论文 (Oral Presentation)，由腾讯 AI Lab 独立完成，王倪剑桥为论文唯一作者。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1704.07987&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.23314606741573032&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2UAF9HpZdt2Wkjh1bmknwOr7C5BbppzVp1dk2IhOogB37EOF3EMbNww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1068&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;中文概要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;L1 范数正则模型是一种常用的高维数据的分析方法。对于现代大规模互联网数据上的该模型，研究其优化算法可以提高其收敛速度，进而在有限时间内显著其模型准确率，或者降低对服务器资源的依赖。经典的随机梯度下降 (SGD) 虽然可以适用于神经网络等多种模型，但对于 L1 范数不可导性并不适用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本文中，我们提出了一种新的随机优化方法，随机象限性消极下降算法 (OPDA)。本算法的出发点是 L1 范数函数在任何一个象限内是连续可导的，因此，模型的参数在每一次更新之后被投影到上一次迭代时所在的象限。我们使用随机方差缩减梯度 (SVRG) 方法产生梯度方向，并结合伪牛顿法 (Quasi-Newton) 来使用损失函数的二阶信息。我们提出了一种新的象限投影方法，使得该算法收敛于一个更加稀疏的最优点。我们在理论上证明了，在强凸和光滑的损失函数上，该算法可以线性收敛。在 RCV1 等典型稀疏数据集上，我们测试了不同参数下 L1/L2 范数约束 Logistic 回归下该算法性能，其结果显著超越了已有的线性收敛算法 Proximal-SVRG，并且在卷积神经网络 (CNN) 的实验上超越 Proximal-SGD 等算法，证明了该算法在凸函数和非凸函数上均有很好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;演讲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;大家好，我是王倪剑桥，来自腾讯 AI Lab。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6100478468899522&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2IiaiccFyf1eqibTED0DMstqGeWbz3oYavLdvG5AjBVG86PF43x9QtDBlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;引言：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学习稀疏表征一直都是一个非常重要的数据分析任务。比如说，在生物学领域，为了对单个个体进行基因分析，常常涉及到数百万个基因，然而其中真正对某任务，比如帮助预测某种稀有癌症，有用的基因片段并不多。在金融序列预测和网络广告等领域，也有很多数据数量甚至比数据维度还小的情况。这本身是一个病态 (ill-condition) 的问题，然而如果对解有一个稀疏先验的话，问题则是可解的。通信领域的压缩感知中的核心部分也是如何高效求解稀疏模型。目前，这些方法包括 Lasso (Robert Tibshirani), Dantzig Selector (Emmanuel Candes, Terrence Tao), OMP (Joel A. Tropp, Tong Zhang), FoBa (Tong Zhang) 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，我们给一个直观的例子，为什么 L1 范数正则项（绝对值的和）适用于求解稀疏模型。下图中，蓝色区域是约束内的可行解区域，左边是 L1 范数球（norm ball），右边是 L2 范数球，红色圈是均方损失函数（average-of-square-loss）的等高线。这些球和等高线之间的交点是模型的解。我们可以看到 L1 正则化模型的解接近 Y 轴，这意味着其 X 维元素更接近于 0。这是一个简单的例子，可以看出来 L1 正则项比 L2 正则项更适合于学习稀疏模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7707317073170732&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2QAG5fcR7g1nZ4IAza0F5BZVkjoiaFKgtpngP8IDXJwvtaX1fzicjAgqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们可以把大部分问题统一为最小化一个正则化函数 P(x)= F(x)+R(x)，其中 F(x) 是 N 个损失函数的平均，其中每个都依赖于一个数据样本，R 是 L1 正则项。我们还假设每个损失函数都满足二次可导 (twice differentiable)、强凸 (strongly-convex) 和光滑 (smooth)。由于该 L1 范数是不可导的（在零点），目前最通用的优化方法是近端方法 (proximal method)，通过迭代式地采取梯度下降步骤，然后在当前点上优化一个 proximal 问题。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7527010804321729&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2VZmAGYbLIUn5Uia7QxAxyuyFghIlskE8Uoq6mZsOdVrUVHLKPkdk8fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;相关文献介绍：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们的主要参考方法是象限性伪牛顿法 (OWL-QN: Galen Andrew, Jianfeng Gao)，这种方法基于 L-BFGS (Jorge Nocedal)，一种最常用的伪牛顿法。该方法 OWL-QN 将更新后的参数限制在一个特定的象限内，因为在每个单个象限中，其绝对值函数实际上是可微分的。OWL-QN 的一个关键创新点与在零点的次梯度 (subgradient) 有关。这里 L1 正则项 R(x) 的次梯度既可以是正λ，也可以是负 λ，那么如何选择次梯度会影响收敛速度。以下面大括号内第三个分支为例：我们研究的是当前点 X 的第 i 维 X_i，和梯度 V_i。如果 X_i 等于 0 且 X_i 加上 λ 为负，那么该次梯度就设为 V_i 加上正 λ，因为在减去这个次梯度之后，X_i 将会是一个正值，那么 R(x) 的次梯度将仍然为正 λ，这会使 L1 范数的次梯度在一次迭代中保持一致。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539203860072377&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2a6toxQiaoUTiczsjSTQ6jco4UO7SiaGKUk1tQb41FkxQX3W2hvTAjyFPg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了处理大规模互联网数据，研究者提出了很多用于加速训练过程的优化方法，比如随机梯度下降法 (SGD)。但是，SGD 通常需要衰减步长才能收敛，而且它的收敛率是次线性的 (sublinear)。近期出现了 SVRG (Rie Johnson, Tong Zhang) 和 SAGA (Aaron Defazio, Francis Bach) 等一些随机方差缩减方法，可以无需降低步长就能收敛，而且可以在光滑和强凸的模型上实现线性收敛率 (linear convergence rate)。在 SGD 方法中，第 k 步的下降方向 v_k 是在该数据集的一个随机子集 S_k 上进行评估的。在 SVRG 方法中，我们需要周期性地在一些参考点（比如 tilde-X）上计算一个准确梯度。这个准确梯度构成了 SVRG 的 v_k 的第三项，然后我们必须通过在 tilde-X 上减去一个随机梯度（这是在同一子集 S_k 上计算的）来平衡它的期望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7535885167464115&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2xoXrW705kktPQiaI1t6ibHfNj9PQ2vn1ROQ8sSzEuhmUZk1oAF2w60Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;受 SVRG 和 OWL-QN 的启发，我们开发了一种针对 L1 正则化模型的随机优化方法。在第一步时，我们计算损失函数 F(x) 的 SVRG，然后我们使用来自 OWL-QN 的思想来计算一个参考方向，尽量使下降方向以在一次迭代后维持同一个象限。而我们的实际下降方向 V_k 是用这里的第三个等式计算的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.749400479616307&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2fF6PreGCOBUgf25HN01ZymqWI96PJ7l70PYsVfcNT3wGOYz7LURZ2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;现在我们可以计算解前进的方向了。我们可以通过计算当前点上的 Hessian 矩阵或估计近似的 Hessian 矩阵（伪牛顿法）来使用该损失函数的二阶信息，从而加速其收敛。然后我们可以通过在当前点附近的 Taylor 二次展开来计算最优下降方向 D_k。如果我们使用 L-BFGS，我们可以绕开耗时的矩阵求逆运算，只通过快速的矩阵向量乘法就可以做到。我们也可以直接将 V_k 分配给 D_k，这样就是一个典型的一阶方法。在这个步骤之后，方向 D_k 的象限必须与参考方向保持一致，这意味着：如果 D_k 的某些维度与参考方向的符号不同，它们就必须被分配为 0，我们将这个对齐后的版本记为 P_k。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7612121212121212&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2cNFibURJ2YuouXqB1bLCfhbrUS9vbZA8mibSlvbDMeYcgJiadpQrqibatA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;除了对齐参考，上述计算梯度并没有涉及到 L1 正则化 R(x) 的偏导数，因为我们要避免对随机梯度的引入额外方差。为了使解是稀疏的，我们提出了一种全新的对齐算子来激励零元素。这个算子作用在 X,Y 两个元素上，如果 X 和 Y 符号不同或 X 的绝对值小于一个阈值，就强制 X 为零。通过这个对齐算子，每次在我们完成了之前的计算之后，我们就检查下一个点是否与当前点在同一个象限，如果不在，下一个点的某些维度就会被强制为零。在这一步之后，显然 X_k 的更多维度应该为零，而不是绝对值很小的非零值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7490996398559424&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2b3q9qRstQiadKLZ50sckvtandmzYwYNyI6PwkTibDo1FdnTmia4d7eJTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;收敛性分析：在这篇论文中，我们证明在平滑性和强凸性的假设下，我们的方法将以一个线性速率收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7621359223300971&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2lldvfuryvFlzbdUbMHJL5SY9MbrzYnG7HorEPEblRdVcXuouFSxbQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了进行可视化，我们在这张图中绘制了在一个简单的二维合成函数的优化轨迹。我们的方法 OPDA 用红线标识，作为基准的 Proximal-Gradient Descent 算法用蓝线标识。在迭代了同样多次数之后，我们看到 OPDA 用更快的速度收敛到了等高线中更低的区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7619047619047619&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2Rx2yIBc1BgohFzPS7KvNN8xBal8zYibWpoLGyHzSzlprHxBPSYGtveQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;819&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在凸函数上的实验：我们还使用 L2/L1 regularized Logistic 回归上进行了一些实验。在这一部分，我们将我们的方法与一个线性收敛算法 Prox-SVRG (Lin Xiao, Tong Zhang) 进行了比较。在这张图中，Y 轴表示解的次优性 (suboptimality)，即当前目标函数与最小值之间的间隔；X 轴表示完整扫过数据集的次数。我们发现使用不同的步长以及 L2 和 L1 正则化系数时，OPDA 的速度稳定地超越了 Prox-SVRG 算法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539015606242497&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ST95OPvOSHfvz2taBQKcA81HwwnxBoqGibiccybHZMjx8LU5d6CCeWgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6020408163265306&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2N9V6ia3ncOYia7mpIias4IZASGCYHiaxedytdaas5m5TMknPesYI1ZwsHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1078&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在深度学习上的实验：我们使用 L1 正则化稀疏卷积神经网络 (sparse-CNN) 进行了实验，以表明我们的方法在非凸函数的有效性。下图中红线表示我们的方法，蓝线表示近端 SVRG。我们测试了不同规模的 L1 正则化。我们看到 OPDA 收敛速度比近 Prox-SGD 更快。而且在 L1 正则项更强的情况下，这种差异更大。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7547846889952153&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ia2GiaT9kCxWhLBP9kbict7ZUX8Ztn8da7lNIJtMzJdEpPJ6890XaY0rA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出的 OPDA 算法可以适用于快速优化 L1 正则的稀疏模型。实际上，由于我们的方法的象限性本质，下降方向和更新后的点的许多维度都会在对齐过程中被强制变为零，这会使等效步长变小很多；但是，在同等步长条件下，我们方法的速度仍然远远快于近端方法。这证明我们提出的对齐算子确实能将方向调校得更好，使其整体框架更为有效，而且在每次迭代中所需额外运算量接近可以忽略不计。 &lt;span style=&quot;color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);&quot;&gt; &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKczlUNeEAmUicw7MXcFnte6PhPpD5AHeEVvqImFdQz3ziaXsDmtjAp2icXupgXc6j3OpGl8dvHEicvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);white-space: normal;font-size: 16px;text-align: justify;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 51px !important;&quot; width=&quot;43px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3654970760233918&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9cWqUGib1I8LicEna2GCqsE2zaRCjXkkQxUj4xSMwic51nHPBia7CbbDHcJTkShoT3z4RZCh1v4KPYGA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1026&quot; width=&quot;auto&quot; style=&quot;font-size: 16px;white-space: normal;color: rgb(62, 62, 62);text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: auto !important;&quot;&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1902842951&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;a class=&quot;media_tool_meta meta_primary&quot; id=&quot;js_view_source&quot; href=&quot;##&quot;&gt;阅读原文&lt;/a&gt;
                                &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;https://mp.weixin.qq.com/mp/homepage?__biz=MzA3MzI4MjgzMw==&amp;amp;hid=11&amp;amp;sn=a2c8b0d29b504f0b5c30cd6c86eb34d7#wechat_redirect&quot; target=&quot;_blank&quot;&gt;阅读原文&lt;/a&gt;
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-24-1000000612_503254558</guid>
<pubDate>Sat, 24 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>AAAI 2018 | 腾讯AI Lab现场陈述论文：训练L1稀疏模型的象限性消极下降算法</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-24-1000000612_503254554.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QAoNFMtkLGSPSQ2J1Abpeo4W4Jv5b-U1wSwO7fSSlPQLW3rx9cWocS1Sw4yQPDeLSYF6tXm*vgcTpYplfNuzrEk=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    AAAI 2018 | 腾讯AI Lab现场陈述论文：训练L1稀疏模型的象限性消极下降算法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-24&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心发布&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);font-size: 12px;&quot;&gt;&lt;strong&gt;演讲者：&lt;span style=&quot;color: rgb(136, 136, 136);text-align: justify;font-size: 12px;&quot;&gt;王倪剑桥&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;腾讯 AI Lab 共有 12 篇论文入选在美国新奥尔良举行的国际人工智能领域顶级学术会议 AAAI 2018。腾讯技术工程官方号独家编译了论文《训练 L1 稀疏模型的象限性消极下降算法》(Training L1-Regularized Models with Orthant-Wise Passive Descent Algorithms)，该论文被 AAAI 2018 录用为现场陈述论文 (Oral Presentation)，由腾讯 AI Lab 独立完成，王倪剑桥为论文唯一作者。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1704.07987&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.23314606741573032&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2UAF9HpZdt2Wkjh1bmknwOr7C5BbppzVp1dk2IhOogB37EOF3EMbNww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1068&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;中文概要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;L1 范数正则模型是一种常用的高维数据的分析方法。对于现代大规模互联网数据上的该模型，研究其优化算法可以提高其收敛速度，进而在有限时间内显著其模型准确率，或者降低对服务器资源的依赖。经典的随机梯度下降 (SGD) 虽然可以适用于神经网络等多种模型，但对于 L1 范数不可导性并不适用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本文中，我们提出了一种新的随机优化方法，随机象限性消极下降算法 (OPDA)。本算法的出发点是 L1 范数函数在任何一个象限内是连续可导的，因此，模型的参数在每一次更新之后被投影到上一次迭代时所在的象限。我们使用随机方差缩减梯度 (SVRG) 方法产生梯度方向，并结合伪牛顿法 (Quasi-Newton) 来使用损失函数的二阶信息。我们提出了一种新的象限投影方法，使得该算法收敛于一个更加稀疏的最优点。我们在理论上证明了，在强凸和光滑的损失函数上，该算法可以线性收敛。在 RCV1 等典型稀疏数据集上，我们测试了不同参数下 L1/L2 范数约束 Logistic 回归下该算法性能，其结果显著超越了已有的线性收敛算法 Proximal-SVRG，并且在卷积神经网络 (CNN) 的实验上超越 Proximal-SGD 等算法，证明了该算法在凸函数和非凸函数上均有很好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;演讲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;大家好，我是王倪剑桥，来自腾讯 AI Lab。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6100478468899522&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2IiaiccFyf1eqibTED0DMstqGeWbz3oYavLdvG5AjBVG86PF43x9QtDBlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;引言：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学习稀疏表征一直都是一个非常重要的数据分析任务。比如说，在生物学领域，为了对单个个体进行基因分析，常常涉及到数百万个基因，然而其中真正对某任务，比如帮助预测某种稀有癌症，有用的基因片段并不多。在金融序列预测和网络广告等领域，也有很多数据数量甚至比数据维度还小的情况。这本身是一个病态 (ill-condition) 的问题，然而如果对解有一个稀疏先验的话，问题则是可解的。通信领域的压缩感知中的核心部分也是如何高效求解稀疏模型。目前，这些方法包括 Lasso (Robert Tibshirani), Dantzig Selector (Emmanuel Candes, Terrence Tao), OMP (Joel A. Tropp, Tong Zhang), FoBa (Tong Zhang) 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，我们给一个直观的例子，为什么 L1 范数正则项（绝对值的和）适用于求解稀疏模型。下图中，蓝色区域是约束内的可行解区域，左边是 L1 范数球（norm ball），右边是 L2 范数球，红色圈是均方损失函数（average-of-square-loss）的等高线。这些球和等高线之间的交点是模型的解。我们可以看到 L1 正则化模型的解接近 Y 轴，这意味着其 X 维元素更接近于 0。这是一个简单的例子，可以看出来 L1 正则项比 L2 正则项更适合于学习稀疏模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7707317073170732&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2QAG5fcR7g1nZ4IAza0F5BZVkjoiaFKgtpngP8IDXJwvtaX1fzicjAgqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们可以把大部分问题统一为最小化一个正则化函数 P(x)= F(x)+R(x)，其中 F(x) 是 N 个损失函数的平均，其中每个都依赖于一个数据样本，R 是 L1 正则项。我们还假设每个损失函数都满足二次可导 (twice differentiable)、强凸 (strongly-convex) 和光滑 (smooth)。由于该 L1 范数是不可导的（在零点），目前最通用的优化方法是近端方法 (proximal method)，通过迭代式地采取梯度下降步骤，然后在当前点上优化一个 proximal 问题。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7527010804321729&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2VZmAGYbLIUn5Uia7QxAxyuyFghIlskE8Uoq6mZsOdVrUVHLKPkdk8fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;相关文献介绍：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们的主要参考方法是象限性伪牛顿法 (OWL-QN: Galen Andrew, Jianfeng Gao)，这种方法基于 L-BFGS (Jorge Nocedal)，一种最常用的伪牛顿法。该方法 OWL-QN 将更新后的参数限制在一个特定的象限内，因为在每个单个象限中，其绝对值函数实际上是可微分的。OWL-QN 的一个关键创新点与在零点的次梯度 (subgradient) 有关。这里 L1 正则项 R(x) 的次梯度既可以是正λ，也可以是负 λ，那么如何选择次梯度会影响收敛速度。以下面大括号内第三个分支为例：我们研究的是当前点 X 的第 i 维 X_i，和梯度 V_i。如果 X_i 等于 0 且 X_i 加上 λ 为负，那么该次梯度就设为 V_i 加上正 λ，因为在减去这个次梯度之后，X_i 将会是一个正值，那么 R(x) 的次梯度将仍然为正 λ，这会使 L1 范数的次梯度在一次迭代中保持一致。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539203860072377&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2a6toxQiaoUTiczsjSTQ6jco4UO7SiaGKUk1tQb41FkxQX3W2hvTAjyFPg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了处理大规模互联网数据，研究者提出了很多用于加速训练过程的优化方法，比如随机梯度下降法 (SGD)。但是，SGD 通常需要衰减步长才能收敛，而且它的收敛率是次线性的 (sublinear)。近期出现了 SVRG (Rie Johnson, Tong Zhang) 和 SAGA (Aaron Defazio, Francis Bach) 等一些随机方差缩减方法，可以无需降低步长就能收敛，而且可以在光滑和强凸的模型上实现线性收敛率 (linear convergence rate)。在 SGD 方法中，第 k 步的下降方向 v_k 是在该数据集的一个随机子集 S_k 上进行评估的。在 SVRG 方法中，我们需要周期性地在一些参考点（比如 tilde-X）上计算一个准确梯度。这个准确梯度构成了 SVRG 的 v_k 的第三项，然后我们必须通过在 tilde-X 上减去一个随机梯度（这是在同一子集 S_k 上计算的）来平衡它的期望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7535885167464115&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2xoXrW705kktPQiaI1t6ibHfNj9PQ2vn1ROQ8sSzEuhmUZk1oAF2w60Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;受 SVRG 和 OWL-QN 的启发，我们开发了一种针对 L1 正则化模型的随机优化方法。在第一步时，我们计算损失函数 F(x) 的 SVRG，然后我们使用来自 OWL-QN 的思想来计算一个参考方向，尽量使下降方向以在一次迭代后维持同一个象限。而我们的实际下降方向 V_k 是用这里的第三个等式计算的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.749400479616307&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2fF6PreGCOBUgf25HN01ZymqWI96PJ7l70PYsVfcNT3wGOYz7LURZ2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;现在我们可以计算解前进的方向了。我们可以通过计算当前点上的 Hessian 矩阵或估计近似的 Hessian 矩阵（伪牛顿法）来使用该损失函数的二阶信息，从而加速其收敛。然后我们可以通过在当前点附近的 Taylor 二次展开来计算最优下降方向 D_k。如果我们使用 L-BFGS，我们可以绕开耗时的矩阵求逆运算，只通过快速的矩阵向量乘法就可以做到。我们也可以直接将 V_k 分配给 D_k，这样就是一个典型的一阶方法。在这个步骤之后，方向 D_k 的象限必须与参考方向保持一致，这意味着：如果 D_k 的某些维度与参考方向的符号不同，它们就必须被分配为 0，我们将这个对齐后的版本记为 P_k。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7612121212121212&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2cNFibURJ2YuouXqB1bLCfhbrUS9vbZA8mibSlvbDMeYcgJiadpQrqibatA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;除了对齐参考，上述计算梯度并没有涉及到 L1 正则化 R(x) 的偏导数，因为我们要避免对随机梯度的引入额外方差。为了使解是稀疏的，我们提出了一种全新的对齐算子来激励零元素。这个算子作用在 X,Y 两个元素上，如果 X 和 Y 符号不同或 X 的绝对值小于一个阈值，就强制 X 为零。通过这个对齐算子，每次在我们完成了之前的计算之后，我们就检查下一个点是否与当前点在同一个象限，如果不在，下一个点的某些维度就会被强制为零。在这一步之后，显然 X_k 的更多维度应该为零，而不是绝对值很小的非零值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7490996398559424&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2b3q9qRstQiadKLZ50sckvtandmzYwYNyI6PwkTibDo1FdnTmia4d7eJTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;收敛性分析：在这篇论文中，我们证明在平滑性和强凸性的假设下，我们的方法将以一个线性速率收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7621359223300971&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2lldvfuryvFlzbdUbMHJL5SY9MbrzYnG7HorEPEblRdVcXuouFSxbQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了进行可视化，我们在这张图中绘制了在一个简单的二维合成函数的优化轨迹。我们的方法 OPDA 用红线标识，作为基准的 Proximal-Gradient Descent 算法用蓝线标识。在迭代了同样多次数之后，我们看到 OPDA 用更快的速度收敛到了等高线中更低的区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7619047619047619&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2Rx2yIBc1BgohFzPS7KvNN8xBal8zYibWpoLGyHzSzlprHxBPSYGtveQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;819&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在凸函数上的实验：我们还使用 L2/L1 regularized Logistic 回归上进行了一些实验。在这一部分，我们将我们的方法与一个线性收敛算法 Prox-SVRG (Lin Xiao, Tong Zhang) 进行了比较。在这张图中，Y 轴表示解的次优性 (suboptimality)，即当前目标函数与最小值之间的间隔；X 轴表示完整扫过数据集的次数。我们发现使用不同的步长以及 L2 和 L1 正则化系数时，OPDA 的速度稳定地超越了 Prox-SVRG 算法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539015606242497&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ST95OPvOSHfvz2taBQKcA81HwwnxBoqGibiccybHZMjx8LU5d6CCeWgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6020408163265306&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2N9V6ia3ncOYia7mpIias4IZASGCYHiaxedytdaas5m5TMknPesYI1ZwsHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1078&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在深度学习上的实验：我们使用 L1 正则化稀疏卷积神经网络 (sparse-CNN) 进行了实验，以表明我们的方法在非凸函数的有效性。下图中红线表示我们的方法，蓝线表示近端 SVRG。我们测试了不同规模的 L1 正则化。我们看到 OPDA 收敛速度比近 Prox-SGD 更快。而且在 L1 正则项更强的情况下，这种差异更大。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7547846889952153&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ia2GiaT9kCxWhLBP9kbict7ZUX8Ztn8da7lNIJtMzJdEpPJ6890XaY0rA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出的 OPDA 算法可以适用于快速优化 L1 正则的稀疏模型。实际上，由于我们的方法的象限性本质，下降方向和更新后的点的许多维度都会在对齐过程中被强制变为零，这会使等效步长变小很多；但是，在同等步长条件下，我们方法的速度仍然远远快于近端方法。这证明我们提出的对齐算子确实能将方向调校得更好，使其整体框架更为有效，而且在每次迭代中所需额外运算量接近可以忽略不计。 &lt;span style=&quot;color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);&quot;&gt; &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKczlUNeEAmUicw7MXcFnte6PhPpD5AHeEVvqImFdQz3ziaXsDmtjAp2icXupgXc6j3OpGl8dvHEicvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);white-space: normal;font-size: 16px;text-align: justify;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 51px !important;&quot; width=&quot;43px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3654970760233918&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9cWqUGib1I8LicEna2GCqsE2zaRCjXkkQxUj4xSMwic51nHPBia7CbbDHcJTkShoT3z4RZCh1v4KPYGA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1026&quot; width=&quot;auto&quot; style=&quot;font-size: 16px;white-space: normal;color: rgb(62, 62, 62);text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: auto !important;&quot;&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1674138183&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;a class=&quot;media_tool_meta meta_primary&quot; id=&quot;js_view_source&quot; href=&quot;##&quot;&gt;阅读原文&lt;/a&gt;
                                &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;https://mp.weixin.qq.com/mp/homepage?__biz=MzA3MzI4MjgzMw==&amp;amp;hid=11&amp;amp;sn=a2c8b0d29b504f0b5c30cd6c86eb34d7#wechat_redirect&quot; target=&quot;_blank&quot;&gt;阅读原文&lt;/a&gt;
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-24-1000000612_503254554</guid>
<pubDate>Sat, 24 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>入门 | 强化学习的基本概念与代码实现</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-24-1000000612_503254538.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QAoNFMtkLGSPSQ2J1Abpeo65N5SlLQOSYJpR-hHNy87kgqRDqgap-u2FOFtl9Jz5VP81EEog7Y5*HA*xYBCpxGc=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    AAAI 2018 | 腾讯AI Lab现场陈述论文：训练L1稀疏模型的象限性消极下降算法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-24&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心发布&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);font-size: 12px;&quot;&gt;&lt;strong&gt;演讲者：&lt;span style=&quot;color: rgb(136, 136, 136);text-align: justify;font-size: 12px;&quot;&gt;王倪剑桥&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;腾讯 AI Lab 共有 12 篇论文入选在美国新奥尔良举行的国际人工智能领域顶级学术会议 AAAI 2018。腾讯技术工程官方号独家编译了论文《训练 L1 稀疏模型的象限性消极下降算法》(Training L1-Regularized Models with Orthant-Wise Passive Descent Algorithms)，该论文被 AAAI 2018 录用为现场陈述论文 (Oral Presentation)，由腾讯 AI Lab 独立完成，王倪剑桥为论文唯一作者。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1704.07987&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.23314606741573032&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2UAF9HpZdt2Wkjh1bmknwOr7C5BbppzVp1dk2IhOogB37EOF3EMbNww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1068&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;中文概要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;L1 范数正则模型是一种常用的高维数据的分析方法。对于现代大规模互联网数据上的该模型，研究其优化算法可以提高其收敛速度，进而在有限时间内显著其模型准确率，或者降低对服务器资源的依赖。经典的随机梯度下降 (SGD) 虽然可以适用于神经网络等多种模型，但对于 L1 范数不可导性并不适用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本文中，我们提出了一种新的随机优化方法，随机象限性消极下降算法 (OPDA)。本算法的出发点是 L1 范数函数在任何一个象限内是连续可导的，因此，模型的参数在每一次更新之后被投影到上一次迭代时所在的象限。我们使用随机方差缩减梯度 (SVRG) 方法产生梯度方向，并结合伪牛顿法 (Quasi-Newton) 来使用损失函数的二阶信息。我们提出了一种新的象限投影方法，使得该算法收敛于一个更加稀疏的最优点。我们在理论上证明了，在强凸和光滑的损失函数上，该算法可以线性收敛。在 RCV1 等典型稀疏数据集上，我们测试了不同参数下 L1/L2 范数约束 Logistic 回归下该算法性能，其结果显著超越了已有的线性收敛算法 Proximal-SVRG，并且在卷积神经网络 (CNN) 的实验上超越 Proximal-SGD 等算法，证明了该算法在凸函数和非凸函数上均有很好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;演讲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;大家好，我是王倪剑桥，来自腾讯 AI Lab。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6100478468899522&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2IiaiccFyf1eqibTED0DMstqGeWbz3oYavLdvG5AjBVG86PF43x9QtDBlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;引言：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学习稀疏表征一直都是一个非常重要的数据分析任务。比如说，在生物学领域，为了对单个个体进行基因分析，常常涉及到数百万个基因，然而其中真正对某任务，比如帮助预测某种稀有癌症，有用的基因片段并不多。在金融序列预测和网络广告等领域，也有很多数据数量甚至比数据维度还小的情况。这本身是一个病态 (ill-condition) 的问题，然而如果对解有一个稀疏先验的话，问题则是可解的。通信领域的压缩感知中的核心部分也是如何高效求解稀疏模型。目前，这些方法包括 Lasso (Robert Tibshirani), Dantzig Selector (Emmanuel Candes, Terrence Tao), OMP (Joel A. Tropp, Tong Zhang), FoBa (Tong Zhang) 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，我们给一个直观的例子，为什么 L1 范数正则项（绝对值的和）适用于求解稀疏模型。下图中，蓝色区域是约束内的可行解区域，左边是 L1 范数球（norm ball），右边是 L2 范数球，红色圈是均方损失函数（average-of-square-loss）的等高线。这些球和等高线之间的交点是模型的解。我们可以看到 L1 正则化模型的解接近 Y 轴，这意味着其 X 维元素更接近于 0。这是一个简单的例子，可以看出来 L1 正则项比 L2 正则项更适合于学习稀疏模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7707317073170732&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2QAG5fcR7g1nZ4IAza0F5BZVkjoiaFKgtpngP8IDXJwvtaX1fzicjAgqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们可以把大部分问题统一为最小化一个正则化函数 P(x)= F(x)+R(x)，其中 F(x) 是 N 个损失函数的平均，其中每个都依赖于一个数据样本，R 是 L1 正则项。我们还假设每个损失函数都满足二次可导 (twice differentiable)、强凸 (strongly-convex) 和光滑 (smooth)。由于该 L1 范数是不可导的（在零点），目前最通用的优化方法是近端方法 (proximal method)，通过迭代式地采取梯度下降步骤，然后在当前点上优化一个 proximal 问题。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7527010804321729&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2VZmAGYbLIUn5Uia7QxAxyuyFghIlskE8Uoq6mZsOdVrUVHLKPkdk8fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;相关文献介绍：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们的主要参考方法是象限性伪牛顿法 (OWL-QN: Galen Andrew, Jianfeng Gao)，这种方法基于 L-BFGS (Jorge Nocedal)，一种最常用的伪牛顿法。该方法 OWL-QN 将更新后的参数限制在一个特定的象限内，因为在每个单个象限中，其绝对值函数实际上是可微分的。OWL-QN 的一个关键创新点与在零点的次梯度 (subgradient) 有关。这里 L1 正则项 R(x) 的次梯度既可以是正λ，也可以是负 λ，那么如何选择次梯度会影响收敛速度。以下面大括号内第三个分支为例：我们研究的是当前点 X 的第 i 维 X_i，和梯度 V_i。如果 X_i 等于 0 且 X_i 加上 λ 为负，那么该次梯度就设为 V_i 加上正 λ，因为在减去这个次梯度之后，X_i 将会是一个正值，那么 R(x) 的次梯度将仍然为正 λ，这会使 L1 范数的次梯度在一次迭代中保持一致。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539203860072377&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2a6toxQiaoUTiczsjSTQ6jco4UO7SiaGKUk1tQb41FkxQX3W2hvTAjyFPg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了处理大规模互联网数据，研究者提出了很多用于加速训练过程的优化方法，比如随机梯度下降法 (SGD)。但是，SGD 通常需要衰减步长才能收敛，而且它的收敛率是次线性的 (sublinear)。近期出现了 SVRG (Rie Johnson, Tong Zhang) 和 SAGA (Aaron Defazio, Francis Bach) 等一些随机方差缩减方法，可以无需降低步长就能收敛，而且可以在光滑和强凸的模型上实现线性收敛率 (linear convergence rate)。在 SGD 方法中，第 k 步的下降方向 v_k 是在该数据集的一个随机子集 S_k 上进行评估的。在 SVRG 方法中，我们需要周期性地在一些参考点（比如 tilde-X）上计算一个准确梯度。这个准确梯度构成了 SVRG 的 v_k 的第三项，然后我们必须通过在 tilde-X 上减去一个随机梯度（这是在同一子集 S_k 上计算的）来平衡它的期望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7535885167464115&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2xoXrW705kktPQiaI1t6ibHfNj9PQ2vn1ROQ8sSzEuhmUZk1oAF2w60Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;受 SVRG 和 OWL-QN 的启发，我们开发了一种针对 L1 正则化模型的随机优化方法。在第一步时，我们计算损失函数 F(x) 的 SVRG，然后我们使用来自 OWL-QN 的思想来计算一个参考方向，尽量使下降方向以在一次迭代后维持同一个象限。而我们的实际下降方向 V_k 是用这里的第三个等式计算的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.749400479616307&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2fF6PreGCOBUgf25HN01ZymqWI96PJ7l70PYsVfcNT3wGOYz7LURZ2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;现在我们可以计算解前进的方向了。我们可以通过计算当前点上的 Hessian 矩阵或估计近似的 Hessian 矩阵（伪牛顿法）来使用该损失函数的二阶信息，从而加速其收敛。然后我们可以通过在当前点附近的 Taylor 二次展开来计算最优下降方向 D_k。如果我们使用 L-BFGS，我们可以绕开耗时的矩阵求逆运算，只通过快速的矩阵向量乘法就可以做到。我们也可以直接将 V_k 分配给 D_k，这样就是一个典型的一阶方法。在这个步骤之后，方向 D_k 的象限必须与参考方向保持一致，这意味着：如果 D_k 的某些维度与参考方向的符号不同，它们就必须被分配为 0，我们将这个对齐后的版本记为 P_k。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7612121212121212&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2cNFibURJ2YuouXqB1bLCfhbrUS9vbZA8mibSlvbDMeYcgJiadpQrqibatA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;除了对齐参考，上述计算梯度并没有涉及到 L1 正则化 R(x) 的偏导数，因为我们要避免对随机梯度的引入额外方差。为了使解是稀疏的，我们提出了一种全新的对齐算子来激励零元素。这个算子作用在 X,Y 两个元素上，如果 X 和 Y 符号不同或 X 的绝对值小于一个阈值，就强制 X 为零。通过这个对齐算子，每次在我们完成了之前的计算之后，我们就检查下一个点是否与当前点在同一个象限，如果不在，下一个点的某些维度就会被强制为零。在这一步之后，显然 X_k 的更多维度应该为零，而不是绝对值很小的非零值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7490996398559424&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2b3q9qRstQiadKLZ50sckvtandmzYwYNyI6PwkTibDo1FdnTmia4d7eJTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;收敛性分析：在这篇论文中，我们证明在平滑性和强凸性的假设下，我们的方法将以一个线性速率收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7621359223300971&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2lldvfuryvFlzbdUbMHJL5SY9MbrzYnG7HorEPEblRdVcXuouFSxbQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了进行可视化，我们在这张图中绘制了在一个简单的二维合成函数的优化轨迹。我们的方法 OPDA 用红线标识，作为基准的 Proximal-Gradient Descent 算法用蓝线标识。在迭代了同样多次数之后，我们看到 OPDA 用更快的速度收敛到了等高线中更低的区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7619047619047619&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2Rx2yIBc1BgohFzPS7KvNN8xBal8zYibWpoLGyHzSzlprHxBPSYGtveQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;819&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在凸函数上的实验：我们还使用 L2/L1 regularized Logistic 回归上进行了一些实验。在这一部分，我们将我们的方法与一个线性收敛算法 Prox-SVRG (Lin Xiao, Tong Zhang) 进行了比较。在这张图中，Y 轴表示解的次优性 (suboptimality)，即当前目标函数与最小值之间的间隔；X 轴表示完整扫过数据集的次数。我们发现使用不同的步长以及 L2 和 L1 正则化系数时，OPDA 的速度稳定地超越了 Prox-SVRG 算法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539015606242497&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ST95OPvOSHfvz2taBQKcA81HwwnxBoqGibiccybHZMjx8LU5d6CCeWgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6020408163265306&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2N9V6ia3ncOYia7mpIias4IZASGCYHiaxedytdaas5m5TMknPesYI1ZwsHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1078&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在深度学习上的实验：我们使用 L1 正则化稀疏卷积神经网络 (sparse-CNN) 进行了实验，以表明我们的方法在非凸函数的有效性。下图中红线表示我们的方法，蓝线表示近端 SVRG。我们测试了不同规模的 L1 正则化。我们看到 OPDA 收敛速度比近 Prox-SGD 更快。而且在 L1 正则项更强的情况下，这种差异更大。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7547846889952153&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ia2GiaT9kCxWhLBP9kbict7ZUX8Ztn8da7lNIJtMzJdEpPJ6890XaY0rA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出的 OPDA 算法可以适用于快速优化 L1 正则的稀疏模型。实际上，由于我们的方法的象限性本质，下降方向和更新后的点的许多维度都会在对齐过程中被强制变为零，这会使等效步长变小很多；但是，在同等步长条件下，我们方法的速度仍然远远快于近端方法。这证明我们提出的对齐算子确实能将方向调校得更好，使其整体框架更为有效，而且在每次迭代中所需额外运算量接近可以忽略不计。 &lt;span style=&quot;color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);&quot;&gt; &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKczlUNeEAmUicw7MXcFnte6PhPpD5AHeEVvqImFdQz3ziaXsDmtjAp2icXupgXc6j3OpGl8dvHEicvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);white-space: normal;font-size: 16px;text-align: justify;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 51px !important;&quot; width=&quot;43px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3654970760233918&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9cWqUGib1I8LicEna2GCqsE2zaRCjXkkQxUj4xSMwic51nHPBia7CbbDHcJTkShoT3z4RZCh1v4KPYGA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1026&quot; width=&quot;auto&quot; style=&quot;font-size: 16px;white-space: normal;color: rgb(62, 62, 62);text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: auto !important;&quot;&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;731002488&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;a class=&quot;media_tool_meta meta_primary&quot; id=&quot;js_view_source&quot; href=&quot;##&quot;&gt;阅读原文&lt;/a&gt;
                                &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;https://mp.weixin.qq.com/mp/homepage?__biz=MzA3MzI4MjgzMw==&amp;amp;hid=11&amp;amp;sn=a2c8b0d29b504f0b5c30cd6c86eb34d7#wechat_redirect&quot; target=&quot;_blank&quot;&gt;阅读原文&lt;/a&gt;
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-24-1000000612_503254538</guid>
<pubDate>Sat, 24 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>既能欺骗机器，也能迷惑人类！Goodfellow等人提出新一代对抗样本</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-24-1000000612.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QAoNFMtkLGSPSQ2J1Abpeo71Vn9cXW25uj5C5BHdZKGGDEif7tCKqJnLdu3ov4Ez7aJgQlyQnwcPz0RITUSiAeA=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    AAAI 2018 | 腾讯AI Lab现场陈述论文：训练L1稀疏模型的象限性消极下降算法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-24&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心发布&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);font-size: 12px;&quot;&gt;&lt;strong&gt;演讲者：&lt;span style=&quot;color: rgb(136, 136, 136);text-align: justify;font-size: 12px;&quot;&gt;王倪剑桥&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;腾讯 AI Lab 共有 12 篇论文入选在美国新奥尔良举行的国际人工智能领域顶级学术会议 AAAI 2018。腾讯技术工程官方号独家编译了论文《训练 L1 稀疏模型的象限性消极下降算法》(Training L1-Regularized Models with Orthant-Wise Passive Descent Algorithms)，该论文被 AAAI 2018 录用为现场陈述论文 (Oral Presentation)，由腾讯 AI Lab 独立完成，王倪剑桥为论文唯一作者。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1704.07987&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.23314606741573032&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2UAF9HpZdt2Wkjh1bmknwOr7C5BbppzVp1dk2IhOogB37EOF3EMbNww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1068&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;中文概要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;L1 范数正则模型是一种常用的高维数据的分析方法。对于现代大规模互联网数据上的该模型，研究其优化算法可以提高其收敛速度，进而在有限时间内显著其模型准确率，或者降低对服务器资源的依赖。经典的随机梯度下降 (SGD) 虽然可以适用于神经网络等多种模型，但对于 L1 范数不可导性并不适用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在本文中，我们提出了一种新的随机优化方法，随机象限性消极下降算法 (OPDA)。本算法的出发点是 L1 范数函数在任何一个象限内是连续可导的，因此，模型的参数在每一次更新之后被投影到上一次迭代时所在的象限。我们使用随机方差缩减梯度 (SVRG) 方法产生梯度方向，并结合伪牛顿法 (Quasi-Newton) 来使用损失函数的二阶信息。我们提出了一种新的象限投影方法，使得该算法收敛于一个更加稀疏的最优点。我们在理论上证明了，在强凸和光滑的损失函数上，该算法可以线性收敛。在 RCV1 等典型稀疏数据集上，我们测试了不同参数下 L1/L2 范数约束 Logistic 回归下该算法性能，其结果显著超越了已有的线性收敛算法 Proximal-SVRG，并且在卷积神经网络 (CNN) 的实验上超越 Proximal-SGD 等算法，证明了该算法在凸函数和非凸函数上均有很好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;演讲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;大家好，我是王倪剑桥，来自腾讯 AI Lab。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6100478468899522&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2IiaiccFyf1eqibTED0DMstqGeWbz3oYavLdvG5AjBVG86PF43x9QtDBlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;引言：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学习稀疏表征一直都是一个非常重要的数据分析任务。比如说，在生物学领域，为了对单个个体进行基因分析，常常涉及到数百万个基因，然而其中真正对某任务，比如帮助预测某种稀有癌症，有用的基因片段并不多。在金融序列预测和网络广告等领域，也有很多数据数量甚至比数据维度还小的情况。这本身是一个病态 (ill-condition) 的问题，然而如果对解有一个稀疏先验的话，问题则是可解的。通信领域的压缩感知中的核心部分也是如何高效求解稀疏模型。目前，这些方法包括 Lasso (Robert Tibshirani), Dantzig Selector (Emmanuel Candes, Terrence Tao), OMP (Joel A. Tropp, Tong Zhang), FoBa (Tong Zhang) 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;首先，我们给一个直观的例子，为什么 L1 范数正则项（绝对值的和）适用于求解稀疏模型。下图中，蓝色区域是约束内的可行解区域，左边是 L1 范数球（norm ball），右边是 L2 范数球，红色圈是均方损失函数（average-of-square-loss）的等高线。这些球和等高线之间的交点是模型的解。我们可以看到 L1 正则化模型的解接近 Y 轴，这意味着其 X 维元素更接近于 0。这是一个简单的例子，可以看出来 L1 正则项比 L2 正则项更适合于学习稀疏模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7707317073170732&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2QAG5fcR7g1nZ4IAza0F5BZVkjoiaFKgtpngP8IDXJwvtaX1fzicjAgqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们可以把大部分问题统一为最小化一个正则化函数 P(x)= F(x)+R(x)，其中 F(x) 是 N 个损失函数的平均，其中每个都依赖于一个数据样本，R 是 L1 正则项。我们还假设每个损失函数都满足二次可导 (twice differentiable)、强凸 (strongly-convex) 和光滑 (smooth)。由于该 L1 范数是不可导的（在零点），目前最通用的优化方法是近端方法 (proximal method)，通过迭代式地采取梯度下降步骤，然后在当前点上优化一个 proximal 问题。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7527010804321729&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2VZmAGYbLIUn5Uia7QxAxyuyFghIlskE8Uoq6mZsOdVrUVHLKPkdk8fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;相关文献介绍：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们的主要参考方法是象限性伪牛顿法 (OWL-QN: Galen Andrew, Jianfeng Gao)，这种方法基于 L-BFGS (Jorge Nocedal)，一种最常用的伪牛顿法。该方法 OWL-QN 将更新后的参数限制在一个特定的象限内，因为在每个单个象限中，其绝对值函数实际上是可微分的。OWL-QN 的一个关键创新点与在零点的次梯度 (subgradient) 有关。这里 L1 正则项 R(x) 的次梯度既可以是正λ，也可以是负 λ，那么如何选择次梯度会影响收敛速度。以下面大括号内第三个分支为例：我们研究的是当前点 X 的第 i 维 X_i，和梯度 V_i。如果 X_i 等于 0 且 X_i 加上 λ 为负，那么该次梯度就设为 V_i 加上正 λ，因为在减去这个次梯度之后，X_i 将会是一个正值，那么 R(x) 的次梯度将仍然为正 λ，这会使 L1 范数的次梯度在一次迭代中保持一致。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539203860072377&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2a6toxQiaoUTiczsjSTQ6jco4UO7SiaGKUk1tQb41FkxQX3W2hvTAjyFPg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了处理大规模互联网数据，研究者提出了很多用于加速训练过程的优化方法，比如随机梯度下降法 (SGD)。但是，SGD 通常需要衰减步长才能收敛，而且它的收敛率是次线性的 (sublinear)。近期出现了 SVRG (Rie Johnson, Tong Zhang) 和 SAGA (Aaron Defazio, Francis Bach) 等一些随机方差缩减方法，可以无需降低步长就能收敛，而且可以在光滑和强凸的模型上实现线性收敛率 (linear convergence rate)。在 SGD 方法中，第 k 步的下降方向 v_k 是在该数据集的一个随机子集 S_k 上进行评估的。在 SVRG 方法中，我们需要周期性地在一些参考点（比如 tilde-X）上计算一个准确梯度。这个准确梯度构成了 SVRG 的 v_k 的第三项，然后我们必须通过在 tilde-X 上减去一个随机梯度（这是在同一子集 S_k 上计算的）来平衡它的期望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7535885167464115&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2xoXrW705kktPQiaI1t6ibHfNj9PQ2vn1ROQ8sSzEuhmUZk1oAF2w60Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;受 SVRG 和 OWL-QN 的启发，我们开发了一种针对 L1 正则化模型的随机优化方法。在第一步时，我们计算损失函数 F(x) 的 SVRG，然后我们使用来自 OWL-QN 的思想来计算一个参考方向，尽量使下降方向以在一次迭代后维持同一个象限。而我们的实际下降方向 V_k 是用这里的第三个等式计算的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.749400479616307&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2fF6PreGCOBUgf25HN01ZymqWI96PJ7l70PYsVfcNT3wGOYz7LURZ2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;现在我们可以计算解前进的方向了。我们可以通过计算当前点上的 Hessian 矩阵或估计近似的 Hessian 矩阵（伪牛顿法）来使用该损失函数的二阶信息，从而加速其收敛。然后我们可以通过在当前点附近的 Taylor 二次展开来计算最优下降方向 D_k。如果我们使用 L-BFGS，我们可以绕开耗时的矩阵求逆运算，只通过快速的矩阵向量乘法就可以做到。我们也可以直接将 V_k 分配给 D_k，这样就是一个典型的一阶方法。在这个步骤之后，方向 D_k 的象限必须与参考方向保持一致，这意味着：如果 D_k 的某些维度与参考方向的符号不同，它们就必须被分配为 0，我们将这个对齐后的版本记为 P_k。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7612121212121212&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2cNFibURJ2YuouXqB1bLCfhbrUS9vbZA8mibSlvbDMeYcgJiadpQrqibatA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;除了对齐参考，上述计算梯度并没有涉及到 L1 正则化 R(x) 的偏导数，因为我们要避免对随机梯度的引入额外方差。为了使解是稀疏的，我们提出了一种全新的对齐算子来激励零元素。这个算子作用在 X,Y 两个元素上，如果 X 和 Y 符号不同或 X 的绝对值小于一个阈值，就强制 X 为零。通过这个对齐算子，每次在我们完成了之前的计算之后，我们就检查下一个点是否与当前点在同一个象限，如果不在，下一个点的某些维度就会被强制为零。在这一步之后，显然 X_k 的更多维度应该为零，而不是绝对值很小的非零值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7490996398559424&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2b3q9qRstQiadKLZ50sckvtandmzYwYNyI6PwkTibDo1FdnTmia4d7eJTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;收敛性分析：在这篇论文中，我们证明在平滑性和强凸性的假设下，我们的方法将以一个线性速率收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7621359223300971&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2lldvfuryvFlzbdUbMHJL5SY9MbrzYnG7HorEPEblRdVcXuouFSxbQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了进行可视化，我们在这张图中绘制了在一个简单的二维合成函数的优化轨迹。我们的方法 OPDA 用红线标识，作为基准的 Proximal-Gradient Descent 算法用蓝线标识。在迭代了同样多次数之后，我们看到 OPDA 用更快的速度收敛到了等高线中更低的区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7619047619047619&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2Rx2yIBc1BgohFzPS7KvNN8xBal8zYibWpoLGyHzSzlprHxBPSYGtveQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;819&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在凸函数上的实验：我们还使用 L2/L1 regularized Logistic 回归上进行了一些实验。在这一部分，我们将我们的方法与一个线性收敛算法 Prox-SVRG (Lin Xiao, Tong Zhang) 进行了比较。在这张图中，Y 轴表示解的次优性 (suboptimality)，即当前目标函数与最小值之间的间隔；X 轴表示完整扫过数据集的次数。我们发现使用不同的步长以及 L2 和 L1 正则化系数时，OPDA 的速度稳定地超越了 Prox-SVRG 算法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7539015606242497&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ST95OPvOSHfvz2taBQKcA81HwwnxBoqGibiccybHZMjx8LU5d6CCeWgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6020408163265306&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2N9V6ia3ncOYia7mpIias4IZASGCYHiaxedytdaas5m5TMknPesYI1ZwsHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1078&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在深度学习上的实验：我们使用 L1 正则化稀疏卷积神经网络 (sparse-CNN) 进行了实验，以表明我们的方法在非凸函数的有效性。下图中红线表示我们的方法，蓝线表示近端 SVRG。我们测试了不同规模的 L1 正则化。我们看到 OPDA 收敛速度比近 Prox-SGD 更快。而且在 L1 正则项更强的情况下，这种差异更大。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7547846889952153&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ia2GiaT9kCxWhLBP9kbict7ZUX8Ztn8da7lNIJtMzJdEpPJ6890XaY0rA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出的 OPDA 算法可以适用于快速优化 L1 正则的稀疏模型。实际上，由于我们的方法的象限性本质，下降方向和更新后的点的许多维度都会在对齐过程中被强制变为零，这会使等效步长变小很多；但是，在同等步长条件下，我们方法的速度仍然远远快于近端方法。这证明我们提出的对齐算子确实能将方向调校得更好，使其整体框架更为有效，而且在每次迭代中所需额外运算量接近可以忽略不计。 &lt;span style=&quot;color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);&quot;&gt; &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKczlUNeEAmUicw7MXcFnte6PhPpD5AHeEVvqImFdQz3ziaXsDmtjAp2icXupgXc6j3OpGl8dvHEicvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);white-space: normal;font-size: 16px;text-align: justify;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 51px !important;&quot; width=&quot;43px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3654970760233918&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9cWqUGib1I8LicEna2GCqsE2zaRCjXkkQxUj4xSMwic51nHPBia7CbbDHcJTkShoT3z4RZCh1v4KPYGA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1026&quot; width=&quot;auto&quot; style=&quot;font-size: 16px;white-space: normal;color: rgb(62, 62, 62);text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: auto !important;&quot;&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;14730061&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;a class=&quot;media_tool_meta meta_primary&quot; id=&quot;js_view_source&quot; href=&quot;##&quot;&gt;阅读原文&lt;/a&gt;
                                &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;https://mp.weixin.qq.com/mp/homepage?__biz=MzA3MzI4MjgzMw==&amp;amp;hid=11&amp;amp;sn=a2c8b0d29b504f0b5c30cd6c86eb34d7#wechat_redirect&quot; target=&quot;_blank&quot;&gt;阅读原文&lt;/a&gt;
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-24-1000000612</guid>
<pubDate>Sat, 24 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>ICLR 2018 | 斯坦福大学论文通过对抗训练实现可保证的分布式鲁棒性</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-23-1000000611_503254510.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519568400&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=nKdWWP9DvsfVeziG4We6Z8jOAOIRdAXoHtwhjstVVczGTCt0BjrQc29NZuHAnD9dowwBcNuInb9xCl231f13QEnhhwTyvIR79OV*UhIGB0OFoPdgPdZAA1VcKHojQdTnx-VDqIRSCRBDgu7X8GGP7xhAPd8o6uivwmT45ouvjKg=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    ICLR 2018 | 斯坦福大学论文通过对抗训练实现可保证的分布式鲁棒性                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-23&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;border: currentcolor;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自ICLR&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 18px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Aman Sinha&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;, &lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Hongseok Namkoong&lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;, &lt;/strong&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;John Duchi&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 18px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);font-size: 12px;&quot;&gt;&lt;strong&gt;参与：Jane W、黄小天、许迪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;神经网络容易受到对抗样本的影响，研究者们提出了许多启发式的攻击和防御机制。本文主要从分布式鲁棒优化的角度出发，从而保证了对抗输入扰动下神经网络的性能。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;试想经典的监督学习问题，我们最小化期望损失函数 EP0 [ℓ(θ;Z)](θ∈Θ)，其中 Z〜P0 是空间 Z 上的分布，ℓ 是损失函数。在许多系统中，鲁棒性对于变化的数据生成分布 P0 是可取的，不管它们来自协变量变化、潜在定义域变化 [2]，还是对抗攻击（adversarial attack）[22,28]。随着深度网络在现代以性能至上的系统中变得普遍（例如自动驾驶车的感知、肿瘤的自动检测），模型失败会日益导致危及生命的情况发生；在这些系统中，部署那些我们无法证实鲁棒性的模型是不负责任的。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;然而，最近的研究表明，神经网络容易受到对抗样本的影响；看似不可察觉的数据扰动可能导致模型的错误，例如输出错误分类 [22,28,34,37]。随后，许多研究者提出了对抗攻击和防御机制 [44,38,39,40,48,13,31,23]。虽然这些工作为对抗训练提供了初步基础，但是不能保证所提出的白箱（white-box）攻击是否能找到最有对抗性的扰动，以及是否存在这些防御一定能够成功阻止的一类攻击。另一方面，使用 SMT 求解器对深度网络的验证提供了鲁棒性的正式保证 [26,27,24]，但通常是 NP-hard；即使在小型网络上，这种方法也需要高昂的计算费用。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们从分布式鲁棒优化的角度出发，提供一种对抗性训练过程，并在计算和统计性能上提供可证明的保证。我们假设数据生成分布 P0 附近的分布类别为 P，并考虑问题最小化 sup P∈P EP [ℓ(θ;Z)]（θ∈Θ）。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;P 的选择影响鲁棒性保证和可计算性；我们发现具有高效计算性松弛（relaxation）的鲁棒性集合 P，即使在损失 ℓ 是非凸的情况下也适用。我们提供了一个对抗训练过程，对于平滑的 ℓ，享有类似于非鲁棒方法的收敛性保证，即使对于最坏情况下的整体损失函数 supP∈P EP [ℓ(θ;Z)]，也可以证明性能。在 Tensorflow 的一个简单实现中，我们的方法实现经验风险最小化（ERM, empirical risk minimization）所需时间是随机梯度方法的 5-10 倍，与其它对抗训练过程的运行时间相匹敌 [22,28,31]。&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们表明，我们的方法通过学习防御训练集中的对抗性干扰来获得泛化能力，使我们训练出的模型能够防止对测试集的攻击。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们简要概述我们的方法。令 c：Z×Z→R +∪{∞}，其中 c(z,z0) 是攻击扰乱 z0 到 z 的成本函数（我们通常使用&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1072961373390558&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2FIdswOuxhf62kL6MDdVcA7ibrpibXeNcGM49CukKGS00uibkg0BW9nZMw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;233&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。我们考虑在 Wasserstein 距离 Wc(·,·) 下的分布 P0 的鲁棒性区域 &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.13636363636363635&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2ibYsxB8Nb4UEBP7xtcG8Izz8mOHnISdKO5O9jbl4ZWAKc0lcmX4ZYXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;176&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;（正式定义参见第 2 节）。对于深度网络和其它复杂模型，&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;这个问题（1）的表达式是在 ρ 取任意值时是难以解决的。因此，我们考虑该表达式在固定惩罚参数 γ≥0 时的拉格朗日松弛，即&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.14664586583463338&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr24hp9K8TP7HDaXp0Q1xjoI6wFrgXte5bBlnIqqH6VsMNVZy5lIbFdrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1282&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;（关于这些等式的严格陈述，请参阅命题 1）。在这里，我们已经用鲁棒性的替代函数 φγ(θ;Z) 代替了通常的损失函数 ℓ(θ;Z)。这个替代函数（2b）允许数据 z 的对抗扰动，由惩罚 γ 调整。我们通常用经验分布 Pbn 代替惩罚问题（2）中的分布 P0 来解决问题，因为 P0 是未知的（我们在下面把这称为惩罚问题）。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;惩罚问题&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;（2）的关键特征是稳健水平的鲁棒性——特别是针对不可察觉的对抗扰动的防御——可以在基本上平滑损失函数 ℓ 没有计算/统计成本下实现。特别的是，对于足够大的惩罚 γ（在对偶、足够小的鲁棒 ρ 下），鲁棒替代函数（2b）z 7→ℓ(θ; z)−γc(z, z0) 是严格下凸（凹函数）的，因此优化更加容易（如果 ℓ(θ, z) 在 z 中是平滑）。因此，应用于问题（2）的随机梯度方法与非鲁棒方法（ERM）具有相似的收敛保证。在第 3 部分中，我们为任意 ρ 提供了鲁棒性保证；我们给出了在最坏情况下可以高效计算的基于数据的损失函数上限 supP：Wc(P,P0)≤ρ EP [ℓ(θ;Z)]。即，我们主要的对抗训练过程输出的最坏情况下的性能保证不比它差。当 ρ=ρbn 时，我们的约束是紧的，这对于经验目标而言是鲁棒的。这些结果表明，使用平滑激活函数的网络比使用 ReLU 的网络更具有优势。我们在第 4 部分通过实验验证了我们的结果，并且表明，即使对于非平滑的损失函数，我们也可以在各种对抗攻击情况下达到最先进网络的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;鲁棒优化和对抗训练对于某些不确定集合 U，标准的鲁棒优化方法可以将以形式为 supu∈U ℓ(θ; z+u) 的损失函数最小化 [3,42,51]。不幸的是，这种方法是棘手的，除了特殊结构的损失函数，如线性和简单的凸函数的组成 [3,51,52]。尽管如此，这种鲁棒方法构成了对抗训练近期取得进展的基础 [46,22,39,13,31]，它启发式地提供了在随机优化过程中扰动数据的方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;其中一种启发式算法使用局部线性化损失函数（以「快速梯度符号法」[22] 提出，p=∞）：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.06962025316455696&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2mPIXUdNzKxAodupOXVH7miaqessPKLwZYCXnCa28uVS60fdVDbaS4SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1264&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;一种对抗训练方式基于这些扰动损失函数进行训练 [22,28]，同时其它许多函数基于迭代的变量 [39,48,13,31]。Madry 等人 [31] 观察到这些过程试图优化目标 &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.13333333333333333&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2qEbtKHxGp7piam3kUZgvT45LDdiaCWaH7LwJH0vYmvG0co9wZ92bvTwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;180&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;，这是惩罚问题（2）的限制版本。这种鲁棒性的概念通常是难以处理的：内含的上确界在 u 中通常是非凹的，因此不清楚使用这些技术的拟合模型是否收敛，并且可能存在这些技术无法发现的最坏情况的扰动。事实上，当深度网络使用 ReLU 激活函数时，发现最坏情况扰动是 NP-hard 的，这意味着快速迭代启发式算法是困难的（参见附录 B 中的引理 2）。平滑可以在标准深度结构中用指数线性单位（ELU&#39;s）[16] 获得，这使我们能够以低计算成本找到拉格朗日最坏情况扰动。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;分布鲁棒优化为了说明当前的工作，我们回顾了一些关于鲁棒性和学习的重要工作。在鲁棒目标中选择 P（1）会影响我们希望考虑的不确定性集合的丰富性以及最终优化问题的易处理性。之前的分布鲁棒性方法已经考虑了 P 的有限维参数，例如矩的约束集、支持度（support）或方向偏差 [14,17,21]，以及概率测量的非参数距离，如 f-散度 [4,5,32,29,18,35] 和 Wasserstein 距离 [8,19,45]。与 f-散度（例如χ2- 或 Kullback-Leibler 散度）相反（当分布 P0 的支持度是固定时有效），围绕 P0 的 Wasserstein 球包含一组分布 Q，它们具有不同支持度并且（在某种意义上）保证对未知数据的鲁棒性。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;许多作者研究了易处理类型的不确定集合 P 和损失函数 ℓ。例如，Ben-Tal 等人 [4] 与 Namkoong 和 Duchi[36] 使用 f-散度球的凸优化方法。对于由 Wasserstein 球形成的最坏情况的 P 域，Esfahani 和 Kuhn[19]、Shafieezadeh-Abadeh 等人 [45] 与 Blanchet 等人 [8] 展示了如何将鞍点（saddle-point）问题（1）转换为正则化的 ERM 问题，但这只适用于有限类凸损失函数 ℓ 和成本函数 c。在这项工作中，我们处理更大的一类损失函数和成本函数，并为拉格朗日松弛鞍点问题提供直接解决方法（1）。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.19538461538461538&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2uyqRVbjWubDGwRC5GmnIwtYu4aic4vgzYKBfMM07DrYF1fC3QoTsFMQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1300&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;算法 1 分布鲁棒优化的对抗训练&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.41484375&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8XTws4VpFoN9vzicbJ9dqZad6zpBgibjic66FdCYl5D9iacIoV6nib6Wz4yECqP9U1ddtVTSeKGu1cFhA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 1. 合成数据的实验结果。训练数据用蓝色和红色表示。ERM、FGM 和 WRM 的分类边界分别以黄色、紫色和绿色表示。左边为边界与训练数据一起的图示，右边为分开的真实类边界的图示。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.38671875&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8XTws4VpFoN9vzicbJ9dqZa3GRib3JMaKVzBaNQUru1iabgU9VXmwhlB3WWX5wFG2heUPBZCcMdAqgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 2. 用合成数据（a）和 MNIST（b）进行实验的鲁棒性保证（11）（蓝色）和样本外（out-of-sample/测试）最差情况下的性能（红色）之间的经验性比较。在（11）中省略了统计误差项 ǫn(t)。垂直虚线表示在训练集 ρbn（θWRM）上达到的鲁棒性水平。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.36953125&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8XTws4VpFoN9vzicbJ9dqZaibr6dAPvMRxdov1KmuQsHT9VeKowfAUYneSWLpJF4jLEhG8t8AHWJbA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 3. 对 MNIST 数据集的 PGM 攻击。（a）和（b）分别显示了对于 PGM 攻击在欧氏距离和∞范数下的测试错误分类错误与对抗扰动水平 ǫadv。（a）中的垂直虚线表示用于训练 PGM、FGM 和 IFGM 模型的扰动水平以及估计的半径 pρbn（θWRM）。对于 MNIST，C2=9.21 和 C∞=1.00。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.41171875&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8XTws4VpFoN9vzicbJ9dqZawMyXbaTMwxy0ibALDWVMNBQ1ohiaFibfFLictwSwh1FC2KFN8iaNS3oDzSQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 4. 损失函数表面的稳定性。在（a）中，我们显示了给定 γadv 的扰动分布 ρbtest 的平均距离，这是对于决策表面的输入的局部稳定性指标。（a）中的垂直虚线表示我们用于训练 WRM 的 γ。在（b）中，我们将最小的 WRM 扰动（最大 γadv）可视化，以使模型对数据点进行错误分类。更多的例子见附录 A.2。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9326923076923077&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8XTws4VpFoN9vzicbJ9dqZakoxoboVYzibRWT6HPc2m15YyZf8AfCicDEQQ6zDpSH9Kdibwpqib004lRg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;832&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;text-align: justify;&quot;&gt;表 1. 1000 次实验后的 Episode 长度（平均数 ± 标准差）&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8823529411764706&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8XTws4VpFoN9vzicbJ9dqZakgUh7lMp7dqx80XzaSm6oInVVeXlE23Sl5It8qk0L0MPXWZl7t9FQQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;884&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 5. 训练中的 Episode 长度。纵坐标 Episode 长度的环境上限为 400 步长。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;论文：Certifiable Distributional Robustness with Principled Adversarial Training&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2895125553914328&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9m4ennicIoM1tibCveiaQzyr2wWicD4kKMao9Z8PBUXJx6Hiawfy0U6hQpicYw2kq6EfoIyTrDXMKJdMvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1354&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(123, 12, 0);font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(123, 12, 0);font-size: 14px;&quot;&gt;论文链接：https://arxiv.org/abs/1710.10571&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;神经网络容易受到对抗样本的影响，研究者们提出了许多启发式的攻击和防御机制。我们主要从分布式鲁棒优化的角度出发，它保证了对抗输入扰动下的性能。通过对在 Wasserstein 球中的潜在数据分布采用拉格朗日惩罚形式的扰动，我们提供了一种用最坏情况下的训练数据扰动来增加模型参数更新的训练过程。对于平滑损失函数，相对于经验风险最小化，我们的过程证明地实现了稳健水平的鲁棒性，并伴有很小的计算/统计成本。此外，我们的统计保证使我们能够有效证明整体损失函数的鲁棒性。对于不可察觉的扰动，我们的方法达到或优于启发式方法的性能。&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKczlUNeEAmUicw7MXcFnte6PhPpD5AHeEVvqImFdQz3ziaXsDmtjAp2icXupgXc6j3OpGl8dvHEicvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; width=&quot;43px&quot; style=&quot;text-align: justify;white-space: normal;color: rgb(62, 62, 62);font-size: 16px;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 51px !important;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;text-align: justify;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;text-align: justify;&quot;&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;background-color: rgb(255, 255, 255);line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;background-color: rgb(255, 255, 255);font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;background-color: rgb(255, 255, 255);font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;background-color: rgb(255, 255, 255);font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;598490296&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-23-1000000611_503254510</guid>
<pubDate>Fri, 23 Feb 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
