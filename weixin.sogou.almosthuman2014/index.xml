<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>机器之心</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/</link>
<description>专业的人工智能媒体和产业服务平台</description>
<language>zh-cn</language>
<lastBuildDate>Tue, 06 Mar 2018 22:09:23 +0800</lastBuildDate>
<item>
<title>学界 | 南京大学宣布成立人工智能学院</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-06-1000000622_503255092.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ4lFAxM7xJ9ajCD*AT*kl5RQgZmkIozlXTchHrmx6aTf79kWHNCgaJU61RbKx3P3jmhnh*3vONMaWDuuRRdAiik=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 结合主动学习与迁移学习：让医学图像标注工作量减少一半                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-06&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#888888;&quot;&gt;&lt;span style=&quot;font-size: 12.000000953674316px;&quot;&gt;&lt;strong&gt;作者：Zongwei Zhou&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Jae Y. Shin&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Suryakanth R. Gurudu&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Michael B. Gotway&lt;span style=&quot;;&quot;&gt;, 梁建明&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Panda&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;和普通图像的标注不一样，生物医学图像的标注需要有专业知识和技能的人来做，因此难以获得大型的有标注数据集供卷积神经网络学习。近日，IEEE 一篇论文提出可以将主动学习和迁移学习结合起来降低标注任务的工作量，实验结果也证明了这种方法的有效性。机器之心对该论文进行了编译介绍，详细的数学过程和结果分析请参阅原论文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在 ImageNet 和 Places 等大规模有标注数据集的帮助下，卷积神经网络（CNN）已经为计算机视觉领域带来了革命性的发展。正如 IEEE TMI 专刊 [4] 和最近的两本书 [5,6] 谈到的那样，人们对在生物医学图像分析中应用 CNN 有着广泛且浓厚的兴趣；但由于生物医学领域缺乏如此大量的有标注数据集，所以 CNN 在这一领域的成功之路还有所阻碍。标注生物医学图像不仅耗时耗力，而且需要高成本的、特定专业的知识和技能，这些都不易取得。因此，我们希望解答这个重要问题：如何显著降低将 CNN 应用于生物医学图像的标注成本；另外我们也想解答一个附属问题：给定一个有标签数据集，如何确定它充分覆盖了不同的相关对象。为此，我们提出了一种名为 AFT* 的全新方法，可以自然地将主动学习（active learning）和迁移学习（transfer learning）整合成单一一个框架。我们的 AFT* 方法首先会使用一个预训练 CNN 来寻找未标注数据中的「显著」样本来进行标注，然后这个（经过微调的）的 CNN 会根据新标注的样本以及所有误分类的样本而持续得到调整改进。我们在三种不同的应用上评估了我们的方法，其中包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测；结果表明标注成本至少可以减少一半。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;这种出色表现主要得益于一个简单而又强大的观察结果：为了提升 CNN 在生物医学图像上的表现，通常会通过数据增强方法为每个候选数据自动生成多个图块（patch）；这些根据同一候选数据生成的图块具有同样的标签，所以当它们被放入训练集中时，自然能够预见当前 CNN 会为它们给出相似的预测结果。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。但是，自动数据增强无可避免地会为某些候选数据生成「困难的」样本，注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5363288718929254&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDdVceKYqcuhcao0pPmDCX5a9SE0Lvku9ibyVlBCrDZybjibEqjchW31hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;算法 1：AFT*——使用混合数据进行主动且持续的微调&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;有些研究已经表明对生物医学图像分析 CNN 进行微调是有用的，但这些研究只执行了一次微调，也就是说，只使用所有可用的训练样本对预训练的 CNN 进行一次微调，而不涉及任何主动选择过程。就我们所知，我们提出的方法是首次以连续的方式将主动学习整合到 CNN 的微调中，可以使 CNN 对生物医学图像分析更加友好，实现极大降低标注成本的目标。算法 1 给出了我们的方法的概览；与传统的主动学习相比，我们的方法有 8 项优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;从全空的有标签数据集开始，不需要任何初始的有标签候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过持续的微调而非反复的再训练来逐步提升学习器的表现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过自然地利用每个候选数据中图块之间的预期一致性来主动选择信息最丰富和最有代表性的候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在每个候选数据中的少量图块上局部地计算选择标准，从而能节省可观的计算时间；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过多数选择（majority selection）自动处理有噪声标签；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动平衡不同类的训练样本；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将新选择的候选数据与误分类的候选数据结合到一起，去除简单样本以提升训练效率，重点关注困难样本以防止灾难性遗忘（catastrophic forgetting）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将随机性纳入主动选择过程，以在探索（exploration）和利用（exploration）之间达到接近最优的平衡。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;更重要的是，我们的方法有望对使用生物医学成像的计算辅助诊断（CAD）产生重要影响，因为当前法规要求 CAD 系统必须部署在「封闭」环境中，其中所有的 CAD 结果都要经过放射科医生的检查，如有错误就会得到纠正；由此，所有的假正例结果都应该被移除，所有的假负例结果都应该补充上来，这是一种即时的在线反馈，也许能让 CAD 系统能够具备自我学习能力并且可能能在我们的方法的持续性微调能力的帮助下在部署之后继续改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3 我们提出的方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT* 是在生物医学成像计算机辅助诊断（CAD）的背景下设计的。CAD 系统通常有一个候选数据生成器，可以快速生成一个候选数据集合，其中有些是真正例，有些是假正例。在生成候选数据之后，任务目标是训练一个分类器来尽可能地去除假正例结果同时尽可能地保留真正例结果。为了训练分类器，必须对每个候选数据进行标注。我们假设每个候选数据都要取多个可能标签中的一个。为了提升用于 CAD 系统的 CNN 的表现，通常要通过数据增强为每个候选数据自动生成多个图块；这些根据同一候选数据生成的图块会继承该候选数据的标签。换句话说，所有标签都是在候选数据层面上获取的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;但是，AFT* 是通用型的，可以应用于计算机视觉和图像分析领域中的很多任务。为了说明清楚，我们将使用 Places 数据库在自然图像中的场景解读任务上阐述 AFT* 背后的思想，其中不需要候选数据生成器，因为每张图像都可以直接被当作是候选数据。为了说明简单同时不失一般性，我们将其限制到了 3 种类别（厨房、客厅和办公室），并且将每一类中的 Places 图像都分成了训练集（14 000 张图像）、验证集（1000 张图像）和测试集（100 张图像），这三个子集之间没有重叠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;设计主动学习算法涉及两个关键问题：（1）如何确定一个标注候选数据的「价值度（worthiness）」；（2）如何更新分类器/学习器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.1 主动候选数据选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 3 给出了用于多类分类的主动候选数据选择过程，同时为了便于理解，表 1 用二元分类情况对其进行了阐述。如表 1 第 1 行所示，二元分类情况有 7 种典型预测模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5162523900573613&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDLwzHl2qHQ550vH0icTLTAcr9p231OqBtL3WP7K7ia8iaOwCumVlMsDgXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：在第 10 步时（经过了 3000 个图像标签查询后），两张图像（A 和 B）以及由 CNN 在主导类别上根据预测结果列出的增强后的图像图块。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5385779122541604&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDicoAJ0dDrTAFGuuDHG8iagdAWH7kZtFaun1TkPicQ1xGq6KznbI2ia6prg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;661&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：主动候选数据选择的 7 种预测模式和 4 种方法之间的关系。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.2 寻找有价值的候选数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;主动学习的关键是开发用于确定标注候选数据「价值度」的指标。我们的标准基于一个简单而强大的观察结果：所有根据同一候选数据增强得到的图块都具有同样的标签；预计当前 CNN 对它们的预测也相似。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。直观上讲，熵代表了分类的确定性——更高的不确定性值表示更高程度的信息（比如，表 1 中的模式 A）；而多样性是指在一个候选数据的多个图块上所得到的预测的一致性——多样性值更高说明预测不一致性程度更高（比如，表 1 中的模式 C）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.3 通过多数选择处理噪声标签&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动数据增强对提升 CNN 的表现而言至关重要，但却无可避免地会为某些候选数据生成「困难的」样本（如图 4(c) 所示），注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.4 将随机性注入主动选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;如 [41] 中讨论的那样，简单的随机选择在一开始时的表现可能优于主动选择，因为主动选择依赖于当前模型来选择用于标注的范例；因此，在早期阶段做出的糟糕选择可能会对后续选择的质量造成不良影响；而随机选择则更不易受到糟糕假设的约束。也就是说，主动选择重在利用从已获得的标签中取得的知识以探索决策边界，而随机选择则重在探索，所以能够定位到特征空间中分类器表现糟糕的区域。因此，有效的主动学习策略必须找到探索和利用之间的平衡。为此，我们通过根据采样概率主动选择而向我们的方法中注入了随机性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.5 比较多种学习策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;根据上面的讨论，可以推导出几种主动学习策略，如表 2 所示。我们对这些策略进行了全面的比较，结果表明：（1）AFT&#39; 不稳定；（2）AFT&#39;&#39; 需要仔细调整参数；（3）AFT 与 AFT&#39; 和 AFT&#39;&#39; 相比是最可靠的，但需要在每一步使用所有目前可用的有标注样本从一开始就对原始模型进行微调。为了克服这个短板，我们开发了一种优化版本 AFT*，可以使用新标注的候选数据以及被误分类的候选数据来持续优化当前模型。有些研究者已经证明微调能带来更好的表现，而且比从头开始训练更加稳健。此外，我们的实验表明 AFT* 的收敛速度比反复微调原来的预训练的 CNN 更快，从而可以节省训练时间；AFT* 还能通过去除简单样本，重点关注困难样本，防止灾难性遗忘来提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.476831091180867&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDc8TaaqC2tks2zIsJMQnvEFpJO5nDcZibpYjh5gN6SsjiazkU2quTStiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 2：主动学习策略&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 2(a) 比较了使用 Places 数据库的 AFT* 和 RFT。RFT 通过系统性的随机采样生成了 6 个不同的序列。最后的曲线是根据 6 次运行的平均结果绘制的。如图 2(a) 所示，在 AUC（曲线下面积）方面，仅使用了 2906 个候选数据查询的 AFT* 可以实现使用了 4452 个候选数据查询的 RFT 的表现；同时 AFT* 仅使用 1176 个候选数据查询就能实现使用全部 42000 个候选数据的完全训练（full training）的表现。因此，AFT* 相比于 RFT 能节省 34.7% 的标注成本，相比于完全训练能节省 97.2% 的标注成本。当使用了大约 100% 的训练数据时，其表现仍然在继续增长；因此，考虑到 GoogLeNet 架构有 22 层，所以这个数据集的大小还是不够。AFT* 是一种通用算法，不仅可用于生物医学数据集，而且也能用于其它数据集；AFT* 可用于有很多类别的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28969957081545067&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDw0iaFNTblRFfDF9uoIy949Y4lnkEJnUDnFz6emdpwN8cxyZML8uSBSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;4 应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们将我们的 AFT 和 AFT* 方法应用到了三种应用上，包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.1 结肠镜检查帧分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7622377622377622&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDT3m79icB090qvvk04g18WjnX5yUKErrJ5nyOeAH8icPNrdgudGysVIhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;858&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：三种结肠镜检查示例：（a）有信息的、（b）无信息的、（c）不明确但标记为「有信息的」——因为专家根据整体质量标注帧：如果某帧（即该应用中的候选数据）中有超过 75% 是清晰的，那么就认为它是有信息的。因此，不明确的候选数据中同时包含清楚和模糊的部分，并且会根据自动数据增强生成图块层面的噪声标签。比如帧（c）整个都被标注为「有信息的」，但并非与该帧相关的所有图块（d）都是「有信息的」，尽管它们都继承了「有信息的」标签。这是我们的 AFT* 方法中使用多数选择的主要动机。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.2 息肉检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2644533485975959&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD8XztBHaXJgeQyic4HQRbp06wrkjZl9R4iaYbMCrcMZDE6Hu85HaxrNBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1747&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 5：使用 AlexNet 在测试数据集上比较用于 3 种医学应用的 8 种主动选择策略。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。黑色实线是使用了全部训练数据的微调方法的当前最佳表现，黑色虚线是使用全部训练数据从头开始训练的表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2511574074074074&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDp0PEvIOKmo6yl4ZDA75maeEGHDFFWNtTw05Uicicy4sbmQYaj8HkQqrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 6：结肠镜检查视频中具有不同形状和外观的息肉。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.3 肺栓塞检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6477272727272727&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDbz7CVSLwSZchm2AKBXalk2deyERcnXla8mNkJCQNog28d2tCmtd51A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;792&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 7：用标准 3 通道表示以及 2 通道表示 [56] 得到的 5 种不同的 PE 图像，本研究使用它的原因是能实现更好的分类准确度和加速 CNN 训练的收敛。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.4 比较所有方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24258600237247924&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDeOAm7Q3OdeKyzIn3CEfJuc4RLJu3KvrAWGmONVibqV07IploZLB7SoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1686&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 3：所有方法的比较。结肠镜检查帧分类的基准表现是 RFT（ALC=.8991），息肉检测的基准表现是 RFT（ALC=.9379）和肺栓塞（PE）检测的基准表现是 RFT（ALC=.7874），使用的都是 AlexNet。加粗的值是其中表现最好的使用了特定主动选择标准的学习策略（见表 2），红色的值是同时使用了两种学习策略和主动选择标准所得到的最佳表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.5 在所选模式上的观察结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3682487725040917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDKnjggFFrDZxwvWAOcqoSgdfo6YJRtLGpcm2O6YRU8libz1ic3tXaEsZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;611&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 8：在结肠镜检查帧分类的第 3 步通过 4 种 AFT* 方法选择出的前 10 个候选数据。正例候选数据用红色表示，负例候选数据用蓝色表示。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.6 正例-负例比例的自动平衡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5123094958968347&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDRmp15MialrPUq3NoQjibc5nyTTbDJlyNx25OIZVPPyfNMZxfKsr7IxIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 9：AFT*、AFT 和 RFT 所选择的候选数据中的正例-负例比例。注意，RFT 的比例大致能代表整个数据集的比例&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.7 AFT* 在 CNN 架构中的泛化性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2580414581844174&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDhEuMgXnVxkiaxiam7x6icWp7PkoVVGWrFk9424Swu9XdSUN1yA0UibuAng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1399&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 10：基于三种应用，在 GoogLeNet 上比较 AFT* 和 AFT 的表现。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。结果表现出了与 AlexNet（见图 5）一样的模式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT*：整合主动学习与迁移学习以减少标注工作（Integrating Active Learning and Transfer Learning to Reduce Annotation Efforts）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2414050822122571&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDXVKNkibPGYtYqgcPDuzkmFU4G8leH6j4GS5Uu7NWvISBnSqQtfx2Msw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1338&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1802.00912&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;卷积神经网络（CNN）在计算机视觉领域的辉煌成功很大程度上可以归功于大型有标注数据集的可用性，比如 ImageNet 和 Places。但是，在生物医学成像领域，创建如此大型的有标注数据集是非常艰难的，因为标注生物医学图像不仅枯燥费力和费时，而且需要高成本的专业技能，这并不容易取得。为了大幅降低标注成本，本论文提出了一种用于将主动学习和迁移学习（微调）自然地整合成一个单一框架的全新方法 AFT*。该方法首先是使用一个预训练的 CNN 来为标注寻找「有价值的」样本，然后通过持续性的微调来增强（微调过的）CNN。我们在三种不同的生物医学成像应用中评估了我们的方法，结果表明与之前最佳的方法相比，这至少可以降低一半的成本。这种表现得益于我们方法的先进的主动连续学习能力的多种优势。尽管 AFT* 最初是在生物医学成像中的计算机辅助诊断背景中设计的，但这种方法是通用的，可用于计算机视觉和图像分析中的很多任务；我们使用 Places 数据库在自然图像的场景解读任务上阐释 AFT* 背后的关键思想。&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD4ubRIdiaRINaIfib2uZ3IFfHzWyoWDiccG7G6wJiayeHMl7PHghUZoadEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 49px !important;visibility: visible !important;&quot; width=&quot;49px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;注：据机器之心了解，本文作者之一梁建明是AI医疗创业公司体素科技的研究开发副总裁，美国亚利桑那州立大学（ASU）副教授，美国梅奥医学中心首届入驻教授，发表了超过70篇论文并获得13项专利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;128472987&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-06-1000000622_503255092</guid>
<pubDate>Tue, 06 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>业界 | 谷歌推出72-qubit量子处理器Bristlecone，意图实现「量子霸权」</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-06-1000000622_503255052.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ4lFAxM7xJ9ajCD*AT*kl5S8YUMMWQ26*b-O-GmlOUfDiAsZCioPWAjJovM4BxohRx3pO1c97ptz2w7PEMdAyPc=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 结合主动学习与迁移学习：让医学图像标注工作量减少一半                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-06&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#888888;&quot;&gt;&lt;span style=&quot;font-size: 12.000000953674316px;&quot;&gt;&lt;strong&gt;作者：Zongwei Zhou&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Jae Y. Shin&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Suryakanth R. Gurudu&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Michael B. Gotway&lt;span style=&quot;;&quot;&gt;, 梁建明&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Panda&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;和普通图像的标注不一样，生物医学图像的标注需要有专业知识和技能的人来做，因此难以获得大型的有标注数据集供卷积神经网络学习。近日，IEEE 一篇论文提出可以将主动学习和迁移学习结合起来降低标注任务的工作量，实验结果也证明了这种方法的有效性。机器之心对该论文进行了编译介绍，详细的数学过程和结果分析请参阅原论文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在 ImageNet 和 Places 等大规模有标注数据集的帮助下，卷积神经网络（CNN）已经为计算机视觉领域带来了革命性的发展。正如 IEEE TMI 专刊 [4] 和最近的两本书 [5,6] 谈到的那样，人们对在生物医学图像分析中应用 CNN 有着广泛且浓厚的兴趣；但由于生物医学领域缺乏如此大量的有标注数据集，所以 CNN 在这一领域的成功之路还有所阻碍。标注生物医学图像不仅耗时耗力，而且需要高成本的、特定专业的知识和技能，这些都不易取得。因此，我们希望解答这个重要问题：如何显著降低将 CNN 应用于生物医学图像的标注成本；另外我们也想解答一个附属问题：给定一个有标签数据集，如何确定它充分覆盖了不同的相关对象。为此，我们提出了一种名为 AFT* 的全新方法，可以自然地将主动学习（active learning）和迁移学习（transfer learning）整合成单一一个框架。我们的 AFT* 方法首先会使用一个预训练 CNN 来寻找未标注数据中的「显著」样本来进行标注，然后这个（经过微调的）的 CNN 会根据新标注的样本以及所有误分类的样本而持续得到调整改进。我们在三种不同的应用上评估了我们的方法，其中包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测；结果表明标注成本至少可以减少一半。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;这种出色表现主要得益于一个简单而又强大的观察结果：为了提升 CNN 在生物医学图像上的表现，通常会通过数据增强方法为每个候选数据自动生成多个图块（patch）；这些根据同一候选数据生成的图块具有同样的标签，所以当它们被放入训练集中时，自然能够预见当前 CNN 会为它们给出相似的预测结果。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。但是，自动数据增强无可避免地会为某些候选数据生成「困难的」样本，注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5363288718929254&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDdVceKYqcuhcao0pPmDCX5a9SE0Lvku9ibyVlBCrDZybjibEqjchW31hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;算法 1：AFT*——使用混合数据进行主动且持续的微调&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;有些研究已经表明对生物医学图像分析 CNN 进行微调是有用的，但这些研究只执行了一次微调，也就是说，只使用所有可用的训练样本对预训练的 CNN 进行一次微调，而不涉及任何主动选择过程。就我们所知，我们提出的方法是首次以连续的方式将主动学习整合到 CNN 的微调中，可以使 CNN 对生物医学图像分析更加友好，实现极大降低标注成本的目标。算法 1 给出了我们的方法的概览；与传统的主动学习相比，我们的方法有 8 项优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;从全空的有标签数据集开始，不需要任何初始的有标签候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过持续的微调而非反复的再训练来逐步提升学习器的表现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过自然地利用每个候选数据中图块之间的预期一致性来主动选择信息最丰富和最有代表性的候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在每个候选数据中的少量图块上局部地计算选择标准，从而能节省可观的计算时间；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过多数选择（majority selection）自动处理有噪声标签；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动平衡不同类的训练样本；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将新选择的候选数据与误分类的候选数据结合到一起，去除简单样本以提升训练效率，重点关注困难样本以防止灾难性遗忘（catastrophic forgetting）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将随机性纳入主动选择过程，以在探索（exploration）和利用（exploration）之间达到接近最优的平衡。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;更重要的是，我们的方法有望对使用生物医学成像的计算辅助诊断（CAD）产生重要影响，因为当前法规要求 CAD 系统必须部署在「封闭」环境中，其中所有的 CAD 结果都要经过放射科医生的检查，如有错误就会得到纠正；由此，所有的假正例结果都应该被移除，所有的假负例结果都应该补充上来，这是一种即时的在线反馈，也许能让 CAD 系统能够具备自我学习能力并且可能能在我们的方法的持续性微调能力的帮助下在部署之后继续改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3 我们提出的方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT* 是在生物医学成像计算机辅助诊断（CAD）的背景下设计的。CAD 系统通常有一个候选数据生成器，可以快速生成一个候选数据集合，其中有些是真正例，有些是假正例。在生成候选数据之后，任务目标是训练一个分类器来尽可能地去除假正例结果同时尽可能地保留真正例结果。为了训练分类器，必须对每个候选数据进行标注。我们假设每个候选数据都要取多个可能标签中的一个。为了提升用于 CAD 系统的 CNN 的表现，通常要通过数据增强为每个候选数据自动生成多个图块；这些根据同一候选数据生成的图块会继承该候选数据的标签。换句话说，所有标签都是在候选数据层面上获取的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;但是，AFT* 是通用型的，可以应用于计算机视觉和图像分析领域中的很多任务。为了说明清楚，我们将使用 Places 数据库在自然图像中的场景解读任务上阐述 AFT* 背后的思想，其中不需要候选数据生成器，因为每张图像都可以直接被当作是候选数据。为了说明简单同时不失一般性，我们将其限制到了 3 种类别（厨房、客厅和办公室），并且将每一类中的 Places 图像都分成了训练集（14 000 张图像）、验证集（1000 张图像）和测试集（100 张图像），这三个子集之间没有重叠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;设计主动学习算法涉及两个关键问题：（1）如何确定一个标注候选数据的「价值度（worthiness）」；（2）如何更新分类器/学习器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.1 主动候选数据选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 3 给出了用于多类分类的主动候选数据选择过程，同时为了便于理解，表 1 用二元分类情况对其进行了阐述。如表 1 第 1 行所示，二元分类情况有 7 种典型预测模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5162523900573613&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDLwzHl2qHQ550vH0icTLTAcr9p231OqBtL3WP7K7ia8iaOwCumVlMsDgXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：在第 10 步时（经过了 3000 个图像标签查询后），两张图像（A 和 B）以及由 CNN 在主导类别上根据预测结果列出的增强后的图像图块。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5385779122541604&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDicoAJ0dDrTAFGuuDHG8iagdAWH7kZtFaun1TkPicQ1xGq6KznbI2ia6prg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;661&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：主动候选数据选择的 7 种预测模式和 4 种方法之间的关系。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.2 寻找有价值的候选数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;主动学习的关键是开发用于确定标注候选数据「价值度」的指标。我们的标准基于一个简单而强大的观察结果：所有根据同一候选数据增强得到的图块都具有同样的标签；预计当前 CNN 对它们的预测也相似。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。直观上讲，熵代表了分类的确定性——更高的不确定性值表示更高程度的信息（比如，表 1 中的模式 A）；而多样性是指在一个候选数据的多个图块上所得到的预测的一致性——多样性值更高说明预测不一致性程度更高（比如，表 1 中的模式 C）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.3 通过多数选择处理噪声标签&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动数据增强对提升 CNN 的表现而言至关重要，但却无可避免地会为某些候选数据生成「困难的」样本（如图 4(c) 所示），注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.4 将随机性注入主动选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;如 [41] 中讨论的那样，简单的随机选择在一开始时的表现可能优于主动选择，因为主动选择依赖于当前模型来选择用于标注的范例；因此，在早期阶段做出的糟糕选择可能会对后续选择的质量造成不良影响；而随机选择则更不易受到糟糕假设的约束。也就是说，主动选择重在利用从已获得的标签中取得的知识以探索决策边界，而随机选择则重在探索，所以能够定位到特征空间中分类器表现糟糕的区域。因此，有效的主动学习策略必须找到探索和利用之间的平衡。为此，我们通过根据采样概率主动选择而向我们的方法中注入了随机性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.5 比较多种学习策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;根据上面的讨论，可以推导出几种主动学习策略，如表 2 所示。我们对这些策略进行了全面的比较，结果表明：（1）AFT&#39; 不稳定；（2）AFT&#39;&#39; 需要仔细调整参数；（3）AFT 与 AFT&#39; 和 AFT&#39;&#39; 相比是最可靠的，但需要在每一步使用所有目前可用的有标注样本从一开始就对原始模型进行微调。为了克服这个短板，我们开发了一种优化版本 AFT*，可以使用新标注的候选数据以及被误分类的候选数据来持续优化当前模型。有些研究者已经证明微调能带来更好的表现，而且比从头开始训练更加稳健。此外，我们的实验表明 AFT* 的收敛速度比反复微调原来的预训练的 CNN 更快，从而可以节省训练时间；AFT* 还能通过去除简单样本，重点关注困难样本，防止灾难性遗忘来提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.476831091180867&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDc8TaaqC2tks2zIsJMQnvEFpJO5nDcZibpYjh5gN6SsjiazkU2quTStiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 2：主动学习策略&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 2(a) 比较了使用 Places 数据库的 AFT* 和 RFT。RFT 通过系统性的随机采样生成了 6 个不同的序列。最后的曲线是根据 6 次运行的平均结果绘制的。如图 2(a) 所示，在 AUC（曲线下面积）方面，仅使用了 2906 个候选数据查询的 AFT* 可以实现使用了 4452 个候选数据查询的 RFT 的表现；同时 AFT* 仅使用 1176 个候选数据查询就能实现使用全部 42000 个候选数据的完全训练（full training）的表现。因此，AFT* 相比于 RFT 能节省 34.7% 的标注成本，相比于完全训练能节省 97.2% 的标注成本。当使用了大约 100% 的训练数据时，其表现仍然在继续增长；因此，考虑到 GoogLeNet 架构有 22 层，所以这个数据集的大小还是不够。AFT* 是一种通用算法，不仅可用于生物医学数据集，而且也能用于其它数据集；AFT* 可用于有很多类别的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28969957081545067&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDw0iaFNTblRFfDF9uoIy949Y4lnkEJnUDnFz6emdpwN8cxyZML8uSBSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;4 应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们将我们的 AFT 和 AFT* 方法应用到了三种应用上，包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.1 结肠镜检查帧分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7622377622377622&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDT3m79icB090qvvk04g18WjnX5yUKErrJ5nyOeAH8icPNrdgudGysVIhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;858&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：三种结肠镜检查示例：（a）有信息的、（b）无信息的、（c）不明确但标记为「有信息的」——因为专家根据整体质量标注帧：如果某帧（即该应用中的候选数据）中有超过 75% 是清晰的，那么就认为它是有信息的。因此，不明确的候选数据中同时包含清楚和模糊的部分，并且会根据自动数据增强生成图块层面的噪声标签。比如帧（c）整个都被标注为「有信息的」，但并非与该帧相关的所有图块（d）都是「有信息的」，尽管它们都继承了「有信息的」标签。这是我们的 AFT* 方法中使用多数选择的主要动机。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.2 息肉检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2644533485975959&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD8XztBHaXJgeQyic4HQRbp06wrkjZl9R4iaYbMCrcMZDE6Hu85HaxrNBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1747&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 5：使用 AlexNet 在测试数据集上比较用于 3 种医学应用的 8 种主动选择策略。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。黑色实线是使用了全部训练数据的微调方法的当前最佳表现，黑色虚线是使用全部训练数据从头开始训练的表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2511574074074074&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDp0PEvIOKmo6yl4ZDA75maeEGHDFFWNtTw05Uicicy4sbmQYaj8HkQqrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 6：结肠镜检查视频中具有不同形状和外观的息肉。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.3 肺栓塞检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6477272727272727&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDbz7CVSLwSZchm2AKBXalk2deyERcnXla8mNkJCQNog28d2tCmtd51A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;792&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 7：用标准 3 通道表示以及 2 通道表示 [56] 得到的 5 种不同的 PE 图像，本研究使用它的原因是能实现更好的分类准确度和加速 CNN 训练的收敛。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.4 比较所有方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24258600237247924&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDeOAm7Q3OdeKyzIn3CEfJuc4RLJu3KvrAWGmONVibqV07IploZLB7SoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1686&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 3：所有方法的比较。结肠镜检查帧分类的基准表现是 RFT（ALC=.8991），息肉检测的基准表现是 RFT（ALC=.9379）和肺栓塞（PE）检测的基准表现是 RFT（ALC=.7874），使用的都是 AlexNet。加粗的值是其中表现最好的使用了特定主动选择标准的学习策略（见表 2），红色的值是同时使用了两种学习策略和主动选择标准所得到的最佳表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.5 在所选模式上的观察结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3682487725040917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDKnjggFFrDZxwvWAOcqoSgdfo6YJRtLGpcm2O6YRU8libz1ic3tXaEsZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;611&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 8：在结肠镜检查帧分类的第 3 步通过 4 种 AFT* 方法选择出的前 10 个候选数据。正例候选数据用红色表示，负例候选数据用蓝色表示。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.6 正例-负例比例的自动平衡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5123094958968347&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDRmp15MialrPUq3NoQjibc5nyTTbDJlyNx25OIZVPPyfNMZxfKsr7IxIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 9：AFT*、AFT 和 RFT 所选择的候选数据中的正例-负例比例。注意，RFT 的比例大致能代表整个数据集的比例&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.7 AFT* 在 CNN 架构中的泛化性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2580414581844174&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDhEuMgXnVxkiaxiam7x6icWp7PkoVVGWrFk9424Swu9XdSUN1yA0UibuAng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1399&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 10：基于三种应用，在 GoogLeNet 上比较 AFT* 和 AFT 的表现。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。结果表现出了与 AlexNet（见图 5）一样的模式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT*：整合主动学习与迁移学习以减少标注工作（Integrating Active Learning and Transfer Learning to Reduce Annotation Efforts）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2414050822122571&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDXVKNkibPGYtYqgcPDuzkmFU4G8leH6j4GS5Uu7NWvISBnSqQtfx2Msw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1338&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1802.00912&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;卷积神经网络（CNN）在计算机视觉领域的辉煌成功很大程度上可以归功于大型有标注数据集的可用性，比如 ImageNet 和 Places。但是，在生物医学成像领域，创建如此大型的有标注数据集是非常艰难的，因为标注生物医学图像不仅枯燥费力和费时，而且需要高成本的专业技能，这并不容易取得。为了大幅降低标注成本，本论文提出了一种用于将主动学习和迁移学习（微调）自然地整合成一个单一框架的全新方法 AFT*。该方法首先是使用一个预训练的 CNN 来为标注寻找「有价值的」样本，然后通过持续性的微调来增强（微调过的）CNN。我们在三种不同的生物医学成像应用中评估了我们的方法，结果表明与之前最佳的方法相比，这至少可以降低一半的成本。这种表现得益于我们方法的先进的主动连续学习能力的多种优势。尽管 AFT* 最初是在生物医学成像中的计算机辅助诊断背景中设计的，但这种方法是通用的，可用于计算机视觉和图像分析中的很多任务；我们使用 Places 数据库在自然图像的场景解读任务上阐释 AFT* 背后的关键思想。&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD4ubRIdiaRINaIfib2uZ3IFfHzWyoWDiccG7G6wJiayeHMl7PHghUZoadEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 49px !important;visibility: visible !important;&quot; width=&quot;49px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;注：据机器之心了解，本文作者之一梁建明是AI医疗创业公司体素科技的研究开发副总裁，美国亚利桑那州立大学（ASU）副教授，美国梅奥医学中心首届入驻教授，发表了超过70篇论文并获得13项专利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1910588434&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-06-1000000622_503255052</guid>
<pubDate>Tue, 06 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>解读 | 起底语音对抗样本：语音助手危险了吗？</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-06-1000000622_503255045.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ4lFAxM7xJ9ajCD*AT*kl5TOnhiLC8JoTdVCC5T4XsJpstO902A78Qa4gMDco43xTQyuYqipK2Fzyf41zdRyYco=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 结合主动学习与迁移学习：让医学图像标注工作量减少一半                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-06&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#888888;&quot;&gt;&lt;span style=&quot;font-size: 12.000000953674316px;&quot;&gt;&lt;strong&gt;作者：Zongwei Zhou&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Jae Y. Shin&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Suryakanth R. Gurudu&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Michael B. Gotway&lt;span style=&quot;;&quot;&gt;, 梁建明&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Panda&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;和普通图像的标注不一样，生物医学图像的标注需要有专业知识和技能的人来做，因此难以获得大型的有标注数据集供卷积神经网络学习。近日，IEEE 一篇论文提出可以将主动学习和迁移学习结合起来降低标注任务的工作量，实验结果也证明了这种方法的有效性。机器之心对该论文进行了编译介绍，详细的数学过程和结果分析请参阅原论文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在 ImageNet 和 Places 等大规模有标注数据集的帮助下，卷积神经网络（CNN）已经为计算机视觉领域带来了革命性的发展。正如 IEEE TMI 专刊 [4] 和最近的两本书 [5,6] 谈到的那样，人们对在生物医学图像分析中应用 CNN 有着广泛且浓厚的兴趣；但由于生物医学领域缺乏如此大量的有标注数据集，所以 CNN 在这一领域的成功之路还有所阻碍。标注生物医学图像不仅耗时耗力，而且需要高成本的、特定专业的知识和技能，这些都不易取得。因此，我们希望解答这个重要问题：如何显著降低将 CNN 应用于生物医学图像的标注成本；另外我们也想解答一个附属问题：给定一个有标签数据集，如何确定它充分覆盖了不同的相关对象。为此，我们提出了一种名为 AFT* 的全新方法，可以自然地将主动学习（active learning）和迁移学习（transfer learning）整合成单一一个框架。我们的 AFT* 方法首先会使用一个预训练 CNN 来寻找未标注数据中的「显著」样本来进行标注，然后这个（经过微调的）的 CNN 会根据新标注的样本以及所有误分类的样本而持续得到调整改进。我们在三种不同的应用上评估了我们的方法，其中包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测；结果表明标注成本至少可以减少一半。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;这种出色表现主要得益于一个简单而又强大的观察结果：为了提升 CNN 在生物医学图像上的表现，通常会通过数据增强方法为每个候选数据自动生成多个图块（patch）；这些根据同一候选数据生成的图块具有同样的标签，所以当它们被放入训练集中时，自然能够预见当前 CNN 会为它们给出相似的预测结果。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。但是，自动数据增强无可避免地会为某些候选数据生成「困难的」样本，注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5363288718929254&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDdVceKYqcuhcao0pPmDCX5a9SE0Lvku9ibyVlBCrDZybjibEqjchW31hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;算法 1：AFT*——使用混合数据进行主动且持续的微调&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;有些研究已经表明对生物医学图像分析 CNN 进行微调是有用的，但这些研究只执行了一次微调，也就是说，只使用所有可用的训练样本对预训练的 CNN 进行一次微调，而不涉及任何主动选择过程。就我们所知，我们提出的方法是首次以连续的方式将主动学习整合到 CNN 的微调中，可以使 CNN 对生物医学图像分析更加友好，实现极大降低标注成本的目标。算法 1 给出了我们的方法的概览；与传统的主动学习相比，我们的方法有 8 项优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;从全空的有标签数据集开始，不需要任何初始的有标签候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过持续的微调而非反复的再训练来逐步提升学习器的表现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过自然地利用每个候选数据中图块之间的预期一致性来主动选择信息最丰富和最有代表性的候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在每个候选数据中的少量图块上局部地计算选择标准，从而能节省可观的计算时间；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过多数选择（majority selection）自动处理有噪声标签；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动平衡不同类的训练样本；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将新选择的候选数据与误分类的候选数据结合到一起，去除简单样本以提升训练效率，重点关注困难样本以防止灾难性遗忘（catastrophic forgetting）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将随机性纳入主动选择过程，以在探索（exploration）和利用（exploration）之间达到接近最优的平衡。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;更重要的是，我们的方法有望对使用生物医学成像的计算辅助诊断（CAD）产生重要影响，因为当前法规要求 CAD 系统必须部署在「封闭」环境中，其中所有的 CAD 结果都要经过放射科医生的检查，如有错误就会得到纠正；由此，所有的假正例结果都应该被移除，所有的假负例结果都应该补充上来，这是一种即时的在线反馈，也许能让 CAD 系统能够具备自我学习能力并且可能能在我们的方法的持续性微调能力的帮助下在部署之后继续改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3 我们提出的方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT* 是在生物医学成像计算机辅助诊断（CAD）的背景下设计的。CAD 系统通常有一个候选数据生成器，可以快速生成一个候选数据集合，其中有些是真正例，有些是假正例。在生成候选数据之后，任务目标是训练一个分类器来尽可能地去除假正例结果同时尽可能地保留真正例结果。为了训练分类器，必须对每个候选数据进行标注。我们假设每个候选数据都要取多个可能标签中的一个。为了提升用于 CAD 系统的 CNN 的表现，通常要通过数据增强为每个候选数据自动生成多个图块；这些根据同一候选数据生成的图块会继承该候选数据的标签。换句话说，所有标签都是在候选数据层面上获取的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;但是，AFT* 是通用型的，可以应用于计算机视觉和图像分析领域中的很多任务。为了说明清楚，我们将使用 Places 数据库在自然图像中的场景解读任务上阐述 AFT* 背后的思想，其中不需要候选数据生成器，因为每张图像都可以直接被当作是候选数据。为了说明简单同时不失一般性，我们将其限制到了 3 种类别（厨房、客厅和办公室），并且将每一类中的 Places 图像都分成了训练集（14 000 张图像）、验证集（1000 张图像）和测试集（100 张图像），这三个子集之间没有重叠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;设计主动学习算法涉及两个关键问题：（1）如何确定一个标注候选数据的「价值度（worthiness）」；（2）如何更新分类器/学习器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.1 主动候选数据选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 3 给出了用于多类分类的主动候选数据选择过程，同时为了便于理解，表 1 用二元分类情况对其进行了阐述。如表 1 第 1 行所示，二元分类情况有 7 种典型预测模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5162523900573613&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDLwzHl2qHQ550vH0icTLTAcr9p231OqBtL3WP7K7ia8iaOwCumVlMsDgXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：在第 10 步时（经过了 3000 个图像标签查询后），两张图像（A 和 B）以及由 CNN 在主导类别上根据预测结果列出的增强后的图像图块。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5385779122541604&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDicoAJ0dDrTAFGuuDHG8iagdAWH7kZtFaun1TkPicQ1xGq6KznbI2ia6prg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;661&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：主动候选数据选择的 7 种预测模式和 4 种方法之间的关系。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.2 寻找有价值的候选数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;主动学习的关键是开发用于确定标注候选数据「价值度」的指标。我们的标准基于一个简单而强大的观察结果：所有根据同一候选数据增强得到的图块都具有同样的标签；预计当前 CNN 对它们的预测也相似。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。直观上讲，熵代表了分类的确定性——更高的不确定性值表示更高程度的信息（比如，表 1 中的模式 A）；而多样性是指在一个候选数据的多个图块上所得到的预测的一致性——多样性值更高说明预测不一致性程度更高（比如，表 1 中的模式 C）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.3 通过多数选择处理噪声标签&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动数据增强对提升 CNN 的表现而言至关重要，但却无可避免地会为某些候选数据生成「困难的」样本（如图 4(c) 所示），注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.4 将随机性注入主动选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;如 [41] 中讨论的那样，简单的随机选择在一开始时的表现可能优于主动选择，因为主动选择依赖于当前模型来选择用于标注的范例；因此，在早期阶段做出的糟糕选择可能会对后续选择的质量造成不良影响；而随机选择则更不易受到糟糕假设的约束。也就是说，主动选择重在利用从已获得的标签中取得的知识以探索决策边界，而随机选择则重在探索，所以能够定位到特征空间中分类器表现糟糕的区域。因此，有效的主动学习策略必须找到探索和利用之间的平衡。为此，我们通过根据采样概率主动选择而向我们的方法中注入了随机性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.5 比较多种学习策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;根据上面的讨论，可以推导出几种主动学习策略，如表 2 所示。我们对这些策略进行了全面的比较，结果表明：（1）AFT&#39; 不稳定；（2）AFT&#39;&#39; 需要仔细调整参数；（3）AFT 与 AFT&#39; 和 AFT&#39;&#39; 相比是最可靠的，但需要在每一步使用所有目前可用的有标注样本从一开始就对原始模型进行微调。为了克服这个短板，我们开发了一种优化版本 AFT*，可以使用新标注的候选数据以及被误分类的候选数据来持续优化当前模型。有些研究者已经证明微调能带来更好的表现，而且比从头开始训练更加稳健。此外，我们的实验表明 AFT* 的收敛速度比反复微调原来的预训练的 CNN 更快，从而可以节省训练时间；AFT* 还能通过去除简单样本，重点关注困难样本，防止灾难性遗忘来提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.476831091180867&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDc8TaaqC2tks2zIsJMQnvEFpJO5nDcZibpYjh5gN6SsjiazkU2quTStiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 2：主动学习策略&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 2(a) 比较了使用 Places 数据库的 AFT* 和 RFT。RFT 通过系统性的随机采样生成了 6 个不同的序列。最后的曲线是根据 6 次运行的平均结果绘制的。如图 2(a) 所示，在 AUC（曲线下面积）方面，仅使用了 2906 个候选数据查询的 AFT* 可以实现使用了 4452 个候选数据查询的 RFT 的表现；同时 AFT* 仅使用 1176 个候选数据查询就能实现使用全部 42000 个候选数据的完全训练（full training）的表现。因此，AFT* 相比于 RFT 能节省 34.7% 的标注成本，相比于完全训练能节省 97.2% 的标注成本。当使用了大约 100% 的训练数据时，其表现仍然在继续增长；因此，考虑到 GoogLeNet 架构有 22 层，所以这个数据集的大小还是不够。AFT* 是一种通用算法，不仅可用于生物医学数据集，而且也能用于其它数据集；AFT* 可用于有很多类别的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28969957081545067&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDw0iaFNTblRFfDF9uoIy949Y4lnkEJnUDnFz6emdpwN8cxyZML8uSBSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;4 应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们将我们的 AFT 和 AFT* 方法应用到了三种应用上，包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.1 结肠镜检查帧分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7622377622377622&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDT3m79icB090qvvk04g18WjnX5yUKErrJ5nyOeAH8icPNrdgudGysVIhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;858&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：三种结肠镜检查示例：（a）有信息的、（b）无信息的、（c）不明确但标记为「有信息的」——因为专家根据整体质量标注帧：如果某帧（即该应用中的候选数据）中有超过 75% 是清晰的，那么就认为它是有信息的。因此，不明确的候选数据中同时包含清楚和模糊的部分，并且会根据自动数据增强生成图块层面的噪声标签。比如帧（c）整个都被标注为「有信息的」，但并非与该帧相关的所有图块（d）都是「有信息的」，尽管它们都继承了「有信息的」标签。这是我们的 AFT* 方法中使用多数选择的主要动机。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.2 息肉检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2644533485975959&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD8XztBHaXJgeQyic4HQRbp06wrkjZl9R4iaYbMCrcMZDE6Hu85HaxrNBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1747&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 5：使用 AlexNet 在测试数据集上比较用于 3 种医学应用的 8 种主动选择策略。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。黑色实线是使用了全部训练数据的微调方法的当前最佳表现，黑色虚线是使用全部训练数据从头开始训练的表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2511574074074074&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDp0PEvIOKmo6yl4ZDA75maeEGHDFFWNtTw05Uicicy4sbmQYaj8HkQqrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 6：结肠镜检查视频中具有不同形状和外观的息肉。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.3 肺栓塞检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6477272727272727&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDbz7CVSLwSZchm2AKBXalk2deyERcnXla8mNkJCQNog28d2tCmtd51A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;792&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 7：用标准 3 通道表示以及 2 通道表示 [56] 得到的 5 种不同的 PE 图像，本研究使用它的原因是能实现更好的分类准确度和加速 CNN 训练的收敛。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.4 比较所有方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24258600237247924&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDeOAm7Q3OdeKyzIn3CEfJuc4RLJu3KvrAWGmONVibqV07IploZLB7SoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1686&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 3：所有方法的比较。结肠镜检查帧分类的基准表现是 RFT（ALC=.8991），息肉检测的基准表现是 RFT（ALC=.9379）和肺栓塞（PE）检测的基准表现是 RFT（ALC=.7874），使用的都是 AlexNet。加粗的值是其中表现最好的使用了特定主动选择标准的学习策略（见表 2），红色的值是同时使用了两种学习策略和主动选择标准所得到的最佳表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.5 在所选模式上的观察结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3682487725040917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDKnjggFFrDZxwvWAOcqoSgdfo6YJRtLGpcm2O6YRU8libz1ic3tXaEsZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;611&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 8：在结肠镜检查帧分类的第 3 步通过 4 种 AFT* 方法选择出的前 10 个候选数据。正例候选数据用红色表示，负例候选数据用蓝色表示。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.6 正例-负例比例的自动平衡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5123094958968347&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDRmp15MialrPUq3NoQjibc5nyTTbDJlyNx25OIZVPPyfNMZxfKsr7IxIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 9：AFT*、AFT 和 RFT 所选择的候选数据中的正例-负例比例。注意，RFT 的比例大致能代表整个数据集的比例&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.7 AFT* 在 CNN 架构中的泛化性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2580414581844174&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDhEuMgXnVxkiaxiam7x6icWp7PkoVVGWrFk9424Swu9XdSUN1yA0UibuAng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1399&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 10：基于三种应用，在 GoogLeNet 上比较 AFT* 和 AFT 的表现。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。结果表现出了与 AlexNet（见图 5）一样的模式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT*：整合主动学习与迁移学习以减少标注工作（Integrating Active Learning and Transfer Learning to Reduce Annotation Efforts）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2414050822122571&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDXVKNkibPGYtYqgcPDuzkmFU4G8leH6j4GS5Uu7NWvISBnSqQtfx2Msw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1338&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1802.00912&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;卷积神经网络（CNN）在计算机视觉领域的辉煌成功很大程度上可以归功于大型有标注数据集的可用性，比如 ImageNet 和 Places。但是，在生物医学成像领域，创建如此大型的有标注数据集是非常艰难的，因为标注生物医学图像不仅枯燥费力和费时，而且需要高成本的专业技能，这并不容易取得。为了大幅降低标注成本，本论文提出了一种用于将主动学习和迁移学习（微调）自然地整合成一个单一框架的全新方法 AFT*。该方法首先是使用一个预训练的 CNN 来为标注寻找「有价值的」样本，然后通过持续性的微调来增强（微调过的）CNN。我们在三种不同的生物医学成像应用中评估了我们的方法，结果表明与之前最佳的方法相比，这至少可以降低一半的成本。这种表现得益于我们方法的先进的主动连续学习能力的多种优势。尽管 AFT* 最初是在生物医学成像中的计算机辅助诊断背景中设计的，但这种方法是通用的，可用于计算机视觉和图像分析中的很多任务；我们使用 Places 数据库在自然图像的场景解读任务上阐释 AFT* 背后的关键思想。&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD4ubRIdiaRINaIfib2uZ3IFfHzWyoWDiccG7G6wJiayeHMl7PHghUZoadEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 49px !important;visibility: visible !important;&quot; width=&quot;49px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;注：据机器之心了解，本文作者之一梁建明是AI医疗创业公司体素科技的研究开发副总裁，美国亚利桑那州立大学（ASU）副教授，美国梅奥医学中心首届入驻教授，发表了超过70篇论文并获得13项专利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;2036684238&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author>邱陆陆</author>
<guid isPermaLink="false">2018-03-06-1000000622_503255045</guid>
<pubDate>Tue, 06 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>学界 | 结合主动学习与迁移学习：让医学图像标注工作量减少一半</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-06-1000000622_503255029.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ4lFAxM7xJ9ajCD*AT*kl5SrgtfmaZ5cJ6L8IEo0QBkiWjz8TMXP0HJzH8kIBUCl8YRIZrmI*RoO-AH4h-EQ4rI=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 结合主动学习与迁移学习：让医学图像标注工作量减少一半                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-06&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#888888;&quot;&gt;&lt;span style=&quot;font-size: 12.000000953674316px;&quot;&gt;&lt;strong&gt;作者：Zongwei Zhou&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Jae Y. Shin&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Suryakanth R. Gurudu&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Michael B. Gotway&lt;span style=&quot;;&quot;&gt;, 梁建明&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Panda&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;和普通图像的标注不一样，生物医学图像的标注需要有专业知识和技能的人来做，因此难以获得大型的有标注数据集供卷积神经网络学习。近日，IEEE 一篇论文提出可以将主动学习和迁移学习结合起来降低标注任务的工作量，实验结果也证明了这种方法的有效性。机器之心对该论文进行了编译介绍，详细的数学过程和结果分析请参阅原论文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在 ImageNet 和 Places 等大规模有标注数据集的帮助下，卷积神经网络（CNN）已经为计算机视觉领域带来了革命性的发展。正如 IEEE TMI 专刊 [4] 和最近的两本书 [5,6] 谈到的那样，人们对在生物医学图像分析中应用 CNN 有着广泛且浓厚的兴趣；但由于生物医学领域缺乏如此大量的有标注数据集，所以 CNN 在这一领域的成功之路还有所阻碍。标注生物医学图像不仅耗时耗力，而且需要高成本的、特定专业的知识和技能，这些都不易取得。因此，我们希望解答这个重要问题：如何显著降低将 CNN 应用于生物医学图像的标注成本；另外我们也想解答一个附属问题：给定一个有标签数据集，如何确定它充分覆盖了不同的相关对象。为此，我们提出了一种名为 AFT* 的全新方法，可以自然地将主动学习（active learning）和迁移学习（transfer learning）整合成单一一个框架。我们的 AFT* 方法首先会使用一个预训练 CNN 来寻找未标注数据中的「显著」样本来进行标注，然后这个（经过微调的）的 CNN 会根据新标注的样本以及所有误分类的样本而持续得到调整改进。我们在三种不同的应用上评估了我们的方法，其中包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测；结果表明标注成本至少可以减少一半。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;这种出色表现主要得益于一个简单而又强大的观察结果：为了提升 CNN 在生物医学图像上的表现，通常会通过数据增强方法为每个候选数据自动生成多个图块（patch）；这些根据同一候选数据生成的图块具有同样的标签，所以当它们被放入训练集中时，自然能够预见当前 CNN 会为它们给出相似的预测结果。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。但是，自动数据增强无可避免地会为某些候选数据生成「困难的」样本，注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5363288718929254&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDdVceKYqcuhcao0pPmDCX5a9SE0Lvku9ibyVlBCrDZybjibEqjchW31hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;算法 1：AFT*——使用混合数据进行主动且持续的微调&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;有些研究已经表明对生物医学图像分析 CNN 进行微调是有用的，但这些研究只执行了一次微调，也就是说，只使用所有可用的训练样本对预训练的 CNN 进行一次微调，而不涉及任何主动选择过程。就我们所知，我们提出的方法是首次以连续的方式将主动学习整合到 CNN 的微调中，可以使 CNN 对生物医学图像分析更加友好，实现极大降低标注成本的目标。算法 1 给出了我们的方法的概览；与传统的主动学习相比，我们的方法有 8 项优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;从全空的有标签数据集开始，不需要任何初始的有标签候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过持续的微调而非反复的再训练来逐步提升学习器的表现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过自然地利用每个候选数据中图块之间的预期一致性来主动选择信息最丰富和最有代表性的候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在每个候选数据中的少量图块上局部地计算选择标准，从而能节省可观的计算时间；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过多数选择（majority selection）自动处理有噪声标签；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动平衡不同类的训练样本；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将新选择的候选数据与误分类的候选数据结合到一起，去除简单样本以提升训练效率，重点关注困难样本以防止灾难性遗忘（catastrophic forgetting）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将随机性纳入主动选择过程，以在探索（exploration）和利用（exploration）之间达到接近最优的平衡。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;更重要的是，我们的方法有望对使用生物医学成像的计算辅助诊断（CAD）产生重要影响，因为当前法规要求 CAD 系统必须部署在「封闭」环境中，其中所有的 CAD 结果都要经过放射科医生的检查，如有错误就会得到纠正；由此，所有的假正例结果都应该被移除，所有的假负例结果都应该补充上来，这是一种即时的在线反馈，也许能让 CAD 系统能够具备自我学习能力并且可能能在我们的方法的持续性微调能力的帮助下在部署之后继续改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3 我们提出的方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT* 是在生物医学成像计算机辅助诊断（CAD）的背景下设计的。CAD 系统通常有一个候选数据生成器，可以快速生成一个候选数据集合，其中有些是真正例，有些是假正例。在生成候选数据之后，任务目标是训练一个分类器来尽可能地去除假正例结果同时尽可能地保留真正例结果。为了训练分类器，必须对每个候选数据进行标注。我们假设每个候选数据都要取多个可能标签中的一个。为了提升用于 CAD 系统的 CNN 的表现，通常要通过数据增强为每个候选数据自动生成多个图块；这些根据同一候选数据生成的图块会继承该候选数据的标签。换句话说，所有标签都是在候选数据层面上获取的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;但是，AFT* 是通用型的，可以应用于计算机视觉和图像分析领域中的很多任务。为了说明清楚，我们将使用 Places 数据库在自然图像中的场景解读任务上阐述 AFT* 背后的思想，其中不需要候选数据生成器，因为每张图像都可以直接被当作是候选数据。为了说明简单同时不失一般性，我们将其限制到了 3 种类别（厨房、客厅和办公室），并且将每一类中的 Places 图像都分成了训练集（14 000 张图像）、验证集（1000 张图像）和测试集（100 张图像），这三个子集之间没有重叠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;设计主动学习算法涉及两个关键问题：（1）如何确定一个标注候选数据的「价值度（worthiness）」；（2）如何更新分类器/学习器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.1 主动候选数据选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 3 给出了用于多类分类的主动候选数据选择过程，同时为了便于理解，表 1 用二元分类情况对其进行了阐述。如表 1 第 1 行所示，二元分类情况有 7 种典型预测模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5162523900573613&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDLwzHl2qHQ550vH0icTLTAcr9p231OqBtL3WP7K7ia8iaOwCumVlMsDgXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：在第 10 步时（经过了 3000 个图像标签查询后），两张图像（A 和 B）以及由 CNN 在主导类别上根据预测结果列出的增强后的图像图块。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5385779122541604&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDicoAJ0dDrTAFGuuDHG8iagdAWH7kZtFaun1TkPicQ1xGq6KznbI2ia6prg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;661&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：主动候选数据选择的 7 种预测模式和 4 种方法之间的关系。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.2 寻找有价值的候选数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;主动学习的关键是开发用于确定标注候选数据「价值度」的指标。我们的标准基于一个简单而强大的观察结果：所有根据同一候选数据增强得到的图块都具有同样的标签；预计当前 CNN 对它们的预测也相似。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。直观上讲，熵代表了分类的确定性——更高的不确定性值表示更高程度的信息（比如，表 1 中的模式 A）；而多样性是指在一个候选数据的多个图块上所得到的预测的一致性——多样性值更高说明预测不一致性程度更高（比如，表 1 中的模式 C）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.3 通过多数选择处理噪声标签&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动数据增强对提升 CNN 的表现而言至关重要，但却无可避免地会为某些候选数据生成「困难的」样本（如图 4(c) 所示），注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.4 将随机性注入主动选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;如 [41] 中讨论的那样，简单的随机选择在一开始时的表现可能优于主动选择，因为主动选择依赖于当前模型来选择用于标注的范例；因此，在早期阶段做出的糟糕选择可能会对后续选择的质量造成不良影响；而随机选择则更不易受到糟糕假设的约束。也就是说，主动选择重在利用从已获得的标签中取得的知识以探索决策边界，而随机选择则重在探索，所以能够定位到特征空间中分类器表现糟糕的区域。因此，有效的主动学习策略必须找到探索和利用之间的平衡。为此，我们通过根据采样概率主动选择而向我们的方法中注入了随机性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.5 比较多种学习策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;根据上面的讨论，可以推导出几种主动学习策略，如表 2 所示。我们对这些策略进行了全面的比较，结果表明：（1）AFT&#39; 不稳定；（2）AFT&#39;&#39; 需要仔细调整参数；（3）AFT 与 AFT&#39; 和 AFT&#39;&#39; 相比是最可靠的，但需要在每一步使用所有目前可用的有标注样本从一开始就对原始模型进行微调。为了克服这个短板，我们开发了一种优化版本 AFT*，可以使用新标注的候选数据以及被误分类的候选数据来持续优化当前模型。有些研究者已经证明微调能带来更好的表现，而且比从头开始训练更加稳健。此外，我们的实验表明 AFT* 的收敛速度比反复微调原来的预训练的 CNN 更快，从而可以节省训练时间；AFT* 还能通过去除简单样本，重点关注困难样本，防止灾难性遗忘来提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.476831091180867&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDc8TaaqC2tks2zIsJMQnvEFpJO5nDcZibpYjh5gN6SsjiazkU2quTStiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 2：主动学习策略&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 2(a) 比较了使用 Places 数据库的 AFT* 和 RFT。RFT 通过系统性的随机采样生成了 6 个不同的序列。最后的曲线是根据 6 次运行的平均结果绘制的。如图 2(a) 所示，在 AUC（曲线下面积）方面，仅使用了 2906 个候选数据查询的 AFT* 可以实现使用了 4452 个候选数据查询的 RFT 的表现；同时 AFT* 仅使用 1176 个候选数据查询就能实现使用全部 42000 个候选数据的完全训练（full training）的表现。因此，AFT* 相比于 RFT 能节省 34.7% 的标注成本，相比于完全训练能节省 97.2% 的标注成本。当使用了大约 100% 的训练数据时，其表现仍然在继续增长；因此，考虑到 GoogLeNet 架构有 22 层，所以这个数据集的大小还是不够。AFT* 是一种通用算法，不仅可用于生物医学数据集，而且也能用于其它数据集；AFT* 可用于有很多类别的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28969957081545067&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDw0iaFNTblRFfDF9uoIy949Y4lnkEJnUDnFz6emdpwN8cxyZML8uSBSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;4 应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们将我们的 AFT 和 AFT* 方法应用到了三种应用上，包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.1 结肠镜检查帧分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7622377622377622&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDT3m79icB090qvvk04g18WjnX5yUKErrJ5nyOeAH8icPNrdgudGysVIhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;858&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：三种结肠镜检查示例：（a）有信息的、（b）无信息的、（c）不明确但标记为「有信息的」——因为专家根据整体质量标注帧：如果某帧（即该应用中的候选数据）中有超过 75% 是清晰的，那么就认为它是有信息的。因此，不明确的候选数据中同时包含清楚和模糊的部分，并且会根据自动数据增强生成图块层面的噪声标签。比如帧（c）整个都被标注为「有信息的」，但并非与该帧相关的所有图块（d）都是「有信息的」，尽管它们都继承了「有信息的」标签。这是我们的 AFT* 方法中使用多数选择的主要动机。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.2 息肉检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2644533485975959&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD8XztBHaXJgeQyic4HQRbp06wrkjZl9R4iaYbMCrcMZDE6Hu85HaxrNBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1747&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 5：使用 AlexNet 在测试数据集上比较用于 3 种医学应用的 8 种主动选择策略。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。黑色实线是使用了全部训练数据的微调方法的当前最佳表现，黑色虚线是使用全部训练数据从头开始训练的表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2511574074074074&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDp0PEvIOKmo6yl4ZDA75maeEGHDFFWNtTw05Uicicy4sbmQYaj8HkQqrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 6：结肠镜检查视频中具有不同形状和外观的息肉。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.3 肺栓塞检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6477272727272727&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDbz7CVSLwSZchm2AKBXalk2deyERcnXla8mNkJCQNog28d2tCmtd51A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;792&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 7：用标准 3 通道表示以及 2 通道表示 [56] 得到的 5 种不同的 PE 图像，本研究使用它的原因是能实现更好的分类准确度和加速 CNN 训练的收敛。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.4 比较所有方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24258600237247924&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDeOAm7Q3OdeKyzIn3CEfJuc4RLJu3KvrAWGmONVibqV07IploZLB7SoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1686&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 3：所有方法的比较。结肠镜检查帧分类的基准表现是 RFT（ALC=.8991），息肉检测的基准表现是 RFT（ALC=.9379）和肺栓塞（PE）检测的基准表现是 RFT（ALC=.7874），使用的都是 AlexNet。加粗的值是其中表现最好的使用了特定主动选择标准的学习策略（见表 2），红色的值是同时使用了两种学习策略和主动选择标准所得到的最佳表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.5 在所选模式上的观察结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3682487725040917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDKnjggFFrDZxwvWAOcqoSgdfo6YJRtLGpcm2O6YRU8libz1ic3tXaEsZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;611&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 8：在结肠镜检查帧分类的第 3 步通过 4 种 AFT* 方法选择出的前 10 个候选数据。正例候选数据用红色表示，负例候选数据用蓝色表示。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.6 正例-负例比例的自动平衡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5123094958968347&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDRmp15MialrPUq3NoQjibc5nyTTbDJlyNx25OIZVPPyfNMZxfKsr7IxIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 9：AFT*、AFT 和 RFT 所选择的候选数据中的正例-负例比例。注意，RFT 的比例大致能代表整个数据集的比例&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.7 AFT* 在 CNN 架构中的泛化性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2580414581844174&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDhEuMgXnVxkiaxiam7x6icWp7PkoVVGWrFk9424Swu9XdSUN1yA0UibuAng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1399&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 10：基于三种应用，在 GoogLeNet 上比较 AFT* 和 AFT 的表现。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。结果表现出了与 AlexNet（见图 5）一样的模式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT*：整合主动学习与迁移学习以减少标注工作（Integrating Active Learning and Transfer Learning to Reduce Annotation Efforts）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2414050822122571&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDXVKNkibPGYtYqgcPDuzkmFU4G8leH6j4GS5Uu7NWvISBnSqQtfx2Msw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1338&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1802.00912&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;卷积神经网络（CNN）在计算机视觉领域的辉煌成功很大程度上可以归功于大型有标注数据集的可用性，比如 ImageNet 和 Places。但是，在生物医学成像领域，创建如此大型的有标注数据集是非常艰难的，因为标注生物医学图像不仅枯燥费力和费时，而且需要高成本的专业技能，这并不容易取得。为了大幅降低标注成本，本论文提出了一种用于将主动学习和迁移学习（微调）自然地整合成一个单一框架的全新方法 AFT*。该方法首先是使用一个预训练的 CNN 来为标注寻找「有价值的」样本，然后通过持续性的微调来增强（微调过的）CNN。我们在三种不同的生物医学成像应用中评估了我们的方法，结果表明与之前最佳的方法相比，这至少可以降低一半的成本。这种表现得益于我们方法的先进的主动连续学习能力的多种优势。尽管 AFT* 最初是在生物医学成像中的计算机辅助诊断背景中设计的，但这种方法是通用的，可用于计算机视觉和图像分析中的很多任务；我们使用 Places 数据库在自然图像的场景解读任务上阐释 AFT* 背后的关键思想。&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD4ubRIdiaRINaIfib2uZ3IFfHzWyoWDiccG7G6wJiayeHMl7PHghUZoadEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 49px !important;visibility: visible !important;&quot; width=&quot;49px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;注：据机器之心了解，本文作者之一梁建明是AI医疗创业公司体素科技的研究开发副总裁，美国亚利桑那州立大学（ASU）副教授，美国梅奥医学中心首届入驻教授，发表了超过70篇论文并获得13项专利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1407466932&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-06-1000000622_503255029</guid>
<pubDate>Tue, 06 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>终于！Keras官方中文版文档正式发布了</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-06-1000000622.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ4lFAxM7xJ9ajCD*AT*kl5SdFKbC2gvrKeDQnNIeVw7n2yAjDAQOlQmxSHoUq4R1Y1QWx4CNKGpirXrRKkC*kog=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 结合主动学习与迁移学习：让医学图像标注工作量减少一半                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-06&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color:#888888;&quot;&gt;&lt;span style=&quot;font-size: 12.000000953674316px;&quot;&gt;&lt;strong&gt;作者：Zongwei Zhou&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Jae Y. Shin&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Suryakanth R. Gurudu&lt;span style=&quot;;&quot;&gt;, &lt;/span&gt;Michael B. Gotway&lt;span style=&quot;;&quot;&gt;, 梁建明&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：Panda&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;和普通图像的标注不一样，生物医学图像的标注需要有专业知识和技能的人来做，因此难以获得大型的有标注数据集供卷积神经网络学习。近日，IEEE 一篇论文提出可以将主动学习和迁移学习结合起来降低标注任务的工作量，实验结果也证明了这种方法的有效性。机器之心对该论文进行了编译介绍，详细的数学过程和结果分析请参阅原论文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在 ImageNet 和 Places 等大规模有标注数据集的帮助下，卷积神经网络（CNN）已经为计算机视觉领域带来了革命性的发展。正如 IEEE TMI 专刊 [4] 和最近的两本书 [5,6] 谈到的那样，人们对在生物医学图像分析中应用 CNN 有着广泛且浓厚的兴趣；但由于生物医学领域缺乏如此大量的有标注数据集，所以 CNN 在这一领域的成功之路还有所阻碍。标注生物医学图像不仅耗时耗力，而且需要高成本的、特定专业的知识和技能，这些都不易取得。因此，我们希望解答这个重要问题：如何显著降低将 CNN 应用于生物医学图像的标注成本；另外我们也想解答一个附属问题：给定一个有标签数据集，如何确定它充分覆盖了不同的相关对象。为此，我们提出了一种名为 AFT* 的全新方法，可以自然地将主动学习（active learning）和迁移学习（transfer learning）整合成单一一个框架。我们的 AFT* 方法首先会使用一个预训练 CNN 来寻找未标注数据中的「显著」样本来进行标注，然后这个（经过微调的）的 CNN 会根据新标注的样本以及所有误分类的样本而持续得到调整改进。我们在三种不同的应用上评估了我们的方法，其中包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测；结果表明标注成本至少可以减少一半。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;这种出色表现主要得益于一个简单而又强大的观察结果：为了提升 CNN 在生物医学图像上的表现，通常会通过数据增强方法为每个候选数据自动生成多个图块（patch）；这些根据同一候选数据生成的图块具有同样的标签，所以当它们被放入训练集中时，自然能够预见当前 CNN 会为它们给出相似的预测结果。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。但是，自动数据增强无可避免地会为某些候选数据生成「困难的」样本，注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5363288718929254&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDdVceKYqcuhcao0pPmDCX5a9SE0Lvku9ibyVlBCrDZybjibEqjchW31hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;算法 1：AFT*——使用混合数据进行主动且持续的微调&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;有些研究已经表明对生物医学图像分析 CNN 进行微调是有用的，但这些研究只执行了一次微调，也就是说，只使用所有可用的训练样本对预训练的 CNN 进行一次微调，而不涉及任何主动选择过程。就我们所知，我们提出的方法是首次以连续的方式将主动学习整合到 CNN 的微调中，可以使 CNN 对生物医学图像分析更加友好，实现极大降低标注成本的目标。算法 1 给出了我们的方法的概览；与传统的主动学习相比，我们的方法有 8 项优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;从全空的有标签数据集开始，不需要任何初始的有标签候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过持续的微调而非反复的再训练来逐步提升学习器的表现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过自然地利用每个候选数据中图块之间的预期一致性来主动选择信息最丰富和最有代表性的候选数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在每个候选数据中的少量图块上局部地计算选择标准，从而能节省可观的计算时间；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;通过多数选择（majority selection）自动处理有噪声标签；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动平衡不同类的训练样本；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将新选择的候选数据与误分类的候选数据结合到一起，去除简单样本以提升训练效率，重点关注困难样本以防止灾难性遗忘（catastrophic forgetting）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;将随机性纳入主动选择过程，以在探索（exploration）和利用（exploration）之间达到接近最优的平衡。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;更重要的是，我们的方法有望对使用生物医学成像的计算辅助诊断（CAD）产生重要影响，因为当前法规要求 CAD 系统必须部署在「封闭」环境中，其中所有的 CAD 结果都要经过放射科医生的检查，如有错误就会得到纠正；由此，所有的假正例结果都应该被移除，所有的假负例结果都应该补充上来，这是一种即时的在线反馈，也许能让 CAD 系统能够具备自我学习能力并且可能能在我们的方法的持续性微调能力的帮助下在部署之后继续改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3 我们提出的方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT* 是在生物医学成像计算机辅助诊断（CAD）的背景下设计的。CAD 系统通常有一个候选数据生成器，可以快速生成一个候选数据集合，其中有些是真正例，有些是假正例。在生成候选数据之后，任务目标是训练一个分类器来尽可能地去除假正例结果同时尽可能地保留真正例结果。为了训练分类器，必须对每个候选数据进行标注。我们假设每个候选数据都要取多个可能标签中的一个。为了提升用于 CAD 系统的 CNN 的表现，通常要通过数据增强为每个候选数据自动生成多个图块；这些根据同一候选数据生成的图块会继承该候选数据的标签。换句话说，所有标签都是在候选数据层面上获取的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;但是，AFT* 是通用型的，可以应用于计算机视觉和图像分析领域中的很多任务。为了说明清楚，我们将使用 Places 数据库在自然图像中的场景解读任务上阐述 AFT* 背后的思想，其中不需要候选数据生成器，因为每张图像都可以直接被当作是候选数据。为了说明简单同时不失一般性，我们将其限制到了 3 种类别（厨房、客厅和办公室），并且将每一类中的 Places 图像都分成了训练集（14 000 张图像）、验证集（1000 张图像）和测试集（100 张图像），这三个子集之间没有重叠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;设计主动学习算法涉及两个关键问题：（1）如何确定一个标注候选数据的「价值度（worthiness）」；（2）如何更新分类器/学习器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.1 主动候选数据选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 3 给出了用于多类分类的主动候选数据选择过程，同时为了便于理解，表 1 用二元分类情况对其进行了阐述。如表 1 第 1 行所示，二元分类情况有 7 种典型预测模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5162523900573613&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDLwzHl2qHQ550vH0icTLTAcr9p231OqBtL3WP7K7ia8iaOwCumVlMsDgXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：在第 10 步时（经过了 3000 个图像标签查询后），两张图像（A 和 B）以及由 CNN 在主导类别上根据预测结果列出的增强后的图像图块。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5385779122541604&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDicoAJ0dDrTAFGuuDHG8iagdAWH7kZtFaun1TkPicQ1xGq6KznbI2ia6prg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;661&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：主动候选数据选择的 7 种预测模式和 4 种方法之间的关系。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.2 寻找有价值的候选数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;主动学习的关键是开发用于确定标注候选数据「价值度」的指标。我们的标准基于一个简单而强大的观察结果：所有根据同一候选数据增强得到的图块都具有同样的标签；预计当前 CNN 对它们的预测也相似。因此，它们的熵和多样性能提供有关候选数据的「能力」的有用指标，从而可帮助提升当前 CNN 的表现。直观上讲，熵代表了分类的确定性——更高的不确定性值表示更高程度的信息（比如，表 1 中的模式 A）；而多样性是指在一个候选数据的多个图块上所得到的预测的一致性——多样性值更高说明预测不一致性程度更高（比如，表 1 中的模式 C）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.3 通过多数选择处理噪声标签&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;自动数据增强对提升 CNN 的表现而言至关重要，但却无可避免地会为某些候选数据生成「困难的」样本（如图 4(c) 所示），注入有噪声的标签；因此，为了显著增强我们的方法的稳健性，我们会根据当前 CNN 的预测结果，通过选择每个候选数据的一小部分图块来计算熵和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.4 将随机性注入主动选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;如 [41] 中讨论的那样，简单的随机选择在一开始时的表现可能优于主动选择，因为主动选择依赖于当前模型来选择用于标注的范例；因此，在早期阶段做出的糟糕选择可能会对后续选择的质量造成不良影响；而随机选择则更不易受到糟糕假设的约束。也就是说，主动选择重在利用从已获得的标签中取得的知识以探索决策边界，而随机选择则重在探索，所以能够定位到特征空间中分类器表现糟糕的区域。因此，有效的主动学习策略必须找到探索和利用之间的平衡。为此，我们通过根据采样概率主动选择而向我们的方法中注入了随机性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;3.5 比较多种学习策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;根据上面的讨论，可以推导出几种主动学习策略，如表 2 所示。我们对这些策略进行了全面的比较，结果表明：（1）AFT&#39; 不稳定；（2）AFT&#39;&#39; 需要仔细调整参数；（3）AFT 与 AFT&#39; 和 AFT&#39;&#39; 相比是最可靠的，但需要在每一步使用所有目前可用的有标注样本从一开始就对原始模型进行微调。为了克服这个短板，我们开发了一种优化版本 AFT*，可以使用新标注的候选数据以及被误分类的候选数据来持续优化当前模型。有些研究者已经证明微调能带来更好的表现，而且比从头开始训练更加稳健。此外，我们的实验表明 AFT* 的收敛速度比反复微调原来的预训练的 CNN 更快，从而可以节省训练时间；AFT* 还能通过去除简单样本，重点关注困难样本，防止灾难性遗忘来提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.476831091180867&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDc8TaaqC2tks2zIsJMQnvEFpJO5nDcZibpYjh5gN6SsjiazkU2quTStiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 2：主动学习策略&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;图 2(a) 比较了使用 Places 数据库的 AFT* 和 RFT。RFT 通过系统性的随机采样生成了 6 个不同的序列。最后的曲线是根据 6 次运行的平均结果绘制的。如图 2(a) 所示，在 AUC（曲线下面积）方面，仅使用了 2906 个候选数据查询的 AFT* 可以实现使用了 4452 个候选数据查询的 RFT 的表现；同时 AFT* 仅使用 1176 个候选数据查询就能实现使用全部 42000 个候选数据的完全训练（full training）的表现。因此，AFT* 相比于 RFT 能节省 34.7% 的标注成本，相比于完全训练能节省 97.2% 的标注成本。当使用了大约 100% 的训练数据时，其表现仍然在继续增长；因此，考虑到 GoogLeNet 架构有 22 层，所以这个数据集的大小还是不够。AFT* 是一种通用算法，不仅可用于生物医学数据集，而且也能用于其它数据集；AFT* 可用于有很多类别的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28969957081545067&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDw0iaFNTblRFfDF9uoIy949Y4lnkEJnUDnFz6emdpwN8cxyZML8uSBSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;4 应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们将我们的 AFT 和 AFT* 方法应用到了三种应用上，包括结肠镜检查帧分类、息肉检测和肺栓塞（PE）检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.1 结肠镜检查帧分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7622377622377622&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDT3m79icB090qvvk04g18WjnX5yUKErrJ5nyOeAH8icPNrdgudGysVIhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;858&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：三种结肠镜检查示例：（a）有信息的、（b）无信息的、（c）不明确但标记为「有信息的」——因为专家根据整体质量标注帧：如果某帧（即该应用中的候选数据）中有超过 75% 是清晰的，那么就认为它是有信息的。因此，不明确的候选数据中同时包含清楚和模糊的部分，并且会根据自动数据增强生成图块层面的噪声标签。比如帧（c）整个都被标注为「有信息的」，但并非与该帧相关的所有图块（d）都是「有信息的」，尽管它们都继承了「有信息的」标签。这是我们的 AFT* 方法中使用多数选择的主要动机。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.2 息肉检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2644533485975959&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD8XztBHaXJgeQyic4HQRbp06wrkjZl9R4iaYbMCrcMZDE6Hu85HaxrNBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1747&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 5：使用 AlexNet 在测试数据集上比较用于 3 种医学应用的 8 种主动选择策略。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。黑色实线是使用了全部训练数据的微调方法的当前最佳表现，黑色虚线是使用全部训练数据从头开始训练的表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2511574074074074&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDp0PEvIOKmo6yl4ZDA75maeEGHDFFWNtTw05Uicicy4sbmQYaj8HkQqrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 6：结肠镜检查视频中具有不同形状和外观的息肉。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.3 肺栓塞检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6477272727272727&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDbz7CVSLwSZchm2AKBXalk2deyERcnXla8mNkJCQNog28d2tCmtd51A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;792&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 7：用标准 3 通道表示以及 2 通道表示 [56] 得到的 5 种不同的 PE 图像，本研究使用它的原因是能实现更好的分类准确度和加速 CNN 训练的收敛。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.4 比较所有方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24258600237247924&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDeOAm7Q3OdeKyzIn3CEfJuc4RLJu3KvrAWGmONVibqV07IploZLB7SoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1686&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 3：所有方法的比较。结肠镜检查帧分类的基准表现是 RFT（ALC=.8991），息肉检测的基准表现是 RFT（ALC=.9379）和肺栓塞（PE）检测的基准表现是 RFT（ALC=.7874），使用的都是 AlexNet。加粗的值是其中表现最好的使用了特定主动选择标准的学习策略（见表 2），红色的值是同时使用了两种学习策略和主动选择标准所得到的最佳表现。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.5 在所选模式上的观察结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3682487725040917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDKnjggFFrDZxwvWAOcqoSgdfo6YJRtLGpcm2O6YRU8libz1ic3tXaEsZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;611&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 8：在结肠镜检查帧分类的第 3 步通过 4 种 AFT* 方法选择出的前 10 个候选数据。正例候选数据用红色表示，负例候选数据用蓝色表示。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.6 正例-负例比例的自动平衡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5123094958968347&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDRmp15MialrPUq3NoQjibc5nyTTbDJlyNx25OIZVPPyfNMZxfKsr7IxIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 9：AFT*、AFT 和 RFT 所选择的候选数据中的正例-负例比例。注意，RFT 的比例大致能代表整个数据集的比例&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;4.7 AFT* 在 CNN 架构中的泛化性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2580414581844174&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDhEuMgXnVxkiaxiam7x6icWp7PkoVVGWrFk9424Swu9XdSUN1yA0UibuAng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1399&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;图 10：基于三种应用，在 GoogLeNet 上比较 AFT* 和 AFT 的表现。（a）结肠镜检查帧分类、（b）息肉检测和（c）肺栓塞检测。结果表现出了与 AlexNet（见图 5）一样的模式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;AFT*：整合主动学习与迁移学习以减少标注工作（Integrating Active Learning and Transfer Learning to Reduce Annotation Efforts）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2414050822122571&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlDXVKNkibPGYtYqgcPDuzkmFU4G8leH6j4GS5Uu7NWvISBnSqQtfx2Msw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1338&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1802.00912&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;卷积神经网络（CNN）在计算机视觉领域的辉煌成功很大程度上可以归功于大型有标注数据集的可用性，比如 ImageNet 和 Places。但是，在生物医学成像领域，创建如此大型的有标注数据集是非常艰难的，因为标注生物医学图像不仅枯燥费力和费时，而且需要高成本的专业技能，这并不容易取得。为了大幅降低标注成本，本论文提出了一种用于将主动学习和迁移学习（微调）自然地整合成一个单一框架的全新方法 AFT*。该方法首先是使用一个预训练的 CNN 来为标注寻找「有价值的」样本，然后通过持续性的微调来增强（微调过的）CNN。我们在三种不同的生物医学成像应用中评估了我们的方法，结果表明与之前最佳的方法相比，这至少可以降低一半的成本。这种表现得益于我们方法的先进的主动连续学习能力的多种优势。尽管 AFT* 最初是在生物医学成像中的计算机辅助诊断背景中设计的，但这种方法是通用的，可用于计算机视觉和图像分析中的很多任务；我们使用 Places 数据库在自然图像的场景解读任务上阐释 AFT* 背后的关键思想。&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQw8xcQY9xL7PksvukNtlD4ubRIdiaRINaIfib2uZ3IFfHzWyoWDiccG7G6wJiayeHMl7PHghUZoadEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 49px !important;visibility: visible !important;&quot; width=&quot;49px&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;注：据机器之心了解，本文作者之一梁建明是AI医疗创业公司体素科技的研究开发副总裁，美国亚利桑那州立大学（ASU）副教授，美国梅奥医学中心首届入驻教授，发表了超过70篇论文并获得13项专利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;955005433&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-06-1000000622</guid>
<pubDate>Tue, 06 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>观点 | 下一步研究目标：盘点NLP领域最具潜力的六大方向</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-05-1000000621_503254975.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ-PyTN7fJYRntRJy8UmHzHCsAtcU2Ou8kSMvYaZcJo09LlxvsbaN9Velk0BVlMukGePWT05R5C08RGfsSsZr-Y0=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 综述论文：对抗攻击的12种攻击方法和15种防御方法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-05&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Naveed Akhtar等&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：许迪、刘晓坤&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;这篇文章首次展示了在对抗攻击领域的综合考察。本文是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。机器之心重点摘要了第 3 节的攻击方法（12 种）和第 6 节的防御方法（15 种），详情请参考原文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;尽管深度学习在很多计算机视觉领域的任务上表现出色，Szegedy et al. [22] 第一次发现了深度神经网络在图像分类领域存在有意思的弱点。他们证明尽管有很高的正确率，现代深度网络是非常容易受到对抗样本的攻击的。这些对抗样本仅有很轻微的扰动，以至于人类视觉系统无法察觉这种扰动（图片看起来几乎一样）。这样的攻击会导致神经网络完全改变它对图片的分类。此外，同样的图片扰动可以欺骗好多网络分类器。这类现象的深远意义吸引了好多研究员在对抗攻击和深度学习安全性领域的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;自从有了 Szegedy 的发现，机器视觉领域中陆续出现了好几个有意思的受对抗攻击影响的结果。例如，除了在特定图像的对抗性扰动之外，Moosavi-Dezfooli et al. [16] 展示了「通用扰动（universal perturbations）」的存在（如图 1 所示），这种通用扰动可以让一个分类器对所有图片错误分类。同样的，Athalye et al. [65] 展示了即使用 3D 打印的真实世界中存在的物体也可以欺骗深度网络分类器（如图 2 所示）。考虑到深度学习研究在计算机视觉的重要性和在真实生活中的潜在应用，这篇文章首次展示了在对抗攻击领域的综合考察。这篇文章是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.406282722513089&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYSCicFX7dlKO3UMOZGSylWKP6DKPqVZ7EPP6UHSiceHPH6OQG4EFmiaLKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 1：三种网络的对抗样本和原始样本的对比，以及错误分类结果。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4090909090909091&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5UVHVolUWtd3JxAHZrG2JOZsqXMkeCWDZBxPZVVjYNK89Ykph0ldJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;814&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2：3D 打印的对抗样本。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 2 节里列举了机器视觉中关于对抗攻击的常用术语。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 3 节回顾了针对图片分类任务的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7760314341846758&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYOwM301T3wQjBDbbamRnqfZFQrhxB1KfwJuhZqo3brj0MPoY42QZFzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;509&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：单像素攻击。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 4 节单独介绍了在实际生活场景中对抗攻击的方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8058455114822547&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY8J1wnsibwHmhg7KP1YgmH4eKwrvdaRiaQGx8VvSgq6qXRJS1MUofs1cQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;479&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：人脸识别的对抗样本构造。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 5 节关注对抗攻击的工作焦点和研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 6 节讨论了防御对抗攻击的文献。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1158301158301158&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYoGiaiaFRMYyBnZLwWMkmA4aHMqcx8EFwJszMuQMAVr2SfLUl7I2Fc07A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;518&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;em style=&quot;color: rgb(136, 136, 136);font-size: 12px;text-align: justify;&quot;&gt;图 5：防御通用扰动的图示。&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在第 7 章里，我们以讨论过的文献为基础的展望了未来的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 8 章总结并画上结尾。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;论文：Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26690712353471596&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYaALMhSj0qvpibbn3z5zlgQ0Iq7fiamMOtItuCwuPCzmDNVmibfKDtZeLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1109&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1801.00553&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度学习正占据如今飞速发展的机器学习和人工智能领域的心脏地位。在机器视觉领域中，它已经变成了从自动驾驶到监控、安保应用中的主力。然而，即便深度网络已经展示了在处理复杂问题时所取得的现象级成功，最近的研究表明它们对于输入中带有的轻微扰动是很脆弱的，从而导致错误的输出。对于图片来说，这样的扰动经常是太小了从而不能被人类感知，但是它们完全愚弄了深度学习模型。对抗攻击造成了深度学习在实践中成功的一系列威胁，进而引导了大量的研究进入这个方向。这篇文章展示了第一个对抗攻击在机器视觉领域的深度学习中的综合考察。我们回顾了对抗攻击设计的研究，分析了这些攻击的存在性以及提出的防御机制。为了强调对抗攻击在实际场所中存在，我们独立地回顾了实际场景中的对抗攻击。最终，我们引用文献来展望更广阔的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.1 对分类网络的攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; 本节列举了 12 种生成对抗样本的方法，专门针对分类网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 Box-constrained L-BFGS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Szegedy[22] 等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导神经网络做出误分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。但由于问题的复杂度太高，他们转而求解简化后的问题，即寻找最小的损失函数添加项，使得神经网络做出误分类，这就将问题转化成了凸优化过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 Fast Gradient Sign Method (FGSM)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Szegedy 等人发现可以通过对抗训练提高深度神经网络的鲁棒性，从而提升防御对抗样本攻击的能力。GoodFellow[23] 等人开发了一种能有效计算对抗扰动的方法。而求解对抗扰动的方法在原文中就被称为 FGSM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Kurakin[80] 等人提出了 FGSM 的「one-step target class」的变体。通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，再将原始图像减去该扰动，原始图像就变成了对抗样本，并能输出目标类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 Basic &amp;amp; Least-Likely-Class Iterative Methods&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;one-step 方法通过一大步运算增大分类器的损失函数而进行图像扰动，因而可以直接将其扩展为通过多个小步增大损失函数的变体，从而我们得到 Basic Iterative Methods（BIM）[35]。而该方法的变体和前述方法类似，通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，而得到 Least-Likely-Class Iterative Methods[35]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 Jacobian-based Saliency Map Attack (JSMA)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;对抗攻击文献中通常使用的方法是限制扰动的 l_∞或 l_2 范数的值以使对抗样本中的扰动无法被人察觉。但 JSMA[60] 提出了限制 l_0 范数的方法，即仅改变几个像素的值，而不是扰动整张图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 One Pixel Attack&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这是一种极端的对抗攻击方法，仅改变图像中的一个像素值就可以实现对抗攻击。Su[68] 等人使用了差分进化算法，对每个像素进行迭代地修改生成子图像，并与母图像对比，根据选择标准保留攻击效果最好的子图像，实现对抗攻击。这种对抗攻击不需要知道网络参数或梯度的任何信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 Carlini and Wagner Attacks (C&amp;amp;W)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Carlini 和 Wagner[36] 提出了三种对抗攻击方法，通过限制 l_∞、l_2 和 l_0 范数使得扰动无法被察觉。实验证明 defensive distillation 完全无法防御这三种攻击。该算法生成的对抗扰动可以从 unsecured 的网络迁移到 secured 的网络上，从而实现黑箱攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 DeepFool&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Moosavi-Dezfooli 等人 [72] 通过迭代计算的方法生成最小规范对抗扰动，将位于分类边界内的图像逐步推到边界外，直到出现错误分类。作者证明他们生成的扰动比 FGSM 更小，同时有相似的欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 Universal Adversarial Perturbations&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;诸如 FGSM [23]、 ILCM [35]、 DeepFool [72] 等方法只能生成单张图像的对抗扰动，而 Universal Adversarial Perturbations[16] 能生成对任何图像实现攻击的扰动，这些扰动同样对人类是几乎不可见的。该论文中使用的方法和 DeepFool 相似，都是用对抗扰动将图像推出分类边界，不过同一个扰动针对的是所有的图像。虽然文中只针对单个网络 ResNet 进行攻击，但已证明这种扰动可以泛化到其它网络上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 UPSET and ANGRI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Sarkar[146] 等人提出了两个黑箱攻击算法，UPSET 和 ANGRI。UPSET 可以为特定的目标类别生成对抗扰动，使得该扰动添加到任何图像时都可以将该图像分类成目标类别。相对于 UPSET 的「图像不可知」扰动，ANGRI 生成的是「图像特定」的扰动。它们都在 MNIST 和 CIFAR 数据集上获得了高欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 Houdini&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Houdini[131] 是一种用于欺骗基于梯度的机器学习算法的方法，通过生成特定于任务损失函数的对抗样本实现对抗攻击，即利用网络的可微损失函数的梯度信息生成对抗扰动。除了图像分类网络，该算法还可以用于欺骗语音识别网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 Adversarial Transformation Networks (ATNs)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Baluja 和 Fischer[42] 训练了多个前向神经网络来生成对抗样本，可用于攻击一个或多个网络。该算法通过最小化一个联合损失函数来生成对抗样本，该损失函数有两个部分，第一部分使对抗样本和原始图像保持相似，第二部分使对抗样本被错误分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 Miscellaneous Attacks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这一部分列举了更多其它的生成对抗样本的方法，详情请参见原文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2628992628992629&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5wMlPSo6s5icLTkrBUeicQPibmx2sCZKQhWGnyRYQLQxrFYcPFpk9Wwow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1221&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：以上列举的各种攻击方法的属性总结：「perturbation norm」表示其限制的 p-范数（p-norm）以使对抗扰动对人类不可见或难以察觉。strength 项（*越多，对抗强度越大）基于回顾过的文献得到的印象。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.2 分类/识别场景以外的对抗攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;除了 Houdini 这个例外, 在 3.1 节中概述的所有主流对抗攻击直接针对于分类任务——欺骗基于 CNN 的分类器。然而，因为对抗性威胁的严重性，对抗攻击的研究已经超越了分类/识别场景。文中概述了以下分类应用领域之外的攻击深度神经网络的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在自编码器和生成模型上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在循环神经网络上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度强化学习上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在语义切割和物体检测上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;目前，在对抗攻击防御上存在三个主要方向：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1）在学习过程中修改训练过程或者修改的输入样本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2）修改网络，比如：添加更多层/子网络、改变损失/激活函数等。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3）当分类未见过的样本时，用外部模型作为附加网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第一个方法没有直接处理学习模型。另一方面，另外两个分类是更加关心神经网络本身的。这些方法可以被进一步细分为两种类型：（a）完全防御；（b）仅探测（detection only）。「完全防御」方法的目标是让网络将对抗样本识别为正确的类别。另一方面，「仅探测」方法意味着在对抗样本上发出报警以拒绝任何进一步的处理。详细的分类在图 9 中展示了。剩下的章节是按这个分类来整理的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4193181818181818&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYjHuWxaE8QnJ4K6efmKwqry6vcjUlWFMCBEZk8jicQERNNRXic6ZzAHyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;880&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 9：防御对抗攻击的方法分类。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.1 修改训练过程/ 输入数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 蛮力对抗训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;通过不断输入新类型的对抗样本并执行对抗训练，从而不断提升网络的鲁棒性。为了保证有效性，该方法需要使用高强度的对抗样本，并且网络架构要有充足的表达能力。这种方法需要大量的训练数据，因而被称为蛮力对抗训练。很多文献中提到这种蛮力的对抗训练可以正则化网络以减少过拟合 [23,90]。然而，Moosavi-Dezfooli[16] 指出，无论添加多少对抗样本，都存在新的对抗攻击样本可以再次欺骗网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 数据压缩&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;注意到大多数训练图像都是 JPG 格式，Dziugaite[123] 等人使用 JPG 图像压缩的方法，减少对抗扰动对准确率的影响。实验证明该方法对部分对抗攻击算法有效，但通常仅采用压缩方法是远远不够的，并且压缩图像时同时也会降低正常分类的准确率，后来提出的 PCA 压缩方法也有同样的缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 基于中央凹机制的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Luo[119] 等人提出用中央凹（foveation）机制可以防御 L-BFGS 和 FGSM 生成的对抗扰动，其假设是图像分布对于转换变动是鲁棒的，而扰动不具备这种特性。但这种方法的普遍性尚未得到证明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 数据随机化方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Xie[115] 等人发现对训练图像引入随机重缩放可以减弱对抗攻击的强度，其它方法还包括随机 padding、训练过程中的图像增强等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.2 修改网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 深度压缩网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;人们观察到简单地将去噪自编码器（Denoising Auto Encoders）堆叠到原来的网络上只会使其变得更加脆弱，因而 Gu 和 Rigazio[24] 引入了深度压缩网络（Deep Contractive Networks），其中使用了和压缩自编码器（Contractive Auto Encoders）类似的平滑度惩罚项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 梯度正则化/ masking&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用输入梯度正则化以提高对抗攻击鲁棒性 [52]，该方法和蛮力对抗训练结合有很好的效果，但计算复杂度太高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 Defensive distillation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;distillation 是指将复杂网络的知识迁移到简单网络上，由 Hinton[166] 提出。Papernot[38] 利用这种技术提出了 Defensive distillation，并证明其可以抵抗小幅度扰动的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 生物启发的防御方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用类似与生物大脑中非线性树突计算的高度非线性激活函数以防御对抗攻击 [124]。另外一项工作 Dense Associative Memory 模型也是基于相似的机制 [127]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 Parseval 网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在一层中利用全局 Lipschitz 常数加控制，利用保持每一层的 Lipschitz 常数来摆脱对抗样本的干扰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 DeepCloak&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在分类层（一般为输出层）前加一层特意为对抗样本训练的层。它背后的理论认为在最显著的层里包含着最敏感的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 混杂方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章包含了多个人从多种角度对深度学习模型的调整从而使模型可以抵抗对抗性攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章介绍了 4 种网络，SafetyNet，Detector subnetwork，Exploiting convolution filter statistics 及 Additional class augmentation。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;SafetyNet 介绍了 ReLU 对对抗样本的模式与一般图片的不一样，文中介绍了一个用 SVM 实现的工作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Detector subnetwork 介绍了用 FGSM, BIM 和 DeepFool 方法实现的对对抗样本免疫的网络的优缺点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Exploiting convolution filter statistics 介绍了同 CNN 和统计学的方法做的模型在分辨对抗样本上可以有 85% 的正确率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.3 使用附加网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;13 防御通用扰动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;利用一个单独训练的网络加在原来的模型上，从而达到不需要调整系数而且免疫对抗样本的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;14 基于 GAN 的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;用 GAN 为基础的网络可以抵抗对抗攻击，而且作者提出在所有模型上用相同的办法来做都可以抵抗对抗样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;15 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;介绍了 Feature Squeezing、MagNet 以及混杂的办法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Feature Squeezing 方法用了两个模型来探查是不是对抗样本。后续的工作介绍了这个方法对 C&amp;amp;W 攻击也有能接受的抵抗力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;MagNet:作者用一个分类器对图片的流行（manifold）测量值来训练，从而分辨出图片是不是带噪声的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;混杂方法（Miscellaneous Methods）：作者训练了一个模型，把所有输入图片当成带噪声的，先学习怎么去平滑图片，之后再进行分类。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYL6ynj6GNuQsBPwA8HsPzMiadOrrjCHG9NNOQqnc4cN32xgUKPBNc4uw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 41px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;以下是机器之心报道过的对抗攻击的案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650738224&amp;amp;idx=1&amp;amp;sn=dd3a9bc5b71cdc23bf92fd8816fd68f0&amp;amp;chksm=871aca4eb06d43585821885b7a769b7d2f9b07fbdabbfc4852c77355102af645fcff53c382c0&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;既能欺骗机器，也能迷惑人类！Goodfellow 等人提出新一代对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735815&amp;amp;idx=5&amp;amp;sn=dd63d33dd27ecd34e27977fcc7682116&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 几张贴纸就让神经网络看不懂道路标志，伯克利为真实环境生成对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735672&amp;amp;idx=5&amp;amp;sn=6cef8b232381a75ec18c4595fe0f9f35&amp;amp;chksm=871ac046b06d4950a53fab52f5fe9f1b2d2e51f88d49a7b0b0016c693164866fed8c010fcf58&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 神奇的面包机！谷歌造出对抗样本的实体版&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650734471&amp;amp;idx=4&amp;amp;sn=f57ea48caebe2edfe4582fd1f5a07437&amp;amp;chksm=871b3bf9b06cb2ef2bd63c72cfe55403425ddb525fb9b5283dcebf4c96e0972a1460226fa0f4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 继图像识别后，图像标注系统也被对抗样本攻陷!&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650732373&amp;amp;idx=1&amp;amp;sn=5e8f0ef4357988e3a4d8374deb0919e6&amp;amp;chksm=871b332bb06cba3d2307cab4dbbf6b1f56ff65df4f63abf5f2552ba4d90a16157452b93768ce&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;修改一个像素，就能让神经网络识别图像出错&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1252908902&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-05-1000000621_503254975</guid>
<pubDate>Mon, 05 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>学界 | 综述论文：对抗攻击的12种攻击方法和15种防御方法</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-05-1000000621_503254971.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ-PyTN7fJYRntRJy8UmHzHD7u9AHn-8oLU1ij0qNMnh3BxyMW*BEUzva1KX*L1cLYL4gcNS4fUdl7OpZTtD0amY=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 综述论文：对抗攻击的12种攻击方法和15种防御方法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-05&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Naveed Akhtar等&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：许迪、刘晓坤&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;这篇文章首次展示了在对抗攻击领域的综合考察。本文是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。机器之心重点摘要了第 3 节的攻击方法（12 种）和第 6 节的防御方法（15 种），详情请参考原文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;尽管深度学习在很多计算机视觉领域的任务上表现出色，Szegedy et al. [22] 第一次发现了深度神经网络在图像分类领域存在有意思的弱点。他们证明尽管有很高的正确率，现代深度网络是非常容易受到对抗样本的攻击的。这些对抗样本仅有很轻微的扰动，以至于人类视觉系统无法察觉这种扰动（图片看起来几乎一样）。这样的攻击会导致神经网络完全改变它对图片的分类。此外，同样的图片扰动可以欺骗好多网络分类器。这类现象的深远意义吸引了好多研究员在对抗攻击和深度学习安全性领域的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;自从有了 Szegedy 的发现，机器视觉领域中陆续出现了好几个有意思的受对抗攻击影响的结果。例如，除了在特定图像的对抗性扰动之外，Moosavi-Dezfooli et al. [16] 展示了「通用扰动（universal perturbations）」的存在（如图 1 所示），这种通用扰动可以让一个分类器对所有图片错误分类。同样的，Athalye et al. [65] 展示了即使用 3D 打印的真实世界中存在的物体也可以欺骗深度网络分类器（如图 2 所示）。考虑到深度学习研究在计算机视觉的重要性和在真实生活中的潜在应用，这篇文章首次展示了在对抗攻击领域的综合考察。这篇文章是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.406282722513089&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYSCicFX7dlKO3UMOZGSylWKP6DKPqVZ7EPP6UHSiceHPH6OQG4EFmiaLKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 1：三种网络的对抗样本和原始样本的对比，以及错误分类结果。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4090909090909091&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5UVHVolUWtd3JxAHZrG2JOZsqXMkeCWDZBxPZVVjYNK89Ykph0ldJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;814&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2：3D 打印的对抗样本。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 2 节里列举了机器视觉中关于对抗攻击的常用术语。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 3 节回顾了针对图片分类任务的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7760314341846758&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYOwM301T3wQjBDbbamRnqfZFQrhxB1KfwJuhZqo3brj0MPoY42QZFzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;509&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：单像素攻击。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 4 节单独介绍了在实际生活场景中对抗攻击的方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8058455114822547&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY8J1wnsibwHmhg7KP1YgmH4eKwrvdaRiaQGx8VvSgq6qXRJS1MUofs1cQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;479&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：人脸识别的对抗样本构造。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 5 节关注对抗攻击的工作焦点和研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 6 节讨论了防御对抗攻击的文献。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1158301158301158&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYoGiaiaFRMYyBnZLwWMkmA4aHMqcx8EFwJszMuQMAVr2SfLUl7I2Fc07A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;518&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;em style=&quot;color: rgb(136, 136, 136);font-size: 12px;text-align: justify;&quot;&gt;图 5：防御通用扰动的图示。&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在第 7 章里，我们以讨论过的文献为基础的展望了未来的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 8 章总结并画上结尾。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;论文：Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26690712353471596&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYaALMhSj0qvpibbn3z5zlgQ0Iq7fiamMOtItuCwuPCzmDNVmibfKDtZeLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1109&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1801.00553&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度学习正占据如今飞速发展的机器学习和人工智能领域的心脏地位。在机器视觉领域中，它已经变成了从自动驾驶到监控、安保应用中的主力。然而，即便深度网络已经展示了在处理复杂问题时所取得的现象级成功，最近的研究表明它们对于输入中带有的轻微扰动是很脆弱的，从而导致错误的输出。对于图片来说，这样的扰动经常是太小了从而不能被人类感知，但是它们完全愚弄了深度学习模型。对抗攻击造成了深度学习在实践中成功的一系列威胁，进而引导了大量的研究进入这个方向。这篇文章展示了第一个对抗攻击在机器视觉领域的深度学习中的综合考察。我们回顾了对抗攻击设计的研究，分析了这些攻击的存在性以及提出的防御机制。为了强调对抗攻击在实际场所中存在，我们独立地回顾了实际场景中的对抗攻击。最终，我们引用文献来展望更广阔的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.1 对分类网络的攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; 本节列举了 12 种生成对抗样本的方法，专门针对分类网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 Box-constrained L-BFGS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Szegedy[22] 等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导神经网络做出误分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。但由于问题的复杂度太高，他们转而求解简化后的问题，即寻找最小的损失函数添加项，使得神经网络做出误分类，这就将问题转化成了凸优化过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 Fast Gradient Sign Method (FGSM)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Szegedy 等人发现可以通过对抗训练提高深度神经网络的鲁棒性，从而提升防御对抗样本攻击的能力。GoodFellow[23] 等人开发了一种能有效计算对抗扰动的方法。而求解对抗扰动的方法在原文中就被称为 FGSM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Kurakin[80] 等人提出了 FGSM 的「one-step target class」的变体。通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，再将原始图像减去该扰动，原始图像就变成了对抗样本，并能输出目标类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 Basic &amp;amp; Least-Likely-Class Iterative Methods&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;one-step 方法通过一大步运算增大分类器的损失函数而进行图像扰动，因而可以直接将其扩展为通过多个小步增大损失函数的变体，从而我们得到 Basic Iterative Methods（BIM）[35]。而该方法的变体和前述方法类似，通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，而得到 Least-Likely-Class Iterative Methods[35]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 Jacobian-based Saliency Map Attack (JSMA)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;对抗攻击文献中通常使用的方法是限制扰动的 l_∞或 l_2 范数的值以使对抗样本中的扰动无法被人察觉。但 JSMA[60] 提出了限制 l_0 范数的方法，即仅改变几个像素的值，而不是扰动整张图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 One Pixel Attack&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这是一种极端的对抗攻击方法，仅改变图像中的一个像素值就可以实现对抗攻击。Su[68] 等人使用了差分进化算法，对每个像素进行迭代地修改生成子图像，并与母图像对比，根据选择标准保留攻击效果最好的子图像，实现对抗攻击。这种对抗攻击不需要知道网络参数或梯度的任何信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 Carlini and Wagner Attacks (C&amp;amp;W)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Carlini 和 Wagner[36] 提出了三种对抗攻击方法，通过限制 l_∞、l_2 和 l_0 范数使得扰动无法被察觉。实验证明 defensive distillation 完全无法防御这三种攻击。该算法生成的对抗扰动可以从 unsecured 的网络迁移到 secured 的网络上，从而实现黑箱攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 DeepFool&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Moosavi-Dezfooli 等人 [72] 通过迭代计算的方法生成最小规范对抗扰动，将位于分类边界内的图像逐步推到边界外，直到出现错误分类。作者证明他们生成的扰动比 FGSM 更小，同时有相似的欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 Universal Adversarial Perturbations&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;诸如 FGSM [23]、 ILCM [35]、 DeepFool [72] 等方法只能生成单张图像的对抗扰动，而 Universal Adversarial Perturbations[16] 能生成对任何图像实现攻击的扰动，这些扰动同样对人类是几乎不可见的。该论文中使用的方法和 DeepFool 相似，都是用对抗扰动将图像推出分类边界，不过同一个扰动针对的是所有的图像。虽然文中只针对单个网络 ResNet 进行攻击，但已证明这种扰动可以泛化到其它网络上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 UPSET and ANGRI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Sarkar[146] 等人提出了两个黑箱攻击算法，UPSET 和 ANGRI。UPSET 可以为特定的目标类别生成对抗扰动，使得该扰动添加到任何图像时都可以将该图像分类成目标类别。相对于 UPSET 的「图像不可知」扰动，ANGRI 生成的是「图像特定」的扰动。它们都在 MNIST 和 CIFAR 数据集上获得了高欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 Houdini&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Houdini[131] 是一种用于欺骗基于梯度的机器学习算法的方法，通过生成特定于任务损失函数的对抗样本实现对抗攻击，即利用网络的可微损失函数的梯度信息生成对抗扰动。除了图像分类网络，该算法还可以用于欺骗语音识别网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 Adversarial Transformation Networks (ATNs)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Baluja 和 Fischer[42] 训练了多个前向神经网络来生成对抗样本，可用于攻击一个或多个网络。该算法通过最小化一个联合损失函数来生成对抗样本，该损失函数有两个部分，第一部分使对抗样本和原始图像保持相似，第二部分使对抗样本被错误分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 Miscellaneous Attacks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这一部分列举了更多其它的生成对抗样本的方法，详情请参见原文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2628992628992629&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5wMlPSo6s5icLTkrBUeicQPibmx2sCZKQhWGnyRYQLQxrFYcPFpk9Wwow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1221&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：以上列举的各种攻击方法的属性总结：「perturbation norm」表示其限制的 p-范数（p-norm）以使对抗扰动对人类不可见或难以察觉。strength 项（*越多，对抗强度越大）基于回顾过的文献得到的印象。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.2 分类/识别场景以外的对抗攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;除了 Houdini 这个例外, 在 3.1 节中概述的所有主流对抗攻击直接针对于分类任务——欺骗基于 CNN 的分类器。然而，因为对抗性威胁的严重性，对抗攻击的研究已经超越了分类/识别场景。文中概述了以下分类应用领域之外的攻击深度神经网络的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在自编码器和生成模型上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在循环神经网络上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度强化学习上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在语义切割和物体检测上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;目前，在对抗攻击防御上存在三个主要方向：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1）在学习过程中修改训练过程或者修改的输入样本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2）修改网络，比如：添加更多层/子网络、改变损失/激活函数等。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3）当分类未见过的样本时，用外部模型作为附加网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第一个方法没有直接处理学习模型。另一方面，另外两个分类是更加关心神经网络本身的。这些方法可以被进一步细分为两种类型：（a）完全防御；（b）仅探测（detection only）。「完全防御」方法的目标是让网络将对抗样本识别为正确的类别。另一方面，「仅探测」方法意味着在对抗样本上发出报警以拒绝任何进一步的处理。详细的分类在图 9 中展示了。剩下的章节是按这个分类来整理的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4193181818181818&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYjHuWxaE8QnJ4K6efmKwqry6vcjUlWFMCBEZk8jicQERNNRXic6ZzAHyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;880&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 9：防御对抗攻击的方法分类。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.1 修改训练过程/ 输入数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 蛮力对抗训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;通过不断输入新类型的对抗样本并执行对抗训练，从而不断提升网络的鲁棒性。为了保证有效性，该方法需要使用高强度的对抗样本，并且网络架构要有充足的表达能力。这种方法需要大量的训练数据，因而被称为蛮力对抗训练。很多文献中提到这种蛮力的对抗训练可以正则化网络以减少过拟合 [23,90]。然而，Moosavi-Dezfooli[16] 指出，无论添加多少对抗样本，都存在新的对抗攻击样本可以再次欺骗网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 数据压缩&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;注意到大多数训练图像都是 JPG 格式，Dziugaite[123] 等人使用 JPG 图像压缩的方法，减少对抗扰动对准确率的影响。实验证明该方法对部分对抗攻击算法有效，但通常仅采用压缩方法是远远不够的，并且压缩图像时同时也会降低正常分类的准确率，后来提出的 PCA 压缩方法也有同样的缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 基于中央凹机制的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Luo[119] 等人提出用中央凹（foveation）机制可以防御 L-BFGS 和 FGSM 生成的对抗扰动，其假设是图像分布对于转换变动是鲁棒的，而扰动不具备这种特性。但这种方法的普遍性尚未得到证明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 数据随机化方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Xie[115] 等人发现对训练图像引入随机重缩放可以减弱对抗攻击的强度，其它方法还包括随机 padding、训练过程中的图像增强等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.2 修改网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 深度压缩网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;人们观察到简单地将去噪自编码器（Denoising Auto Encoders）堆叠到原来的网络上只会使其变得更加脆弱，因而 Gu 和 Rigazio[24] 引入了深度压缩网络（Deep Contractive Networks），其中使用了和压缩自编码器（Contractive Auto Encoders）类似的平滑度惩罚项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 梯度正则化/ masking&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用输入梯度正则化以提高对抗攻击鲁棒性 [52]，该方法和蛮力对抗训练结合有很好的效果，但计算复杂度太高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 Defensive distillation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;distillation 是指将复杂网络的知识迁移到简单网络上，由 Hinton[166] 提出。Papernot[38] 利用这种技术提出了 Defensive distillation，并证明其可以抵抗小幅度扰动的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 生物启发的防御方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用类似与生物大脑中非线性树突计算的高度非线性激活函数以防御对抗攻击 [124]。另外一项工作 Dense Associative Memory 模型也是基于相似的机制 [127]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 Parseval 网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在一层中利用全局 Lipschitz 常数加控制，利用保持每一层的 Lipschitz 常数来摆脱对抗样本的干扰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 DeepCloak&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在分类层（一般为输出层）前加一层特意为对抗样本训练的层。它背后的理论认为在最显著的层里包含着最敏感的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 混杂方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章包含了多个人从多种角度对深度学习模型的调整从而使模型可以抵抗对抗性攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章介绍了 4 种网络，SafetyNet，Detector subnetwork，Exploiting convolution filter statistics 及 Additional class augmentation。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;SafetyNet 介绍了 ReLU 对对抗样本的模式与一般图片的不一样，文中介绍了一个用 SVM 实现的工作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Detector subnetwork 介绍了用 FGSM, BIM 和 DeepFool 方法实现的对对抗样本免疫的网络的优缺点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Exploiting convolution filter statistics 介绍了同 CNN 和统计学的方法做的模型在分辨对抗样本上可以有 85% 的正确率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.3 使用附加网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;13 防御通用扰动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;利用一个单独训练的网络加在原来的模型上，从而达到不需要调整系数而且免疫对抗样本的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;14 基于 GAN 的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;用 GAN 为基础的网络可以抵抗对抗攻击，而且作者提出在所有模型上用相同的办法来做都可以抵抗对抗样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;15 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;介绍了 Feature Squeezing、MagNet 以及混杂的办法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Feature Squeezing 方法用了两个模型来探查是不是对抗样本。后续的工作介绍了这个方法对 C&amp;amp;W 攻击也有能接受的抵抗力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;MagNet:作者用一个分类器对图片的流行（manifold）测量值来训练，从而分辨出图片是不是带噪声的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;混杂方法（Miscellaneous Methods）：作者训练了一个模型，把所有输入图片当成带噪声的，先学习怎么去平滑图片，之后再进行分类。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYL6ynj6GNuQsBPwA8HsPzMiadOrrjCHG9NNOQqnc4cN32xgUKPBNc4uw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 41px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;以下是机器之心报道过的对抗攻击的案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650738224&amp;amp;idx=1&amp;amp;sn=dd3a9bc5b71cdc23bf92fd8816fd68f0&amp;amp;chksm=871aca4eb06d43585821885b7a769b7d2f9b07fbdabbfc4852c77355102af645fcff53c382c0&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;既能欺骗机器，也能迷惑人类！Goodfellow 等人提出新一代对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735815&amp;amp;idx=5&amp;amp;sn=dd63d33dd27ecd34e27977fcc7682116&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 几张贴纸就让神经网络看不懂道路标志，伯克利为真实环境生成对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735672&amp;amp;idx=5&amp;amp;sn=6cef8b232381a75ec18c4595fe0f9f35&amp;amp;chksm=871ac046b06d4950a53fab52f5fe9f1b2d2e51f88d49a7b0b0016c693164866fed8c010fcf58&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 神奇的面包机！谷歌造出对抗样本的实体版&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650734471&amp;amp;idx=4&amp;amp;sn=f57ea48caebe2edfe4582fd1f5a07437&amp;amp;chksm=871b3bf9b06cb2ef2bd63c72cfe55403425ddb525fb9b5283dcebf4c96e0972a1460226fa0f4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 继图像识别后，图像标注系统也被对抗样本攻陷!&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650732373&amp;amp;idx=1&amp;amp;sn=5e8f0ef4357988e3a4d8374deb0919e6&amp;amp;chksm=871b332bb06cba3d2307cab4dbbf6b1f56ff65df4f63abf5f2552ba4d90a16157452b93768ce&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;修改一个像素，就能让神经网络识别图像出错&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;53227934&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-05-1000000621_503254971</guid>
<pubDate>Mon, 05 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>教程 | 如何通过Scikit-Learn实现多类别文本分类？</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-05-1000000621_503254962.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ-PyTN7fJYRntRJy8UmHzHAnXlh278mexFsYDq17-*ccOXJZPayxCKJPUN75BxAHinayTiCjJx1PLaG9IRCEKAc=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 综述论文：对抗攻击的12种攻击方法和15种防御方法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-05&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Naveed Akhtar等&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：许迪、刘晓坤&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;这篇文章首次展示了在对抗攻击领域的综合考察。本文是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。机器之心重点摘要了第 3 节的攻击方法（12 种）和第 6 节的防御方法（15 种），详情请参考原文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;尽管深度学习在很多计算机视觉领域的任务上表现出色，Szegedy et al. [22] 第一次发现了深度神经网络在图像分类领域存在有意思的弱点。他们证明尽管有很高的正确率，现代深度网络是非常容易受到对抗样本的攻击的。这些对抗样本仅有很轻微的扰动，以至于人类视觉系统无法察觉这种扰动（图片看起来几乎一样）。这样的攻击会导致神经网络完全改变它对图片的分类。此外，同样的图片扰动可以欺骗好多网络分类器。这类现象的深远意义吸引了好多研究员在对抗攻击和深度学习安全性领域的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;自从有了 Szegedy 的发现，机器视觉领域中陆续出现了好几个有意思的受对抗攻击影响的结果。例如，除了在特定图像的对抗性扰动之外，Moosavi-Dezfooli et al. [16] 展示了「通用扰动（universal perturbations）」的存在（如图 1 所示），这种通用扰动可以让一个分类器对所有图片错误分类。同样的，Athalye et al. [65] 展示了即使用 3D 打印的真实世界中存在的物体也可以欺骗深度网络分类器（如图 2 所示）。考虑到深度学习研究在计算机视觉的重要性和在真实生活中的潜在应用，这篇文章首次展示了在对抗攻击领域的综合考察。这篇文章是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.406282722513089&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYSCicFX7dlKO3UMOZGSylWKP6DKPqVZ7EPP6UHSiceHPH6OQG4EFmiaLKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 1：三种网络的对抗样本和原始样本的对比，以及错误分类结果。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4090909090909091&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5UVHVolUWtd3JxAHZrG2JOZsqXMkeCWDZBxPZVVjYNK89Ykph0ldJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;814&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2：3D 打印的对抗样本。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 2 节里列举了机器视觉中关于对抗攻击的常用术语。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 3 节回顾了针对图片分类任务的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7760314341846758&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYOwM301T3wQjBDbbamRnqfZFQrhxB1KfwJuhZqo3brj0MPoY42QZFzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;509&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：单像素攻击。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 4 节单独介绍了在实际生活场景中对抗攻击的方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8058455114822547&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY8J1wnsibwHmhg7KP1YgmH4eKwrvdaRiaQGx8VvSgq6qXRJS1MUofs1cQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;479&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：人脸识别的对抗样本构造。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 5 节关注对抗攻击的工作焦点和研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 6 节讨论了防御对抗攻击的文献。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1158301158301158&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYoGiaiaFRMYyBnZLwWMkmA4aHMqcx8EFwJszMuQMAVr2SfLUl7I2Fc07A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;518&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;em style=&quot;color: rgb(136, 136, 136);font-size: 12px;text-align: justify;&quot;&gt;图 5：防御通用扰动的图示。&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在第 7 章里，我们以讨论过的文献为基础的展望了未来的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 8 章总结并画上结尾。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;论文：Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26690712353471596&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYaALMhSj0qvpibbn3z5zlgQ0Iq7fiamMOtItuCwuPCzmDNVmibfKDtZeLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1109&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1801.00553&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度学习正占据如今飞速发展的机器学习和人工智能领域的心脏地位。在机器视觉领域中，它已经变成了从自动驾驶到监控、安保应用中的主力。然而，即便深度网络已经展示了在处理复杂问题时所取得的现象级成功，最近的研究表明它们对于输入中带有的轻微扰动是很脆弱的，从而导致错误的输出。对于图片来说，这样的扰动经常是太小了从而不能被人类感知，但是它们完全愚弄了深度学习模型。对抗攻击造成了深度学习在实践中成功的一系列威胁，进而引导了大量的研究进入这个方向。这篇文章展示了第一个对抗攻击在机器视觉领域的深度学习中的综合考察。我们回顾了对抗攻击设计的研究，分析了这些攻击的存在性以及提出的防御机制。为了强调对抗攻击在实际场所中存在，我们独立地回顾了实际场景中的对抗攻击。最终，我们引用文献来展望更广阔的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.1 对分类网络的攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; 本节列举了 12 种生成对抗样本的方法，专门针对分类网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 Box-constrained L-BFGS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Szegedy[22] 等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导神经网络做出误分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。但由于问题的复杂度太高，他们转而求解简化后的问题，即寻找最小的损失函数添加项，使得神经网络做出误分类，这就将问题转化成了凸优化过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 Fast Gradient Sign Method (FGSM)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Szegedy 等人发现可以通过对抗训练提高深度神经网络的鲁棒性，从而提升防御对抗样本攻击的能力。GoodFellow[23] 等人开发了一种能有效计算对抗扰动的方法。而求解对抗扰动的方法在原文中就被称为 FGSM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Kurakin[80] 等人提出了 FGSM 的「one-step target class」的变体。通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，再将原始图像减去该扰动，原始图像就变成了对抗样本，并能输出目标类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 Basic &amp;amp; Least-Likely-Class Iterative Methods&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;one-step 方法通过一大步运算增大分类器的损失函数而进行图像扰动，因而可以直接将其扩展为通过多个小步增大损失函数的变体，从而我们得到 Basic Iterative Methods（BIM）[35]。而该方法的变体和前述方法类似，通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，而得到 Least-Likely-Class Iterative Methods[35]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 Jacobian-based Saliency Map Attack (JSMA)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;对抗攻击文献中通常使用的方法是限制扰动的 l_∞或 l_2 范数的值以使对抗样本中的扰动无法被人察觉。但 JSMA[60] 提出了限制 l_0 范数的方法，即仅改变几个像素的值，而不是扰动整张图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 One Pixel Attack&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这是一种极端的对抗攻击方法，仅改变图像中的一个像素值就可以实现对抗攻击。Su[68] 等人使用了差分进化算法，对每个像素进行迭代地修改生成子图像，并与母图像对比，根据选择标准保留攻击效果最好的子图像，实现对抗攻击。这种对抗攻击不需要知道网络参数或梯度的任何信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 Carlini and Wagner Attacks (C&amp;amp;W)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Carlini 和 Wagner[36] 提出了三种对抗攻击方法，通过限制 l_∞、l_2 和 l_0 范数使得扰动无法被察觉。实验证明 defensive distillation 完全无法防御这三种攻击。该算法生成的对抗扰动可以从 unsecured 的网络迁移到 secured 的网络上，从而实现黑箱攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 DeepFool&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Moosavi-Dezfooli 等人 [72] 通过迭代计算的方法生成最小规范对抗扰动，将位于分类边界内的图像逐步推到边界外，直到出现错误分类。作者证明他们生成的扰动比 FGSM 更小，同时有相似的欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 Universal Adversarial Perturbations&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;诸如 FGSM [23]、 ILCM [35]、 DeepFool [72] 等方法只能生成单张图像的对抗扰动，而 Universal Adversarial Perturbations[16] 能生成对任何图像实现攻击的扰动，这些扰动同样对人类是几乎不可见的。该论文中使用的方法和 DeepFool 相似，都是用对抗扰动将图像推出分类边界，不过同一个扰动针对的是所有的图像。虽然文中只针对单个网络 ResNet 进行攻击，但已证明这种扰动可以泛化到其它网络上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 UPSET and ANGRI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Sarkar[146] 等人提出了两个黑箱攻击算法，UPSET 和 ANGRI。UPSET 可以为特定的目标类别生成对抗扰动，使得该扰动添加到任何图像时都可以将该图像分类成目标类别。相对于 UPSET 的「图像不可知」扰动，ANGRI 生成的是「图像特定」的扰动。它们都在 MNIST 和 CIFAR 数据集上获得了高欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 Houdini&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Houdini[131] 是一种用于欺骗基于梯度的机器学习算法的方法，通过生成特定于任务损失函数的对抗样本实现对抗攻击，即利用网络的可微损失函数的梯度信息生成对抗扰动。除了图像分类网络，该算法还可以用于欺骗语音识别网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 Adversarial Transformation Networks (ATNs)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Baluja 和 Fischer[42] 训练了多个前向神经网络来生成对抗样本，可用于攻击一个或多个网络。该算法通过最小化一个联合损失函数来生成对抗样本，该损失函数有两个部分，第一部分使对抗样本和原始图像保持相似，第二部分使对抗样本被错误分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 Miscellaneous Attacks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这一部分列举了更多其它的生成对抗样本的方法，详情请参见原文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2628992628992629&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5wMlPSo6s5icLTkrBUeicQPibmx2sCZKQhWGnyRYQLQxrFYcPFpk9Wwow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1221&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：以上列举的各种攻击方法的属性总结：「perturbation norm」表示其限制的 p-范数（p-norm）以使对抗扰动对人类不可见或难以察觉。strength 项（*越多，对抗强度越大）基于回顾过的文献得到的印象。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.2 分类/识别场景以外的对抗攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;除了 Houdini 这个例外, 在 3.1 节中概述的所有主流对抗攻击直接针对于分类任务——欺骗基于 CNN 的分类器。然而，因为对抗性威胁的严重性，对抗攻击的研究已经超越了分类/识别场景。文中概述了以下分类应用领域之外的攻击深度神经网络的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在自编码器和生成模型上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在循环神经网络上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度强化学习上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在语义切割和物体检测上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;目前，在对抗攻击防御上存在三个主要方向：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1）在学习过程中修改训练过程或者修改的输入样本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2）修改网络，比如：添加更多层/子网络、改变损失/激活函数等。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3）当分类未见过的样本时，用外部模型作为附加网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第一个方法没有直接处理学习模型。另一方面，另外两个分类是更加关心神经网络本身的。这些方法可以被进一步细分为两种类型：（a）完全防御；（b）仅探测（detection only）。「完全防御」方法的目标是让网络将对抗样本识别为正确的类别。另一方面，「仅探测」方法意味着在对抗样本上发出报警以拒绝任何进一步的处理。详细的分类在图 9 中展示了。剩下的章节是按这个分类来整理的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4193181818181818&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYjHuWxaE8QnJ4K6efmKwqry6vcjUlWFMCBEZk8jicQERNNRXic6ZzAHyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;880&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 9：防御对抗攻击的方法分类。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.1 修改训练过程/ 输入数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 蛮力对抗训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;通过不断输入新类型的对抗样本并执行对抗训练，从而不断提升网络的鲁棒性。为了保证有效性，该方法需要使用高强度的对抗样本，并且网络架构要有充足的表达能力。这种方法需要大量的训练数据，因而被称为蛮力对抗训练。很多文献中提到这种蛮力的对抗训练可以正则化网络以减少过拟合 [23,90]。然而，Moosavi-Dezfooli[16] 指出，无论添加多少对抗样本，都存在新的对抗攻击样本可以再次欺骗网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 数据压缩&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;注意到大多数训练图像都是 JPG 格式，Dziugaite[123] 等人使用 JPG 图像压缩的方法，减少对抗扰动对准确率的影响。实验证明该方法对部分对抗攻击算法有效，但通常仅采用压缩方法是远远不够的，并且压缩图像时同时也会降低正常分类的准确率，后来提出的 PCA 压缩方法也有同样的缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 基于中央凹机制的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Luo[119] 等人提出用中央凹（foveation）机制可以防御 L-BFGS 和 FGSM 生成的对抗扰动，其假设是图像分布对于转换变动是鲁棒的，而扰动不具备这种特性。但这种方法的普遍性尚未得到证明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 数据随机化方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Xie[115] 等人发现对训练图像引入随机重缩放可以减弱对抗攻击的强度，其它方法还包括随机 padding、训练过程中的图像增强等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.2 修改网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 深度压缩网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;人们观察到简单地将去噪自编码器（Denoising Auto Encoders）堆叠到原来的网络上只会使其变得更加脆弱，因而 Gu 和 Rigazio[24] 引入了深度压缩网络（Deep Contractive Networks），其中使用了和压缩自编码器（Contractive Auto Encoders）类似的平滑度惩罚项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 梯度正则化/ masking&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用输入梯度正则化以提高对抗攻击鲁棒性 [52]，该方法和蛮力对抗训练结合有很好的效果，但计算复杂度太高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 Defensive distillation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;distillation 是指将复杂网络的知识迁移到简单网络上，由 Hinton[166] 提出。Papernot[38] 利用这种技术提出了 Defensive distillation，并证明其可以抵抗小幅度扰动的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 生物启发的防御方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用类似与生物大脑中非线性树突计算的高度非线性激活函数以防御对抗攻击 [124]。另外一项工作 Dense Associative Memory 模型也是基于相似的机制 [127]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 Parseval 网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在一层中利用全局 Lipschitz 常数加控制，利用保持每一层的 Lipschitz 常数来摆脱对抗样本的干扰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 DeepCloak&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在分类层（一般为输出层）前加一层特意为对抗样本训练的层。它背后的理论认为在最显著的层里包含着最敏感的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 混杂方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章包含了多个人从多种角度对深度学习模型的调整从而使模型可以抵抗对抗性攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章介绍了 4 种网络，SafetyNet，Detector subnetwork，Exploiting convolution filter statistics 及 Additional class augmentation。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;SafetyNet 介绍了 ReLU 对对抗样本的模式与一般图片的不一样，文中介绍了一个用 SVM 实现的工作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Detector subnetwork 介绍了用 FGSM, BIM 和 DeepFool 方法实现的对对抗样本免疫的网络的优缺点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Exploiting convolution filter statistics 介绍了同 CNN 和统计学的方法做的模型在分辨对抗样本上可以有 85% 的正确率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.3 使用附加网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;13 防御通用扰动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;利用一个单独训练的网络加在原来的模型上，从而达到不需要调整系数而且免疫对抗样本的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;14 基于 GAN 的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;用 GAN 为基础的网络可以抵抗对抗攻击，而且作者提出在所有模型上用相同的办法来做都可以抵抗对抗样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;15 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;介绍了 Feature Squeezing、MagNet 以及混杂的办法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Feature Squeezing 方法用了两个模型来探查是不是对抗样本。后续的工作介绍了这个方法对 C&amp;amp;W 攻击也有能接受的抵抗力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;MagNet:作者用一个分类器对图片的流行（manifold）测量值来训练，从而分辨出图片是不是带噪声的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;混杂方法（Miscellaneous Methods）：作者训练了一个模型，把所有输入图片当成带噪声的，先学习怎么去平滑图片，之后再进行分类。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYL6ynj6GNuQsBPwA8HsPzMiadOrrjCHG9NNOQqnc4cN32xgUKPBNc4uw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 41px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;以下是机器之心报道过的对抗攻击的案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650738224&amp;amp;idx=1&amp;amp;sn=dd3a9bc5b71cdc23bf92fd8816fd68f0&amp;amp;chksm=871aca4eb06d43585821885b7a769b7d2f9b07fbdabbfc4852c77355102af645fcff53c382c0&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;既能欺骗机器，也能迷惑人类！Goodfellow 等人提出新一代对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735815&amp;amp;idx=5&amp;amp;sn=dd63d33dd27ecd34e27977fcc7682116&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 几张贴纸就让神经网络看不懂道路标志，伯克利为真实环境生成对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735672&amp;amp;idx=5&amp;amp;sn=6cef8b232381a75ec18c4595fe0f9f35&amp;amp;chksm=871ac046b06d4950a53fab52f5fe9f1b2d2e51f88d49a7b0b0016c693164866fed8c010fcf58&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 神奇的面包机！谷歌造出对抗样本的实体版&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650734471&amp;amp;idx=4&amp;amp;sn=f57ea48caebe2edfe4582fd1f5a07437&amp;amp;chksm=871b3bf9b06cb2ef2bd63c72cfe55403425ddb525fb9b5283dcebf4c96e0972a1460226fa0f4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 继图像识别后，图像标注系统也被对抗样本攻陷!&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650732373&amp;amp;idx=1&amp;amp;sn=5e8f0ef4357988e3a4d8374deb0919e6&amp;amp;chksm=871b332bb06cba3d2307cab4dbbf6b1f56ff65df4f63abf5f2552ba4d90a16157452b93768ce&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;修改一个像素，就能让神经网络识别图像出错&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;578474125&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-05-1000000621_503254962</guid>
<pubDate>Mon, 05 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>南京大学周志华教授综述论文：弱监督学习</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-05-1000000621.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ-PyTN7fJYRntRJy8UmHzHD2FqE416oPRNeS20Lvtis3VbxToq1SjEhDA2v6KdN2j-oZfhtpyFuFGsb0*5*URfI=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 综述论文：对抗攻击的12种攻击方法和15种防御方法                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-05&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：Naveed Akhtar等&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：许迪、刘晓坤&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;这篇文章首次展示了在对抗攻击领域的综合考察。本文是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。机器之心重点摘要了第 3 节的攻击方法（12 种）和第 6 节的防御方法（15 种），详情请参考原文。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;尽管深度学习在很多计算机视觉领域的任务上表现出色，Szegedy et al. [22] 第一次发现了深度神经网络在图像分类领域存在有意思的弱点。他们证明尽管有很高的正确率，现代深度网络是非常容易受到对抗样本的攻击的。这些对抗样本仅有很轻微的扰动，以至于人类视觉系统无法察觉这种扰动（图片看起来几乎一样）。这样的攻击会导致神经网络完全改变它对图片的分类。此外，同样的图片扰动可以欺骗好多网络分类器。这类现象的深远意义吸引了好多研究员在对抗攻击和深度学习安全性领域的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;自从有了 Szegedy 的发现，机器视觉领域中陆续出现了好几个有意思的受对抗攻击影响的结果。例如，除了在特定图像的对抗性扰动之外，Moosavi-Dezfooli et al. [16] 展示了「通用扰动（universal perturbations）」的存在（如图 1 所示），这种通用扰动可以让一个分类器对所有图片错误分类。同样的，Athalye et al. [65] 展示了即使用 3D 打印的真实世界中存在的物体也可以欺骗深度网络分类器（如图 2 所示）。考虑到深度学习研究在计算机视觉的重要性和在真实生活中的潜在应用，这篇文章首次展示了在对抗攻击领域的综合考察。这篇文章是为了比机器视觉更广泛的社区而写的，假设了读者只有基本的深度学习和图像处理知识。不管怎样，这里也为感兴趣的读者讨论了有重要贡献的技术细节。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.406282722513089&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYSCicFX7dlKO3UMOZGSylWKP6DKPqVZ7EPP6UHSiceHPH6OQG4EFmiaLKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 1：三种网络的对抗样本和原始样本的对比，以及错误分类结果。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4090909090909091&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5UVHVolUWtd3JxAHZrG2JOZsqXMkeCWDZBxPZVVjYNK89Ykph0ldJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;814&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 2：3D 打印的对抗样本。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 2 节里列举了机器视觉中关于对抗攻击的常用术语。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 3 节回顾了针对图片分类任务的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7760314341846758&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYOwM301T3wQjBDbbamRnqfZFQrhxB1KfwJuhZqo3brj0MPoY42QZFzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;509&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 3：单像素攻击。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 4 节单独介绍了在实际生活场景中对抗攻击的方法。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8058455114822547&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY8J1wnsibwHmhg7KP1YgmH4eKwrvdaRiaQGx8VvSgq6qXRJS1MUofs1cQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;479&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 4：人脸识别的对抗样本构造。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 5 节关注对抗攻击的工作焦点和研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 6 节讨论了防御对抗攻击的文献。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1158301158301158&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYoGiaiaFRMYyBnZLwWMkmA4aHMqcx8EFwJszMuQMAVr2SfLUl7I2Fc07A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;518&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;em style=&quot;color: rgb(136, 136, 136);font-size: 12px;text-align: justify;&quot;&gt;图 5：防御通用扰动的图示。&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在第 7 章里，我们以讨论过的文献为基础的展望了未来的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第 8 章总结并画上结尾。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;论文：Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.26690712353471596&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYaALMhSj0qvpibbn3z5zlgQ0Iq7fiamMOtItuCwuPCzmDNVmibfKDtZeLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1109&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文地址：https://arxiv.org/abs/1801.00553&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度学习正占据如今飞速发展的机器学习和人工智能领域的心脏地位。在机器视觉领域中，它已经变成了从自动驾驶到监控、安保应用中的主力。然而，即便深度网络已经展示了在处理复杂问题时所取得的现象级成功，最近的研究表明它们对于输入中带有的轻微扰动是很脆弱的，从而导致错误的输出。对于图片来说，这样的扰动经常是太小了从而不能被人类感知，但是它们完全愚弄了深度学习模型。对抗攻击造成了深度学习在实践中成功的一系列威胁，进而引导了大量的研究进入这个方向。这篇文章展示了第一个对抗攻击在机器视觉领域的深度学习中的综合考察。我们回顾了对抗攻击设计的研究，分析了这些攻击的存在性以及提出的防御机制。为了强调对抗攻击在实际场所中存在，我们独立地回顾了实际场景中的对抗攻击。最终，我们引用文献来展望更广阔的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.1 对分类网络的攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; 本节列举了 12 种生成对抗样本的方法，专门针对分类网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 Box-constrained L-BFGS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Szegedy[22] 等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导神经网络做出误分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。但由于问题的复杂度太高，他们转而求解简化后的问题，即寻找最小的损失函数添加项，使得神经网络做出误分类，这就将问题转化成了凸优化过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 Fast Gradient Sign Method (FGSM)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Szegedy 等人发现可以通过对抗训练提高深度神经网络的鲁棒性，从而提升防御对抗样本攻击的能力。GoodFellow[23] 等人开发了一种能有效计算对抗扰动的方法。而求解对抗扰动的方法在原文中就被称为 FGSM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Kurakin[80] 等人提出了 FGSM 的「one-step target class」的变体。通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，再将原始图像减去该扰动，原始图像就变成了对抗样本，并能输出目标类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 Basic &amp;amp; Least-Likely-Class Iterative Methods&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;one-step 方法通过一大步运算增大分类器的损失函数而进行图像扰动，因而可以直接将其扩展为通过多个小步增大损失函数的变体，从而我们得到 Basic Iterative Methods（BIM）[35]。而该方法的变体和前述方法类似，通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，而得到 Least-Likely-Class Iterative Methods[35]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 Jacobian-based Saliency Map Attack (JSMA)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;对抗攻击文献中通常使用的方法是限制扰动的 l_∞或 l_2 范数的值以使对抗样本中的扰动无法被人察觉。但 JSMA[60] 提出了限制 l_0 范数的方法，即仅改变几个像素的值，而不是扰动整张图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 One Pixel Attack&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这是一种极端的对抗攻击方法，仅改变图像中的一个像素值就可以实现对抗攻击。Su[68] 等人使用了差分进化算法，对每个像素进行迭代地修改生成子图像，并与母图像对比，根据选择标准保留攻击效果最好的子图像，实现对抗攻击。这种对抗攻击不需要知道网络参数或梯度的任何信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 Carlini and Wagner Attacks (C&amp;amp;W)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt; Carlini 和 Wagner[36] 提出了三种对抗攻击方法，通过限制 l_∞、l_2 和 l_0 范数使得扰动无法被察觉。实验证明 defensive distillation 完全无法防御这三种攻击。该算法生成的对抗扰动可以从 unsecured 的网络迁移到 secured 的网络上，从而实现黑箱攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 DeepFool&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Moosavi-Dezfooli 等人 [72] 通过迭代计算的方法生成最小规范对抗扰动，将位于分类边界内的图像逐步推到边界外，直到出现错误分类。作者证明他们生成的扰动比 FGSM 更小，同时有相似的欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 Universal Adversarial Perturbations&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;诸如 FGSM [23]、 ILCM [35]、 DeepFool [72] 等方法只能生成单张图像的对抗扰动，而 Universal Adversarial Perturbations[16] 能生成对任何图像实现攻击的扰动，这些扰动同样对人类是几乎不可见的。该论文中使用的方法和 DeepFool 相似，都是用对抗扰动将图像推出分类边界，不过同一个扰动针对的是所有的图像。虽然文中只针对单个网络 ResNet 进行攻击，但已证明这种扰动可以泛化到其它网络上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 UPSET and ANGRI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Sarkar[146] 等人提出了两个黑箱攻击算法，UPSET 和 ANGRI。UPSET 可以为特定的目标类别生成对抗扰动，使得该扰动添加到任何图像时都可以将该图像分类成目标类别。相对于 UPSET 的「图像不可知」扰动，ANGRI 生成的是「图像特定」的扰动。它们都在 MNIST 和 CIFAR 数据集上获得了高欺骗率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 Houdini&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Houdini[131] 是一种用于欺骗基于梯度的机器学习算法的方法，通过生成特定于任务损失函数的对抗样本实现对抗攻击，即利用网络的可微损失函数的梯度信息生成对抗扰动。除了图像分类网络，该算法还可以用于欺骗语音识别网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 Adversarial Transformation Networks (ATNs)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Baluja 和 Fischer[42] 训练了多个前向神经网络来生成对抗样本，可用于攻击一个或多个网络。该算法通过最小化一个联合损失函数来生成对抗样本，该损失函数有两个部分，第一部分使对抗样本和原始图像保持相似，第二部分使对抗样本被错误分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 Miscellaneous Attacks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这一部分列举了更多其它的生成对抗样本的方法，详情请参见原文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2628992628992629&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5wMlPSo6s5icLTkrBUeicQPibmx2sCZKQhWGnyRYQLQxrFYcPFpk9Wwow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1221&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;表 1：以上列举的各种攻击方法的属性总结：「perturbation norm」表示其限制的 p-范数（p-norm）以使对抗扰动对人类不可见或难以察觉。strength 项（*越多，对抗强度越大）基于回顾过的文献得到的印象。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;3.2 分类/识别场景以外的对抗攻击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;除了 Houdini 这个例外, 在 3.1 节中概述的所有主流对抗攻击直接针对于分类任务——欺骗基于 CNN 的分类器。然而，因为对抗性威胁的严重性，对抗攻击的研究已经超越了分类/识别场景。文中概述了以下分类应用领域之外的攻击深度神经网络的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在自编码器和生成模型上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在循环神经网络上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;深度强化学习上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在语义切割和物体检测上的攻击&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;目前，在对抗攻击防御上存在三个主要方向：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1）在学习过程中修改训练过程或者修改的输入样本。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2）修改网络，比如：添加更多层/子网络、改变损失/激活函数等。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3）当分类未见过的样本时，用外部模型作为附加网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;第一个方法没有直接处理学习模型。另一方面，另外两个分类是更加关心神经网络本身的。这些方法可以被进一步细分为两种类型：（a）完全防御；（b）仅探测（detection only）。「完全防御」方法的目标是让网络将对抗样本识别为正确的类别。另一方面，「仅探测」方法意味着在对抗样本上发出报警以拒绝任何进一步的处理。详细的分类在图 9 中展示了。剩下的章节是按这个分类来整理的。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4193181818181818&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYjHuWxaE8QnJ4K6efmKwqry6vcjUlWFMCBEZk8jicQERNNRXic6ZzAHyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;880&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 12px;&quot;&gt;&lt;em&gt;图 9：防御对抗攻击的方法分类。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.1 修改训练过程/ 输入数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;1 蛮力对抗训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;通过不断输入新类型的对抗样本并执行对抗训练，从而不断提升网络的鲁棒性。为了保证有效性，该方法需要使用高强度的对抗样本，并且网络架构要有充足的表达能力。这种方法需要大量的训练数据，因而被称为蛮力对抗训练。很多文献中提到这种蛮力的对抗训练可以正则化网络以减少过拟合 [23,90]。然而，Moosavi-Dezfooli[16] 指出，无论添加多少对抗样本，都存在新的对抗攻击样本可以再次欺骗网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;2 数据压缩&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;注意到大多数训练图像都是 JPG 格式，Dziugaite[123] 等人使用 JPG 图像压缩的方法，减少对抗扰动对准确率的影响。实验证明该方法对部分对抗攻击算法有效，但通常仅采用压缩方法是远远不够的，并且压缩图像时同时也会降低正常分类的准确率，后来提出的 PCA 压缩方法也有同样的缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;3 基于中央凹机制的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Luo[119] 等人提出用中央凹（foveation）机制可以防御 L-BFGS 和 FGSM 生成的对抗扰动，其假设是图像分布对于转换变动是鲁棒的，而扰动不具备这种特性。但这种方法的普遍性尚未得到证明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;4 数据随机化方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Xie[115] 等人发现对训练图像引入随机重缩放可以减弱对抗攻击的强度，其它方法还包括随机 padding、训练过程中的图像增强等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.2 修改网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;5 深度压缩网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;人们观察到简单地将去噪自编码器（Denoising Auto Encoders）堆叠到原来的网络上只会使其变得更加脆弱，因而 Gu 和 Rigazio[24] 引入了深度压缩网络（Deep Contractive Networks），其中使用了和压缩自编码器（Contractive Auto Encoders）类似的平滑度惩罚项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;6 梯度正则化/ masking&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用输入梯度正则化以提高对抗攻击鲁棒性 [52]，该方法和蛮力对抗训练结合有很好的效果，但计算复杂度太高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;7 Defensive distillation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;distillation 是指将复杂网络的知识迁移到简单网络上，由 Hinton[166] 提出。Papernot[38] 利用这种技术提出了 Defensive distillation，并证明其可以抵抗小幅度扰动的对抗攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;8 生物启发的防御方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;使用类似与生物大脑中非线性树突计算的高度非线性激活函数以防御对抗攻击 [124]。另外一项工作 Dense Associative Memory 模型也是基于相似的机制 [127]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;9 Parseval 网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在一层中利用全局 Lipschitz 常数加控制，利用保持每一层的 Lipschitz 常数来摆脱对抗样本的干扰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;10 DeepCloak&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;在分类层（一般为输出层）前加一层特意为对抗样本训练的层。它背后的理论认为在最显著的层里包含着最敏感的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;11 混杂方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章包含了多个人从多种角度对深度学习模型的调整从而使模型可以抵抗对抗性攻击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;12 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;这章介绍了 4 种网络，SafetyNet，Detector subnetwork，Exploiting convolution filter statistics 及 Additional class augmentation。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;SafetyNet 介绍了 ReLU 对对抗样本的模式与一般图片的不一样，文中介绍了一个用 SVM 实现的工作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Detector subnetwork 介绍了用 FGSM, BIM 和 DeepFool 方法实现的对对抗样本免疫的网络的优缺点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Exploiting convolution filter statistics 介绍了同 CNN 和统计学的方法做的模型在分辨对抗样本上可以有 85% 的正确率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(0, 0, 0);&quot;&gt;6.3 使用附加网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;13 防御通用扰动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;利用一个单独训练的网络加在原来的模型上，从而达到不需要调整系数而且免疫对抗样本的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;14 基于 GAN 的防御&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;用 GAN 为基础的网络可以抵抗对抗攻击，而且作者提出在所有模型上用相同的办法来做都可以抵抗对抗样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;15 仅探测方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;介绍了 Feature Squeezing、MagNet 以及混杂的办法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;Feature Squeezing 方法用了两个模型来探查是不是对抗样本。后续的工作介绍了这个方法对 C&amp;amp;W 攻击也有能接受的抵抗力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;MagNet:作者用一个分类器对图片的流行（manifold）测量值来训练，从而分辨出图片是不是带噪声的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;混杂方法（Miscellaneous Methods）：作者训练了一个模型，把所有输入图片当成带噪声的，先学习怎么去平滑图片，之后再进行分类。&lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYL6ynj6GNuQsBPwA8HsPzMiadOrrjCHG9NNOQqnc4cN32xgUKPBNc4uw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; style=&quot;width: 41px;height: 20px;&quot;&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;以下是机器之心报道过的对抗攻击的案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650738224&amp;amp;idx=1&amp;amp;sn=dd3a9bc5b71cdc23bf92fd8816fd68f0&amp;amp;chksm=871aca4eb06d43585821885b7a769b7d2f9b07fbdabbfc4852c77355102af645fcff53c382c0&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;既能欺骗机器，也能迷惑人类！Goodfellow 等人提出新一代对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735815&amp;amp;idx=5&amp;amp;sn=dd63d33dd27ecd34e27977fcc7682116&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 几张贴纸就让神经网络看不懂道路标志，伯克利为真实环境生成对抗样本&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650735672&amp;amp;idx=5&amp;amp;sn=6cef8b232381a75ec18c4595fe0f9f35&amp;amp;chksm=871ac046b06d4950a53fab52f5fe9f1b2d2e51f88d49a7b0b0016c693164866fed8c010fcf58&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 神奇的面包机！谷歌造出对抗样本的实体版&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650734471&amp;amp;idx=4&amp;amp;sn=f57ea48caebe2edfe4582fd1f5a07437&amp;amp;chksm=871b3bf9b06cb2ef2bd63c72cfe55403425ddb525fb9b5283dcebf4c96e0972a1460226fa0f4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;学界 | 继图像识别后，图像标注系统也被对抗样本攻陷!&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650732373&amp;amp;idx=1&amp;amp;sn=5e8f0ef4357988e3a4d8374deb0919e6&amp;amp;chksm=871b332bb06cba3d2307cab4dbbf6b1f56ff65df4f63abf5f2552ba4d90a16157452b93768ce&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;修改一个像素，就能让神经网络识别图像出错&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(0, 0, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1203890811&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-05-1000000621</guid>
<pubDate>Mon, 05 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>教程 | 5种快速易用的Python Matplotlib数据可视化方法</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-03-04-1000000620_503254942.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1520345350&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=5P2G0q38u-Qh1J5h3*aPircU*Pg0IswQco0nl634SNAzRyea1ytAtHQUDhHUjl7t1Ugg7mjJOABmHngM40cYZ1sjLKRVDLCcvoSJbzha-Xo4c5b0wj806*Fnmpgk-nEA7tiDsaKIyWOyP03cJzXZP*Z6x77*Zh-DdQE4uNhR02E=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    CVPR 2018 | 残差密集网络：利用所有分层特征的图像超分辨率网络                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-03-04&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：白悦、思源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;blockquote style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;图像超分辨率在安防等很多领域有这广泛的应用，而美国东北大学最近提出了一种残差密集网络来从原图生成高分辨率图像。该网络结合残差网络与密集连接网络的特性充分利用原始 LR 图像的所有分层特征，因而能重构出高质量的图像。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;单幅图像超分辨率（SISR）旨在于低分辨率（LR）测量的基础上生成视觉良好的高分辨率（HR）图像。SISR 用于各种计算机视觉任务，如安全和监视成像 [38]、医学成像 [22] 和图像生成 [9]。图像超分辨率是一个不适定（ill-posed）逆过程，因为对于任何 LR 输入都存在多种解决方案。为了解决这个逆问题，研究者们已经提出了大量的图像 SR 算法，包括基于插值、基于重建和基于学习的方法 [27, 28, 19, 2, 20, 8, 10, 30]。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4992887624466572&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5dicvvxib2PD7Tn3picY5IrZpb5loefaJMYvq7rib2lOKUpXp2czibLhIfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;703&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 1. 之前的网络结构（a，b）和我们残差密集块（residual dense block）（c）的比较。其中（a）为 MDSR 中的残差块（residual block）[16]，（b）为 SRDenseNet 中的密集块（dense block）[30]，（c）为我们的残差密集块。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;其中，Dong 等人 [2] 首先将一个三层卷积神经网络（CNN）引入到图像 SR 中，与传统方法相比，此方法有了明显的改进。Kim 等人通过使用梯度截断（gradient clipping）、跳过连接（skip connection）或递归监督（recursive-supervision）来降低训练深度网络的难度。通过使用有效的构建模块，图像 SR 的网络变得更深，性能变得更好。Lim 等人使用残差块（图 1（a））构建了一个非常大的有残差缩放（residual scaling）[23] 的网络 EDSR [16] 和一个非常深的网络 MDSR [16]。Tai 等人提出通过记忆块构建 MemNet [25]。随着网络变深，每个卷积层中的特征将具有不同层级的感受野。然而，这些方法忽略了充分利用每个卷积层的信息。尽管提出的记忆块中的门控单元是控制短期记忆 [25] 的，但局部卷积层不能直接访问后续层，所以很难说记忆块充分利用了其内部所有层的信息。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此外，图像中的物体具有不同的大小、视角和高宽比。一个非常深的网络的分层特征将为重构提供更多的线索。然而大多基于深度学习（DL）的方法（如 VDSR [10]、LapSRN [13] 和 EDSR [16]）在重构时忽略了使用分层特征。尽管记忆块 [25] 也使用之前记忆块的信息，但没有从原始 LR 图像是提取多级特征。MemNet 将原始 LR 图像内插至所需大小形成输入。这个预处理的步骤不仅使计算的复杂度平方地增加，而且也丢失了原始 LR 图像的一些细节。Tong 等人为较低增长率（如 16）的图像 SR 引入了密集块（图 1（b））。根据我们的实验（见第 5.2 节），更高的增长率可以进一步提高网络的性能。而在图 1（b）中，很难用密集块来训练更大的网络。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了解决这些缺点，我们提出了残差密集网络（RDN）（图 2），通过残差密集块（RDB）（图 1（c））来充分利用原始 LR 图像的所有分层特征。对于一个很深的网络来说，直接提取 LR 空间中的每个卷积层的输出很难，可以说是不切实际的。我们使残差密集块（RDB）作为 RDN 的构建模块。RDB 包含密集连通层和带有局部残差学习（LRL）的局部特征融合（LFF）。我们的残差密集块还支持 RDB 间的连续记忆。一个 RDB 的输出可以直接访问下一个 RDB 各层，从而使状态连续传递。RDB 每个卷积层都可以访问所有的后续层，传递需要保留的信息 [7]。将前面的 RDB 与当前 RDB 的所有前面层的状态连接，LFF 通过自适应地保存信息来提取局部密集特征。此外，LFF 通过稳定更大网络的训练来实现极高的增长率。在提取多层局部密集特征后，我们进一步进行全局特征融合（GFF）以全局方式自适应地保留分层特征。如图 2 和图 3 所示，每层都可以直接访问原始的 LR 输入，从而产生隐式的深层监督 [15]。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;总得来说，这项工作的主要贡献有三个：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出了一个统一的框架，它通过不同的退化模型（degradation models）使用残差密集网络生成高质量的超分辨率图像，网络充分利用原始低分辨率图像的所有分层特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出了残差密集块（RDB），它不仅可以通过连续记忆（CM）机制从前一个 RDB 读取状态，还可以通过局部密集连接充分利用其中的所有层。然后通过局部特征融合（LFF）自适应地保留累积的特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;我们提出了全局特征融合以自适应地融合 LR 空间中所有 RDB 的分层特征。利用全局残差学习，我们将浅层特征和深层特征结合在一起，从原始 LR 图像中得到全局密集特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2282793867120954&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYMUSxaKic1MIcTulwQy8nfZmeGXW3BuBibhmkpJaWiaODPPliarvGRTEVdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1174&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 2. 我们提出的残差密集网络（RDN）的结构。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;如图 2 所示，我们的 RDN 主要包含四部分：浅层特征提取网络（SFENet）、残差密集块（RDBs）、密集特征融合（DFF）以及上采样网络（UPNet）。我们将 ILR 和 ISR 表示为 RDN 的输入和输出，具体来说，我们使用两个 Conv 层来提取浅层特征。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.27529761904761907&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYzMFrIloib21f1LxQCcJKPBeS6FHP9zXPiboaibsGlQrceqTSGCjmUf6IA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;672&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 3. 残差密集块（RDB）架构。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2264280798348245&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYFvcgCb4Y9XbUZyA4nkfDv3YPHHoBgDk66fr6Rs6hF0FsbgOGN77MXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1453&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;表 3. BD 和 DN 退化模型的基准结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6962552011095701&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYA6WCUeXPVP5bhunY7VMncXf8NEE4aHjibicCGafB62arcbSibibtDG7LSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;721&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 7. 使用缩放因子×3 的 BD 退化模型的可视化结果。SR 结果分别是由 Urban100 的图像得到的「img 096」和由 Urban100 得到的「img 099」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9342657342657342&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYiaPKF7NxH2yaVqBb7BXic5gbrT2WsODgIU2ZjdjHZH0YWKVXjrwQ9FFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;715&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 8. 使用缩放因子×3 的 DN 退化模型的可视化结果。SR 结果分别是由 B100 的图像得到的「302008」和 Manga109 得到的「LancelotFullThrottle」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2703081232492997&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYJhjAwicib1qfjTjXpMx5dT1ia0PjxxibYFvkYBSa5dfdLXYnRiaVEEqaMzg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;714&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;图 9. 缩放因子×4 的实际图像视觉效果。两行分别为图像「chip」和「hatc」的 SR 结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：Residual Dense Network for Image Super-Resolution&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3998447204968944&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYCXibXUsR7hOxA1DWy9DoL3AibvqmVwUdmJHNZWiaygZDZyBMhfuNZ3RUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1288&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.08797&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;一个非常深的卷积神经网络（CNN）最近在图像超分辨率（SR）方面取得了巨大的成功，并提供了分层特征。然而，大多数基于 SR 模型的深层 CNN 并没有充分利用原始低分辨率（LR）图像的分层特征，从而其性能较低。本文中，我们得出了一种新的残差密集网络（RDN）来解决图像超分辨率问题。我们充分利用所有卷积层的分层特征。具体来说，我们提出了残差密集块（RDB），通过密集卷积层来提取充分的局部特征。RDB 还允许将前一个 RDB 的状态直接连接至当前 RDB 的所有层，从而形成连续记忆（CM）机制。然后使用 RDB 中的局部特征融合来自适应地学习来自先前和当前局部特征的更有效特征，并稳定更大网络的训练。在完全获得密集的局部特征后，我们使用全局特征融合整体地联合和自适应地学习全局分层特征。在不同退化模型的基准数据上的大量实验表明，我们的 RDN 相对最先进的方法取得了良好的性能。&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650726048&amp;amp;idx=3&amp;amp;sn=bd73de47cd65a1772c2df027cabd6a5c&amp;amp;scene=21#wechat_redirect&quot; style=&quot;text-decoration: underline;font-size: 14px;text-align: justify;white-space: normal;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0JZxz5ovG7gL67yGQmoN7cKRk8EfHpuibXtdTP5lajgBIicEgEnWYzibP1BnWtKCOmZEibzX09iaSXrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; width=&quot;50px&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 50px !important;&quot;&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;340488782&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-03-04-1000000620_503254942</guid>
<pubDate>Sun, 04 Mar 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
