<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>机器之心</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/</link>
<description>专业的人工智能媒体和产业服务平台</description>
<language>zh-cn</language>
<lastBuildDate>Wed, 28 Feb 2018 22:36:24 +0800</lastBuildDate>
<item>
<title>业界 | 前微软城市计算负责人郑宇出任京东金融首席数据科学家</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-28-1000000616_503254748.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTcxZFAp2JoY-1kbsh8B0VmdaSnHKX-SU7b4ec-zzU3qxZH1S3PuR0XRFOyv96BjyGbGaqk43emLvOepQFIdu1e4=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-28&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;max-width: 100%;font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Matthew Sotoudeh等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：路雪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，英特尔的研究者提出新型深度神经网络压缩技术 DeepThin，适合移动端设备，性能优于其他压缩技术。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：DeepThin: A Self-Compressing Library for Deep Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28087167070217917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15LvOapOzFkq9vSWuJ4kRIFgz80UYn2wMMvfGnufYWSm49U2Wng3E55A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.06944&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：随着业界在移动设备上部署越来越大、越来越复杂的神经网络，这些设备的内存和计算资源所面临的压力也越来越大。深度压缩（或深度神经网络权重矩阵压缩）技术为此类场景扩展了应用资源。现有的压缩方法无法高效压缩模型，压缩 1-2% 都比较困难。我们开发了一种新的压缩技术 DeepThin，该技术基于低秩分解领域的现有研究。我们将秩分解和向近似函数添加非线性的重塑过程结合起来，从而识别和打破由低秩近似造成的人工约束。我们将 DeepThin 部署为一个与 TensorFlow 相整合的 plug-gable 库，使用户无缝压缩不同粒度的模型。我们在两个顶尖的声学模型 TFKaldi 和 ZXC DeepSpeech 上评估 DeepThin，将其与之前的压缩方法（剪枝、HashNet 和秩分解）、实证有限研究方法和手动调整模型进行了对比。在 TFKaldi 上，DeepThin 网络的词错率（WER）在几乎所有测试压缩率情况下优于其他方法，平均优于秩分解 60%，优于剪枝 57%，优于等大小的手动调整网络 23%，优于计算成本高昂的 HashNet 6%。在 DeepSpeech 上，DeepThin 压缩网络比所有其他压缩方法的测试损失都低，优于秩分解 28%，优于剪枝 27%，优于手动调整同样大小网络 20%，优于 HashNet 12%。DeepThin 还使推断速度提升了 2 倍到 14 倍，提升幅度取决于压缩率和平台缓存大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;1 引言和动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近年来，机器学习算法越来越广泛地应用于消费者产品中，如个人助手中的语音识别。这些算法依赖于大型权重矩阵将网络中的不同节点之间的关系进行编码。完美情况下，这些算法将直接在客户端设备上运行，如 Amazon Echo [20] 和 Google Home [14]。&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;不过，此类设备通常是移动、低功耗设备，因此运行此类对内存、性能和能耗有很高要求的算法并不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了解决该问题，很多开发者致力于在高性能云服务器上执行推断模型，和在客户端和服务器之间传输模型输入和输出。但是，该解决方案带来了很多问题，如高昂的运算成本、移动网络上的大量数据迁移、用户隐私担忧，以及延迟增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期研究调查了可将模型压缩至能够在客户端设备上直接高效执行的方法。此类压缩方法必须在基本不影响预测准确率、运行时性能或工程时间量的前提下降低模型空间需求。我们的研究基于低秩分解领域的现有研究，我们开发了一种新型压缩方法和 DeepThin 库，该方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;使用辅助中间矩阵和高效的重新布局操作，解决了机器学习模型参数极低秩矩阵分解的基础对称性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;整合了流行和常用的 TensorFlow 框架，使用户无缝压缩不同粒度的模型。我们在该库中实现了之前的压缩技术，以对比不同压缩方法的准确率损失。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在同样大小的网络上，比其他压缩方法的准确率更高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在我们基于 MKL [11] 的自定义 C++ TensorFlow 操作帮助下，实验证明其推断性能加速比未压缩的模型提高 2 倍到 14 倍。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3. DeepThin 压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;标准的深度神经网络包含一系列有序连接的层级（layer），输入数据依次通过各层直到获得想要的输出。每个层计算先前层输出与当前层权重矩阵之间的矩阵乘积。在计算完矩阵乘积之后，将结果加上偏置项并馈送到非线性激活函数而得到输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对有时间依赖性的数据，可使用循环神经网络。尽管有很多不同类型的 RNN，但它们都涉及一种包含若干（通常 3 或 4）类似于上述计算步骤的模型。这样的模型要比寻常的 DNN 更具参数效率，但仍旧需要特别大的权重矩阵来获得优秀的准确率，因此它们可以从压缩方法中得到巨大收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对视觉数据而言，卷积神经网络从输入数据中学习到滤波器组（权重），来提取常见特征。每层的正向传播步骤都类似于上面描述的层运算。在此论文中，我们重点放在了 RNN 和前馈 DNN。然而，把 DeepThin 压缩方法应用到 CNN 也没有任何基础限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在该研究中，我们将该压缩方法单独应用到每层的权重矩阵。具备非线性激活函数 a、权重 W、偏置项 B 的单个层可定义为：Y = a(X.W + B) (1)，其中 W 和 B 是必须存储在该网络内的可学习参数。B 的大小与 W 相比可以忽略不计，因此这里我们只考虑 W 参数的压缩（不过我们在评估中也压缩偏置项）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;DeepThin 架构可压缩任意存储大型权重矩阵（如公式 1 中的 W）的模型，不过准确率会有些微损失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.6998158379373849&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM155ia6Ftg3eHMibBYIUKQUZSSgJxYS2cyRJv53LAfFM0TULWsZGMNQ6rIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;543&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 权重矩阵的低秩分解：随着 r 变小，重构矩阵的行和列对应地实现缩放。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.339652448657188&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15HUZs34HwTWRupBpq635qlqMeABNNEWa5cmazodeEZoAT44GTycloCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 2. 打破分解创建的人工结构约束。该变换具备两个可学习参数：低秩因子 X^f 和 W^f。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;6 准确率结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19978517722878625&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15lv0k63lcOEwfJpkZo4Act0ibeCZicneVUaR3fm3pA8onmx2rzrIrAdpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;931&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 1. 与其他四种压缩方法相比，DeepThin 的平均提升。TFKaldi 数值是关于词错率下降，DeepSpeech 数值是关于测试误差减少。这里，我们看到不同的压缩方法在不同的数据集上各有偏重，而 DeepThin 在几乎所有测试情况中打败了其他压缩方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;7 性能结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5651282051282052&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15oViceFUtfiaic85pq66Fe3pUQqzjpqff3dHaIyYxSibibkteiaofIanCkic3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;975&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 2. TFKaldi 和 DeepSpeech 上，DeepThin 模型在不同压缩大小和机器情况中的执行速度对比。不同机器之间的压缩大小略有不同，但是准确程度在 0.0001 以内。所有结果都以比未压缩的基线模型速度「X faster」的形式呈现。我们发现最大的提升来自缓存较小的平台，使用 DeepThin 可持续降低所有测试配置中的执行时间，使之更适合延迟和电量使用比较重要的环境。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1435818873&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-28-1000000616_503254748</guid>
<pubDate>Wed, 28 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>资源 | 微软开源MMdnn：实现多个框架之间的模型转换</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-28-1000000616_503254734.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTcxZFAp2JoY-1kbsh8B0VmcnsYQ7Rk1v-LzZIPiuZlSFGctM1jwz4MRQlPgIrx7B-Lqg6smdxCQm1p8G5tzpa6Y=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-28&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;max-width: 100%;font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Matthew Sotoudeh等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：路雪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，英特尔的研究者提出新型深度神经网络压缩技术 DeepThin，适合移动端设备，性能优于其他压缩技术。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：DeepThin: A Self-Compressing Library for Deep Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28087167070217917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15LvOapOzFkq9vSWuJ4kRIFgz80UYn2wMMvfGnufYWSm49U2Wng3E55A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.06944&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：随着业界在移动设备上部署越来越大、越来越复杂的神经网络，这些设备的内存和计算资源所面临的压力也越来越大。深度压缩（或深度神经网络权重矩阵压缩）技术为此类场景扩展了应用资源。现有的压缩方法无法高效压缩模型，压缩 1-2% 都比较困难。我们开发了一种新的压缩技术 DeepThin，该技术基于低秩分解领域的现有研究。我们将秩分解和向近似函数添加非线性的重塑过程结合起来，从而识别和打破由低秩近似造成的人工约束。我们将 DeepThin 部署为一个与 TensorFlow 相整合的 plug-gable 库，使用户无缝压缩不同粒度的模型。我们在两个顶尖的声学模型 TFKaldi 和 ZXC DeepSpeech 上评估 DeepThin，将其与之前的压缩方法（剪枝、HashNet 和秩分解）、实证有限研究方法和手动调整模型进行了对比。在 TFKaldi 上，DeepThin 网络的词错率（WER）在几乎所有测试压缩率情况下优于其他方法，平均优于秩分解 60%，优于剪枝 57%，优于等大小的手动调整网络 23%，优于计算成本高昂的 HashNet 6%。在 DeepSpeech 上，DeepThin 压缩网络比所有其他压缩方法的测试损失都低，优于秩分解 28%，优于剪枝 27%，优于手动调整同样大小网络 20%，优于 HashNet 12%。DeepThin 还使推断速度提升了 2 倍到 14 倍，提升幅度取决于压缩率和平台缓存大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;1 引言和动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近年来，机器学习算法越来越广泛地应用于消费者产品中，如个人助手中的语音识别。这些算法依赖于大型权重矩阵将网络中的不同节点之间的关系进行编码。完美情况下，这些算法将直接在客户端设备上运行，如 Amazon Echo [20] 和 Google Home [14]。&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;不过，此类设备通常是移动、低功耗设备，因此运行此类对内存、性能和能耗有很高要求的算法并不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了解决该问题，很多开发者致力于在高性能云服务器上执行推断模型，和在客户端和服务器之间传输模型输入和输出。但是，该解决方案带来了很多问题，如高昂的运算成本、移动网络上的大量数据迁移、用户隐私担忧，以及延迟增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期研究调查了可将模型压缩至能够在客户端设备上直接高效执行的方法。此类压缩方法必须在基本不影响预测准确率、运行时性能或工程时间量的前提下降低模型空间需求。我们的研究基于低秩分解领域的现有研究，我们开发了一种新型压缩方法和 DeepThin 库，该方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;使用辅助中间矩阵和高效的重新布局操作，解决了机器学习模型参数极低秩矩阵分解的基础对称性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;整合了流行和常用的 TensorFlow 框架，使用户无缝压缩不同粒度的模型。我们在该库中实现了之前的压缩技术，以对比不同压缩方法的准确率损失。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在同样大小的网络上，比其他压缩方法的准确率更高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在我们基于 MKL [11] 的自定义 C++ TensorFlow 操作帮助下，实验证明其推断性能加速比未压缩的模型提高 2 倍到 14 倍。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3. DeepThin 压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;标准的深度神经网络包含一系列有序连接的层级（layer），输入数据依次通过各层直到获得想要的输出。每个层计算先前层输出与当前层权重矩阵之间的矩阵乘积。在计算完矩阵乘积之后，将结果加上偏置项并馈送到非线性激活函数而得到输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对有时间依赖性的数据，可使用循环神经网络。尽管有很多不同类型的 RNN，但它们都涉及一种包含若干（通常 3 或 4）类似于上述计算步骤的模型。这样的模型要比寻常的 DNN 更具参数效率，但仍旧需要特别大的权重矩阵来获得优秀的准确率，因此它们可以从压缩方法中得到巨大收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对视觉数据而言，卷积神经网络从输入数据中学习到滤波器组（权重），来提取常见特征。每层的正向传播步骤都类似于上面描述的层运算。在此论文中，我们重点放在了 RNN 和前馈 DNN。然而，把 DeepThin 压缩方法应用到 CNN 也没有任何基础限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在该研究中，我们将该压缩方法单独应用到每层的权重矩阵。具备非线性激活函数 a、权重 W、偏置项 B 的单个层可定义为：Y = a(X.W + B) (1)，其中 W 和 B 是必须存储在该网络内的可学习参数。B 的大小与 W 相比可以忽略不计，因此这里我们只考虑 W 参数的压缩（不过我们在评估中也压缩偏置项）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;DeepThin 架构可压缩任意存储大型权重矩阵（如公式 1 中的 W）的模型，不过准确率会有些微损失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.6998158379373849&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM155ia6Ftg3eHMibBYIUKQUZSSgJxYS2cyRJv53LAfFM0TULWsZGMNQ6rIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;543&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 权重矩阵的低秩分解：随着 r 变小，重构矩阵的行和列对应地实现缩放。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.339652448657188&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15HUZs34HwTWRupBpq635qlqMeABNNEWa5cmazodeEZoAT44GTycloCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 2. 打破分解创建的人工结构约束。该变换具备两个可学习参数：低秩因子 X^f 和 W^f。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;6 准确率结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19978517722878625&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15lv0k63lcOEwfJpkZo4Act0ibeCZicneVUaR3fm3pA8onmx2rzrIrAdpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;931&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 1. 与其他四种压缩方法相比，DeepThin 的平均提升。TFKaldi 数值是关于词错率下降，DeepSpeech 数值是关于测试误差减少。这里，我们看到不同的压缩方法在不同的数据集上各有偏重，而 DeepThin 在几乎所有测试情况中打败了其他压缩方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;7 性能结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5651282051282052&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15oViceFUtfiaic85pq66Fe3pUQqzjpqff3dHaIyYxSibibkteiaofIanCkic3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;975&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 2. TFKaldi 和 DeepSpeech 上，DeepThin 模型在不同压缩大小和机器情况中的执行速度对比。不同机器之间的压缩大小略有不同，但是准确程度在 0.0001 以内。所有结果都以比未压缩的基线模型速度「X faster」的形式呈现。我们发现最大的提升来自缓存较小的平台，使用 DeepThin 可持续降低所有测试配置中的执行时间，使之更适合延迟和电量使用比较重要的环境。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;268374764&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-28-1000000616_503254734</guid>
<pubDate>Wed, 28 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>前沿 | 受AlphaGo启发，AI重建量子系统新方法登上Nature Physics</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-28-1000000616_503254720.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTcxZFAp2JoY-1kbsh8B0VmfOrHDKvQTCiRTPrbpRRHZdIN3*kYhdZxpiwpkDycz0fcHL6-m79IJ9LJO0KbQHGPU=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-28&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;max-width: 100%;font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Matthew Sotoudeh等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：路雪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，英特尔的研究者提出新型深度神经网络压缩技术 DeepThin，适合移动端设备，性能优于其他压缩技术。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：DeepThin: A Self-Compressing Library for Deep Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28087167070217917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15LvOapOzFkq9vSWuJ4kRIFgz80UYn2wMMvfGnufYWSm49U2Wng3E55A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.06944&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：随着业界在移动设备上部署越来越大、越来越复杂的神经网络，这些设备的内存和计算资源所面临的压力也越来越大。深度压缩（或深度神经网络权重矩阵压缩）技术为此类场景扩展了应用资源。现有的压缩方法无法高效压缩模型，压缩 1-2% 都比较困难。我们开发了一种新的压缩技术 DeepThin，该技术基于低秩分解领域的现有研究。我们将秩分解和向近似函数添加非线性的重塑过程结合起来，从而识别和打破由低秩近似造成的人工约束。我们将 DeepThin 部署为一个与 TensorFlow 相整合的 plug-gable 库，使用户无缝压缩不同粒度的模型。我们在两个顶尖的声学模型 TFKaldi 和 ZXC DeepSpeech 上评估 DeepThin，将其与之前的压缩方法（剪枝、HashNet 和秩分解）、实证有限研究方法和手动调整模型进行了对比。在 TFKaldi 上，DeepThin 网络的词错率（WER）在几乎所有测试压缩率情况下优于其他方法，平均优于秩分解 60%，优于剪枝 57%，优于等大小的手动调整网络 23%，优于计算成本高昂的 HashNet 6%。在 DeepSpeech 上，DeepThin 压缩网络比所有其他压缩方法的测试损失都低，优于秩分解 28%，优于剪枝 27%，优于手动调整同样大小网络 20%，优于 HashNet 12%。DeepThin 还使推断速度提升了 2 倍到 14 倍，提升幅度取决于压缩率和平台缓存大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;1 引言和动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近年来，机器学习算法越来越广泛地应用于消费者产品中，如个人助手中的语音识别。这些算法依赖于大型权重矩阵将网络中的不同节点之间的关系进行编码。完美情况下，这些算法将直接在客户端设备上运行，如 Amazon Echo [20] 和 Google Home [14]。&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;不过，此类设备通常是移动、低功耗设备，因此运行此类对内存、性能和能耗有很高要求的算法并不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了解决该问题，很多开发者致力于在高性能云服务器上执行推断模型，和在客户端和服务器之间传输模型输入和输出。但是，该解决方案带来了很多问题，如高昂的运算成本、移动网络上的大量数据迁移、用户隐私担忧，以及延迟增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期研究调查了可将模型压缩至能够在客户端设备上直接高效执行的方法。此类压缩方法必须在基本不影响预测准确率、运行时性能或工程时间量的前提下降低模型空间需求。我们的研究基于低秩分解领域的现有研究，我们开发了一种新型压缩方法和 DeepThin 库，该方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;使用辅助中间矩阵和高效的重新布局操作，解决了机器学习模型参数极低秩矩阵分解的基础对称性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;整合了流行和常用的 TensorFlow 框架，使用户无缝压缩不同粒度的模型。我们在该库中实现了之前的压缩技术，以对比不同压缩方法的准确率损失。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在同样大小的网络上，比其他压缩方法的准确率更高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在我们基于 MKL [11] 的自定义 C++ TensorFlow 操作帮助下，实验证明其推断性能加速比未压缩的模型提高 2 倍到 14 倍。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3. DeepThin 压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;标准的深度神经网络包含一系列有序连接的层级（layer），输入数据依次通过各层直到获得想要的输出。每个层计算先前层输出与当前层权重矩阵之间的矩阵乘积。在计算完矩阵乘积之后，将结果加上偏置项并馈送到非线性激活函数而得到输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对有时间依赖性的数据，可使用循环神经网络。尽管有很多不同类型的 RNN，但它们都涉及一种包含若干（通常 3 或 4）类似于上述计算步骤的模型。这样的模型要比寻常的 DNN 更具参数效率，但仍旧需要特别大的权重矩阵来获得优秀的准确率，因此它们可以从压缩方法中得到巨大收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对视觉数据而言，卷积神经网络从输入数据中学习到滤波器组（权重），来提取常见特征。每层的正向传播步骤都类似于上面描述的层运算。在此论文中，我们重点放在了 RNN 和前馈 DNN。然而，把 DeepThin 压缩方法应用到 CNN 也没有任何基础限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在该研究中，我们将该压缩方法单独应用到每层的权重矩阵。具备非线性激活函数 a、权重 W、偏置项 B 的单个层可定义为：Y = a(X.W + B) (1)，其中 W 和 B 是必须存储在该网络内的可学习参数。B 的大小与 W 相比可以忽略不计，因此这里我们只考虑 W 参数的压缩（不过我们在评估中也压缩偏置项）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;DeepThin 架构可压缩任意存储大型权重矩阵（如公式 1 中的 W）的模型，不过准确率会有些微损失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.6998158379373849&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM155ia6Ftg3eHMibBYIUKQUZSSgJxYS2cyRJv53LAfFM0TULWsZGMNQ6rIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;543&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 权重矩阵的低秩分解：随着 r 变小，重构矩阵的行和列对应地实现缩放。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.339652448657188&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15HUZs34HwTWRupBpq635qlqMeABNNEWa5cmazodeEZoAT44GTycloCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 2. 打破分解创建的人工结构约束。该变换具备两个可学习参数：低秩因子 X^f 和 W^f。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;6 准确率结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19978517722878625&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15lv0k63lcOEwfJpkZo4Act0ibeCZicneVUaR3fm3pA8onmx2rzrIrAdpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;931&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 1. 与其他四种压缩方法相比，DeepThin 的平均提升。TFKaldi 数值是关于词错率下降，DeepSpeech 数值是关于测试误差减少。这里，我们看到不同的压缩方法在不同的数据集上各有偏重，而 DeepThin 在几乎所有测试情况中打败了其他压缩方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;7 性能结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5651282051282052&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15oViceFUtfiaic85pq66Fe3pUQqzjpqff3dHaIyYxSibibkteiaofIanCkic3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;975&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 2. TFKaldi 和 DeepSpeech 上，DeepThin 模型在不同压缩大小和机器情况中的执行速度对比。不同机器之间的压缩大小略有不同，但是准确程度在 0.0001 以内。所有结果都以比未压缩的基线模型速度「X faster」的形式呈现。我们发现最大的提升来自缓存较小的平台，使用 DeepThin 可持续降低所有测试配置中的执行时间，使之更适合延迟和电量使用比较重要的环境。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;31498965&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-28-1000000616_503254720</guid>
<pubDate>Wed, 28 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-28-1000000616_503254714.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTcxZFAp2JoY-1kbsh8B0Vmf9*XXJjU3RVbs3Ln9C*n0WbNsVN4jAvct9ku4LDRvnlXavvZc4KEoxilAaIWMEOoA=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-28&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;max-width: 100%;font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Matthew Sotoudeh等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：路雪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，英特尔的研究者提出新型深度神经网络压缩技术 DeepThin，适合移动端设备，性能优于其他压缩技术。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：DeepThin: A Self-Compressing Library for Deep Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28087167070217917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15LvOapOzFkq9vSWuJ4kRIFgz80UYn2wMMvfGnufYWSm49U2Wng3E55A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.06944&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：随着业界在移动设备上部署越来越大、越来越复杂的神经网络，这些设备的内存和计算资源所面临的压力也越来越大。深度压缩（或深度神经网络权重矩阵压缩）技术为此类场景扩展了应用资源。现有的压缩方法无法高效压缩模型，压缩 1-2% 都比较困难。我们开发了一种新的压缩技术 DeepThin，该技术基于低秩分解领域的现有研究。我们将秩分解和向近似函数添加非线性的重塑过程结合起来，从而识别和打破由低秩近似造成的人工约束。我们将 DeepThin 部署为一个与 TensorFlow 相整合的 plug-gable 库，使用户无缝压缩不同粒度的模型。我们在两个顶尖的声学模型 TFKaldi 和 ZXC DeepSpeech 上评估 DeepThin，将其与之前的压缩方法（剪枝、HashNet 和秩分解）、实证有限研究方法和手动调整模型进行了对比。在 TFKaldi 上，DeepThin 网络的词错率（WER）在几乎所有测试压缩率情况下优于其他方法，平均优于秩分解 60%，优于剪枝 57%，优于等大小的手动调整网络 23%，优于计算成本高昂的 HashNet 6%。在 DeepSpeech 上，DeepThin 压缩网络比所有其他压缩方法的测试损失都低，优于秩分解 28%，优于剪枝 27%，优于手动调整同样大小网络 20%，优于 HashNet 12%。DeepThin 还使推断速度提升了 2 倍到 14 倍，提升幅度取决于压缩率和平台缓存大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;1 引言和动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近年来，机器学习算法越来越广泛地应用于消费者产品中，如个人助手中的语音识别。这些算法依赖于大型权重矩阵将网络中的不同节点之间的关系进行编码。完美情况下，这些算法将直接在客户端设备上运行，如 Amazon Echo [20] 和 Google Home [14]。&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;不过，此类设备通常是移动、低功耗设备，因此运行此类对内存、性能和能耗有很高要求的算法并不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了解决该问题，很多开发者致力于在高性能云服务器上执行推断模型，和在客户端和服务器之间传输模型输入和输出。但是，该解决方案带来了很多问题，如高昂的运算成本、移动网络上的大量数据迁移、用户隐私担忧，以及延迟增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期研究调查了可将模型压缩至能够在客户端设备上直接高效执行的方法。此类压缩方法必须在基本不影响预测准确率、运行时性能或工程时间量的前提下降低模型空间需求。我们的研究基于低秩分解领域的现有研究，我们开发了一种新型压缩方法和 DeepThin 库，该方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;使用辅助中间矩阵和高效的重新布局操作，解决了机器学习模型参数极低秩矩阵分解的基础对称性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;整合了流行和常用的 TensorFlow 框架，使用户无缝压缩不同粒度的模型。我们在该库中实现了之前的压缩技术，以对比不同压缩方法的准确率损失。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在同样大小的网络上，比其他压缩方法的准确率更高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在我们基于 MKL [11] 的自定义 C++ TensorFlow 操作帮助下，实验证明其推断性能加速比未压缩的模型提高 2 倍到 14 倍。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3. DeepThin 压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;标准的深度神经网络包含一系列有序连接的层级（layer），输入数据依次通过各层直到获得想要的输出。每个层计算先前层输出与当前层权重矩阵之间的矩阵乘积。在计算完矩阵乘积之后，将结果加上偏置项并馈送到非线性激活函数而得到输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对有时间依赖性的数据，可使用循环神经网络。尽管有很多不同类型的 RNN，但它们都涉及一种包含若干（通常 3 或 4）类似于上述计算步骤的模型。这样的模型要比寻常的 DNN 更具参数效率，但仍旧需要特别大的权重矩阵来获得优秀的准确率，因此它们可以从压缩方法中得到巨大收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对视觉数据而言，卷积神经网络从输入数据中学习到滤波器组（权重），来提取常见特征。每层的正向传播步骤都类似于上面描述的层运算。在此论文中，我们重点放在了 RNN 和前馈 DNN。然而，把 DeepThin 压缩方法应用到 CNN 也没有任何基础限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在该研究中，我们将该压缩方法单独应用到每层的权重矩阵。具备非线性激活函数 a、权重 W、偏置项 B 的单个层可定义为：Y = a(X.W + B) (1)，其中 W 和 B 是必须存储在该网络内的可学习参数。B 的大小与 W 相比可以忽略不计，因此这里我们只考虑 W 参数的压缩（不过我们在评估中也压缩偏置项）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;DeepThin 架构可压缩任意存储大型权重矩阵（如公式 1 中的 W）的模型，不过准确率会有些微损失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.6998158379373849&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM155ia6Ftg3eHMibBYIUKQUZSSgJxYS2cyRJv53LAfFM0TULWsZGMNQ6rIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;543&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 权重矩阵的低秩分解：随着 r 变小，重构矩阵的行和列对应地实现缩放。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.339652448657188&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15HUZs34HwTWRupBpq635qlqMeABNNEWa5cmazodeEZoAT44GTycloCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 2. 打破分解创建的人工结构约束。该变换具备两个可学习参数：低秩因子 X^f 和 W^f。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;6 准确率结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19978517722878625&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15lv0k63lcOEwfJpkZo4Act0ibeCZicneVUaR3fm3pA8onmx2rzrIrAdpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;931&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 1. 与其他四种压缩方法相比，DeepThin 的平均提升。TFKaldi 数值是关于词错率下降，DeepSpeech 数值是关于测试误差减少。这里，我们看到不同的压缩方法在不同的数据集上各有偏重，而 DeepThin 在几乎所有测试情况中打败了其他压缩方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;7 性能结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5651282051282052&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15oViceFUtfiaic85pq66Fe3pUQqzjpqff3dHaIyYxSibibkteiaofIanCkic3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;975&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 2. TFKaldi 和 DeepSpeech 上，DeepThin 模型在不同压缩大小和机器情况中的执行速度对比。不同机器之间的压缩大小略有不同，但是准确程度在 0.0001 以内。所有结果都以比未压缩的基线模型速度「X faster」的形式呈现。我们发现最大的提升来自缓存较小的平台，使用 DeepThin 可持续降低所有测试配置中的执行时间，使之更适合延迟和电量使用比较重要的环境。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1071178859&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-28-1000000616_503254714</guid>
<pubDate>Wed, 28 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>机器学习+区块链：算法商店Algorithmia推出DanKu，用以太坊合约交易ML模型</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-28-1000000616.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTcxZFAp2JoY-1kbsh8B0VmfxClCIv6jGdC0jlF1JUBmKalzAPI**2OQWJ4BxAV7kePsB36lbgceHHuFS6ntSZJ8=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-28&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;选自&lt;span style=&quot;max-width: 100%;font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;作者：&lt;span style=&quot;max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;Matthew Sotoudeh等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;参与：路雪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(136, 136, 136);&quot;&gt;近日，英特尔的研究者提出新型深度神经网络压缩技术 DeepThin，适合移动端设备，性能优于其他压缩技术。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;论文：DeepThin: A Self-Compressing Library for Deep Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28087167070217917&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15LvOapOzFkq9vSWuJ4kRIFgz80UYn2wMMvfGnufYWSm49U2Wng3E55A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;论文链接：https://arxiv.org/abs/1802.06944&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;摘要：随着业界在移动设备上部署越来越大、越来越复杂的神经网络，这些设备的内存和计算资源所面临的压力也越来越大。深度压缩（或深度神经网络权重矩阵压缩）技术为此类场景扩展了应用资源。现有的压缩方法无法高效压缩模型，压缩 1-2% 都比较困难。我们开发了一种新的压缩技术 DeepThin，该技术基于低秩分解领域的现有研究。我们将秩分解和向近似函数添加非线性的重塑过程结合起来，从而识别和打破由低秩近似造成的人工约束。我们将 DeepThin 部署为一个与 TensorFlow 相整合的 plug-gable 库，使用户无缝压缩不同粒度的模型。我们在两个顶尖的声学模型 TFKaldi 和 ZXC DeepSpeech 上评估 DeepThin，将其与之前的压缩方法（剪枝、HashNet 和秩分解）、实证有限研究方法和手动调整模型进行了对比。在 TFKaldi 上，DeepThin 网络的词错率（WER）在几乎所有测试压缩率情况下优于其他方法，平均优于秩分解 60%，优于剪枝 57%，优于等大小的手动调整网络 23%，优于计算成本高昂的 HashNet 6%。在 DeepSpeech 上，DeepThin 压缩网络比所有其他压缩方法的测试损失都低，优于秩分解 28%，优于剪枝 27%，优于手动调整同样大小网络 20%，优于 HashNet 12%。DeepThin 还使推断速度提升了 2 倍到 14 倍，提升幅度取决于压缩率和平台缓存大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;1 引言和动机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近年来，机器学习算法越来越广泛地应用于消费者产品中，如个人助手中的语音识别。这些算法依赖于大型权重矩阵将网络中的不同节点之间的关系进行编码。完美情况下，这些算法将直接在客户端设备上运行，如 Amazon Echo [20] 和 Google Home [14]。&lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;不过，此类设备通常是移动、低功耗设备，因此运行此类对内存、性能和能耗有很高要求的算法并不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;为了解决该问题，很多开发者致力于在高性能云服务器上执行推断模型，和在客户端和服务器之间传输模型输入和输出。但是，该解决方案带来了很多问题，如高昂的运算成本、移动网络上的大量数据迁移、用户隐私担忧，以及延迟增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;近期研究调查了可将模型压缩至能够在客户端设备上直接高效执行的方法。此类压缩方法必须在基本不影响预测准确率、运行时性能或工程时间量的前提下降低模型空间需求。我们的研究基于低秩分解领域的现有研究，我们开发了一种新型压缩方法和 DeepThin 库，该方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ol class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: decimal;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;使用辅助中间矩阵和高效的重新布局操作，解决了机器学习模型参数极低秩矩阵分解的基础对称性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;整合了流行和常用的 TensorFlow 框架，使用户无缝压缩不同粒度的模型。我们在该库中实现了之前的压缩技术，以对比不同压缩方法的准确率损失。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在同样大小的网络上，比其他压缩方法的准确率更高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在我们基于 MKL [11] 的自定义 C++ TensorFlow 操作帮助下，实验证明其推断性能加速比未压缩的模型提高 2 倍到 14 倍。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;3. DeepThin 压缩模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;标准的深度神经网络包含一系列有序连接的层级（layer），输入数据依次通过各层直到获得想要的输出。每个层计算先前层输出与当前层权重矩阵之间的矩阵乘积。在计算完矩阵乘积之后，将结果加上偏置项并馈送到非线性激活函数而得到输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对有时间依赖性的数据，可使用循环神经网络。尽管有很多不同类型的 RNN，但它们都涉及一种包含若干（通常 3 或 4）类似于上述计算步骤的模型。这样的模型要比寻常的 DNN 更具参数效率，但仍旧需要特别大的权重矩阵来获得优秀的准确率，因此它们可以从压缩方法中得到巨大收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;对视觉数据而言，卷积神经网络从输入数据中学习到滤波器组（权重），来提取常见特征。每层的正向传播步骤都类似于上面描述的层运算。在此论文中，我们重点放在了 RNN 和前馈 DNN。然而，把 DeepThin 压缩方法应用到 CNN 也没有任何基础限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在该研究中，我们将该压缩方法单独应用到每层的权重矩阵。具备非线性激活函数 a、权重 W、偏置项 B 的单个层可定义为：Y = a(X.W + B) (1)，其中 W 和 B 是必须存储在该网络内的可学习参数。B 的大小与 W 相比可以忽略不计，因此这里我们只考虑 W 参数的压缩（不过我们在评估中也压缩偏置项）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;DeepThin 架构可压缩任意存储大型权重矩阵（如公式 1 中的 W）的模型，不过准确率会有些微损失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.6998158379373849&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM155ia6Ftg3eHMibBYIUKQUZSSgJxYS2cyRJv53LAfFM0TULWsZGMNQ6rIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;543&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;图 1. 权重矩阵的低秩分解：随着 r 变小，重构矩阵的行和列对应地实现缩放。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.339652448657188&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15HUZs34HwTWRupBpq635qlqMeABNNEWa5cmazodeEZoAT44GTycloCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图 2. 打破分解创建的人工结构约束。该变换具备两个可学习参数：低秩因子 X^f 和 W^f。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;6 准确率结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19978517722878625&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15lv0k63lcOEwfJpkZo4Act0ibeCZicneVUaR3fm3pA8onmx2rzrIrAdpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;931&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 1. 与其他四种压缩方法相比，DeepThin 的平均提升。TFKaldi 数值是关于词错率下降，DeepSpeech 数值是关于测试误差减少。这里，我们看到不同的压缩方法在不同的数据集上各有偏重，而 DeepThin 在几乎所有测试情况中打败了其他压缩方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: center;&quot;&gt;&lt;strong&gt;7 性能结果&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5651282051282052&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15oViceFUtfiaic85pq66Fe3pUQqzjpqff3dHaIyYxSibibkteiaofIanCkic3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;975&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;表 2. TFKaldi 和 DeepSpeech 上，DeepThin 模型在不同压缩大小和机器情况中的执行速度对比。不同机器之间的压缩大小略有不同，但是准确程度在 0.0001 以内。所有结果都以比未压缩的基线模型速度「X faster」的形式呈现。我们发现最大的提升来自缓存较小的平台，使用 DeepThin 可持续降低所有测试配置中的执行时间，使之更适合延迟和电量使用比较重要的环境。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心编译，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;889077257&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-28-1000000616</guid>
<pubDate>Wed, 28 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>业界 | OpenAI发布8个仿真机器人环境和HER实现：可用于训练实体机器人模型</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-27-1000000615_503254704.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTWVTPx9AotzGB9gWtTo1T4j9eAJcFGG5pD*7fAw9JcRiEqqJzKLOc0hOJymKrAqrfeGv4OOmt3m36JFzcs4c9HI=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | CVPR 2018接收论文公布，上海交通大学6篇论文简介                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-27&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;color: rgb(62, 62, 62);max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;&quot;&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;作者：吴欣&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;blockquote style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;不久之前，CVPR 2018 论文接收列表公布。据机器之心了解，上海交通大学电子系人工智能实验室倪冰冰教授课题组有 6 篇论文入选，本文对这几篇论文做了简介，更多详细内容可通过论文网盘链接下载查看。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;CVPR 2018 论文接收列表：http://cvpr2018.thecvf.com/files/cvpr_2018_final_accept_list.txt&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 1：《Fine-grained Video Captioning for Sports Narrative》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;细粒度视频描述——体育视频自动解说&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1miUzoCC&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;视频描述方向的研究在近段时间取得了较大的进展，但是一直都停留在粗略的视频内容讲述上，没有做到对于人物交互关系和动作细节的细致描述，而这些恰恰都是体育视频中非常重要的部分。在这篇 CVPR 工作中，作者提出了一个全新的细粒度视频描述课题，做出了一个对应的体育视频细粒度描述数据集，并用一个完善的视频描述网络解决了该问题，实现了国际首次人工智能体育视频自动解说。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8360655737704918&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15Np6v2Rz9MibNb9yrjm0hncOoKPuOtPo8boxxLToWxuUI8LxrmVF5soA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;体育视频自动解说效果展示。所有球员的角色、关系和位置，及球的位置都实现了准确的理解识别。相比较传统的「一群人在打篮球」的粗略描述，这篇文章实现的描述更加细致、准确，可以全面真实地反映运动场上的实际情况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在文章中，作者通过一个时域-空域定位子网络来进行动作片段的分割和球员角色的定位；通过一个引入骨骼信息的细粒度动作识别子网络来精确地识别球员在高速运动中做出的细小动作；再通过一个群体交互子网络来构建球员间的交互关系。通过以上三个子网络捕获充足全面的视频特征，从而输出准确的细粒度视频描述语句。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此外，文章中提出的细粒度体育视频自动解说数据集（FSN dataset）也将会在不久后公开供科研使用，以促进细粒度视频描述领域的技术发展。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 2：《Structure Preserving Video Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;面向保持结构一致性的视频预测模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1kWUb4c3&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;像素级的视频生成一直是计算机视觉领域的热点问题。过去的方法一直试图解决所预测的视频中存在的运动模糊问题。这个问题一方面由随时间增加所带来的累计误差引起，另一方面由于像素级的视频生成的解空间非常巨大。这里将像素级的视频生成一直存在的两个问题总结如下：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;静态结构预测损失 这个问题来源于预测具有固定结构的场景，城市景观中的交通标志、树木等任务。这些静态结构的运动常常是由相机运动引起的。现有方法的预测结构大多不能保持原始对象结构，例如物体的边缘结构信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;动态结构预测损失 虽然最近的一些工作可以预测一般粗粒度运动。但是一般不能精确预测精细的局部运动，如人体关节运动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3707440100882724&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15094v02K29lKWib0osL9NPbXGf6I7F4nZazNsq1Sf14Pv0PxrTVyaf8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;论文提出的视频预测模型图示。该架构使用论文提出的多频带分析和时变卷积核技术，能够更大限度的利用输入信息和更灵活的应对视频内容的动态变化，使得更精确地预测像素级的视频内容成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在这篇文章中，作者提出基于多频带分析和时变卷积核的视频预测模型来解决上述两个问题。一方面作者将输入视频分解为多个频率分量分别进行处理，以求从原始视频中获取尽可能多的物体静态结构信息，称之为多频带分析；另一方面作者利用输入视频帧来生成最终预测模型中的卷积核，以求能够更灵活的应对动态结构预测任务，称之为时变卷集核。两个方法分别较好地解决了上述两个问题，显著提高了视频预测精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 3：《Multiple Granularity Group Interaction Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于多粒度的群体交互预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6HovGh&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.40226986128625475&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15d5ibarujPxEibjMtkZx6YMzdBg8HYtOPNfmRc1sOTVGnibVOHOSxzAMcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;多粒度群体交互预测框架。首先我们把骨架序列处理成两个不同粒度的信息，分别代表整体轨迹运动和肢体细节运动。基于 seq2seq 预测结构，我们设计了同粒度间信息交互子网络来考虑群体之间的相互影响，以及不同粒度间的信息交互子网络来促进两个粒度上信息的交互，更准确地预测结果。最后整合预测出的两个粒度信息，展示群体交互预测结果。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;当前大多数人体活动分析（识别或预测）的工作仅关注于单个粒度，例如在粗粒度层次对整体运动进行建模（轨迹预测）；或者在细粒度层次对肢体细节运动进行建模（骨骼动作预测）。相反，在这项工作中，作者提出了多粒度群体交互预测网络，能够同时考虑两个粒度上的信息（整体轨迹和细节动作）。首先对于每个人的骨架运动序列，作者把它处理成能够分别代表轨迹运动和肢体运动的两个粒度上的运动序列。对于每个粒度上的信息，基于 seq2seq 网络结构，作者设计了同粒度间的交互网络，在预测每个人这个粒度上的运动信息时能够考虑其他人的运动信息。同时，基于双向 LSTM，作者设计了不同粒度间的信息交互网络，来促进每个人的不同粒度上信息的交互，更准确地预测未来轨迹和细节动作。最后作者把两个粒度上的信息整合在一起，多景观式地展示预测的群体交互。此方法在 SBU 和 Choi&#39;s New Dataset 数据集上都取得了目前最佳效果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 4：《pose transferrable person re-identification》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;姿态可迁移行人再识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1nwFetDZ&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;行人再识别旨在解决跨时空匹配行人的问题，其在智能安防领域有极大的应用价值。由于行人姿态、外观、光照、遮挡等因素的影响，行人再识别仍然是一项极具挑战性的任务。为了解决行人姿态变化丰富导致模型难以在有限训练集下获得良好性能的问题，作者在这篇 CVPR 的工作中提出了一个姿态可迁移的行人再识别模型。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6305170239596469&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM154vibjHx2H3cfuQVkkg2097fOkgf1AF28Cic33JvhVicSmmKgt2e3V8VPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;姿态可迁移行人再识别框架。首先训练姿态迁移模块，其中我们引入了「向导」子模块来提升生成器的性能。然后使用训练好的生成器实现行人姿态由源数据集到目标数据集的迁移，进而提升行人再识别在目标数据集上的性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;假设给定大小两个数据集，分别称为 A 和 B。其中数据集 A 中覆盖的行人姿态少，而 B 中的样本包含丰富的姿态。作者提出将数据集 A 中的图片样本与数据集 B 中样本的骨架进行配对，并通过 Skeleton-to-Image 模型生成与 A 中样本共享身份信息且与 B 中样本共享姿态的新样本集 C。为了提高生成样本的质量，作者提出了一个与对抗生成网络中的判别器平行的向导模块。向导模块是一个预训练好的行人再识别模型，用于指导生成器生成包含更丰富身份信息、更适应行人再识别任务的样本。在得到了生成样本集 C 后，作者将其与数据集 A 混合并通过平滑机制分配样本权重后训练模型。实验结果表明此方法能够与其他高性能方法 (包括特征学习、度量学习类方法) 结合并进一步提升它们的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 5：《Crowd Counting via Adversarial Cross-Scale Consistency Pursuit》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于对抗跨尺度一致性追求的人群计数方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1mjPpKqG&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者提出了一个新的人群计数的网络结构 Adversarial Cross-Scale Consistency Pursuit Network，在四个公开的人群计数数据集上刷新了目前国际最佳的计数精度。人群计数任务是一个极具挑战的任务，原因在于其存在场景变化跨度大、目标空间尺度变化大、人群之间存在严重遮挡等困难。现有的方法存在以下两个缺陷：一、由不同大小的卷积子构成的多通道卷积网络融合得到的图像多尺度特征，再经传统的欧式损失（L1/L2）回归用来计数的人群密度图会导致密度图模糊，同时由于在网络中使用池化层，大大降低了密度图的分辨率，给最终的计数带来误差；二、输入一张图像计算得出的人数与将此图像分割成 4 份分别输入得到的总人数存在差异，此即为跨尺度统计不一致带来的误差。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5838587641866331&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15R13Ykfw9g1ah0pcynPYibHlVU31BOMlAa4SHBA5tFEbyAWBLZFqn3QQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于对抗跨尺度一致性追求网络的结构图，两种尺度的生成器 G/判别器 D 利用跨尺度一致性损失实现联合训练。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;针对以上两点，作者提出了基于生成对抗网络的跨尺度结构模型，其中对抗损失的引入使得生成的密度图更加尖锐，U-net 结构的生成网络保证了密度图的高分辨率，同时跨尺度一致性正则子约束了图像间的跨尺度误差。因此，该提出的模型最终能生成质量好分辨率高的人群密度图，从而获得更高的人群计数精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 6：《Scale-Transferrable Object Detection》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于尺度变换模块的物体检测器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6Yjvpz&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4968474148802018&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15WKCphF5KePicGlsFGBqyK22EYrMe3JGFVJ9SaibXLHiaO7jw6QQsvkN2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于尺度转移模块的物体检测。尺度转移模块由简单的 mean pooling 层和尺度转移层构成，被嵌入到 DenseNet 网络的最后一个模块中，从而得到不同分辨率的被用来做物体检测的特征图。尺度转移层可以有效地减少输入特征图的通道数，同时扩大其分辨率，不增加额外的计算开销。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者构建了一个类似于 SSD 的一阶段物体检测器，称之为 STDN（尺度转移检测网络）。与 SSD 物体检测方法相比主要有两点不同，一是基础网络使用的是 DenseNet，二是作者使用了一个尺度转移模块来获得不同分辨率的特征图，这些特征图被用来做物体检测。这个尺度转移模块由 mean pooling 层和像素重排层构成。Mean pooling 层用来获得低分辨率的特征图；像素重排层通过压缩特征图的通道数来扩大特征图的分辨率，没有额外的计算开销。尺度转移模块可以直接嵌入到 DenseNet 网络中，不需要在 DenseNet 网络之后添加额外的层就能获得多尺度的特征图。而且像素重排层可以有效地压缩 DenseNet 网络特征图的通道数，从而减少之后卷积层的参数数量。作者在 pascal voc07 和 coco 数据集上取得了不错的检测性能，对构建开销较小的物体检测器具有一定的启发意义。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;注：上海交通大学电子系人工智能实验室由倪冰冰教授、徐奕教授领衔，杨小康教授、张文军教授指导 &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0JZxz5ovG7gL67yGQmoN7cKRk8EfHpuibXtdTP5lajgBIicEgEnWYzibP1BnWtKCOmZEibzX09iaSXrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; width=&quot;50px&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 50px !important;visibility: visible !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心报道，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;878746311&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-27-1000000615_503254704</guid>
<pubDate>Tue, 27 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>业界 | 哪家GPU云提供商最合适？也许这份评测能给你答案</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-27-1000000615_503254691.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTWVTPx9AotzGB9gWtTo1T4ipXoaXF57mUDr7xxSDZW5-NSOqX*frWM633x1U38T7bjfUMN4XUxY4xOlB0xMO*I0=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | CVPR 2018接收论文公布，上海交通大学6篇论文简介                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-27&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;color: rgb(62, 62, 62);max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;&quot;&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;作者：吴欣&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;blockquote style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;不久之前，CVPR 2018 论文接收列表公布。据机器之心了解，上海交通大学电子系人工智能实验室倪冰冰教授课题组有 6 篇论文入选，本文对这几篇论文做了简介，更多详细内容可通过论文网盘链接下载查看。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;CVPR 2018 论文接收列表：http://cvpr2018.thecvf.com/files/cvpr_2018_final_accept_list.txt&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 1：《Fine-grained Video Captioning for Sports Narrative》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;细粒度视频描述——体育视频自动解说&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1miUzoCC&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;视频描述方向的研究在近段时间取得了较大的进展，但是一直都停留在粗略的视频内容讲述上，没有做到对于人物交互关系和动作细节的细致描述，而这些恰恰都是体育视频中非常重要的部分。在这篇 CVPR 工作中，作者提出了一个全新的细粒度视频描述课题，做出了一个对应的体育视频细粒度描述数据集，并用一个完善的视频描述网络解决了该问题，实现了国际首次人工智能体育视频自动解说。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8360655737704918&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15Np6v2Rz9MibNb9yrjm0hncOoKPuOtPo8boxxLToWxuUI8LxrmVF5soA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;体育视频自动解说效果展示。所有球员的角色、关系和位置，及球的位置都实现了准确的理解识别。相比较传统的「一群人在打篮球」的粗略描述，这篇文章实现的描述更加细致、准确，可以全面真实地反映运动场上的实际情况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在文章中，作者通过一个时域-空域定位子网络来进行动作片段的分割和球员角色的定位；通过一个引入骨骼信息的细粒度动作识别子网络来精确地识别球员在高速运动中做出的细小动作；再通过一个群体交互子网络来构建球员间的交互关系。通过以上三个子网络捕获充足全面的视频特征，从而输出准确的细粒度视频描述语句。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此外，文章中提出的细粒度体育视频自动解说数据集（FSN dataset）也将会在不久后公开供科研使用，以促进细粒度视频描述领域的技术发展。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 2：《Structure Preserving Video Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;面向保持结构一致性的视频预测模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1kWUb4c3&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;像素级的视频生成一直是计算机视觉领域的热点问题。过去的方法一直试图解决所预测的视频中存在的运动模糊问题。这个问题一方面由随时间增加所带来的累计误差引起，另一方面由于像素级的视频生成的解空间非常巨大。这里将像素级的视频生成一直存在的两个问题总结如下：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;静态结构预测损失 这个问题来源于预测具有固定结构的场景，城市景观中的交通标志、树木等任务。这些静态结构的运动常常是由相机运动引起的。现有方法的预测结构大多不能保持原始对象结构，例如物体的边缘结构信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;动态结构预测损失 虽然最近的一些工作可以预测一般粗粒度运动。但是一般不能精确预测精细的局部运动，如人体关节运动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3707440100882724&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15094v02K29lKWib0osL9NPbXGf6I7F4nZazNsq1Sf14Pv0PxrTVyaf8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;论文提出的视频预测模型图示。该架构使用论文提出的多频带分析和时变卷积核技术，能够更大限度的利用输入信息和更灵活的应对视频内容的动态变化，使得更精确地预测像素级的视频内容成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在这篇文章中，作者提出基于多频带分析和时变卷积核的视频预测模型来解决上述两个问题。一方面作者将输入视频分解为多个频率分量分别进行处理，以求从原始视频中获取尽可能多的物体静态结构信息，称之为多频带分析；另一方面作者利用输入视频帧来生成最终预测模型中的卷积核，以求能够更灵活的应对动态结构预测任务，称之为时变卷集核。两个方法分别较好地解决了上述两个问题，显著提高了视频预测精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 3：《Multiple Granularity Group Interaction Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于多粒度的群体交互预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6HovGh&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.40226986128625475&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15d5ibarujPxEibjMtkZx6YMzdBg8HYtOPNfmRc1sOTVGnibVOHOSxzAMcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;多粒度群体交互预测框架。首先我们把骨架序列处理成两个不同粒度的信息，分别代表整体轨迹运动和肢体细节运动。基于 seq2seq 预测结构，我们设计了同粒度间信息交互子网络来考虑群体之间的相互影响，以及不同粒度间的信息交互子网络来促进两个粒度上信息的交互，更准确地预测结果。最后整合预测出的两个粒度信息，展示群体交互预测结果。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;当前大多数人体活动分析（识别或预测）的工作仅关注于单个粒度，例如在粗粒度层次对整体运动进行建模（轨迹预测）；或者在细粒度层次对肢体细节运动进行建模（骨骼动作预测）。相反，在这项工作中，作者提出了多粒度群体交互预测网络，能够同时考虑两个粒度上的信息（整体轨迹和细节动作）。首先对于每个人的骨架运动序列，作者把它处理成能够分别代表轨迹运动和肢体运动的两个粒度上的运动序列。对于每个粒度上的信息，基于 seq2seq 网络结构，作者设计了同粒度间的交互网络，在预测每个人这个粒度上的运动信息时能够考虑其他人的运动信息。同时，基于双向 LSTM，作者设计了不同粒度间的信息交互网络，来促进每个人的不同粒度上信息的交互，更准确地预测未来轨迹和细节动作。最后作者把两个粒度上的信息整合在一起，多景观式地展示预测的群体交互。此方法在 SBU 和 Choi&#39;s New Dataset 数据集上都取得了目前最佳效果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 4：《pose transferrable person re-identification》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;姿态可迁移行人再识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1nwFetDZ&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;行人再识别旨在解决跨时空匹配行人的问题，其在智能安防领域有极大的应用价值。由于行人姿态、外观、光照、遮挡等因素的影响，行人再识别仍然是一项极具挑战性的任务。为了解决行人姿态变化丰富导致模型难以在有限训练集下获得良好性能的问题，作者在这篇 CVPR 的工作中提出了一个姿态可迁移的行人再识别模型。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6305170239596469&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM154vibjHx2H3cfuQVkkg2097fOkgf1AF28Cic33JvhVicSmmKgt2e3V8VPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;姿态可迁移行人再识别框架。首先训练姿态迁移模块，其中我们引入了「向导」子模块来提升生成器的性能。然后使用训练好的生成器实现行人姿态由源数据集到目标数据集的迁移，进而提升行人再识别在目标数据集上的性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;假设给定大小两个数据集，分别称为 A 和 B。其中数据集 A 中覆盖的行人姿态少，而 B 中的样本包含丰富的姿态。作者提出将数据集 A 中的图片样本与数据集 B 中样本的骨架进行配对，并通过 Skeleton-to-Image 模型生成与 A 中样本共享身份信息且与 B 中样本共享姿态的新样本集 C。为了提高生成样本的质量，作者提出了一个与对抗生成网络中的判别器平行的向导模块。向导模块是一个预训练好的行人再识别模型，用于指导生成器生成包含更丰富身份信息、更适应行人再识别任务的样本。在得到了生成样本集 C 后，作者将其与数据集 A 混合并通过平滑机制分配样本权重后训练模型。实验结果表明此方法能够与其他高性能方法 (包括特征学习、度量学习类方法) 结合并进一步提升它们的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 5：《Crowd Counting via Adversarial Cross-Scale Consistency Pursuit》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于对抗跨尺度一致性追求的人群计数方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1mjPpKqG&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者提出了一个新的人群计数的网络结构 Adversarial Cross-Scale Consistency Pursuit Network，在四个公开的人群计数数据集上刷新了目前国际最佳的计数精度。人群计数任务是一个极具挑战的任务，原因在于其存在场景变化跨度大、目标空间尺度变化大、人群之间存在严重遮挡等困难。现有的方法存在以下两个缺陷：一、由不同大小的卷积子构成的多通道卷积网络融合得到的图像多尺度特征，再经传统的欧式损失（L1/L2）回归用来计数的人群密度图会导致密度图模糊，同时由于在网络中使用池化层，大大降低了密度图的分辨率，给最终的计数带来误差；二、输入一张图像计算得出的人数与将此图像分割成 4 份分别输入得到的总人数存在差异，此即为跨尺度统计不一致带来的误差。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5838587641866331&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15R13Ykfw9g1ah0pcynPYibHlVU31BOMlAa4SHBA5tFEbyAWBLZFqn3QQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于对抗跨尺度一致性追求网络的结构图，两种尺度的生成器 G/判别器 D 利用跨尺度一致性损失实现联合训练。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;针对以上两点，作者提出了基于生成对抗网络的跨尺度结构模型，其中对抗损失的引入使得生成的密度图更加尖锐，U-net 结构的生成网络保证了密度图的高分辨率，同时跨尺度一致性正则子约束了图像间的跨尺度误差。因此，该提出的模型最终能生成质量好分辨率高的人群密度图，从而获得更高的人群计数精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 6：《Scale-Transferrable Object Detection》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于尺度变换模块的物体检测器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6Yjvpz&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4968474148802018&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15WKCphF5KePicGlsFGBqyK22EYrMe3JGFVJ9SaibXLHiaO7jw6QQsvkN2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于尺度转移模块的物体检测。尺度转移模块由简单的 mean pooling 层和尺度转移层构成，被嵌入到 DenseNet 网络的最后一个模块中，从而得到不同分辨率的被用来做物体检测的特征图。尺度转移层可以有效地减少输入特征图的通道数，同时扩大其分辨率，不增加额外的计算开销。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者构建了一个类似于 SSD 的一阶段物体检测器，称之为 STDN（尺度转移检测网络）。与 SSD 物体检测方法相比主要有两点不同，一是基础网络使用的是 DenseNet，二是作者使用了一个尺度转移模块来获得不同分辨率的特征图，这些特征图被用来做物体检测。这个尺度转移模块由 mean pooling 层和像素重排层构成。Mean pooling 层用来获得低分辨率的特征图；像素重排层通过压缩特征图的通道数来扩大特征图的分辨率，没有额外的计算开销。尺度转移模块可以直接嵌入到 DenseNet 网络中，不需要在 DenseNet 网络之后添加额外的层就能获得多尺度的特征图。而且像素重排层可以有效地压缩 DenseNet 网络特征图的通道数，从而减少之后卷积层的参数数量。作者在 pascal voc07 和 coco 数据集上取得了不错的检测性能，对构建开销较小的物体检测器具有一定的启发意义。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;注：上海交通大学电子系人工智能实验室由倪冰冰教授、徐奕教授领衔，杨小康教授、张文军教授指导 &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0JZxz5ovG7gL67yGQmoN7cKRk8EfHpuibXtdTP5lajgBIicEgEnWYzibP1BnWtKCOmZEibzX09iaSXrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; width=&quot;50px&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 50px !important;visibility: visible !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心报道，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1425143964&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-27-1000000615_503254691</guid>
<pubDate>Tue, 27 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>学界 | CVPR 2018接收论文公布，上海交通大学6篇论文简介</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-27-1000000615_503254689.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTWVTPx9AotzGB9gWtTo1T4i-gmJuozTh1Xkq6yAHyN6BAS1iOCJDCEErbgJl6MgpGerk-8uuSMsb*viXnMvPqbQ=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | CVPR 2018接收论文公布，上海交通大学6篇论文简介                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-27&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;color: rgb(62, 62, 62);max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;&quot;&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;作者：吴欣&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;blockquote style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;不久之前，CVPR 2018 论文接收列表公布。据机器之心了解，上海交通大学电子系人工智能实验室倪冰冰教授课题组有 6 篇论文入选，本文对这几篇论文做了简介，更多详细内容可通过论文网盘链接下载查看。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;CVPR 2018 论文接收列表：http://cvpr2018.thecvf.com/files/cvpr_2018_final_accept_list.txt&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 1：《Fine-grained Video Captioning for Sports Narrative》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;细粒度视频描述——体育视频自动解说&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1miUzoCC&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;视频描述方向的研究在近段时间取得了较大的进展，但是一直都停留在粗略的视频内容讲述上，没有做到对于人物交互关系和动作细节的细致描述，而这些恰恰都是体育视频中非常重要的部分。在这篇 CVPR 工作中，作者提出了一个全新的细粒度视频描述课题，做出了一个对应的体育视频细粒度描述数据集，并用一个完善的视频描述网络解决了该问题，实现了国际首次人工智能体育视频自动解说。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8360655737704918&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15Np6v2Rz9MibNb9yrjm0hncOoKPuOtPo8boxxLToWxuUI8LxrmVF5soA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;体育视频自动解说效果展示。所有球员的角色、关系和位置，及球的位置都实现了准确的理解识别。相比较传统的「一群人在打篮球」的粗略描述，这篇文章实现的描述更加细致、准确，可以全面真实地反映运动场上的实际情况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在文章中，作者通过一个时域-空域定位子网络来进行动作片段的分割和球员角色的定位；通过一个引入骨骼信息的细粒度动作识别子网络来精确地识别球员在高速运动中做出的细小动作；再通过一个群体交互子网络来构建球员间的交互关系。通过以上三个子网络捕获充足全面的视频特征，从而输出准确的细粒度视频描述语句。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此外，文章中提出的细粒度体育视频自动解说数据集（FSN dataset）也将会在不久后公开供科研使用，以促进细粒度视频描述领域的技术发展。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 2：《Structure Preserving Video Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;面向保持结构一致性的视频预测模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1kWUb4c3&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;像素级的视频生成一直是计算机视觉领域的热点问题。过去的方法一直试图解决所预测的视频中存在的运动模糊问题。这个问题一方面由随时间增加所带来的累计误差引起，另一方面由于像素级的视频生成的解空间非常巨大。这里将像素级的视频生成一直存在的两个问题总结如下：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;静态结构预测损失 这个问题来源于预测具有固定结构的场景，城市景观中的交通标志、树木等任务。这些静态结构的运动常常是由相机运动引起的。现有方法的预测结构大多不能保持原始对象结构，例如物体的边缘结构信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;动态结构预测损失 虽然最近的一些工作可以预测一般粗粒度运动。但是一般不能精确预测精细的局部运动，如人体关节运动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3707440100882724&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15094v02K29lKWib0osL9NPbXGf6I7F4nZazNsq1Sf14Pv0PxrTVyaf8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;论文提出的视频预测模型图示。该架构使用论文提出的多频带分析和时变卷积核技术，能够更大限度的利用输入信息和更灵活的应对视频内容的动态变化，使得更精确地预测像素级的视频内容成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在这篇文章中，作者提出基于多频带分析和时变卷积核的视频预测模型来解决上述两个问题。一方面作者将输入视频分解为多个频率分量分别进行处理，以求从原始视频中获取尽可能多的物体静态结构信息，称之为多频带分析；另一方面作者利用输入视频帧来生成最终预测模型中的卷积核，以求能够更灵活的应对动态结构预测任务，称之为时变卷集核。两个方法分别较好地解决了上述两个问题，显著提高了视频预测精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 3：《Multiple Granularity Group Interaction Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于多粒度的群体交互预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6HovGh&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.40226986128625475&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15d5ibarujPxEibjMtkZx6YMzdBg8HYtOPNfmRc1sOTVGnibVOHOSxzAMcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;多粒度群体交互预测框架。首先我们把骨架序列处理成两个不同粒度的信息，分别代表整体轨迹运动和肢体细节运动。基于 seq2seq 预测结构，我们设计了同粒度间信息交互子网络来考虑群体之间的相互影响，以及不同粒度间的信息交互子网络来促进两个粒度上信息的交互，更准确地预测结果。最后整合预测出的两个粒度信息，展示群体交互预测结果。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;当前大多数人体活动分析（识别或预测）的工作仅关注于单个粒度，例如在粗粒度层次对整体运动进行建模（轨迹预测）；或者在细粒度层次对肢体细节运动进行建模（骨骼动作预测）。相反，在这项工作中，作者提出了多粒度群体交互预测网络，能够同时考虑两个粒度上的信息（整体轨迹和细节动作）。首先对于每个人的骨架运动序列，作者把它处理成能够分别代表轨迹运动和肢体运动的两个粒度上的运动序列。对于每个粒度上的信息，基于 seq2seq 网络结构，作者设计了同粒度间的交互网络，在预测每个人这个粒度上的运动信息时能够考虑其他人的运动信息。同时，基于双向 LSTM，作者设计了不同粒度间的信息交互网络，来促进每个人的不同粒度上信息的交互，更准确地预测未来轨迹和细节动作。最后作者把两个粒度上的信息整合在一起，多景观式地展示预测的群体交互。此方法在 SBU 和 Choi&#39;s New Dataset 数据集上都取得了目前最佳效果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 4：《pose transferrable person re-identification》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;姿态可迁移行人再识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1nwFetDZ&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;行人再识别旨在解决跨时空匹配行人的问题，其在智能安防领域有极大的应用价值。由于行人姿态、外观、光照、遮挡等因素的影响，行人再识别仍然是一项极具挑战性的任务。为了解决行人姿态变化丰富导致模型难以在有限训练集下获得良好性能的问题，作者在这篇 CVPR 的工作中提出了一个姿态可迁移的行人再识别模型。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6305170239596469&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM154vibjHx2H3cfuQVkkg2097fOkgf1AF28Cic33JvhVicSmmKgt2e3V8VPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;姿态可迁移行人再识别框架。首先训练姿态迁移模块，其中我们引入了「向导」子模块来提升生成器的性能。然后使用训练好的生成器实现行人姿态由源数据集到目标数据集的迁移，进而提升行人再识别在目标数据集上的性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;假设给定大小两个数据集，分别称为 A 和 B。其中数据集 A 中覆盖的行人姿态少，而 B 中的样本包含丰富的姿态。作者提出将数据集 A 中的图片样本与数据集 B 中样本的骨架进行配对，并通过 Skeleton-to-Image 模型生成与 A 中样本共享身份信息且与 B 中样本共享姿态的新样本集 C。为了提高生成样本的质量，作者提出了一个与对抗生成网络中的判别器平行的向导模块。向导模块是一个预训练好的行人再识别模型，用于指导生成器生成包含更丰富身份信息、更适应行人再识别任务的样本。在得到了生成样本集 C 后，作者将其与数据集 A 混合并通过平滑机制分配样本权重后训练模型。实验结果表明此方法能够与其他高性能方法 (包括特征学习、度量学习类方法) 结合并进一步提升它们的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 5：《Crowd Counting via Adversarial Cross-Scale Consistency Pursuit》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于对抗跨尺度一致性追求的人群计数方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1mjPpKqG&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者提出了一个新的人群计数的网络结构 Adversarial Cross-Scale Consistency Pursuit Network，在四个公开的人群计数数据集上刷新了目前国际最佳的计数精度。人群计数任务是一个极具挑战的任务，原因在于其存在场景变化跨度大、目标空间尺度变化大、人群之间存在严重遮挡等困难。现有的方法存在以下两个缺陷：一、由不同大小的卷积子构成的多通道卷积网络融合得到的图像多尺度特征，再经传统的欧式损失（L1/L2）回归用来计数的人群密度图会导致密度图模糊，同时由于在网络中使用池化层，大大降低了密度图的分辨率，给最终的计数带来误差；二、输入一张图像计算得出的人数与将此图像分割成 4 份分别输入得到的总人数存在差异，此即为跨尺度统计不一致带来的误差。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5838587641866331&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15R13Ykfw9g1ah0pcynPYibHlVU31BOMlAa4SHBA5tFEbyAWBLZFqn3QQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于对抗跨尺度一致性追求网络的结构图，两种尺度的生成器 G/判别器 D 利用跨尺度一致性损失实现联合训练。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;针对以上两点，作者提出了基于生成对抗网络的跨尺度结构模型，其中对抗损失的引入使得生成的密度图更加尖锐，U-net 结构的生成网络保证了密度图的高分辨率，同时跨尺度一致性正则子约束了图像间的跨尺度误差。因此，该提出的模型最终能生成质量好分辨率高的人群密度图，从而获得更高的人群计数精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 6：《Scale-Transferrable Object Detection》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于尺度变换模块的物体检测器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6Yjvpz&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4968474148802018&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15WKCphF5KePicGlsFGBqyK22EYrMe3JGFVJ9SaibXLHiaO7jw6QQsvkN2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于尺度转移模块的物体检测。尺度转移模块由简单的 mean pooling 层和尺度转移层构成，被嵌入到 DenseNet 网络的最后一个模块中，从而得到不同分辨率的被用来做物体检测的特征图。尺度转移层可以有效地减少输入特征图的通道数，同时扩大其分辨率，不增加额外的计算开销。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者构建了一个类似于 SSD 的一阶段物体检测器，称之为 STDN（尺度转移检测网络）。与 SSD 物体检测方法相比主要有两点不同，一是基础网络使用的是 DenseNet，二是作者使用了一个尺度转移模块来获得不同分辨率的特征图，这些特征图被用来做物体检测。这个尺度转移模块由 mean pooling 层和像素重排层构成。Mean pooling 层用来获得低分辨率的特征图；像素重排层通过压缩特征图的通道数来扩大特征图的分辨率，没有额外的计算开销。尺度转移模块可以直接嵌入到 DenseNet 网络中，不需要在 DenseNet 网络之后添加额外的层就能获得多尺度的特征图。而且像素重排层可以有效地压缩 DenseNet 网络特征图的通道数，从而减少之后卷积层的参数数量。作者在 pascal voc07 和 coco 数据集上取得了不错的检测性能，对构建开销较小的物体检测器具有一定的启发意义。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;注：上海交通大学电子系人工智能实验室由倪冰冰教授、徐奕教授领衔，杨小康教授、张文军教授指导 &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0JZxz5ovG7gL67yGQmoN7cKRk8EfHpuibXtdTP5lajgBIicEgEnWYzibP1BnWtKCOmZEibzX09iaSXrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; width=&quot;50px&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 50px !important;visibility: visible !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心报道，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1788211803&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-27-1000000615_503254689</guid>
<pubDate>Tue, 27 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>资源 | DeepPavlov：一个训练对话系统和聊天机器人的开源库</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-27-1000000615_503254681.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTWVTPx9AotzGB9gWtTo1T4g6PxrZoVLK6LYrFUldWvtKvlJfMU5X71OqMwoN67OjsI1oCwyDjV9hQthfS06LRM4=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | CVPR 2018接收论文公布，上海交通大学6篇论文简介                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-27&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;color: rgb(62, 62, 62);max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;&quot;&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;作者：吴欣&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;blockquote style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;不久之前，CVPR 2018 论文接收列表公布。据机器之心了解，上海交通大学电子系人工智能实验室倪冰冰教授课题组有 6 篇论文入选，本文对这几篇论文做了简介，更多详细内容可通过论文网盘链接下载查看。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;CVPR 2018 论文接收列表：http://cvpr2018.thecvf.com/files/cvpr_2018_final_accept_list.txt&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 1：《Fine-grained Video Captioning for Sports Narrative》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;细粒度视频描述——体育视频自动解说&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1miUzoCC&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;视频描述方向的研究在近段时间取得了较大的进展，但是一直都停留在粗略的视频内容讲述上，没有做到对于人物交互关系和动作细节的细致描述，而这些恰恰都是体育视频中非常重要的部分。在这篇 CVPR 工作中，作者提出了一个全新的细粒度视频描述课题，做出了一个对应的体育视频细粒度描述数据集，并用一个完善的视频描述网络解决了该问题，实现了国际首次人工智能体育视频自动解说。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8360655737704918&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15Np6v2Rz9MibNb9yrjm0hncOoKPuOtPo8boxxLToWxuUI8LxrmVF5soA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;体育视频自动解说效果展示。所有球员的角色、关系和位置，及球的位置都实现了准确的理解识别。相比较传统的「一群人在打篮球」的粗略描述，这篇文章实现的描述更加细致、准确，可以全面真实地反映运动场上的实际情况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在文章中，作者通过一个时域-空域定位子网络来进行动作片段的分割和球员角色的定位；通过一个引入骨骼信息的细粒度动作识别子网络来精确地识别球员在高速运动中做出的细小动作；再通过一个群体交互子网络来构建球员间的交互关系。通过以上三个子网络捕获充足全面的视频特征，从而输出准确的细粒度视频描述语句。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此外，文章中提出的细粒度体育视频自动解说数据集（FSN dataset）也将会在不久后公开供科研使用，以促进细粒度视频描述领域的技术发展。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 2：《Structure Preserving Video Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;面向保持结构一致性的视频预测模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1kWUb4c3&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;像素级的视频生成一直是计算机视觉领域的热点问题。过去的方法一直试图解决所预测的视频中存在的运动模糊问题。这个问题一方面由随时间增加所带来的累计误差引起，另一方面由于像素级的视频生成的解空间非常巨大。这里将像素级的视频生成一直存在的两个问题总结如下：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;静态结构预测损失 这个问题来源于预测具有固定结构的场景，城市景观中的交通标志、树木等任务。这些静态结构的运动常常是由相机运动引起的。现有方法的预测结构大多不能保持原始对象结构，例如物体的边缘结构信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;动态结构预测损失 虽然最近的一些工作可以预测一般粗粒度运动。但是一般不能精确预测精细的局部运动，如人体关节运动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3707440100882724&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15094v02K29lKWib0osL9NPbXGf6I7F4nZazNsq1Sf14Pv0PxrTVyaf8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;论文提出的视频预测模型图示。该架构使用论文提出的多频带分析和时变卷积核技术，能够更大限度的利用输入信息和更灵活的应对视频内容的动态变化，使得更精确地预测像素级的视频内容成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在这篇文章中，作者提出基于多频带分析和时变卷积核的视频预测模型来解决上述两个问题。一方面作者将输入视频分解为多个频率分量分别进行处理，以求从原始视频中获取尽可能多的物体静态结构信息，称之为多频带分析；另一方面作者利用输入视频帧来生成最终预测模型中的卷积核，以求能够更灵活的应对动态结构预测任务，称之为时变卷集核。两个方法分别较好地解决了上述两个问题，显著提高了视频预测精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 3：《Multiple Granularity Group Interaction Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于多粒度的群体交互预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6HovGh&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.40226986128625475&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15d5ibarujPxEibjMtkZx6YMzdBg8HYtOPNfmRc1sOTVGnibVOHOSxzAMcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;多粒度群体交互预测框架。首先我们把骨架序列处理成两个不同粒度的信息，分别代表整体轨迹运动和肢体细节运动。基于 seq2seq 预测结构，我们设计了同粒度间信息交互子网络来考虑群体之间的相互影响，以及不同粒度间的信息交互子网络来促进两个粒度上信息的交互，更准确地预测结果。最后整合预测出的两个粒度信息，展示群体交互预测结果。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;当前大多数人体活动分析（识别或预测）的工作仅关注于单个粒度，例如在粗粒度层次对整体运动进行建模（轨迹预测）；或者在细粒度层次对肢体细节运动进行建模（骨骼动作预测）。相反，在这项工作中，作者提出了多粒度群体交互预测网络，能够同时考虑两个粒度上的信息（整体轨迹和细节动作）。首先对于每个人的骨架运动序列，作者把它处理成能够分别代表轨迹运动和肢体运动的两个粒度上的运动序列。对于每个粒度上的信息，基于 seq2seq 网络结构，作者设计了同粒度间的交互网络，在预测每个人这个粒度上的运动信息时能够考虑其他人的运动信息。同时，基于双向 LSTM，作者设计了不同粒度间的信息交互网络，来促进每个人的不同粒度上信息的交互，更准确地预测未来轨迹和细节动作。最后作者把两个粒度上的信息整合在一起，多景观式地展示预测的群体交互。此方法在 SBU 和 Choi&#39;s New Dataset 数据集上都取得了目前最佳效果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 4：《pose transferrable person re-identification》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;姿态可迁移行人再识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1nwFetDZ&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;行人再识别旨在解决跨时空匹配行人的问题，其在智能安防领域有极大的应用价值。由于行人姿态、外观、光照、遮挡等因素的影响，行人再识别仍然是一项极具挑战性的任务。为了解决行人姿态变化丰富导致模型难以在有限训练集下获得良好性能的问题，作者在这篇 CVPR 的工作中提出了一个姿态可迁移的行人再识别模型。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6305170239596469&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM154vibjHx2H3cfuQVkkg2097fOkgf1AF28Cic33JvhVicSmmKgt2e3V8VPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;姿态可迁移行人再识别框架。首先训练姿态迁移模块，其中我们引入了「向导」子模块来提升生成器的性能。然后使用训练好的生成器实现行人姿态由源数据集到目标数据集的迁移，进而提升行人再识别在目标数据集上的性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;假设给定大小两个数据集，分别称为 A 和 B。其中数据集 A 中覆盖的行人姿态少，而 B 中的样本包含丰富的姿态。作者提出将数据集 A 中的图片样本与数据集 B 中样本的骨架进行配对，并通过 Skeleton-to-Image 模型生成与 A 中样本共享身份信息且与 B 中样本共享姿态的新样本集 C。为了提高生成样本的质量，作者提出了一个与对抗生成网络中的判别器平行的向导模块。向导模块是一个预训练好的行人再识别模型，用于指导生成器生成包含更丰富身份信息、更适应行人再识别任务的样本。在得到了生成样本集 C 后，作者将其与数据集 A 混合并通过平滑机制分配样本权重后训练模型。实验结果表明此方法能够与其他高性能方法 (包括特征学习、度量学习类方法) 结合并进一步提升它们的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 5：《Crowd Counting via Adversarial Cross-Scale Consistency Pursuit》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于对抗跨尺度一致性追求的人群计数方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1mjPpKqG&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者提出了一个新的人群计数的网络结构 Adversarial Cross-Scale Consistency Pursuit Network，在四个公开的人群计数数据集上刷新了目前国际最佳的计数精度。人群计数任务是一个极具挑战的任务，原因在于其存在场景变化跨度大、目标空间尺度变化大、人群之间存在严重遮挡等困难。现有的方法存在以下两个缺陷：一、由不同大小的卷积子构成的多通道卷积网络融合得到的图像多尺度特征，再经传统的欧式损失（L1/L2）回归用来计数的人群密度图会导致密度图模糊，同时由于在网络中使用池化层，大大降低了密度图的分辨率，给最终的计数带来误差；二、输入一张图像计算得出的人数与将此图像分割成 4 份分别输入得到的总人数存在差异，此即为跨尺度统计不一致带来的误差。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5838587641866331&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15R13Ykfw9g1ah0pcynPYibHlVU31BOMlAa4SHBA5tFEbyAWBLZFqn3QQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于对抗跨尺度一致性追求网络的结构图，两种尺度的生成器 G/判别器 D 利用跨尺度一致性损失实现联合训练。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;针对以上两点，作者提出了基于生成对抗网络的跨尺度结构模型，其中对抗损失的引入使得生成的密度图更加尖锐，U-net 结构的生成网络保证了密度图的高分辨率，同时跨尺度一致性正则子约束了图像间的跨尺度误差。因此，该提出的模型最终能生成质量好分辨率高的人群密度图，从而获得更高的人群计数精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 6：《Scale-Transferrable Object Detection》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于尺度变换模块的物体检测器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6Yjvpz&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4968474148802018&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15WKCphF5KePicGlsFGBqyK22EYrMe3JGFVJ9SaibXLHiaO7jw6QQsvkN2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于尺度转移模块的物体检测。尺度转移模块由简单的 mean pooling 层和尺度转移层构成，被嵌入到 DenseNet 网络的最后一个模块中，从而得到不同分辨率的被用来做物体检测的特征图。尺度转移层可以有效地减少输入特征图的通道数，同时扩大其分辨率，不增加额外的计算开销。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者构建了一个类似于 SSD 的一阶段物体检测器，称之为 STDN（尺度转移检测网络）。与 SSD 物体检测方法相比主要有两点不同，一是基础网络使用的是 DenseNet，二是作者使用了一个尺度转移模块来获得不同分辨率的特征图，这些特征图被用来做物体检测。这个尺度转移模块由 mean pooling 层和像素重排层构成。Mean pooling 层用来获得低分辨率的特征图；像素重排层通过压缩特征图的通道数来扩大特征图的分辨率，没有额外的计算开销。尺度转移模块可以直接嵌入到 DenseNet 网络中，不需要在 DenseNet 网络之后添加额外的层就能获得多尺度的特征图。而且像素重排层可以有效地压缩 DenseNet 网络特征图的通道数，从而减少之后卷积层的参数数量。作者在 pascal voc07 和 coco 数据集上取得了不错的检测性能，对构建开销较小的物体检测器具有一定的启发意义。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;注：上海交通大学电子系人工智能实验室由倪冰冰教授、徐奕教授领衔，杨小康教授、张文军教授指导 &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0JZxz5ovG7gL67yGQmoN7cKRk8EfHpuibXtdTP5lajgBIicEgEnWYzibP1BnWtKCOmZEibzX09iaSXrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; width=&quot;50px&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 50px !important;visibility: visible !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心报道，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;1151590734&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-27-1000000615_503254681</guid>
<pubDate>Tue, 27 Feb 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>使用Faster R-CNN、ResNet诊断皮肤病，深度学习再次超越人类专家</title>
<link>https://henix.github.io/feeds/weixin.sogou.almosthuman2014/2018-02-27-1000000615.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?timestamp=1519828572&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=qKtrz30nkMH3465tZdduMp8TdxXmgOKf1SOG8VSyqzxLcTKBUNvQe8YwbBn5SfGjkcPLhG5DGPM4Nef5tborTWVTPx9AotzGB9gWtTo1T4gUktLzJFiOF6eo6Z5lXLxQB2FlSI4vXFrUDKEl7K2gxX183*TQzptBRKjxVWXSEvc=&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;img-content&quot;&gt;
                
                &lt;h2 class=&quot;rich_media_title&quot; id=&quot;activity-name&quot;&gt;
                    学界 | CVPR 2018接收论文公布，上海交通大学6篇论文简介                                    &lt;/h2&gt;
                &lt;div id=&quot;meta_content&quot; class=&quot;rich_media_meta_list&quot;&gt;
                                                            &lt;em id=&quot;post-date&quot; class=&quot;rich_media_meta rich_media_meta_text&quot;&gt;2018-02-27&lt;/em&gt;

                                        &lt;a class=&quot;rich_media_meta rich_media_meta_link rich_media_meta_nickname&quot; href=&quot;##&quot; id=&quot;post-user&quot;&gt;机器之心&lt;/a&gt;
                    &lt;span class=&quot;rich_media_meta rich_media_meta_text rich_media_meta_nickname&quot;&gt;机器之心&lt;/span&gt;


                    &lt;div id=&quot;js_profile_qrcode&quot; class=&quot;profile_container&quot; style=&quot;display:none;&quot;&gt;
                        &lt;div class=&quot;profile_inner&quot;&gt;
                            &lt;strong class=&quot;profile_nickname&quot;&gt;机器之心&lt;/strong&gt;
                            &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;微信号&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;almosthuman2014&lt;/span&gt;
                            &lt;/p&gt;

                            &lt;p class=&quot;profile_meta&quot;&gt;
                            &lt;label class=&quot;profile_meta_label&quot;&gt;功能介绍&lt;/label&gt;
                            &lt;span class=&quot;profile_meta_value&quot;&gt;专业的人工智能媒体和产业服务平台&lt;/span&gt;
                            &lt;/p&gt;
                            
                        &lt;/div&gt;
                        &lt;span class=&quot;profile_arrow_wrp&quot; id=&quot;js_profile_arrow_wrp&quot;&gt;
                            &lt;i class=&quot;profile_arrow arrow_out&quot;&gt;&lt;/i&gt;
                            &lt;i class=&quot;profile_arrow arrow_in&quot;&gt;&lt;/i&gt;
                        &lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                
                
                
                                                
                                                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section style=&quot;white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-color=&quot;rgb(117, 117, 118)&quot; style=&quot;max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;section style=&quot;margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;margin-top: -1.2em;color: rgb(62, 62, 62);max-width: 100%;min-height: 1em;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;text-align: justify;&quot;&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; style=&quot;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;text-align: center;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;color: rgb(127, 127, 127);&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;strong&gt;作者：吴欣&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;blockquote style=&quot;font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;p style=&quot;max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;font-size: 14px;text-align: justify;&quot;&gt;不久之前，CVPR 2018 论文接收列表公布。据机器之心了解，上海交通大学电子系人工智能实验室倪冰冰教授课题组有 6 篇论文入选，本文对这几篇论文做了简介，更多详细内容可通过论文网盘链接下载查看。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;CVPR 2018 论文接收列表：http://cvpr2018.thecvf.com/files/cvpr_2018_final_accept_list.txt&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 1：《Fine-grained Video Captioning for Sports Narrative》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;细粒度视频描述——体育视频自动解说&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1miUzoCC&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;视频描述方向的研究在近段时间取得了较大的进展，但是一直都停留在粗略的视频内容讲述上，没有做到对于人物交互关系和动作细节的细致描述，而这些恰恰都是体育视频中非常重要的部分。在这篇 CVPR 工作中，作者提出了一个全新的细粒度视频描述课题，做出了一个对应的体育视频细粒度描述数据集，并用一个完善的视频描述网络解决了该问题，实现了国际首次人工智能体育视频自动解说。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8360655737704918&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15Np6v2Rz9MibNb9yrjm0hncOoKPuOtPo8boxxLToWxuUI8LxrmVF5soA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;体育视频自动解说效果展示。所有球员的角色、关系和位置，及球的位置都实现了准确的理解识别。相比较传统的「一群人在打篮球」的粗略描述，这篇文章实现的描述更加细致、准确，可以全面真实地反映运动场上的实际情况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在文章中，作者通过一个时域-空域定位子网络来进行动作片段的分割和球员角色的定位；通过一个引入骨骼信息的细粒度动作识别子网络来精确地识别球员在高速运动中做出的细小动作；再通过一个群体交互子网络来构建球员间的交互关系。通过以上三个子网络捕获充足全面的视频特征，从而输出准确的细粒度视频描述语句。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;此外，文章中提出的细粒度体育视频自动解说数据集（FSN dataset）也将会在不久后公开供科研使用，以促进细粒度视频描述领域的技术发展。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 2：《Structure Preserving Video Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;面向保持结构一致性的视频预测模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1kWUb4c3&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;像素级的视频生成一直是计算机视觉领域的热点问题。过去的方法一直试图解决所预测的视频中存在的运动模糊问题。这个问题一方面由随时间增加所带来的累计误差引起，另一方面由于像素级的视频生成的解空间非常巨大。这里将像素级的视频生成一直存在的两个问题总结如下：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;静态结构预测损失 这个问题来源于预测具有固定结构的场景，城市景观中的交通标志、树木等任务。这些静态结构的运动常常是由相机运动引起的。现有方法的预测结构大多不能保持原始对象结构，例如物体的边缘结构信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;动态结构预测损失 虽然最近的一些工作可以预测一般粗粒度运动。但是一般不能精确预测精细的局部运动，如人体关节运动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3707440100882724&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15094v02K29lKWib0osL9NPbXGf6I7F4nZazNsq1Sf14Pv0PxrTVyaf8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;论文提出的视频预测模型图示。该架构使用论文提出的多频带分析和时变卷积核技术，能够更大限度的利用输入信息和更灵活的应对视频内容的动态变化，使得更精确地预测像素级的视频内容成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;在这篇文章中，作者提出基于多频带分析和时变卷积核的视频预测模型来解决上述两个问题。一方面作者将输入视频分解为多个频率分量分别进行处理，以求从原始视频中获取尽可能多的物体静态结构信息，称之为多频带分析；另一方面作者利用输入视频帧来生成最终预测模型中的卷积核，以求能够更灵活的应对动态结构预测任务，称之为时变卷集核。两个方法分别较好地解决了上述两个问题，显著提高了视频预测精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 3：《Multiple Granularity Group Interaction Prediction》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于多粒度的群体交互预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6HovGh&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.40226986128625475&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15d5ibarujPxEibjMtkZx6YMzdBg8HYtOPNfmRc1sOTVGnibVOHOSxzAMcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;多粒度群体交互预测框架。首先我们把骨架序列处理成两个不同粒度的信息，分别代表整体轨迹运动和肢体细节运动。基于 seq2seq 预测结构，我们设计了同粒度间信息交互子网络来考虑群体之间的相互影响，以及不同粒度间的信息交互子网络来促进两个粒度上信息的交互，更准确地预测结果。最后整合预测出的两个粒度信息，展示群体交互预测结果。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;当前大多数人体活动分析（识别或预测）的工作仅关注于单个粒度，例如在粗粒度层次对整体运动进行建模（轨迹预测）；或者在细粒度层次对肢体细节运动进行建模（骨骼动作预测）。相反，在这项工作中，作者提出了多粒度群体交互预测网络，能够同时考虑两个粒度上的信息（整体轨迹和细节动作）。首先对于每个人的骨架运动序列，作者把它处理成能够分别代表轨迹运动和肢体运动的两个粒度上的运动序列。对于每个粒度上的信息，基于 seq2seq 网络结构，作者设计了同粒度间的交互网络，在预测每个人这个粒度上的运动信息时能够考虑其他人的运动信息。同时，基于双向 LSTM，作者设计了不同粒度间的信息交互网络，来促进每个人的不同粒度上信息的交互，更准确地预测未来轨迹和细节动作。最后作者把两个粒度上的信息整合在一起，多景观式地展示预测的群体交互。此方法在 SBU 和 Choi&#39;s New Dataset 数据集上都取得了目前最佳效果。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 4：《pose transferrable person re-identification》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;姿态可迁移行人再识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1nwFetDZ&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;行人再识别旨在解决跨时空匹配行人的问题，其在智能安防领域有极大的应用价值。由于行人姿态、外观、光照、遮挡等因素的影响，行人再识别仍然是一项极具挑战性的任务。为了解决行人姿态变化丰富导致模型难以在有限训练集下获得良好性能的问题，作者在这篇 CVPR 的工作中提出了一个姿态可迁移的行人再识别模型。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6305170239596469&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM154vibjHx2H3cfuQVkkg2097fOkgf1AF28Cic33JvhVicSmmKgt2e3V8VPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;姿态可迁移行人再识别框架。首先训练姿态迁移模块，其中我们引入了「向导」子模块来提升生成器的性能。然后使用训练好的生成器实现行人姿态由源数据集到目标数据集的迁移，进而提升行人再识别在目标数据集上的性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;假设给定大小两个数据集，分别称为 A 和 B。其中数据集 A 中覆盖的行人姿态少，而 B 中的样本包含丰富的姿态。作者提出将数据集 A 中的图片样本与数据集 B 中样本的骨架进行配对，并通过 Skeleton-to-Image 模型生成与 A 中样本共享身份信息且与 B 中样本共享姿态的新样本集 C。为了提高生成样本的质量，作者提出了一个与对抗生成网络中的判别器平行的向导模块。向导模块是一个预训练好的行人再识别模型，用于指导生成器生成包含更丰富身份信息、更适应行人再识别任务的样本。在得到了生成样本集 C 后，作者将其与数据集 A 混合并通过平滑机制分配样本权重后训练模型。实验结果表明此方法能够与其他高性能方法 (包括特征学习、度量学习类方法) 结合并进一步提升它们的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 5：《Crowd Counting via Adversarial Cross-Scale Consistency Pursuit》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于对抗跨尺度一致性追求的人群计数方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1mjPpKqG&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者提出了一个新的人群计数的网络结构 Adversarial Cross-Scale Consistency Pursuit Network，在四个公开的人群计数数据集上刷新了目前国际最佳的计数精度。人群计数任务是一个极具挑战的任务，原因在于其存在场景变化跨度大、目标空间尺度变化大、人群之间存在严重遮挡等困难。现有的方法存在以下两个缺陷：一、由不同大小的卷积子构成的多通道卷积网络融合得到的图像多尺度特征，再经传统的欧式损失（L1/L2）回归用来计数的人群密度图会导致密度图模糊，同时由于在网络中使用池化层，大大降低了密度图的分辨率，给最终的计数带来误差；二、输入一张图像计算得出的人数与将此图像分割成 4 份分别输入得到的总人数存在差异，此即为跨尺度统计不一致带来的误差。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5838587641866331&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15R13Ykfw9g1ah0pcynPYibHlVU31BOMlAa4SHBA5tFEbyAWBLZFqn3QQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于对抗跨尺度一致性追求网络的结构图，两种尺度的生成器 G/判别器 D 利用跨尺度一致性损失实现联合训练。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;针对以上两点，作者提出了基于生成对抗网络的跨尺度结构模型，其中对抗损失的引入使得生成的密度图更加尖锐，U-net 结构的生成网络保证了密度图的高分辨率，同时跨尺度一致性正则子约束了图像间的跨尺度误差。因此，该提出的模型最终能生成质量好分辨率高的人群密度图，从而获得更高的人群计数精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;Paper 6：《Scale-Transferrable Object Detection》&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;基于尺度变换模块的物体检测器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;网盘链接：https://pan.baidu.com/s/1i6Yjvpz&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;color: rgb(123, 12, 0);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4968474148802018&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15WKCphF5KePicGlsFGBqyK22EYrMe3JGFVJ9SaibXLHiaO7jw6QQsvkN2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; style=&quot;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;基于尺度转移模块的物体检测。尺度转移模块由简单的 mean pooling 层和尺度转移层构成，被嵌入到 DenseNet 网络的最后一个模块中，从而得到不同分辨率的被用来做物体检测的特征图。尺度转移层可以有效地减少输入特征图的通道数，同时扩大其分辨率，不增加额外的计算开销。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 12px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;作者构建了一个类似于 SSD 的一阶段物体检测器，称之为 STDN（尺度转移检测网络）。与 SSD 物体检测方法相比主要有两点不同，一是基础网络使用的是 DenseNet，二是作者使用了一个尺度转移模块来获得不同分辨率的特征图，这些特征图被用来做物体检测。这个尺度转移模块由 mean pooling 层和像素重排层构成。Mean pooling 层用来获得低分辨率的特征图；像素重排层通过压缩特征图的通道数来扩大特征图的分辨率，没有额外的计算开销。尺度转移模块可以直接嵌入到 DenseNet 网络中，不需要在 DenseNet 网络之后添加额外的层就能获得多尺度的特征图。而且像素重排层可以有效地压缩 DenseNet 网络特征图的通道数，从而减少之后卷积层的参数数量。作者在 pascal voc07 和 coco 数据集上取得了不错的检测性能，对构建开销较小的物体检测器具有一定的启发意义。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;line-height: 1.75em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;注：上海交通大学电子系人工智能实验室由倪冰冰教授、徐奕教授领衔，杨小康教授、张文军教授指导 &lt;/span&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3287671232876712&quot; data-s=&quot;300,640&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0JZxz5ovG7gL67yGQmoN7cKRk8EfHpuibXtdTP5lajgBIicEgEnWYzibP1BnWtKCOmZEibzX09iaSXrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; width=&quot;50px&quot; style=&quot;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 50px !important;visibility: visible !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;本文为机器之心报道，&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;br style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;strong style=&quot;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;&lt;span style=&quot;max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;&quot;&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;script nonce=&quot;672743122&quot; type=&quot;text/javascript&quot;&gt;
                    var first_sceen__time = (+new Date());

                    if (&quot;&quot; == 1 &amp;&amp; document.getElementById(&#39;js_content&#39;)) {
                        document.getElementById(&#39;js_content&#39;).addEventListener(&quot;selectstart&quot;,function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf(&quot;WindowsWechat&quot;) != -1){
                            var link = document.createElement(&#39;link&#39;);
                            var head = document.getElementsByTagName(&#39;head&#39;)[0];
                            link.rel = &#39;stylesheet&#39;;
                            link.type = &#39;text/css&#39;;
                            link.href = &quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css&quot;;
                            head.appendChild(link);
                        }
                    })();
                &lt;/script&gt;
                
                
                                
                &lt;div class=&quot;ct_mpda_wrp&quot; id=&quot;js_sponsor_ad_area&quot; style=&quot;display:none;&quot;&gt;&lt;/div&gt;

                
                                &lt;div class=&quot;reward_area tc&quot; id=&quot;js_preview_reward&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p id=&quot;js_preview_reward_wording&quot; class=&quot;tips_global reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;p&gt;
                        &lt;a class=&quot;reward_access&quot; id=&quot;js_preview_reward_link&quot; href=&quot;##&quot;&gt;&lt;span class=&quot;icon-reward&quot;&gt;&lt;/span&gt;赞赏&lt;/a&gt;

                    &lt;/p&gt;
                &lt;/div&gt;
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_preview_reward_qrcode&quot; style=&quot;display:none;&quot;&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;长按二维码向我转账&lt;/p&gt;
                    &lt;p id=&quot;js_preview_reward_ios_wording&quot; class=&quot;reward_tips&quot; style=&quot;display:none;&quot;&gt;&lt;/p&gt;
                    &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; src=&quot;//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png&quot;&gt;&lt;/span&gt;
                    &lt;p class=&quot;tips_global&quot;&gt;受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。&lt;/p&gt;
                &lt;/div&gt;
                            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_toobar3&quot;&gt;
                
                                
                                            &lt;div id=&quot;js_read_area3&quot; class=&quot;media_tool_meta tips_global meta_primary&quot; style=&quot;display:none;&quot;&gt;阅读 &lt;span id=&quot;readNum3&quot;&gt;&lt;/span&gt;&lt;/div&gt;

                &lt;span style=&quot;display:none;&quot; class=&quot;media_tool_meta meta_primary tips_global meta_praise&quot; id=&quot;like3&quot;&gt;
                    &lt;i class=&quot;icon_praise_gray&quot;&gt;&lt;/i&gt;&lt;span class=&quot;praise_num&quot; id=&quot;likeNum3&quot;&gt;&lt;/span&gt;
                &lt;/span&gt;

                &lt;a id=&quot;js_report_article3&quot; style=&quot;display:none;&quot; class=&quot;media_tool_meta tips_global meta_extra&quot; href=&quot;##&quot;&gt;投诉&lt;/a&gt;

            &lt;/div&gt;&lt;div class=&quot;rich_media_tool&quot; id=&quot;js_sg_bar&quot;&gt;
                
                                
                                
            &lt;/div&gt;</description>
<author></author>
<guid isPermaLink="false">2018-02-27-1000000615</guid>
<pubDate>Tue, 27 Feb 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
