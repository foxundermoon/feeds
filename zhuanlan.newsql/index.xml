<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sat, 25 Aug 2018 06:21:58 +0800</lastBuildDate>
<item>
<title>TiDB 2.1 RC1 Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-24-42900414.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42900414&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-547ba61d15cf1a27d999b7155098de96_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 8 月 24 日，TiDB 发布 2.1 RC1 版。相比 2.1 Beta 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;修复某些情况下关联子查询去关联后结果不正确的问题 &lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Explain&lt;/code&gt; 输出结果 &lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;IndexJoin&lt;/code&gt; 驱动表选择策略&lt;/li&gt;&lt;li&gt;去掉非 &lt;code class=&quot;inline&quot;&gt;PREPARE&lt;/code&gt; 语句的 Plan Cache&lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;INSERT&lt;/code&gt; 语句无法正常解析执行的问题&lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;IndexJoin&lt;/code&gt; 结果不正确的问题&lt;/li&gt;&lt;li&gt;修复某些情况下使用唯一索引不能查询到 &lt;code class=&quot;inline&quot;&gt;NULL&lt;/code&gt; 值的问题 &lt;/li&gt;&lt;li&gt;修复 UTF-8 编码情况下前缀索引的范围计算不正确的问题 &lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;Project&lt;/code&gt; 算子消除导致的结果不正确的问题 &lt;/li&gt;&lt;li&gt;修复主键为整数类型时无法使用 &lt;code class=&quot;inline&quot;&gt;USE INDEX(PRIMARY)&lt;/code&gt; 的问题 &lt;/li&gt;&lt;li&gt;修复某些情况下使用关联列无法计算索引范围的问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. SQL 执行引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复某些情况下夏令时时间计算结果不正确的问题&lt;/li&gt;&lt;li&gt;重构聚合函数框架，提升 &lt;code class=&quot;inline&quot;&gt;Stream&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;Hash&lt;/code&gt; 聚合算子的执行效率&lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;Hash&lt;/code&gt; 聚合算子不能正常退出的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;BIT_AND&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;BIT_OR&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;BIT_XOR&lt;/code&gt; 没有正确处理非整型数据的问题&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;REPLACE INTO&lt;/code&gt; 语句的执行速度，性能提升近 10 倍&lt;/li&gt;&lt;li&gt;优化时间类型的内存占用，时间类型数据的内存使用降低为原来的一半&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;UNION&lt;/code&gt; 语句整合有符号和无符号型整数结果时与 MySQL 不兼容的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;LPAD&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;RPAD&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;TO_BASE64&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;FROM_BASE64&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;REPEAT&lt;/code&gt; 因为申请过多内存导致 TiDB panic 的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;MergeJoin&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;IndexJoin&lt;/code&gt; 在处理 &lt;code class=&quot;inline&quot;&gt;NULL&lt;/code&gt; 值时结果不正确的问题&lt;/li&gt;&lt;li&gt;修复某些情况下 Outer Join 结果不正确的问题&lt;/li&gt;&lt;li&gt;增强 &lt;code class=&quot;inline&quot;&gt;Data Truncated&lt;/code&gt; 的报错信息，便于定位出错的数据和表中对应的字段&lt;/li&gt;&lt;li&gt;修复某些情况下 Decimal 计算结果不正确的问题&lt;/li&gt;&lt;li&gt;优化点查的查询性能&lt;/li&gt;&lt;li&gt;禁用 &lt;code class=&quot;inline&quot;&gt;Read Commited&lt;/code&gt; 隔离级别，避免潜在的问题 &lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;LTRIM&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;RTRIM&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;TRIM&lt;/code&gt; 结果不正确的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;MaxOneRow&lt;/code&gt; 算子无法保证返回结果不超过 1 行的问题&lt;/li&gt;&lt;li&gt;拆分 range 个数过多的 Coprocessor 请求&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 统计信息&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;优化统计信息动态收集机制&lt;/li&gt;&lt;li&gt;解决数据频繁更新场景下 &lt;code class=&quot;inline&quot;&gt;Auto Analyze&lt;/code&gt; 不工作的问题&lt;/li&gt;&lt;li&gt;减少统计信息动态更新过程中的写入冲突 &lt;/li&gt;&lt;li&gt;优化统计信息不准确情况下的代价估算&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;AccessPath&lt;/code&gt; 的代价估算策略 &lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. Server&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复加载权限信息时的 bug&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;Kill&lt;/code&gt; 命令对权限的检查过严问题&lt;/li&gt;&lt;li&gt;解决 Binary 协议中某些数值类型移除的问题&lt;/li&gt;&lt;li&gt;精简日志输出 &lt;/li&gt;&lt;li&gt;处理 &lt;code class=&quot;inline&quot;&gt;mismatchClusterID&lt;/code&gt; 问题&lt;/li&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;advertise-address&lt;/code&gt; 配置项&lt;/li&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;GrpcKeepAlive&lt;/code&gt; 选项&lt;/li&gt;&lt;li&gt;增加连接或者 &lt;code class=&quot;inline&quot;&gt;Token&lt;/code&gt; 时间监控&lt;/li&gt;&lt;li&gt;优化数据解码性能 &lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INFORMMATION_SCHEMA&lt;/code&gt; 中增加 &lt;code class=&quot;inline&quot;&gt;PROCESSLIST&lt;/code&gt; 表&lt;/li&gt;&lt;li&gt;解决权限验证时多条规则可以命中情况下的顺序问题&lt;/li&gt;&lt;li&gt;将部分编码相关的系统变量默认值改为 UTF-8 &lt;/li&gt;&lt;li&gt;慢查询日志显示更详细的信息&lt;/li&gt;&lt;li&gt;支持在 PD 注册 tidb-server 的相关信息并通过 HTTP API 获取 &lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;5. 兼容性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;Session&lt;/code&gt; 变量 &lt;code class=&quot;inline&quot;&gt;warning_count&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;error_count&lt;/code&gt; &lt;/li&gt;&lt;li&gt;读取系统变量时增加 Scope 检查&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;MAX_EXECUTION_TIME&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持更多的 &lt;code class=&quot;inline&quot;&gt;SET&lt;/code&gt; 语法 &lt;/li&gt;&lt;li&gt;Set 系统变量值过程中增加合法性校验&lt;/li&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;Prepare&lt;/code&gt; 语句中 &lt;code class=&quot;inline&quot;&gt;PlaceHolder&lt;/code&gt; 数量的校验&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;set character_set_results = null&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;flush status&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;SET&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;ENUM&lt;/code&gt;  类型在 &lt;code class=&quot;inline&quot;&gt;information_schema&lt;/code&gt; 里的 column size&lt;/li&gt;&lt;li&gt;支持建表语句里的 &lt;code class=&quot;inline&quot;&gt;NATIONAL CHARACTER&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;CHARACTER SET&lt;/code&gt; 语法 &lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;SET&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;ENUM&lt;/code&gt; 类型的 column info&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;CREATE USER&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;IDENTIFIED WITH&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;TIMESTAMP&lt;/code&gt; 类型计算过程中丢失精度的问题 &lt;/li&gt;&lt;li&gt;支持更多 &lt;code class=&quot;inline&quot;&gt;SYSTEM&lt;/code&gt; 变量的合法性验证&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;CHAR_LENGTH&lt;/code&gt; 函数在计算 binary string 时结果不正确的问题&lt;/li&gt;&lt;li&gt;修复在包含 &lt;code class=&quot;inline&quot;&gt;GROUP BY&lt;/code&gt; 的语句里 &lt;code class=&quot;inline&quot;&gt;CONCAT&lt;/code&gt; 结果不正确的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;DECIMAL&lt;/code&gt; 类型 CAST 到 &lt;code class=&quot;inline&quot;&gt;STRING&lt;/code&gt; 类型时，类型长度不准确的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;6. DML&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;解决 &lt;code class=&quot;inline&quot;&gt;Load Data&lt;/code&gt; 语句的稳定性 &lt;/li&gt;&lt;li&gt;解决一些 &lt;code class=&quot;inline&quot;&gt;Batch&lt;/code&gt; 操作情况下的内存使用问题 &lt;/li&gt;&lt;li&gt;提升 &lt;code class=&quot;inline&quot;&gt;Replace Into&lt;/code&gt; 语句的性能&lt;/li&gt;&lt;li&gt;修复写入 &lt;code class=&quot;inline&quot;&gt;CURRENT_TIMESTAMP&lt;/code&gt; 时，精度不一致的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;7. DDL&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;改进 DDL 判断 &lt;code class=&quot;inline&quot;&gt;Schema&lt;/code&gt; 是否已经同步的方法, 避免某些情况下的误判&lt;/li&gt;&lt;li&gt;修复在 &lt;code class=&quot;inline&quot;&gt;ADD INDEX&lt;/code&gt; 过程中的 &lt;code class=&quot;inline&quot;&gt;SHOW CREATE TABLE&lt;/code&gt; 结果&lt;/li&gt;&lt;li&gt;非严格 &lt;code class=&quot;inline&quot;&gt;sql-mode&lt;/code&gt; 模式下, &lt;code class=&quot;inline&quot;&gt;text&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;blob&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;json&lt;/code&gt; 的默认值可以为空 &lt;/li&gt;&lt;li&gt;修复某些特定场景下 &lt;code class=&quot;inline&quot;&gt;ADD INDEX&lt;/code&gt; 的问题&lt;/li&gt;&lt;li&gt;大幅度提升添加 &lt;code class=&quot;inline&quot;&gt;UNIQUE-KEY&lt;/code&gt; 索引操作的速度&lt;/li&gt;&lt;li&gt;修复 Prefix-index 在 UTF-8 字符集的场景下的截断问题&lt;/li&gt;&lt;li&gt;增加环境变量 &lt;code class=&quot;inline&quot;&gt;tidb_ddl_reorg_priority&lt;/code&gt; 来控制 &lt;code class=&quot;inline&quot;&gt;add-index&lt;/code&gt; 操作的优先级&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;information_schema.tables&lt;/code&gt; 中 &lt;code class=&quot;inline&quot;&gt;AUTO-INCREMENT&lt;/code&gt; 的显示问题 &lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;admin show ddl jobs &amp;lt;number&amp;gt;&lt;/code&gt; 命令, 支持输出 number 个 DDL jobs&lt;/li&gt;&lt;li&gt;支持并行 DDL 任务执行&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;8. &lt;a href=&quot;https://github.com/pingcap/tidb/projects/6&quot;&gt;Table Partition&lt;/a&gt;（实验性）&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;支持一级分区&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;Range Partition&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;引入版本控制机制，支持集群滚动兼容升级&lt;/li&gt;&lt;li&gt;开启 &lt;code class=&quot;inline&quot;&gt;Region merge&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;GetPrevRegion&lt;/code&gt; 接口&lt;/li&gt;&lt;li&gt;支持批量 &lt;code class=&quot;inline&quot;&gt;split Region&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持存储 GC safepoint&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 功能改进&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;优化系统时间回退影响 TSO 分配的问题&lt;/li&gt;&lt;li&gt;优化处理 Region heartbeat 的性能&lt;/li&gt;&lt;li&gt;优化 Region tree 性能&lt;/li&gt;&lt;li&gt;优化计算热点统计的性能问题&lt;/li&gt;&lt;li&gt;优化 API 接口错误码返回&lt;/li&gt;&lt;li&gt;新增一些控制调度策略的开关&lt;/li&gt;&lt;li&gt;禁止在 label 中使用特殊字符&lt;/li&gt;&lt;li&gt;完善调度模拟器&lt;/li&gt;&lt;li&gt;pd-ctl 支持使用统计信息进行 Region split&lt;/li&gt;&lt;li&gt;pd-ctl 支持调用 &lt;code class=&quot;inline&quot;&gt;jq&lt;/code&gt; 来格式化 JSON 输出&lt;/li&gt;&lt;li&gt;新增 etcd Raft 状态机相关 metrics&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. Bug 修复&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复 leader 切换后 namespace 未重新加载的问题&lt;/li&gt;&lt;li&gt;修复 namespace 调度超出 schedule limit 配置的问题&lt;/li&gt;&lt;li&gt;修复热点调度超出 schedule limit 的问题&lt;/li&gt;&lt;li&gt;修复 PD client 关闭时输出一些错误日志的问题&lt;/li&gt;&lt;li&gt;修复 Region 心跳延迟统计有误的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;batch split&lt;/code&gt;，防止热点 Region 写入产生超大 Region&lt;/li&gt;&lt;li&gt;支持设置根据数据行数 split Region，提升 index scan 效率&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 性能优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code class=&quot;inline&quot;&gt;LocalReader&lt;/code&gt; 将 Read 操作从 raftstore 线程分离，减少 Read 延迟&lt;/li&gt;&lt;li&gt;重构 MVCC 框架，优化 memory 使用，提升 scan read 性能&lt;/li&gt;&lt;li&gt;支持基于统计估算进行 Region split，减少 I/O 开销&lt;/li&gt;&lt;li&gt;优化连续写入 Rollback 记录后影响读性能的问题&lt;/li&gt;&lt;li&gt;减少下推聚合计算的内存开销&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 功能改进&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;增加大量内建函数下推支持，更完善的 charset 支持&lt;/li&gt;&lt;li&gt;优化 GC 流程，提升 GC 速度并降低 GC 对系统的影响&lt;/li&gt;&lt;li&gt;开启 &lt;code class=&quot;inline&quot;&gt;prevote&lt;/code&gt;，加快网络异常时的恢复服务速度&lt;/li&gt;&lt;li&gt;增加 RocksDB 日志文件相关的配置项&lt;/li&gt;&lt;li&gt;调整 &lt;code class=&quot;inline&quot;&gt;scheduler latch&lt;/code&gt; 默认配置&lt;/li&gt;&lt;li&gt;使用 tikv-ctl 手动 compact 时可设定是否 compact RocksDB 最底层数据&lt;/li&gt;&lt;li&gt;增加启动时的环境变量检查&lt;/li&gt;&lt;li&gt;支持基于已有数据动态设置 &lt;code class=&quot;inline&quot;&gt;dynamic_level_bytes&lt;/code&gt; 参数&lt;/li&gt;&lt;li&gt;支持自定义日志格式&lt;/li&gt;&lt;li&gt;tikv-ctl 整合 tikv-fail 工具&lt;/li&gt;&lt;li&gt;增加 threads IO metrics&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. Bug 修复&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复 decimal 相关问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;gRPC max_send_message_len&lt;/code&gt; 设置有误的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;region_size&lt;/code&gt; 配置不当时产生的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如今，在社区和 PingCAP 技术团队的共同努力下，TiDB 2.1 RC1 版已发布，在此感谢社区小伙伴们长久以来的参与和贡献。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;作为明星级开源的分布式关系型数据库，TiDB 灵感来自于 Google Spanner/F1，具备『分布式强一致性事务、在线弹性水平扩展、故障自恢复的高可用、跨数据中心多活』等核心特性。TiDB 于 2015 年 5 月在 GitHub 创建，同年 12 月发布 Alpha 版本，而后于 2016 年 6 月发布 Beta 版，12 月发布 RC1 版， 2017 年 3 月发布 RC2 版，6 月发布 RC3 版，8 月发布 RC4 版，10 月发版 TiDB 1.0，2018 年 3 月发版 2.0 RC1，4 月发版 2.0 GA。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-24-42900414</guid>
<pubDate>Fri, 24 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>【详解】What’s New in TiDB 2.1 RC1</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-24-42900183.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42900183&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c5471d4c277c4314ece59344787b7a49_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 4 月底，我们发布了 TiDB 2.0 GA 版本，过去的几个月中，这个版本在上百家用户的生产环境中上线，覆盖了多个行业，包括大型互联网、银行、教育、电信、制造业等。与此同时，我们也开始了 2.1 版本的开发，经过 4 个月时间、1058 次代码提交，2.1 RC1 带着更全面的功能和大幅性能提升来到这里，与大家见面。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;新增特性&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Raft 新特性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Raft 是整个 TiKV 存储引擎的基础，2.1 版本中我们引入了 PreVote、Learner、Region Merge、Region Batch Split 这样四个特性，提升这一基础组件的性能和稳定性。其中 Learner 也是由我们贡献给 Etcd 的新特性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;热点调度&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;热点是分布式系统最大的敌人之一，并且大家的业务场景复杂多变，让热点问题捉摸不定，也是最狡猾的敌人。2.1 版本中，我们一方面增强热点检测能力，尽可能详细地统计系统负载，更快的发现热点；另一方面优化热点调度策略，用尽可能小的代价，尽快地打散热点。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;并行 DDL&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DDL 是 SQL 的基础。在 2.1 版本之前，所有的 DDL 操作的都是串行进行，比如在对一张大表进行 Add Index 操作时，所有的 Create Table、Create Database 语句都会被阻塞，我们在 2.1 版本中对此进行了优化。Add Index 操作和其他 DDL 操作的处理分离，不相关的表上面的操作不会相互阻塞。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Table Partition（实验性）&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;分布式数据库可以很容易的存储海量数据，但是 Table Parition 也能找到用武之地。比如在存储日志并定期进行数据归档的场景下，可以通过 Drop Partition 来方便的清理历史数据。在高并发写入的场景下，将单表数据分成多个 Parition 也有助于将写入流量打散在集群上。我们期望这个特性能够在 2.2 或者 3.0 版本中稳定下来。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;统计信息动态更新&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 OLTP 场景中，数据的统计分布决定了查询计划的合理性，在数据变化频繁的场景下，维护统计信息的实时性和准确性非常重要。2.1 版本中我们重点优化了统计信息的实时更新，通过执行查询过程中的反馈信息，不断地纠正已有的统计信息。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;并行聚合算子&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 OLAP 场景中，聚合和 Join 是最重要的两个算子，其性能决定了语句的处理速度，Join 算子在 2.0 版本中已经是并行模式，2.1 版本中我们对聚合算子做了重点优化，一方面将单线程变成多线程模式，另一方面对聚合的框架做了重构，聚合算子的运行速度、内存使用效率都有极大地提升。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;性能优化&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的定位是一个 HTAP 数据库，OLTP 和 OLAP 都是目标场景。2.1 RC1 版本中，我们对点查、区间扫描、聚合运算这些通用场景进行了优化，也对 “replace into” 语句， Add Index 这些特定场景做了优化。这些场景都有很好的性能提升，有的甚至有数量级的提升。&lt;/p&gt;&lt;p&gt;我们将会在 2.1 GA 版本中发布相比 2.0 GA 的 Benchmark 结果，也希望大家在自己的业务场景中实测对比，然后告诉我们在实际业务上的表现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;开源社区&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在这些激动人心的特性背后，一方面是 PingCAP 开发团队的辛勤工作，另一方面是日益壮大的 TiDB 全球社区。我们欣喜地看到，从 TiDB 2.1 Beta 版发布到现在的短短两个月时间，新增 30 多位 Contributor，其中杜川成为了 TiDB Committer。在这里对社区贡献者表示由衷的感谢，也希望更多志同道合的人能加入进来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;做分布式关系型数据库这样一个通用基础软件如同在夜晚的茫茫大海中航行，充满无数的未知和挑战，社区就是照亮我们前进路线的满天星斗。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;TiDB 2.1 Beta 版到 RC1 版期间新增 Contributor List&lt;/b&gt;&lt;br&gt;mz1999&lt;br&gt;liuzhengyang&lt;br&gt;cityonsky&lt;br&gt;mail2fish&lt;br&gt;ceohockey60&lt;br&gt;crazycs520&lt;br&gt;zbdba&lt;br&gt;laidahe&lt;br&gt;birdstorm&lt;br&gt;gregwebs&lt;br&gt;hhxcc&lt;br&gt;liukun4515&lt;br&gt;morgo&lt;br&gt;supernan1994&lt;br&gt;bb7133&lt;br&gt;maninalift&lt;br&gt;kbacha&lt;br&gt;ceohockey60&lt;br&gt;DorianZheng&lt;br&gt;GuillaumeGomez&lt;br&gt;TennyZhuang&lt;br&gt;lerencao&lt;br&gt;smallyard&lt;br&gt;sweetIan&lt;br&gt;arosspope&lt;br&gt;York Xiang&lt;br&gt;Mason Hua&lt;br&gt;ice1000&lt;br&gt;opensourcegeek&lt;br&gt;xiangyuf&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-24-42900183</guid>
<pubDate>Fri, 24 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Operator 开源技术细节详解</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-23-42752388.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42752388&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-48f8f9e31ea70d19e831ccc983565e3b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;原标题：TiDB Operator，让 TiDB 成为真正的 Cloud-Native 数据库&lt;/i&gt;&lt;/p&gt;&lt;p&gt;TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具。目前，TiDB Operator 已正式开源（&lt;a href=&quot;https://github.com/pingcap/tidb-operator/&quot;&gt;pingcap/tidb-operator&lt;/a&gt;）。借助 TiDB Operator，TiDB 可以无缝运行在公有云厂商提供的 Kubernetes 平台上，让 TiDB 成为真正的 Cloud-Native 数据库。&lt;/p&gt;&lt;p&gt;要了解 TiDB Operator，首先需要对 TiDB 和 Kubernetes 有一定了解，相信长期以来一直关注 TiDB 的同学可能对 TiDB 已经比较熟悉了。本文将首先简单介绍一下 TiDB 和 Kubernetes，聊一聊为什么我们要做 TiDB Operator，然后讲讲如何快速体验 TiDB Operator，以及如何参与到 TiDB Operator 项目中来成为 Contributor。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 和 Kubernetes 简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 作为一个开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。&lt;/li&gt;&lt;li&gt;TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。&lt;/li&gt;&lt;li&gt;PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ad51136bfaadda2d121e2f0c54d171e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;312&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2ad51136bfaadda2d121e2f0c54d171e&quot; data-watermark-src=&quot;v2-631273bf6d410f73038521245f886545&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Kubernetes 最早是作为一个纯粹的容器编排系统而诞生的，用户部署好 Kubernetes 集群之后，直接使用其内置的各种功能部署应用服务。&lt;/p&gt;&lt;p&gt;由于这个 PaaS 平台使用起来非常便利，吸引了很多用户，不同用户也提出了各种不同的需求。有些特性需求 Kubernetes 直接在其核心代码里面实现了，但是有些特性并不适合合并到主干分支。&lt;/p&gt;&lt;p&gt;为满足这类需求，Kubernetes 开放出一些 API 供用户自己扩展，实现自己的需求。当前 Kubernetes 内部的 API 变得越来越开放，使其更像是一个跑在云上的操作系统。用户可以把它当作一套云的 SDK 或 Framework 来使用，而且可以很方便地开发组件来扩展满足自己的业务需求。对有状态服务的支持就是一个很有代表性的例子。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么我们要做 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第一，使用传统的自动化工具带来了很高的部署和运维成本。TiDB 的分层架构对于分布式系统是比较常见的，各个组件都可以根据业务需求独立水平伸缩，并且 TiKV 和 TiDB 都可以独立使用。比如，在 TiKV 之上可以构建兼容 Redis 协议的 KV 数据库，而 TiDB 也可以对接 LevelDB 这样的 KV 存储引擎。&lt;/p&gt;&lt;p&gt;但是，这种多组件的分布式系统增加了手工部署和运维的成本。一些传统的自动化部署和运维工具如 Puppet/Chef/SaltStack/Ansible，由于缺乏全局状态管理，不能及时对各种异常情况做自动故障转移，并且很难发挥分布式系统的弹性伸缩能力。其中有些还需要写大量的 DSL 甚至与 Shell 脚本一起混合使用，可移植性较差，维护成本比较高。&lt;/p&gt;&lt;p&gt;第二，在云时代，容器成为应用分发部署的基本单位，而谷歌基于内部使用数十年的容器编排系统 Borg 经验推出的开源容器编排系统 Kubernetes 成为当前容器编排技术事实上的标准。如今各大云厂商都开始提供托管的 Kubernetes 集群，部署在 Kubernetes 平台的应用可以不用绑定在特定云平台，轻松实现在各种云平台之间的迁移，其容器化打包和发布方式也解决了对操作系统环境的依赖。&lt;/p&gt;&lt;p&gt;Kubernetes 项目最早期只支持无状态服务（Stateless Service）的管理。无状态服务通过 ReplicationController 定义多个副本，由 Kubernetes 调度器来决定在不同节点上启动多个 Pod，实现负载均衡和故障转移。对于无状态服务，多个副本对应的 Pod 是等价的，所以在节点出现故障时，在新节点上启动一个 Pod 与失效的 Pod 是等价的，不会涉及状态迁移问题，因而管理非常简单。&lt;/p&gt;&lt;p&gt;但是对于有状态服务（Stateful Service），由于需要将数据持久化到磁盘，使得不同 Pod 之间不能再认为成等价，也就不能再像无状态服务那样随意进行调度迁移。&lt;/p&gt;&lt;p&gt;Kubernetes v1.3 版本提出 PetSet 的概念，用来管理有状态服务并于 v1.5 将其更名为 StatefulSet。StatefulSet 明确定义一组 Pod 中每个的身份，启动和升级都按特定顺序来操作。另外使用持久化卷存储（PersistentVolume）来作为存储数据的载体，当节点失效 Pod 需要迁移时，对应的 PV 也会重新挂载，而 PV 的底层依托于分布式文件系统，所以 Pod 仍然能访问到之前的数据。同时 Pod 在发生迁移时，其网络身份例如 IP 地址是会发生变化的，很多分布式系统不能接受这种情况。所以 StatefulSet 在迁移 Pod 时可以通过绑定域名的方式来保证 Pod 在集群中网络身份不发生变化。&lt;/p&gt;&lt;p&gt;但是由于有状态服务的特殊性，当节点出现异常时，出于数据安全性考虑，Kubernetes 并不会像无状态服务那样自动做故障转移。尽管网络存储能挂载到不同的节点上供其上的 Pod 使用，但是如果出现节点故障时，简单粗暴地将网络 PV 挂载到其它节点上是比较危险的。&lt;/p&gt;&lt;p&gt;Kubernetes 判断节点故障是基于部署在每个节点上的 Kubelet 服务是否能正常上报节点状态，Kubelet 能否正常工作与用户应用并没有必然联系，在一些特殊情况下，Kubelet 服务进程可能无法正常启动，但是节点上的业务容器还在运行，将 PV 再挂载到其它节点可能会出现双写问题。&lt;/p&gt;&lt;p&gt;为了在 Kubernetes 上部署和管理 TiDB 这种有状态的服务，我们需要扩展 StatefulSet 的功能。TiDB Operator 正是基于 Kubernetes 内置的 StatefulSet 开发的 TiDB 集群管理和运维工具。&lt;/p&gt;&lt;p&gt;Kubernetes 直到 v1.7 才试验性引入本地 PV，在这之前只有网络 PV，TiKV 自身在存储数据时就是多副本的，网络 PV 的多副本会增加数据冗余，降低 TiDB 的性能。在这之前我们基于 Kubernetes 内置的 hostPath volume 实现了本地 PV 满足 TiKV 对磁盘 IO 的要求。官方本地 PV 方案直到最近的 Kubernetes v1.10 才相对稳定地支持调度功能，满足用户对本地 PV 的需求。为了降低用户的使用和管理成本并且拥抱 Kubernetes 开源社区，我们又重新基于官方的本地 PV 方案实现了对数据的管理。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Operator 原理解析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Operator 本质上是 Kubernetes 的控制器（Controller），其核心思想是用户给定一个 Spec 描述文件，Controller 根据 Spec 的变化，在 Kubernetes 集群中创建对应资源，并且不断调整资源使其状态满足用户预期的 Spec。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-78ccc29e59b2fb801becd9a21a21f2c4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;326&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-78ccc29e59b2fb801becd9a21a21f2c4&quot; data-watermark-src=&quot;v2-ef84de5460a9792d5e27f7800786473c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图是 TiDB Operator 工作流程原理图，其中 TidbCluster 是通过 CRD（Custom Resource Definition）扩展的内置资源类型：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户通过 Helm 往 Kubernetes API Server 创建或更新 TidbCluster 对象。&lt;/li&gt;&lt;li&gt;TiDB Operator 通过 watch API Server 中的 TidbCluster 对象创建更新或删除，维护 PD/TiKV/TiDB StatefulSet, Service 和 Deployment 对象更新。&lt;/li&gt;&lt;li&gt;Kubernetes 根据 StatefulSet, Service 和 Deployment 对象创建更新或删除对应的容器和服务。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在第 2 步中，TiDB Operator 在更新 StatefulSet 等对象时会参考 PD API 给出的集群状态来做出 TiDB 集群的运维处理。通过 TiDB Operator 和 Kubernetes 的动态调度处理，创建出符合用户预期的 TiDB 集群。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;快速体验 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB Operator 需要运行在 Kubernetes v1.10 及以上版本。TiDB Operator 和 TiDB 集群的部署和管理是通过 Kubernetes 平台上的包管理工具 Helm 实现的。运行 TiDB Operator 前请确保 Helm 已经正确安装在 Kubernetes 集群里。&lt;/p&gt;&lt;p&gt;如果没有 Kubernetes 集群，可以通过 TiDB Operator 提供的脚本快速在本地启动一个多节点的 Kubernetes 集群：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;git clone https://github.com/pingcap/tidb-operator
cd tidb-operator
NUM_NODES=3    # the default node number is 2
KUBE_REPO_PREFIX=uhub.ucloud.cn/pingcap manifests/local-dind/dind-cluster-v1.10.sh up&lt;/code&gt;&lt;p&gt;等 Kubernetes 集群准备好，就可以通过 Helm 和 Kubectl 安装部署 TiDB Operator 和 TiDB 集群了。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;安装 TiDB Operator&lt;/li&gt;&lt;/ol&gt;&lt;code lang=&quot;text&quot;&gt;kubectl apply -f manifests/crd.yaml
helm install charts/tidb-operator --name=tidb-operator --namespace=tidb-admin&lt;/code&gt;&lt;p&gt;2. 部署 TiDB 集群&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;helm install charts/tidb-cluster --name=demo-tidb --namespace=tidb --set clusterName=demo&lt;/code&gt;&lt;p&gt;集群默认使用 local-storage 作为 PD 和 TiKV 的数据存储，如果想使用其它持久化存储，需要修改 charts/tidb-cluster/values.yaml 里面的 storageClassName。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参与 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB Operator 让 TiDB 成为真正意义上的 Cloud-Native 数据库，开源只是一个起点，需要 TiDB 社区和 Kubernetes 社区的共同参与。&lt;/p&gt;&lt;p&gt;大家在使用过程发现 bug 或缺失什么功能，都可以直接在 GitHub 上面提 issue 或 PR，一起参与讨论。要想成为 Contributor 具体可以参考 &lt;a href=&quot;https://github.com/pingcap/tidb-operator/blob/master/docs/CONTRIBUTING.md&quot;&gt;这个文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;作者：邓栓&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-23-42752388</guid>
<pubDate>Thu, 23 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十六）INSERT 语句详解</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-17-42287696.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42287696&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-dbb96df5fd6db3b140bfbe6de5aaf9c0_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：于帅鹏&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在之前的一篇文章 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;《TiDB 源码阅读系列文章（四）INSERT 语句概览》&lt;/a&gt; 中，我们已经介绍了 INSERT 语句的大体流程。为什么需要为 INSERT 单独再写一篇？因为在 TiDB 中，单纯插入一条数据是最简单的情况，也是最常用的情况；更为复杂的是在 INSERT 语句中设定各种行为，比如，对于 Unique Key 冲突的情况应如何处理：是报错？是忽略当前插入的数据？还是覆盖已有数据？所以，这篇会为大家继续深入介绍 INSERT 语句。&lt;/p&gt;&lt;p&gt;本文将首先介绍在 TiDB 中的 INSERT 语句的分类，以及各语句的语法和语义，然后分别介绍五种 INSERT 语句的源码实现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT 语句的种类&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;从广义上讲，TiDB 有以下六种 INSERT 语句：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;REPLACE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这六种语句理论上都属于 INSERT 语句。&lt;/p&gt;&lt;p&gt;第一种，&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;，即是最普通的 INSERT 语句，语法 &lt;code class=&quot;inline&quot;&gt;INSERT INTO VALUES ()&lt;/code&gt;，语义为插入一条语句，若发生唯一约束冲突（主键冲突、唯一索引冲突），则返回执行失败。&lt;/p&gt;&lt;p&gt;第二种，语法 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE INTO VALUES ()&lt;/code&gt;，是当 INSERT 的时候遇到唯一约束冲突后，忽略当前 INSERT 的行，并记一个 warning。当语句执行结束后，可以通过 &lt;code class=&quot;inline&quot;&gt;SHOW WARNINGS&lt;/code&gt; 看到哪些行没有被插入。&lt;/p&gt;&lt;p&gt;第三种，语法 &lt;code class=&quot;inline&quot;&gt;INSERT INTO VALUES () ON DUPLICATE KEY UPDATE&lt;/code&gt;，是当冲突后，更新冲突行后插入数据。如果更新后的行跟表中另一行冲突，则返回错误。&lt;/p&gt;&lt;p&gt;第四种，是在上一种情况，更新后的行又跟另一行冲突后，不插入该行并显示为一个 warning。&lt;/p&gt;&lt;p&gt;第五种，语法 &lt;code class=&quot;inline&quot;&gt;REPLACE INTO VALUES ()&lt;/code&gt;，是当冲突后，删除表上的冲突行，并继续尝试插入数据，如再次冲突，则继续删除标上冲突数据，直到表上没有与改行冲突的数据后，插入数据。&lt;/p&gt;&lt;p&gt;最后一种，语法 &lt;code class=&quot;inline&quot;&gt;LOAD DATA INFILE INTO&lt;/code&gt; 的语义与 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 相同，都是冲突即忽略，不同的是 &lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 的作用是将数据文件导入到表中，也就是其数据来源于 csv 数据文件。&lt;/p&gt;&lt;p&gt;由于 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt; 是在 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 上做了些特殊处理，将不再单独详细介绍，而是放在同一小节中介绍；&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 由于其自身的特殊性，将留到其他篇章介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Basic INSERT 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;几种 INSERT 语句的最大不同在于执行层面，这里接着 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;《TiDB 源码阅读系列文章（四）INSERT 语句概览》&lt;/a&gt; 来讲语句执行过程。不记得前面内容的同学可以返回去看原文章。&lt;/p&gt;&lt;p&gt;INSERT 的执行逻辑在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert.go&quot;&gt;executor/insert.go&lt;/a&gt; 中。其实前面讲的前四种 INSERT 的执行逻辑都在这个文件里。这里先讲最普通的 &lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;InsertExec&lt;/code&gt; 是 INSERT 的执行器实现，其实现了 Executor 接口。最重要的是下面三个接口：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Open：进行一些初始化&lt;/li&gt;&lt;li&gt;Next：执行写入操作&lt;/li&gt;&lt;li&gt;Close：做一些清理工作&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中最重要也是最复杂的是 Next 方法，根据是否通过一个 SELECT 语句来获取数据（&lt;code class=&quot;inline&quot;&gt;INSERT SELECT FROM&lt;/code&gt;），将 Next 流程分为，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L180:24&quot;&gt;insertRows&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L277:24&quot;&gt;insertRowsFromSelect&lt;/a&gt; 两个流程。两个流程最终都会进入 &lt;code class=&quot;inline&quot;&gt;exec&lt;/code&gt; 函数，执行 INSERT。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;exec&lt;/code&gt; 函数里处理了前四种 INSERT 语句，其中本节要讲的普通 INSERT 直接进入了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在讲 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 之前，我们先看一段 SQL。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (i INT UNIQUE);
INSERT INTO t VALUES (1);
BEGIN;
INSERT INTO t VALUES (1);
COMMIT;&lt;/code&gt;&lt;p&gt;把这段 SQL 分别一行行地粘在 MySQL 和 TiDB 中看下结果。&lt;/p&gt;&lt;p&gt;MySQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;mysql&amp;gt; CREATE TABLE t (i INT UNIQUE);
Query OK, 0 rows affected (0.15 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;i&#39;
mysql&amp;gt; COMMIT;
Query OK, 0 rows affected (0.11 sec)&lt;/code&gt;&lt;p&gt;TiDB：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;mysql&amp;gt; CREATE TABLE t (i INT UNIQUE);
Query OK, 0 rows affected (1.04 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.12 sec)

mysql&amp;gt; BEGIN;
Query OK, 0 rows affected (0.01 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; COMMIT;
ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;i&#39;&lt;/code&gt;&lt;p&gt;可以看出来，对于 INSERT 语句 TiDB 是在事务提交的时候才做冲突检测而 MySQL 是在语句执行的时候做的检测。这样处理的原因是，TiDB 在设计上，与 TiKV 是分层的结构，为了保证高效率的执行，在事务内只有读操作是必须从存储引擎获取数据，而所有的写操作都事先放在单 TiDB 实例内事务自有的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/kv/memdb_buffer.go#L31&quot;&gt;memDbBuffer&lt;/a&gt; 中，在事务提交时才一次性将事务写入 TiKV。在实现中是在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 中设置了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/e28a81813cfd290296df32056d437ccd17f321fe/kv/kv.go#L23&quot;&gt;PresumeKeyNotExists&lt;/a&gt; 选项，所有的 INSERT 操作如果在本地检测没发现冲突，就先假设插入不会发生冲突，不需要去 TiKV 中检查冲突数据是否存在，只将这些数据标记为待检测状态。最后到提交过程中，统一将整个事务里待检测数据使用 &lt;code class=&quot;inline&quot;&gt;BatchGet&lt;/code&gt; 接口做一次批量检测。&lt;/p&gt;&lt;p&gt;当所有的数据都通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 执行完插入后，INSERT 语句基本结束，剩余的工作为设置一下 lastInsertID 等返回信息，并最终将其结果返回给客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT IGNORE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 的语义在前面已经介绍了。之前介绍了普通 INSERT 在提交的时候才检查，那 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 是否可以呢？答案是不行的。因为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 如果在提交时检测，那事务模块就需要知道哪些行需要忽略，哪些直接报错回滚，这无疑增加了模块间的耦合。&lt;/li&gt;&lt;li&gt;用户希望立刻获取 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 有哪些行没有写入进去。即，立刻通过 &lt;code class=&quot;inline&quot;&gt;SHOW WARNINGS&lt;/code&gt; 看到哪些行实际没有写入。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这就需要在执行 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 的时候，及时检查数据的冲突情况。一个显而易见的做法是，把需要插入的数据试着读出来，当发现冲突后，记一个 warning，再继续下一行。但是对于一个语句插入多行的情况，就需要反复从 TiKV 读取数据来进行检测，显然，这样的效率并不高。于是，TiDB 实现了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt;，代码在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/batch_checker.go&quot;&gt;executor/batch_checker.go&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt; 中，首先，拿待插入的数据，将其中可能冲突的唯一约束在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L85:24&quot;&gt;getKeysNeedCheck&lt;/a&gt; 中构造成 Key（TiDB 是通过构造唯一的 Key 来实现唯一约束的，详见 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-2/&quot;&gt;《三篇文章了解 TiDB 技术内幕——说计算》&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;然后，将构造出来的 Key 通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 一次性读上来，得到一个 Key-Value map，能被读到的都是冲突的数据。&lt;/p&gt;&lt;p&gt;最后，拿即将插入的数据的 Key 到 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 的结果中进行查询。如果查到了冲突的行，构造好 warning 信息，然后开始下一行，如果查不到冲突的行，就可以进行安全的 INSERT 了。这部分的实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L490:24&quot;&gt;batchCheckAndInsert&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;同样，在所有数据执行完插入后，设置返回信息，并将执行结果返回客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT ON DUPLICATE KEY UPDATE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 是几种 INSERT 语句中最为复杂的。其语义的本质是包含了一个 INSERT 和 一个 UPDATE。较之与其他 INSERT 复杂的地方就在于，UPDATE 语义是可以将一行更新成任何合法的样子。&lt;/p&gt;&lt;p&gt;在上一节中，介绍了 TiDB 中对于特殊的 INSERT 语句采用了 batch 的方式来实现其冲突检查。在处理 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 的时候我们采用了同样的方式，但由于语义的复杂性，实现步骤也复杂了不少。&lt;/p&gt;&lt;p&gt;首先，与 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 相同，首先将待插入数据构造出来的 Key，通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 一次性地读出来，得到一个 Key-Value map。再把所有读出来的 Key 对应的表上的记录也通过一次 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 读出来，这部分数据是为了将来做 UPDATE 准备的，具体实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L225:24&quot;&gt;initDupOldRowValue&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;然后，在做冲突检查的时候，如果遇到冲突，则首先进行一次 UPDATE。我们在前面 Basic INSERT 小节中已经介绍了，TiDB 的 INSERT 是提交的时候才去 TiKV 真正执行。同样的，UPDATE 语句也是在事务提交的时候才真正去 TiKV 执行的。在这次 UPDATE 中，可能还是会遇到唯一约束冲突的问题，如果遇到了，此时即报错返回，如果该语句是 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt; 则会忽略这个错误，继续下一行。&lt;/p&gt;&lt;p&gt;在上一步的 UPDATE 中，还需要处理以下场景，如下面这个 SQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (i INT UNIQUE);
INSERT INTO t VALUES (1), (1) ON DUPLICATE KEY UPDATE i = i;&lt;/code&gt;&lt;p&gt;可以看到，这个 SQL 中，表中原来并没有数据，第二句的 INSERT 也就不可能读到可能冲突的数据，但是，这句 INSERT 本身要插入的两行数据之间冲突了。这里的正确执行应该是，第一个 1 正常插入，第二个 1 插入的时候发现有冲突，更新第一个 1。此时，就需要做如下处理。将上一步被 UPDATE 的数据对应的 Key-Value 从第一步的 Key-Value map 中删掉，将 UPDATE 出来的数据再根据其表信息构造出唯一约束的 Key 和 Value，把这个 Key-Value 对放回第一步读出来 Key-Value map 中，用于后续数据进行冲突检查。这个细节的实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/2fba9931c7ffbb6dd939d5b890508eaa21281b4f/executor/batch_checker.go#L232&quot;&gt;fillBackKeys&lt;/a&gt;。这种场景同样出现在，其他 INSERT 语句中，如 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;REPLACE&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt;。之所以在这里介绍是因为，&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 是最能完整展现 &lt;code class=&quot;inline&quot;&gt;batchChecker&lt;/code&gt; 的各方面的语句。&lt;/p&gt;&lt;p&gt;最后，同样在所有数据执行完插入/更新后，设置返回信息，并将执行结果返回客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;REPLACE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;REPLACE 语句虽然它看起来像是独立的一类 DML，实际上观察语法的话，它与 &lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt; 只是把 INSERT 换成了 REPLACE。与之前介绍的所有 INSERT 语句不同的是，REPLACE 语句是一个一对多的语句。简要说明一下就是，一般的 INSERT 语句如果需要 INSERT 某一行，那将会当遭遇了唯一约束冲突的时候，出现以下几种处理方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;放弃插入，报错返回：&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;&lt;/li&gt;&lt;li&gt;放弃插入，不报错：&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;放弃插入，改成更新冲突的行，如果更新的值再次冲突&lt;/li&gt;&lt;li&gt;报错：&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;不报错：&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;他们都是处理一行数据跟表中的某一行冲突时的不同处理。但是 REPLACE 语句不同，它将会删除遇到的所有冲突行，直到没有冲突后再插入数据。如果表中有 5 个唯一索引，那有可能有 5 条与等待插入的行冲突的行。那么 REPLACE 语句将会一次性删除这 5 行，再将自己插入。看以下 SQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (
i int unique, 
j int unique, 
k int unique, 
l int unique, 
m int unique);

INSERT INTO t VALUES 
(1, 1, 1, 1, 1), 
(2, 2, 2, 2, 2), 
(3, 3, 3, 3, 3), 
(4, 4, 4, 4, 4);

REPLACE INTO t VALUES (1, 2, 3, 4, 5);

SELECT * FROM t;
i j k l m
1 2 3 4 5&lt;/code&gt;&lt;p&gt;在执行完之后，实际影响了 5 行数据。&lt;/p&gt;&lt;p&gt;理解了 REPLACE 语句的特殊性以后，我们就可以更容易理解其具体实现。&lt;/p&gt;&lt;p&gt;与 INSERT 语句类似，REPLACE 语句的主要执行部分也在其 Next 方法中，与 INSERT 不同的是，其中的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L277:24&quot;&gt;insertRowsFromSelect&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L180:24&quot;&gt;insertRows&lt;/a&gt; 传递了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L27&quot;&gt;ReplaceExec&lt;/a&gt; 自己的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L160&quot;&gt;exec&lt;/a&gt; 方法。在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L160&quot;&gt;exec&lt;/a&gt; 中调用了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L95&quot;&gt;replaceRow&lt;/a&gt;，其中同样使用了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt; 中的批量冲突检测，与 INSERT 有所不同的是，这里会删除一切检测出的冲突，最后将待插入行写入。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;INSERT 语句是所有 DML 语句中最复杂，功能最强大多变的一个。其既有像 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE UPDATE&lt;/code&gt; 这种能执行 INSERT 也能执行 UPDATE 的语句，也有像 REPLACE 这种一行数据能影响许多行数据的语句。INSERT 语句自身都可以连接一个 SELECT 语句作为待插入数据的输入，因此，其又受到了来自 planner 的影响（关于 planner 的部分详见相关的源码阅读文章： &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt; 和 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt; ）。熟悉 TiDB 的 INSERT 各个语句实现，可以帮助各位读者在将来使用这些语句时，更好地根据其特色使用最为合理、高效语句。另外，如果有兴趣向 TiDB 贡献代码的读者，也可以通过本文更快的理解这部分的实现。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-17-42287696</guid>
<pubDate>Fri, 17 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读（十五） Sort Merge Join</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-08-41535500.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41535500&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e445e0a331d683cab8f11fda36478022_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/5202d0b6a9c623e0674ff36891c8ab52&quot; data-hash=&quot;5202d0b6a9c623e0674ff36891c8ab52&quot; data-hovercard=&quot;p$b$5202d0b6a9c623e0674ff36891c8ab52&quot;&gt;@姚维&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是 Sort Merge Join&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在开始阅读源码之前, 我们来看看什么是 Sort Merge Join (SMJ)，定义可以看 &lt;a href=&quot;https://en.wikipedia.org/wiki/Sort-merge_join&quot;&gt;wikipedia&lt;/a&gt;。简单说来就是将 Join 的两个表，首先根据连接属性进行排序，然后进行一次扫描归并, 进而就可以得出最后的结果。这个算法最大的消耗在于对内外表数据进行排序，而当连接列为索引列时，我们可以利用索引的有序性避免排序带来的消耗, 所以通常在查询优化器中，连接列为索引列的情况下可以考虑选择使用 SMJ。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Sort Merge Join 实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;执行过程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的实现代码在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/merge_join.go&quot;&gt;tidb/executor/merge_join.go&lt;/a&gt; 中 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.NextChunk&lt;/code&gt; 是这个算子的入口。下面以 &lt;code class=&quot;inline&quot;&gt;SELECT * FROM A JOIN B ON A.a = B.a&lt;/code&gt; 为例，对 SMJ 执行过程进行简述，假设此时外表为 A，内表为 B，join-keys 为 a，A，B 表的 a 列上都有索引：&lt;/p&gt;&lt;p&gt;1.顺序读取外表 A 直到 join-keys 中出现另外的值，把相同 keys 的行放入数组 a1，同样的规则读取内表 B，把相同 keys 的行放入数组 a2。如果外表数据或者内表数据读取结束，退出。&lt;/p&gt;&lt;p&gt;2. 从 a1 中读取当前第一行数据，设为 v1。从 a2 中读取当前第一行数据，设为 v2。&lt;/p&gt;&lt;p&gt;3. 根据 join-keys 比较 v1，v2，结果分为几种情况：&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0, 表示 v1 大于 v2，把当前 a2 的数据丢弃，从内表读取下一批数据，读取方法同 1。重复 2。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0, 表示 v1 小于 v2，说明外表的 v1 没有内表的值与之相同，把外表数据输出给 resultGenerator（不同的连接类型会有不同的结果输出，例如外连接会把不匹配的外表数据输出）。&lt;/li&gt;&lt;li&gt;cmpResult == 0, 表示 v1 等于 v2。那么遍历 a1 里面的数据，跟 a2 的数据，输出给 resultGenerator 作一次连接。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;4. 回到步骤 1。&lt;/p&gt;&lt;p&gt;下面的图展示了 SMJ 的过程：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b72f20067fcc79e607e567fbc8711bad_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;942&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b72f20067fcc79e607e567fbc8711bad&quot; data-watermark-src=&quot;v2-08f69ef7725298bf5d409e0fc691037f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;读取内表 / 外表数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们分别通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取内表和外表的数据。这两个函数实现的功能类似，这里只详述函数 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 的实现。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子读取数据，是通过迭代器 &lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 完成，&lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 可以顺序读取数据。&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子维护两个 readerIterator：&lt;code class=&quot;inline&quot;&gt;outerIter&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;innerIter&lt;/code&gt;，它们在 &lt;code class=&quot;inline&quot;&gt;buildMergeJoin&lt;/code&gt; 函数中被构造。&lt;/p&gt;&lt;p&gt;真正读取数据的操作是在 &lt;code class=&quot;inline&quot;&gt;readerIterator.nextSelectedRow&lt;/code&gt; 中完成, 这里会通过 &lt;code class=&quot;inline&quot;&gt;ri.reader.NextChunk&lt;/code&gt; 每次读取一个 Chunk 的数据，关于 Chunk 的相关内容，可以查看我们之前的文章 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;TiDB 源码阅读系列文章（十）Chunk 和执行框架简介&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;这里值得注意的是，我们通过 &lt;code class=&quot;inline&quot;&gt;expression.VectorizedFilter&lt;/code&gt; 对外表数据进行过滤，返回一个 curSelected 布尔数组，用于外表的每一行数据是否是满足 filter 过滤条件。以 &lt;code class=&quot;inline&quot;&gt;select * from t1 left outer join t2 on t1.a=100;&lt;/code&gt; 为例, 这里的 filter 是 &lt;code class=&quot;inline&quot;&gt;t1.a=100&lt;/code&gt;, 对于没有通过这个过滤条件的行，我们通过 &lt;code class=&quot;inline&quot;&gt;ri.joinResultGenerator.emitToChunk&lt;/code&gt; 函数发送给 resultGenerator, 这个 resultGenerator 是一个 interface，具体是否输出这行数据，会由 join 的类型决定，比如外连接则会输出，内连接则会忽略。具体关于 resultGenerator, 可以参考之前的文章：&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-9/&quot;&gt;TiDB 源码阅读系列文章（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;rowsWithSameKey&lt;/code&gt; 通过 &lt;code class=&quot;inline&quot;&gt;nextSelectedRow&lt;/code&gt; 不断读取下一行数据，并通过对每行数据的 join-keys 进行判断是不是属于同一个 join-keys，如果是，会把相同 join-keys 的行分别放入到 &lt;code class=&quot;inline&quot;&gt;innerChunkRows&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;outerIter4Row&lt;/code&gt; 数组中。然后对其分别建立迭代器 innerIter4Row 和 outerIter4Row。在 SMJ 中的执行过程中，会利用这两个迭代器来获取数据进行真正的比较得出 join result。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Merge-Join&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实现 Merge-Join 逻辑的代码在函数 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.joinToChunk&lt;/code&gt;, 对内外表迭代器的当前数据根据各自的 join-keys 作对比，有如下几个结果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0，代表外表当前数据大于内表数据，那么通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 直接读取下一个内表数据，然后重新比较即可。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0，代表外表当前数据小于内表数据，这个时候就分几种情况了，如果是外连接，那么需要输出外表数据 + NULL，如果是内连接，那么这个外表数据就被忽略，对于这个不同逻辑的处理，统一由 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator&lt;/code&gt; 来控制，我们只需要把外表数据通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 调用它即可。然后通过 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取下一个外表数据，重新比较。&lt;/li&gt;&lt;li&gt;cmpResult == 0，代表外表当前数据等于内表当前数据，这个时候就把外表数据跟内表当前数据做一次连接，通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 生成结果。之后外表跟内表分别获取下一个数据，重新开始比较。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;重复上面的过程，直到外表或者内表数据被遍历完，退出 Merge-Join 的过程。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们上面的分析代码基于 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/source-code&quot;&gt;Source-code&lt;/a&gt; 分支，可能大家已经发现了一些问题，比如我们会一次性读取内外表的 Join group（相同的 key）。这里如果相同的 key 比较多，是有内存 OOM 的风险的。针对这个问题，我们在最新的 master 分支做了几个事情来优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;外表其实不需要把相同的 keys 一次性都读取上来， 它只需要按次迭代外表数据，再跟内表逐一对比作连接即可。这里至少可以减少外表发生 OOM 的问题，可以大大减少 OOM 的概率。&lt;/li&gt;&lt;li&gt;对于内表，我们对 OOM 也不是没有办法，我们用 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 这个内存追踪器来记录当前内表已经使用的中间结果的内存大小，如果它超过我们设置的阈值，我们会采取输出日志或者终止 SQL 继续运行的方法来规避 OOM 的发生。关于 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 我们不在此展开，可以留意我们后续的源码分析文章。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续我们还会在 Merge-Join 方面做一些优化， 比如我们可以做多路归并，中间结果存外存等等，敬请期待。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-08-41535500</guid>
<pubDate>Wed, 08 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>30 分钟成为 TiKV Contributor</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-02-41103417.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41103417&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3e6973721ffe23e838d18d1d6cebc858_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;作者：吴雪莲&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;背景知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;SQL 语句发送到 TiDB 后经过 parser 生成 AST（抽象语法树），再经过 Query Optimizer 生成执行计划，执行计划切分成很多子任务，这些子任务以表达式的方式最后下推到底层的各个 TiKV 来执行。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d54ea1017d24caf90ab9d7f987f40fae_r.jpg&quot; data-caption=&quot;图 1&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;860&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d54ea1017d24caf90ab9d7f987f40fae&quot; data-watermark-src=&quot;v2-d826905412f823c66e227f7c2ec3f603&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;如图 1，当 TiDB 收到来自客户端的查询请求&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;select count(*) from t where a + b &amp;gt; 5&lt;/code&gt;&lt;/p&gt;&lt;p&gt;时，执行顺序如下：&lt;/p&gt;&lt;p&gt;1.TiDB 对 SQL 进行解析，组织成对应的表达式，下推给 TiKV&lt;/p&gt;&lt;p&gt;2. TiKV 收到请求后，循环以下过程&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;获取下一行完整数据，并按列解析&lt;/li&gt;&lt;li&gt;使用参数中的 where 表达式对数据进行过滤&lt;/li&gt;&lt;li&gt;若上一条件符合，进行聚合计算&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;3. TiKV 向 TiDB 返回聚合计算结果&lt;/p&gt;&lt;p&gt;4. TiDB 对所有涉及的结果进行二次聚合，返回给客户端&lt;/p&gt;&lt;p&gt;这里的 where 条件便是以表达式树的形式下推给 TiKV。在此之前 TiDB 只会向 TiKV 下推一小部分简单的表达式，比如取出某一个列的某个数据类型的值，简单数据类型的比较操作，算术运算等。为了充分利用分布式集群的资源，进一步提升 SQL 在整个集群的执行速度，我们需要将更多种类的表达式下推到 TiKV 来运行，其中的一大类就是 MySQL built-in 函数。&lt;br&gt;目前，由于 TiKV 的 built-in 函数尚未全部实现，对于无法下推的表达式，TiDB 只能自行解决。这无疑将成为提升 TiDB 速度的最大绊脚石。好消息是，TiKV 在实现 built-in 函数时，可以直接参考 TiDB 的对应函数逻辑（顺便可以帮 TiDB 找找 Bug），为我们减少了不少工作量。&lt;/p&gt;&lt;p&gt;Built-in 函数无疑是 TiDB 和 TiKV 成长道路上不可替代的一步，如此艰巨又庞大的任务，我们需要广大社区朋友们的支持与鼓励。亲爱的朋友们，想玩 Rust 吗？想给 TiKV 提 PR 吗？想帮助 TiDB 跑得更快吗？动动您的小手指，拿 PR 来砸我们吧。您的 PR 一旦被采用，将会有小惊喜哦。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;手把手教你实现 built-in 函数&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Step 1：准备下推函数&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiKV 的 &lt;a href=&quot;https://github.com/pingcap/tikv/issues/3275&quot;&gt;https://github.com/pingcap/tikv/issues/3275&lt;/a&gt; issue 中，找到未实现的函数签名列表，选一个您想要实现的函数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 2：获取 TiDB 中可参考的逻辑实现&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下查找相关 builtinXXXSig 对象，这里 XXX 为您要实现的函数签名，本例中以 &lt;a href=&quot;https://github.com/pingcap/tikv/pull/3277&quot;&gt;MultiplyIntUnsigned&lt;/a&gt; 为例，可以在 TiDB 中找到其对应的函数签名（&lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;）及 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;实现&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 3：确定函数定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1.built-in 函数所在的文件名要求与 TiDB 的名称对应，如 TiDB 中，&lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下的下推文件统一以 builtin_XXX 命名，对应到 TiKV 这边，就是 &lt;code class=&quot;inline&quot;&gt;builtin_XXX.rs&lt;/code&gt;。若同名对应的文件不存在，则需要自行在同级目录下新建。对于本例，当前函数存放于 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;builtin_arithmetic.go&lt;/a&gt; 文件里，对应到 TiKV 便是存放在 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;2. 函数名称：函数签名转为 Rust 的函数名称规范，这里 &lt;code class=&quot;inline&quot;&gt;MultiplyIntUnsigned&lt;/code&gt; 将会被定义为 &lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;3. 函数返回值，可以参考 TiDB 中实现的 &lt;code class=&quot;inline&quot;&gt;Eval&lt;/code&gt; 函数，对应关系如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4fb256c456c3220224e6055ca6ab6bf6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1158&quot; data-rawheight=&quot;838&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4fb256c456c3220224e6055ca6ab6bf6&quot; data-watermark-src=&quot;v2-6781bac667ad6b94c4a8b7ec58af83eb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;  对象实现了 evalInt 方法，故当前函数（&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;）的返回类型应该为 &lt;code class=&quot;inline&quot;&gt;Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;4. 函数的参数, 所有 builtin-in 的参数都与 Expression 的 &lt;code class=&quot;inline&quot;&gt;eval&lt;/code&gt; 函数一致，即：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;环境配置量 (ctx:&amp;amp;StatementContext)&lt;/li&gt;&lt;li&gt;该行数据每列具体值 (row:&amp;amp;[Datum])&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上，&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt; 的下推函数定义为：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 4：实现函数逻辑&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一块相对简单，直接对照 TiDB 的相关逻辑实现即可。这里，我们可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt; 的具体实现如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;func (s *builtinArithmeticMultiplyIntUnsignedSig) evalInt(row types.Row) (val int64, isNull bool, err error) {
  a, isNull, err := s.args[0].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedA := uint64(a)
  b, isNull, err := s.args[1].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedB := uint64(b)
  result := unsignedA * unsignedB
  if unsignedA != 0 &amp;amp;&amp;amp; result/unsignedA != unsignedB {
     return 0, true, types.ErrOverflow.GenByArgs(&quot;BIGINT UNSIGNED&quot;, fmt.Sprintf(&quot;(%s * %s)&quot;, s.args[0].String(), s.args[1].String()))
  }
  return int64(result), false, nil
}&lt;/code&gt;&lt;p&gt;参考以上代码，翻译到 TiKV 即可，如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt; {
       let lhs = try_opt!(self.children[0].eval_int(ctx, row));
       let rhs = try_opt!(self.children[1].eval_int(ctx, row));
       let res = (lhs as u64).checked_mul(rhs as u64).map(|t| t as i64);
       // TODO: output expression in error when column&#39;s name pushed down.
       res.ok_or_else(|| Error::overflow(&quot;BIGINT UNSIGNED&quot;, &amp;amp;format!(&quot;({} * {})&quot;, lhs, rhs)))
           .map(Some)
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 5：添加参数检查&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在收到下推请求时，首先会对所有的表达式进行检查，表达式的参数个数检查就在这一步进行。&lt;/p&gt;&lt;p&gt;TiDB 中对每个 built-in 函数的参数个数有严格的限制，这一部分检查可参考 TiDB 同目录下 builtin.go 相关代码。&lt;/p&gt;&lt;p&gt;在 TiKV 同级目录的 scalar_function.rs 文件里，找到 ScalarFunc 的 check_args 函数，按照现有的模式，加入参数个数的检查即可。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 6：添加下推支持&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在对一行数据执行具体的 expression 时，会调用 eval 函数，eval 函数又会根据具体的返回类型，执行具体的子函数。这一部分工作在 scalar_function.rs 中以宏（dispatch_call）的形式完成。&lt;/p&gt;&lt;p&gt;对于 MultiplyIntUnsigned, 我们最终返回的数据类型为 Int，所以可以在 dispatch_call 中找到 INT_CALLS，然后照着加入 MultiplyIntUnsigned =&amp;gt; multiply_int_unsigned , 表示当解析到函数签名 MultiplyIntUnsigned 时，调用上述已实现的函数 multiply_int_unsigned。&lt;/p&gt;&lt;p&gt;至此 MultiplyIntUnsigned 下推逻辑已完全实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 7：添加测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在函数 multiply_int_unsigned 所在文件 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 底部的 test 模块中加入对该函数签名的单元测试，要求覆盖到上述添加的所有代码，这一部分也可以参考 TiDB 中相关的测试代码。本例在 TiKV 中实现的测试代码如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;#[test]
   fn test_multiply_int_unsigned() {
       let cases = vec![
           (Datum::I64(1), Datum::I64(2), Datum::U64(2)),
           (
               Datum::I64(i64::MIN),
               Datum::I64(1),
               Datum::U64(i64::MIN as u64),
           ),
           (
               Datum::I64(i64::MAX),
               Datum::I64(1),
               Datum::U64(i64::MAX as u64),
           ),
           (Datum::U64(u64::MAX), Datum::I64(1), Datum::U64(u64::MAX)),
       ];

       let mut ctx = EvalContext::default();
       for (left, right, exp) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap();
           assert_eq!(got, exp);
       }

       // test overflow
       let cases = vec![
           (Datum::I64(-1), Datum::I64(2)),
           (Datum::I64(i64::MAX), Datum::I64(i64::MAX)),
           (Datum::I64(i64::MIN), Datum::I64(i64::MIN)),
       ];

       for (left, right) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap_err();
           assert!(check_overflow(got).is_ok());
       }
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 8：运行测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;运行 make expression，确保所有的 test case 都能跑过。&lt;/p&gt;&lt;p&gt;完成以上几个步骤之后，就可以给 TiKV 项目提 PR 啦。想要了解提 PR 的基础知识，尝试移步 &lt;a href=&quot;https://pingcap.com/blog-how-to-contribute-zh&quot;&gt;此文&lt;/a&gt;，看看是否有帮助。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;欢迎大家踊跃贡献代码，加入 TiDB community ！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://github.com/pingcap.com&quot;&gt;http://github.com/pingcap.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-02-41103417</guid>
<pubDate>Thu, 02 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>社区 | 如何优雅降落到 TiDB 星球？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-25-40529913.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40529913&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74fe289237a86bdb2092bfb84524db33_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;提到「开源项目 TiDB」人们总是习惯性反应：它在 GitHub 上 Star 数已经超过 17000，并拥有 260+ 位全球各地的 Contributors 。但数据总归是冷冰冰的，不能生动的展现 TiDB 社区的魅力。所以今天推送一篇 &lt;b&gt;TiDB contributor&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;杜川&lt;/b&gt;同学加入 TiDB 社区前后的「心路历程」，他从亲历者的角度告诉你——&lt;/i&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;PingCAPer 够 nice 么？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;积极参与 TiDB 社区对自己的能力提升有何帮助？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;如何在 TiDB 星球上找到最适合自己的落点？（ 或者在大树上找到自己最擅长的“小树杈”hhhhhh）&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;&lt;b&gt;以及…利用好碎片时间，你也可以一年给 TiDB 提&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;70&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;个 PR！&lt;/b&gt;&lt;/i&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;🚀&lt;/b&gt; 作者：杜川，TiDB contributor&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;最近这一年多断断续续一直在往 TiDB 中提交一些修改，前两天看了一些 GitHub  提交记录，发现竟然已经累计了 70 来个 PR 了。考虑到最近这一年基本处于疯狂加班的节奏，另外忙里偷闲还基本上刷完了之前列的十几本书的读书清单，我觉得这也算一个不大不小的成就吧，值得 mark 一下。&lt;/p&gt;&lt;p&gt;话说回来，虽然我 17 年年中才开始给 TiDB 提交 PR，其实在之前一年多以前，大概在 2016 年 4 月份左右, 就听说过 TiDB 这个项目了。当时我的主要工作也是车一个 SQL 执行引擎，所以对分布式数据库业界的相关新闻还是比较关注的。&lt;/p&gt;&lt;p&gt;虽然数据库是一个轮子高发领域，各种轮子五花八门，但是在国内，数据库，特别是分布式数据库这块的轮子，基本还是几个大厂在车，要么不开源，要么开源了社区也不甚活跃。像 TiDB 这样要从头车一个分布式数据库，并且还是完全开源的方式来搞，确实让我印象深刻。后来组里一个小哥离职投奔 PingCAP，我借着面基的名义陆陆续续参加了 TiDB 几次线下 Meetup，也由此认识了很多 TiDB 社区的小伙伴。&lt;/p&gt;&lt;p&gt;16 年底从北京回到成都以后，工作重心发生了一些变化，从之前的纯做 infra，转变为更多地要面对业务层面的需求。不过做了几年 infra，自己本身对数据库内核还是很感兴趣的，所以工作之余，开始研究 TiDB 的实现，并且搭了一套 TiDB，在开发环境里代替 MySQL。我们都知道，MySQL 经过多年的发展，其 SQL 语法是比较复杂的。TiDB 虽然全面兼容 MySQL 的语法和协议，但是因为没有复用 MySQL 代码，肯定不可能做到 100% 兼容，落实到一些具体的语句上，肯定会和 MySQL 有一些区别。因为之前我也一直在做 OLAP 系统的 SQL 引擎的开发工作，对这一块比较熟悉，在遇到这方面问题后，感觉解决起来也并不很麻烦，因此慢慢开始在这个方面给 TiDB 提一些 PR。到后面熟悉了以后，有时间的话也会到 TiDB 的 issue list 上捞相关的 issue 解决，主要集中于 SQL Parser, 表达式计算和 MySQL 兼容性等方面。最近抽空在做的是和聚合函数相关的一些 Feature。&lt;/p&gt;&lt;p&gt;因为平时工作还是比较忙，加班也是家常便饭，因此给 TiDB 提交 PR，回复 Review 意见的时间段基本都集中在周末，晚上老婆睡觉以后，或者午休间隙。这样有一个问题是时间段比较离散，很难有长时间的连贯思考的时间。因此现阶段一方面我在提 PR 的时候会选择一些相对较小，独立一些的 Feature。&lt;b&gt;另一方面，我尽量把开发放在时间相对充裕的周末，把晚上和其他零碎时间用来查看和回复 Review 意见，Update 代码和跑回归测试。这样算下来，平均提交一个 PR，算上开发，测试，和社区小伙伴沟通，大概要消耗 3 到 5 个工时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不过这个时间投入我觉得倒是非常划算，一是因为我本身对数据库就非常感兴趣，把参与 TiDB 社区开发当成了一种兴趣，可以看做是工作之余的一种放松，二是我一直在从事数据库相关的工作，包括之前 OLAP SQL 引擎的运行时优化相关工作，和现在云数据库相关的工作，其实和在社区所做的事情都是密切相关的。比如一个 MySQL Builtin 函数, 在各种极端输入下的表现是怎样的，或是 SQL_MODE 的各种组合对这个 Builtin 函数的行为有什么样的影响，这些问题在平时工作中，我可能很难考虑得非常周全；但是要在社区中提一个 PR 实现这个 Builtin 函数，我就非得把这些问题考虑清楚，并经受社区小伙伴各种 Case 的轰炸考验。等这个 PR 顺利被 Commit，这些细节我也烂熟于心了。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-13d78a931d43996617464c58e89c8b85_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2006&quot; data-rawheight=&quot;1034&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-13d78a931d43996617464c58e89c8b85&quot; data-watermark-src=&quot;v2-2370357a5b7bf01a8e24495f78b5f21b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;说到社区，我觉得 TiDB 做得相当不错。一方面 PingCAPers 都很活跃，在 GitHub 上提的 Issue 一般很快就能得到回复, 有什么疑问通过 GitHub, 微信群甚至知乎提问等很快都能得到反馈；另一方面更重要的是在 Review PR 的时候社区小伙伴能保持比较严谨的态度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就我的经历而言，我在开发过程中没有注意到的一些 Corner Case 和细节错误，基本都能在 Review PR 过程被翻出来，这不仅需要 Reviewer 理清楚 PR 对应 Feature 的相关细节，构造出可能有问题的场景，还需要 Reviewer 理解 PR 作者的开发思路。其中需要花费的精力，常常不低于开发这个 Feature 本身。此外，还有一个我觉得很赞的方面是 TiDB 花了很多心思来构建从 UT，FT 到集成测试的一系列测试框架，让我在参与开发工程中比较容易对自己开发的 Feature 进行各个方位的测试，节省了很多来回捣腾的麻烦。&lt;/p&gt;&lt;p&gt;总的来说，参与 TiDB 社区是一件非常有意思的事情，给我带来很多收获，我也会继续关注 TiDB 项目的进展。短时间来看，我的计划主要还是抽空完成手头聚合函数相关的一些 Feature，包括对 MySQL 聚合函数 STDDEV，VARIANCE 等的支持，以及在 TiKV Coprocessor 侧的对应改动。之后，我打算看看能不能够结合我之前在 OLAP SQL 引擎的运行时优化方面的经验，提升 TiDB 在 OLAP 领域的能力。不过这个是一个比较大的目标了，到时候还要和社区的小伙伴多多讨论。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;TiDB 社区大事件&lt;/b&gt;&lt;/i&gt; &lt;/p&gt;&lt;p&gt;&lt;i&gt;TiDB TechDay2018 即将于 7 月 28 日在深圳举办，目前报名已满，我们周六见哦！点击&lt;u&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486395&amp;amp;idx=1&amp;amp;sn=bfa0227d14a27e02dcd0e26939125c24&amp;amp;chksm=eb162cd1dc61a5c7d6da2bc2e3dc8e6413e28c1085a69cb0518adb1dc27cd38c8bdc64ec1fbb&amp;amp;scene=21#wechat_redirect&quot;&gt;【这里】&lt;/a&gt;&lt;/u&gt;查看活动详情。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;P.S 欢迎踊跃勾搭 &lt;b&gt;TiDB Robot （微信号：tidbai）&lt;/b&gt;加入 TiDB 星球～&lt;/i&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-84bfe17ec8227fa695e364a4815dfe35_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;3515&quot; data-rawheight=&quot;1758&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-84bfe17ec8227fa695e364a4815dfe35&quot; data-watermark-src=&quot;v2-15585058505faf294ec8f410cce97ab5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-25-40529913</guid>
<pubDate>Wed, 25 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十四）统计信息（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-19-40079139.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40079139&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c34786efbf579d9eef6f636c5afda076_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：谢海滨&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价，本篇将会结合原理介绍 TiDB 的源码实现。&lt;/p&gt;&lt;p&gt;文内会先介绍直方图和 Count-Min(CM) Sketch 的数据结构，然后介绍 TiDB 是如何实现统计信息的查询、收集以及更新的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据结构定义&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;直方图的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L40&quot;&gt;histograms.go&lt;/a&gt; 中找到，值得注意的是，对于桶的上下界，我们使用了在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;《TiDB 源码阅读系列文章（十）Chunk 和执行框架简介》&lt;/a&gt; 中介绍到 Chunk 来存储，相比于用 Datum 的方式，可以减少内存分配开销。&lt;/p&gt;&lt;p&gt;CM Sketch 的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L31&quot;&gt;cmsketch.go&lt;/a&gt; 中找到，比较简单，包含了 CM Sketch 的核心——二维数组 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt;，并存储了其深度与宽度，以及总共插入的值的数量，当然这些都可以直接从 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt; 中得到。&lt;/p&gt;&lt;p&gt;除此之外，对列和索引的统计信息，分别使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L699&quot;&gt;Column&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L773&quot;&gt;Index&lt;/a&gt; 来记录，主要包含了直方图，CM Sketch 等。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息创建&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在执行 analyze 语句时，TiDB 会收集直方图和 CM Sketch 的信息。在执行 analyze 命令时，会先将需要 analyze 的列和索引在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/master/plan/planbuilder.go#L609&quot;&gt;builder.go&lt;/a&gt; 中切分成不同的任务，然后在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/executor/analyze.go#L114&quot;&gt;analyze.go&lt;/a&gt; 中将任务下推至 TiKV 上执行。由于在 TiDB 中也包含了 TiKV 部分的实现，因此在这里还是会以 TiDB 的代码来介绍。在这个部分中，我们会着重介绍直方图的创建。&lt;/p&gt;&lt;p&gt;&lt;b&gt;列直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在统计信息（上）中提到，在建立列直方图的时候，会先进行抽样，然后再建立直方图。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/sample.go#L113&quot;&gt;collect&lt;/a&gt; 函数中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。由于其原理和代码都比较简单，在这里不再介绍。&lt;/p&gt;&lt;p&gt;采样完成后，在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L97&quot;&gt;BuildColumn&lt;/a&gt; 中，我们实现了列直方图的创建。首先将样本排序，确定每个桶的高度，然后顺序遍历每个值 V：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如果 V 等于上一个值，那么把 V 放在与上一个值同一个桶里，无论桶是不是已经满，这样可以保证每个值只存在于一个桶中。&lt;/li&gt;&lt;li&gt;如果不等于上一个值，那么判断当前桶是否已经满，就直接放入当前桶，并用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L146&quot;&gt;updateLastBucket&lt;/a&gt; 更改桶的上界和深度。&lt;/li&gt;&lt;li&gt;否则的话，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L151&quot;&gt;AppendBucket&lt;/a&gt; 放入一个新的桶。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;索引直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在建立索引列直方图的时候，我们使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L24&quot;&gt;SortedBuilder&lt;/a&gt; 来维护建立直方图的中间状态。由于不能事先知道有多少行的数据，也就不能确定每一个桶的深度，不过由于索引列的数据是已经有序的，因次我们在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L38&quot;&gt;NewSortedBuilder&lt;/a&gt; 中将每个桶的初始深度设为 1。对于每一个数据，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L50&quot;&gt;Iterate&lt;/a&gt; 会使用建立列直方图时类似的方法插入数据。如果在某一时刻，所需桶的个数超过了当前桶深度，那么用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L74&quot;&gt;mergeBucket&lt;/a&gt; 将之前的每两个桶合并为 1 个，并将桶深扩大一倍，然后继续插入。&lt;/p&gt;&lt;p&gt;在收集了每一个 Region 上分别建立的直方图后，还需要用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L609&quot;&gt;MergeHistogram&lt;/a&gt; 把每个 Region 上的直方图进行合并。在这个函数中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了保证每个值只在一个桶中，我们处理了处理一下交界处桶的问题，即如果交界处两个桶的上界和下界 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L623&quot;&gt;相等&lt;/a&gt;，那么需要先合并这两个桶；&lt;/li&gt;&lt;li&gt;在真正合并前，我们分别将两个直方图的平均桶深 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L642&quot;&gt;调整&lt;/a&gt; 至大致相等；&lt;/li&gt;&lt;li&gt;如果直方图合并之后桶的个数超过了限制，那么把两两相邻的桶 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L653&quot;&gt;合二为一&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息维护&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了 TiDB 是如何更新直方图和 CM Sketch 的。对于 CM Sketch 其更新比较简单，在这里不再介绍。这个部分主要介绍一下 TiDB 是如何收集反馈信息和维护直方图的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;反馈信息的收集&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，为了不去假设所有桶贡献的误差都是均匀的，需要收集每一个桶的反馈信息，因此需要先把查询的范围按照直方图桶的边界切分成不相交的部分。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L511&quot;&gt;SplitRange&lt;/a&gt; 中，我们按照直方图去切分查询的范围。由于目前直方图中的一个桶会包含上下界，为了方便，这里只按照上界去划分，即这里将第 i 个桶的范围看做 &lt;code class=&quot;inline&quot;&gt;(i-1 桶的上界，i 桶的上界]&lt;/code&gt;。特别的，对于最后一个桶，将其的上界视为无穷大。比方说一个直方图包含 ３ 个桶，范围分别是: [2，5]，[8，8]，[10，13]，查询的范围是 (3，20]，那么最终切分得到的查询范围就是 (3，5]，(5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;将查询范围切分好后，会被存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，以便在每个 Region 的结果返回时，调用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L165&quot;&gt;Update&lt;/a&gt; 函数来更新每个范围所包含的 key 数目。注意到这个函数需要两个参数：每个 Region 上扫描的 start key 以及 Region 上每一个扫描范围输出的 key 数目 output counts，那么要如何更新 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 中每个范围包含的 key 的数目呢？&lt;/p&gt;&lt;p&gt;继续以划分好的 (3，5]，(5，8]，(8，20] 为例，假设这个请求需要发送到两个 region 上，region1 的范围是 [0，6)，region2 的范围是 [6，30)，由于 coprocessor 在发请求的时候还会根据 Region 的范围切分 range，因此 region1 的请求范围是 (3，5]，(5，6)，region2 的请求范围是 [6，8]，(8，20]。为了将对应的 key 数目更新到 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，需要知道每一个 output count 对应的查询范围。注意到 coprocessor 返回的 output counts 其对应的 Range 都是连续的，并且同一个值只会对应一个 range，那么我们只需要知道第一个 output count 所对应的 range，即只需要知道这次扫描的 start key 就可以了。举个例子，对于 region1 来说，start key 是 3，那么 output counts 对应的 range 就是 (3，5]，(5，8]，对 region2 来说，start key 是 6，output countshangyipians 对应的 range 就是 (5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;&lt;b&gt;直方图的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在收集了 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 后，我们就可以去使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L536&quot;&gt;UpdateHistogram&lt;/a&gt; 来更新直方图了。其大体上可以分为分裂与合并。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L503&quot;&gt;splitBuckets&lt;/a&gt; 中，我们实现了直方图的分裂：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先，由于桶与桶之间的反馈信息不相关，为了方便，先将 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L504&quot;&gt;buildBucketFeedback&lt;/a&gt; 拆分了每一个桶的反馈信息，并存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L213&quot;&gt;BucketFeedback&lt;/a&gt; 中。&lt;/li&gt;&lt;li&gt;接着，使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L507&quot;&gt;getSplitCount&lt;/a&gt; 来根据可用的桶的个数和反馈信息的总数来决定分裂的数目。&lt;/li&gt;&lt;li&gt;对于每一个桶，将可以分裂的桶按照反馈信息数目的比例均分，然后用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;splitBucket&lt;/a&gt; 来分裂出需要的桶的数目：&lt;/li&gt;&lt;li&gt;首先，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;getBoundaries&lt;/a&gt; 会每隔几个点取一个作为边界，得到新的桶。&lt;/li&gt;&lt;li&gt;然后，对于每一个桶，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L32%201&quot;&gt;refineBucketCount&lt;/a&gt; 用与新生成的桶重合部分最多的反馈信息更新桶的深度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，在分裂的时候，如果一个桶过小，那么这个桶不会被分裂；如果一个分裂后生成的桶过小，那么它也不会被生成。&lt;/p&gt;&lt;p&gt;在桶的分裂完成后，我们会使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L467&quot;&gt;mergeBuckets&lt;/a&gt; 来合并桶，对于那些超过：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在分裂的时候，会记录每一个桶是不是新生成的，这样，对于原先就存在的桶，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L476&quot;&gt;getBucketScore&lt;/a&gt; 计算合并的之后产生的误差，令第一个桶占合并后桶的比例为 r，那么令合并后产生的误差为 abs（合并前第一个桶的高度 - r * 两个桶的高度和）/ 合并前第一个桶的高度。&lt;/li&gt;&lt;li&gt;接着，对每一桶的合并的误差进行排序。&lt;/li&gt;&lt;li&gt;最后，按照合并的误差从下到大的顺序，合并需要的桶。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在查询语句中，我们常常会使用一些过滤条件，而统计信息估算的主要作用就是估计经过这些过滤条件后的数据条数，以便优化器选择最优的执行计划。&lt;/p&gt;&lt;p&gt;由于在单列上的查询比较简单，这里不再赘述，代码基本是按照 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中的原理实现，感兴趣可以参考 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L408&quot;&gt;histogram.go/lessRowCount&lt;/a&gt;  以及 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L69&quot;&gt;cmsketch.go/queryValue&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L148&quot;&gt;Selectivity&lt;/a&gt; 是统计信息模块对优化器提供的最重要的接口，处理了多列查询的情况。Selectivity 的一个最重要的任务就是将所有的查询条件分成尽量少的组，使得每一组中的条件都可以用某一列或者某一索引上的统计信息进行估计，这样我们就可以做尽量少的独立性假设。&lt;/p&gt;&lt;p&gt;需要注意的是，我们将单列的统计信息分为 3 类：&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L42&quot;&gt;indexType&lt;/a&gt; 即索引列，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L43&quot;&gt;pkType&lt;/a&gt; 即 Int 类型的主键，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L44&quot;&gt;colType&lt;/a&gt; 即普通的列类型，如果一个条件可以同时被多种类型的统计信息覆盖，那么我们优先会选择 pkType 或者 indexType。&lt;/p&gt;&lt;p&gt;在 Selectivity 中，有如下几个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L230&quot;&gt;getMaskAndRange&lt;/a&gt; 为每一列和每一个索引计算了可以覆盖的过滤条件，用一个 int64 来当做一个 bitset，并把将该列可以覆盖的过滤条件的位置置为 1。&lt;/li&gt;&lt;li&gt;接下来在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L258&quot;&gt;getUsableSetsByGreedy&lt;/a&gt; 中，选择尽量少的 bitset，来覆盖尽量多的过滤条件。每一次在还没有使用的 bitset 中，选择一个可以覆盖最多尚未覆盖的过滤条件。并且如果可以覆盖同样多的过滤条件，我们会优先选择 pkType 或者 indexType。&lt;/li&gt;&lt;li&gt;用统计信息（上）提到的方法对每一个列和每一个索引上的统计信息进行估计，并用独立性假设将它们组合起来当做最终的结果。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;统计信息的收集和维护是数据库的核心功能，对于基于代价的查询优化器，统计信息的准确性直接影响了查询效率。在分布式数据库中，收集统计信息和单机差别不大，但是维护统计信息有比较大的挑战，比如怎样在多节点更新的情况下，准确及时的维护统计信息。&lt;/p&gt;&lt;p&gt;对于直方图的动态更新，业界一般有两种方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于每一次增删，都去更新对应的桶深。在一个桶的桶深过高的时候分裂桶，一般是把桶的宽度等分，不过这样很难准确的确定分界点，引起误差。&lt;/li&gt;&lt;li&gt;使用查询得到的真实数去反馈调整直方图，假定所有桶贡献的误差都是均匀的，用连续值假设去调整所有涉及到的桶。然而误差均匀的假设常常会引起问题，比如当当新插入的值大于直方图的最大值时，就会把新插入的值引起的误差分摊到直方图中，从而引起误差。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 TiDB 的统计信息还是以单列的统计信息为主，为了减少独立性假设的使用，在将来 TiDB 会探索多列统计信息的收集和维护，为优化器提供更准确的统计信息。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39649659&quot;&gt;（十三）索引范围计算简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;（十二）统计信息（上）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-19-40079139</guid>
<pubDate>Thu, 19 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>邀请函 | TiDB TechDay2018 我们在深圳等你</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-17-39909349.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39909349&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9c5c16735754d909c3d8e9f011d55d3c_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;7 月 28 日，第二届 TiDB TechDay 即将落地深圳。&lt;/b&gt;我们准备了干货 Talk、美食和你们心心念念的 T 恤、贴纸……想和你一起聊聊技术，吃吃喝喝，谈谈情面面基&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;自由软件之父 Richard Matthew Stallman 曾说过：“如果你想为这世界做些什么，仅有理想是不够的，你需要找条通往目标的道路并走完。”&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 选择的开源之路，让我们在正确的道路上可以快速奔跑，同时收获了一个充满能量又有趣的社区。&lt;/b&gt;目前 TiDB/TiKV 已经汇聚了 &lt;b&gt;260&lt;/b&gt; 位来自全球各地的 Contributors，并在 GitHub 上获得了 &lt;b&gt;17000+&lt;/b&gt; Stars，这是我们遥远征途上的一个小小的成就，感谢社区帮助我们一起走得更远。&lt;/p&gt;&lt;p&gt;去年七月，我们在上海举办了首场 TiDB TechDay，用一整天的时间为社区小伙伴抽丝剥茧的讲解 TiDB 技术细节。今年我们除了 TiDB 技术分享之外，还带来了精彩的用户实践和社区小伙伴的贡献心得。希望这一天，能满足你对 TiDB 更深层细节的所有好奇。&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家加入这一场社区狂欢，和我们一起感受开源的魅力！&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-053f8cff20688c7ffd8efe58269f1851_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1028&quot; data-rawheight=&quot;1626&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-053f8cff20688c7ffd8efe58269f1851&quot; data-watermark-src=&quot;v2-ddcc1d914a44963e876074df60a70a79&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2018-07-28 周六&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：深圳市 · 南山区 · 南海大道 1079 号花园城数码大厦 A 座 2 楼 201 优客工场&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href=&quot;http://www.huodongxing.com/event/6449101295200&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-f59f2b532f746892c5b17729eed83b3b&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; data-image-size=&quot;180x120&quot;&gt;TiDB TechDay2018 · 深圳&lt;/a&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;TiDB TechDay2018 日 程 &lt;/b&gt;&lt;br&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;9:00 - 9:45  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;现场签到&lt;/p&gt;&lt;p&gt;&lt;b&gt;9:45 - 10:00  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;开场&lt;/p&gt;&lt;p&gt;&lt;b&gt;10:00 - 11:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.1: What&#39;s new and What&#39;s next&lt;br&gt;申砾 | PingCAP Engineering VP&lt;/p&gt;&lt;p&gt;&lt;b&gt;11:00 - 11:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 1：TiDB 在转转的千亿级大规模实践&lt;br&gt;孙玄 | 转转 首席架构师&lt;/p&gt;&lt;p&gt;&lt;b&gt;11:30 - 12:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 社区及开源大生态&lt;br&gt;黄东旭 | PingCAP 联合创始人兼 CTO &lt;/p&gt;&lt;p&gt;&lt;b&gt;12:30 - 13:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;午餐&lt;/p&gt;&lt;p&gt;&lt;b&gt;13:30 - 14:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 2：平安产险 TiDB 应用实践&lt;br&gt;丁永 | 平安产险 大数据平台产品团队负责人&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:00 - 14:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 3：TiDB contributor 之路&lt;br&gt;杨文 | TiDB contributor&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:30 - 14:40 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;Break&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:40 - 15:40&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Chaos Practice in TiDB&lt;br&gt;唐刘 | PingCAP 首席架构师&lt;/p&gt;&lt;p&gt;&lt;b&gt;15:40 - 16:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;领取 T 恤、贴纸等周边&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://www.huodongxing.com/event/6449101295200&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-f59f2b532f746892c5b17729eed83b3b&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; data-image-size=&quot;180x120&quot;&gt;TiDB TechDay2018 · 深圳&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-17-39909349</guid>
<pubDate>Tue, 17 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十三）索引范围计算简介</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-13-39649659.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39649659&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b7f88291dd3855ebcc79e627554a10c3_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：崔一丁&lt;/blockquote&gt;&lt;h2&gt;简述&lt;/h2&gt;&lt;p&gt;在数据库中处理查询请求时，如果可以尽早的将无关数据过滤掉，那么后续的算子就可以少做无用功，提升整个 SQL 的执行效率。过滤数据最常用的手段是使用索引，TiDB 的优化器也会尽量采用索引过滤的方式处理请求，利用索引有序的特点来提升查询效率。比如当查询条件为 &lt;code class=&quot;inline&quot;&gt;a = 1&lt;/code&gt; 时，如果 a 这一列上有索引，我们就可以利用索引很快的把满足 &lt;code class=&quot;inline&quot;&gt;a = 1&lt;/code&gt; 的数据拿出来，而不需要逐行检查 a 的值是否为 1。当然是否会选择索引过滤也取决于代价估算。&lt;/p&gt;&lt;p&gt;索引分为单列索引和多列索引（组合索引），筛选条件也往往不会是简单的一个等值条件，可能是非常复杂的条件组合。TiDB 是如何分析这些复杂条件，来得到这些条件在对应的索引上的逻辑区间范围（range），就是本文要介绍的内容。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 TiDB 如何构建索引，如何存储索引数据，希望读者能够有基本的了解（参考阅读：&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-2/&quot;&gt;三篇文章了解 TiDB 技术内幕 - 说计算&lt;/a&gt; ）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里是一个例子，展示这里所说的索引范围计算是做什么的，建表语句和查询语句如下：&lt;br&gt;CREATE TABLE t (a int primary key, b int, c int);&lt;br&gt;select * from t where ((a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2) or (a &amp;gt; 8 and a &amp;lt; 10 and c &amp;gt; 3)) and d = 5;&lt;br&gt;计算索引逻辑区间范围的流程如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6721b3933dec315f3de020d2a6df28d7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;677&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6721b3933dec315f3de020d2a6df28d7&quot; data-watermark-src=&quot;v2-fe49c70702f4c93c2fc2fd8104f7cc19&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;从上图可以看出，整个流程分为从 Filter 中抽取可用索引的表达式以及利用选出的表达式构造数据范围两个步骤，接下来分别描述。&lt;/p&gt;&lt;h2&gt;抽取表达式&lt;/h2&gt;&lt;p&gt;这个步骤是从 Filter 中将能够用上索引的表达式选出来。由于单列索引和多列索引在处理逻辑上有很大的不同，所以会分单列索引和多列索引两中情况进行讲解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;单列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;单列索引的情况相对来说比较简单。很多满足 Column op Constant 形式的简单表达式都可以用来计算 range，单个表达式的判断逻辑在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/checker.go&quot;&gt;checker.go&lt;/a&gt; 的 conditionChecker 中。而对于包含了 AND 或者 OR 的复杂情况，我们可以按照下述规则进行处理：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;AND 表达式无关的 filter 并不会影响其可以计算 range 的子项。所以直接舍去无关的表示即可。以流程图中的一个子表达式 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2&lt;/code&gt; 为例，我们只要将 &lt;code class=&quot;inline&quot;&gt;b &amp;gt; 2&lt;/code&gt; 扔掉，保留 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 5&lt;/code&gt; 即可。&lt;/li&gt;&lt;li&gt;OR 表达式中，每个子项都要可以用来计算 range，如果有不可以计算 range 的子项，那么这整个表达式都不可用来计算 range。以 &lt;code class=&quot;inline&quot;&gt;a = 1 or b = 2&lt;/code&gt;为例，&lt;code class=&quot;inline&quot;&gt;b = 2&lt;/code&gt; 这一子项不可以用来计算 a 的 range，所以这个表达式整体上无法计算 a 的 range。而如果是 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 or ( a &amp;lt; 2 and b = 1)&lt;/code&gt;，根据 1 中的规则，第二个子项会留下 &lt;code class=&quot;inline&quot;&gt;a &amp;lt; 2&lt;/code&gt; 的部分，可以用来计算 a 的 range，因此整个表达式会返回 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 2&lt;/code&gt; 来供接下来计算 range 的部分处理。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这里补充说明一点，TiDB 的主键在实现方式上限定了只有整数类型的单列主键会把主键值当做 RowID，然后编码成 RowKey，和这行数据存储在一起。其他类型的单列主键会作为普通的 unique key 看待，当查询的列包含索引上没有的列时，需要一次查索引 + 一次扫表。所以我们将这种整数类型作为主键的索引处理逻辑单独抽取出来，其入口函数为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L329&quot;&gt;DetachCondsForTableRange&lt;/a&gt; 。其中对 AND 表达式和 OR 表达式的处理入口分别为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L28&quot;&gt;detachColumnCNFConditions&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L61&quot;&gt;detachColumnDNFConditions&lt;/a&gt;。这两个函数也用来处理其他类型的主键或者索引的的 range 计算。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;多列索引的情况较单列索引而言会复杂一些，因为在处理 OR 表达式中列与列之间的关系需要考虑更多情况。TiDB 中为了简化 ranger 的逻辑，目前只考虑下列情况：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;AND 表达式中，只有当之前的列均为点查的情况下，才会考虑下一个列。&lt;br&gt;e.g. 对于索引 (a, b, c)，有条件 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and b = 1&lt;/code&gt;，那么会被选中的只有 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1&lt;/code&gt;。对于条件 &lt;code class=&quot;inline&quot;&gt;a in (1, 2, 3) and b &amp;gt; 1&lt;/code&gt;，两个条件均会被选到用来计算 range。&lt;br&gt;由于非点查的部分只会涉及到一个列，所以可以直接复用 &lt;code class=&quot;inline&quot;&gt;detachColumnCNFConditions&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;OR 表达式中，每个子项会视为 AND 表达式分开考虑。与单列索引的情况一样，如果其中一个子项无法用来计算索引，那么该 OR 表达式便完全无法计算索引。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;多列索引处理的入口函数为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L270&quot;&gt;DetachCondAndBuildRangeForIndex&lt;/a&gt;，AND 表达式和 OR 表达式的处理入口分别为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L142&quot;&gt;detachCNFCondAndBuildRangeForIndex&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L214&quot;&gt;detachDNFCondAndBuildRangeForIndex&lt;/a&gt;。（由于多列索引对 range 的处理相对单列索引而言会复杂一些，所以没有拆分为 DetachCondition 和 BuildRange 两部分，而是由 DetachCondAndBuildRangeForIndex 处理。）&lt;/p&gt;&lt;p&gt;由于逻辑进行到了简化，因此目前 TiDB 的 ranger 存在无法正确处理的情况。比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;a = 1 and (b = 1 or b = 2) and c &amp;gt; 1&lt;/code&gt;。对于这个式子，当 (a, b ,c) 为索引时，如上述所言，由于 &lt;code class=&quot;inline&quot;&gt;(b = 1 or b = 2)&lt;/code&gt; 形式上是 OR 表达式的情况，而非点查。所以会在 b 列停止，不会考虑 &lt;code class=&quot;inline&quot;&gt;c &amp;gt; 1&lt;/code&gt; 的情况。所以目前为了兼容 TiDB 的逻辑，遇到这种情况尽量改写为 &lt;code class=&quot;inline&quot;&gt;a = 1 and b in (1, 2) and c &amp;gt; 1&lt;/code&gt; 的形式。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d2c052d9158e790bde962cd16d0e8c07_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1155&quot; data-rawheight=&quot;286&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d2c052d9158e790bde962cd16d0e8c07&quot; data-watermark-src=&quot;v2-fe43cc0ef0d02aefe44bd3d95026677b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;类似的如 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1) or (a = 2 and b = 2)) and c = 1&lt;/code&gt; 形式的式子，前段 OR 表达式实际上为点查的行为，但是由于是 OR 连接起来的式子，所以在 TiDB 的逻辑中作为范围查询处理，因此 &lt;code class=&quot;inline&quot;&gt;c = 1&lt;/code&gt; 不会作为索引的计算条件处理。而这时改写为 &lt;code class=&quot;inline&quot;&gt;(a, b) in ((1, 1)&lt;/code&gt;,  &lt;code class=&quot;inline&quot;&gt;(2, 2)) and c = 1&lt;/code&gt; 的形式也不会使 &lt;code class=&quot;inline&quot;&gt;c = 1&lt;/code&gt; 选入索引计算的条件，原因是多列 in 的函数会被 TiDB 改写为 OR 连接的形式，所以 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1) or (a = 2 and b = 2))&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;(a, b) in ((1, 1),  (2, 2))&lt;/code&gt; 在 TiDB 中是完全一致的行为。针对这种情况，目前的办法只有将这些条件都放入 OR 的子项中，针对这里用到的例子，那就是要改写为 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1 and c = 1) or (a = 2 and b = 2 and c = 1))&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-50e759f5b37e8f6e5b2a1fbf430bfc3a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1155&quot; data-rawheight=&quot;294&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-50e759f5b37e8f6e5b2a1fbf430bfc3a&quot; data-watermark-src=&quot;v2-54cef9f6e4aac480b9e3a8b5f5021aa1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;计算逻辑区间&lt;/h2&gt;&lt;p&gt;这一步骤中，利用上一步抽取出来的表达式估算出数据的逻辑区间范围，后续会根据这个逻辑区间以及数据编码方式构造物理区间进行数据访问。我们仍然分为单列索引和多列索引两个情况来介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;单列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这种情况下，输入的表达式为 Column op Constant 形式的简单表达式由 OR 以及 AND 连接而成。我们对每一个具体的操作符，都设计了一段对应的计算 range 的逻辑，当遇到 AND 或者 OR 时，会对两个区间求交或者求并。在 point.go 中有一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L146&quot;&gt;builder&lt;/a&gt; 的结构体用来处理上述逻辑。&lt;/p&gt;&lt;p&gt;在这个阶段我们记录 range 时用 rangePoint 的结构来存储 range。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// Point is the end point of range interval.
type point struct {
	value types.Datum
	excl  bool // exclude
	start bool
}&lt;/code&gt;&lt;p&gt;每个 point 代表区间的一个端点，其中的 excl 表示端点为开区间的端点还是闭区间的端点。start 表示这个端点是左端点还是右端点。&lt;/p&gt;&lt;p&gt;builder 中每个 buildFromXXX 的方法都是计算一个具体函数的 range 的方法。比如 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L299&quot;&gt;buildFromIn&lt;/a&gt; 便是处理 &lt;a href=&quot;https://dev.mysql.com/doc/refman/5.7/en/comparison-operators.html#function_in&quot;&gt;in 函数&lt;/a&gt; 的方法。可以看到它首先对 in 函数的值列表的每个值都构造了一个 rangPoint 的单点区间，然后对这些区间放在一个 slice 中做排序以及去重。最终将去重后的结果输出。&lt;/p&gt;&lt;p&gt;在 pointer.go 中还包含其他各类的函数的处理，具体可以翻阅源代码。&lt;/p&gt;&lt;p&gt;除了对具体函数的处理外，pointer.go 中还有区间交和区间并的操作。&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L484&quot;&gt;intersection&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L488&quot;&gt;union&lt;/a&gt; 分别代表区间交和区间并。两个函数的逻辑均通过 merge 方法进行处理，通过传入一个 flag 来区分。merge 函数做了如下两个假设：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;a, b 两个区间均已经做过去重&lt;/li&gt;&lt;li&gt;单个区间序列内部不会有重叠的部分&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;merge 函数使用 inRangeCount 来记录当前位置被 a, b 两个区间序列覆盖的情况。区间求并的情况时，只要 a, b 两个区间序列中有一个区间序列覆盖便可以作为解输出，被两个区间同时覆盖的端点必然是属于一个更大的区间的内部不需要输出。所以当 inRangeCount 为 1 时，即为需要输出的区间端点。&lt;/p&gt;&lt;p&gt;当区间求交时，需要两个序列都覆盖到才是可以输出的端点，所以当 inRangeCount 为 2 时，即为需要输出的区间端点。&lt;/p&gt;&lt;p&gt;在得到最后的区间端点序列后，由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/ranger.go#L174&quot;&gt;points2TableRanges&lt;/a&gt; 转化为对外暴露的 range 结构，由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/ranger.go#L224&quot;&gt;BuildTableRange&lt;/a&gt; 输出到 plan package。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// NewRange represents a range generated in physical plan building phase.
type NewRange struct {
	LowVal  []types.Datum
	HighVal []types.Datum

	LowExclude  bool // Low value is exclusive.
	HighExclude bool // High value is exclusive.
}&lt;/code&gt;&lt;p&gt;在现在的 TiDB 中，单列索引和多列索引使用了相同的 range 结构，所以这里的端点值为 slice 的形式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于多列索引，当其为 AND 表达式时，根据前述我们可以知道，其形式必为索引前缀列上的等值条件再加上关于前缀之后一个列的复杂条件组成。所以我们只需要按顺序处理点查的等值条件部分，将点查的区间依次 append 到 NewRange 中的 LowVal 和 HighVal 两个 Slice 中即可（&lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L133&quot;&gt;appendPoints2Ranges&lt;/a&gt;）。处理到最后一列时，将之前的 NewRange 按最后非点查列所计算得到的区间个数拷贝一下，再依次 append 即可。具体代码可见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L282&quot;&gt;buildCNFIndexRange&lt;/a&gt;。&lt;br&gt;对于 OR 表达式的情况，由于此时 range 已经无法转回 point 的结构。所以这里重新实现了一下区间并的操作。实现的形式便是比较常见的将区间按左端点排序，在依次扫过区间的同时，记录当前所有重叠过的区间的最右右端点来进行做区间并的算法。区间并的具体的实现可见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L357&quot;&gt;unionRanges&lt;/a&gt; 方法。&lt;/p&gt;&lt;h2&gt;Future Plan&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;目前 TiDB 对单列索引的处理在逻辑上已经非常完备，在实际表现上可能由于没有对部分函数实现计算 range 的逻辑而有遗漏。这部分会根据情况进行优化。&lt;/li&gt;&lt;li&gt;如上文提到的，目前 TiDB 为了简化 ranger 的逻辑，对多列索引做了一些假设。未来会尝试去掉或者弱化这些假设，或者在前期对 SQL 进行更充分的改写使得 SQL 不会触发这些假设，来提供更加强大的功能，免于手动 rewrite 的麻烦。&lt;/li&gt;&lt;li&gt;目前 TiDB 对简单式子的形式的检查限定在了 Column op Constant 的形式。所以诸如 &lt;code class=&quot;inline&quot;&gt;from_unixtime(timestamp_col) op datetime_constant&lt;/code&gt; 形式的条件是无法计算索引的，也需要手动 rewrite 为 &lt;code class=&quot;inline&quot;&gt;timestamp_col op timestamp_constant&lt;/code&gt; 才可以使用到索引。这部分也会考虑进行改进以提升用户体验。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;（十二）统计信息（上）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-13-39649659</guid>
<pubDate>Fri, 13 Jul 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
