<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 30 Aug 2018 10:00:39 +0800</lastBuildDate>
<item>
<title>TiKV 加入 CNCF 沙箱托管项目</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-29-43278790.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43278790&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0b95a167ac111d328b7091dd4d9ce487_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;TiKV 加入 CNCF 沙箱托管项目&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://cncf.io/&quot;&gt;云原生计算基金会 (CNCF)&lt;/a&gt;今天宣布接纳 &lt;a href=&quot;https://github.com/tikv/tikv&quot;&gt;TiKV&lt;/a&gt; 开源分布式事务键值数据库作为 CNCF 沙箱的早期发展云原生项目。&lt;/p&gt;&lt;p&gt;TiKV 采用 &lt;a href=&quot;https://www.rust-lang.org/&quot;&gt;Rust&lt;/a&gt; 构建，由 &lt;a href=&quot;https://en.wikipedia.org/wiki/Raft_(computer_science)&quot;&gt;Raft&lt;/a&gt;（通过 etcd）驱动，并受到 Google Spanner 设计的激励，提供简化的调度和自动平衡，而不依赖于任何分布式文件系统。该项目是一个开源、统一分布式存储层，支持功能强大的数据一致性、分布式事务、水平可扩展性和云原生架构。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27ad63df5d6339a8264a57aec1efaee2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;975&quot; data-rawheight=&quot;513&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-27ad63df5d6339a8264a57aec1efaee2&quot; data-watermark-src=&quot;v2-d8fa777cb71f3f36f0d4d0334607aa85&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://www.pingcap.com/en/&quot;&gt;PingCAP&lt;/a&gt; 的首席工程师 和 TiKV 项目负责人 Siddon Tang 表示：“随着我们产生和收集的数据量继续以惊人的速度增长，各组织需要一种方法确保云原生环境的水平可扩展性和高度可用性。”“通过加入 CNCF，我们期待着建立项目治理，并在这一开发商中立之家培育愈发壮大的贡献者基地，让我们能够构建更多组件，例如，支持更多语言和新的有用功能。”&lt;/p&gt;&lt;p&gt;TiKV 最初于 2016 年在 PingCAP 开发，现在得到三星、摩拜单车、今日头条、饿了么、腾讯云和 UCloud 的支持。用户包括北京银行、饿了么、Hulu、联想、摩拜单车和&lt;a href=&quot;https://github.com/tikv/tikv/blob/master/docs/adopters.md&quot;&gt;诸多其他企业&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;该项目的 TOC 赞助商是 Bryan Cantrill 和 Ben Hindman。&lt;/p&gt;&lt;p&gt;CNCF 沙箱是早期阶段项目的孵化器，如需进一步了解 CNCF 项目成熟度，请访问&lt;a href=&quot;https://github.com/cncf/toc/blob/master/process/graduation_criteria.adoc&quot;&gt;毕业标准&lt;/a&gt;纲要。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;h2&gt;&lt;b&gt;CNCF to Host TiKV in the Sandbox&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Today, the &lt;a href=&quot;http://cncf.io/&quot;&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt; accepted &lt;a href=&quot;https://github.com/tikv/tikv&quot;&gt;TiKV&lt;/a&gt;, an open source distributed transactional key-value database, into the CNCF Sandbox for early stage and evolving cloud native projects.&lt;/p&gt;&lt;p&gt;Built in &lt;a href=&quot;https://www.rust-lang.org/&quot;&gt;Rust&lt;/a&gt;, powered by &lt;a href=&quot;https://en.wikipedia.org/wiki/Raft_(computer_science)&quot;&gt;Raft&lt;/a&gt; (via etcd) and inspired by the design of Google Spanner, TiKV offers simplified scheduling and auto-balancing without dependency on any distributed file system. The project serves as an open source, unifying distributed storage layer that supports strong data consistency, distributed transactions, horizontal scalability, and cloud native architecture.&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27ad63df5d6339a8264a57aec1efaee2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;975&quot; data-rawheight=&quot;513&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-27ad63df5d6339a8264a57aec1efaee2&quot; data-watermark-src=&quot;v2-d8fa777cb71f3f36f0d4d0334607aa85&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;“As the amount of data we are producing and collecting continues to grow at an astounding pace, organizations need a way to ensure horizontal scalability and high availability for cloud native applications,” said Siddon Tang, Chief Engineer at &lt;a href=&quot;https://www.pingcap.com/en/&quot;&gt;PingCAP&lt;/a&gt; and TiKV project lead. “By joining CNCF, we look forward to establishing project governance and growing a broader contributor base in this vendor neutral home – allowing us to build additional components like support for more languages and new useful features.”&lt;/p&gt;&lt;p&gt;TiKV was originally developed at PingCAP in 2016, and today includes contributions from Samsung, Mobike, Toutiao.com, Ele.me, Tencent Cloud and UCloud. Users include Bank of Beijing, Ele.me, Hulu, Lenovo, Mobike and &lt;a href=&quot;https://github.com/tikv/tikv/blob/master/docs/adopters.md&quot;&gt;many others&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The TOC sponsors of the project are Bryan Cantrill and Ben Hindman.&lt;/p&gt;&lt;p&gt;The CNCF Sandbox is a home for early stage projects, for further clarification around project maturity levels in CNCF, please visit our outlined &lt;a href=&quot;https://github.com/cncf/toc/blob/master/process/graduation_criteria.adoc&quot;&gt;Graduation Criteria&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://www.cncf.io/blog/2018/08/28/cncf-to-host-tikv-in-the-sandbox/&quot;&gt;CNCF to Host TiKV in the Sandbox - Cloud Native Computing Foundation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-29-43278790</guid>
<pubDate>Wed, 29 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十七）DDL 源码解析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-27-43088324.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43088324&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eef68c3b98ddf29ee7a0311e6259636c_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：陈霜&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;DDL 是数据库非常核心的组件，其正确性和稳定性是整个 SQL 引擎的基石，在分布式数据库中，如何在保证数据一致性的前提下实现无锁的 DDL 操作是一件有挑战的事情。&lt;/p&gt;&lt;p&gt;本文首先会介绍 TiDB DDL 组件的总体设计，以及如何在分布式场景下支持无锁 shema 变更，并描述这套算法的大致流程，然后详细介绍一些常见的 DDL 语句的源码实现，包括 &lt;code class=&quot;inline&quot;&gt;create table&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;add index&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;drop column&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;drop table&lt;/code&gt; 这四种。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;DDL in TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的 DDL 通过实现 Google F1 的在线异步 schema 变更算法，来完成在分布式场景下的无锁，在线 schema 变更。为了简化设计，TiDB 在同一时刻，只允许一个节点执行 DDL 操作。用户可以把多个 DDL 请求发给任何 TiDB 节点，但是所有的 DDL 请求在 TiDB 内部是由 &lt;b&gt;owner&lt;/b&gt; 节点的 &lt;b&gt;worker &lt;/b&gt;串行执行的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;worker：每个节点都有一个 worker 用来处理 DDL 操作。&lt;/li&gt;&lt;li&gt;owner：整个集群中只有一个节点能当选 owner，每个节点都可能当选这个角色。当选 owner 后的节点 worker 才有处理 DDL 操作的权利。owner 节点的产生是用 Etcd 的选举功能从多个 TiDB 节点选举出 owner 节点。owner 是有任期的，owner 会主动维护自己的任期，即续约。当 owner 节点宕机后，其他节点可以通过 Etcd 感知到并且选举出新的 owner。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里只是简单概述了 TiDB 的 DDL 设计，下两篇文章详细介绍了 TiDB DDL 的设计实现以及优化，推荐阅读：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/ngaut/builddatabase/blob/master/f1/schema-change-implement.md&quot;&gt;TiDB 的异步 schema 变更实现  &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://zimulala.github.io/2017/12/24/optimize/&quot;&gt;TiDB 的异步 schema 变更优化&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下图描述了一个 DDL 请求在 TiDB 中的简单处理流程：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b50b7dac9057fcc661c11624a87f5eb7_r.jpg&quot; data-caption=&quot;图 1：TiDB 中 DDL SQL 的处理流程&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1088&quot; data-rawheight=&quot;730&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b50b7dac9057fcc661c11624a87f5eb7&quot; data-watermark-src=&quot;v2-ec295f4a6baf2e4d815cefcca89fcacb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;TiDB 的 DDL 组件相关代码存放在源码目录的 &lt;code class=&quot;inline&quot;&gt;ddl&lt;/code&gt; 目录下。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-830cd4ddaaaf3919c05a60248d81cc42_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;635&quot; data-rawheight=&quot;276&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-830cd4ddaaaf3919c05a60248d81cc42&quot; data-watermark-src=&quot;v2-de4c148aff1c3ed3f886bcce72f5ebc5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;ddl owner&lt;/code&gt; 相关的代码单独放在 &lt;code class=&quot;inline&quot;&gt;owner&lt;/code&gt; 目录下，实现了 owner 选举等功能。&lt;/p&gt;&lt;p&gt;另外，&lt;code class=&quot;inline&quot;&gt;ddl job queue&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;history ddl job queue&lt;/code&gt; 这两个队列都是持久化到 TiKV 中的。&lt;code class=&quot;inline&quot;&gt;structure&lt;/code&gt; 目录下有 list，&lt;code class=&quot;inline&quot;&gt;hash&lt;/code&gt; 等数据结构在 TiKV 上的实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文接下来按照 TiDB 源码的&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/tree/source-code&quot;&gt;origin/source-code&lt;/a&gt;&lt;/b&gt; &lt;b&gt;分支讲解，最新的 master 分支和 source-code 分支代码会稍有一些差异。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Create table&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;create table&lt;/code&gt; 需要把 table 的元信息（&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/model/model.go#L95&quot;&gt;TableInfo&lt;/a&gt;）从 SQL 中解析出来，做一些检查，然后把 table 的元信息持久化保存到 TiKV 中。具体流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;语法解析：&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/session.go#L790&quot;&gt;ParseSQL&lt;/a&gt; 解析成抽象语法树 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ast/ddl.go#L393&quot;&gt;CreateTableStmt&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;编译生成 Plan：&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/session.go#L805&quot;&gt;Compile&lt;/a&gt; 生成 DDL plan , 并 check 权限等。&lt;/li&gt;&lt;li&gt;生成执行器：&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/adapter.go#L227&quot;&gt;buildExecutor&lt;/a&gt; 生成 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/ddl.go#L33&quot;&gt; DDLExec&lt;/a&gt; 执行器。TiDB 的执行器是火山模型。&lt;/li&gt;&lt;li&gt;执行器调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/adapter.go#L300&quot;&gt;e.Next&lt;/a&gt; 开始执行，即 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/ddl.go#L42&quot;&gt;DDLExec.Next&lt;/a&gt; 方法，判断 DDL 类型后执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/ddl.go#L68&quot;&gt;executeCreateTable&lt;/a&gt; , 其实质是调用 &lt;code class=&quot;inline&quot;&gt;ddl_api.go&lt;/code&gt; 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_api.go#L739&quot;&gt;CreateTable&lt;/a&gt; 函数。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_api.go#L739&quot;&gt;CreateTable&lt;/a&gt; 方法是主要流程如下：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;会先 check 一些限制，比如 table name 是否已经存在，table 名是否太长，是否有重复定义的列等等限制。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_api.go#L775&quot;&gt;buildTableInfo&lt;/a&gt; 获取 global table ID，生成 &lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt; , 即 table 的元信息，然后封装成一个 DDL job，这个 job 包含了 &lt;code class=&quot;inline&quot;&gt;table ID&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt;，并将这个 job 的 type 标记为 &lt;code class=&quot;inline&quot;&gt;ActionCreateTable&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_api.go#L793&quot;&gt;d.doDDLJob(ctx, job)&lt;/a&gt; 函数中的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl.go#L423&quot;&gt;d.addDDLJob(ctx, job)&lt;/a&gt; 会先给 job 获取一个 global job ID 然后放到 job queue 中去。&lt;/li&gt;&lt;li&gt;DDL 组件启动后，在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl.go#L318&quot;&gt;start&lt;/a&gt; 函数中会启动一个 &lt;code class=&quot;inline&quot;&gt;ddl_worker&lt;/code&gt; 协程运行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L37&quot;&gt;onDDLWorker&lt;/a&gt; 函数（最新 Master 分支函数名已重命名为 start），每隔一段时间调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L193&quot;&gt;handleDDLJobQueu&lt;/a&gt; 函数去尝试处理 DDL job 队列里的 job，&lt;code class=&quot;inline&quot;&gt;ddl_worker&lt;/code&gt; 会先 check 自己是不是 owner，如果不是 owner，就什么也不做，然后返回；如果是 owner，就调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L212&quot;&gt;getFirstDDLJob&lt;/a&gt; 函数获取 DDL 队列中的第一个 job，然后调 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L236&quot;&gt;runDDLJob&lt;/a&gt; 函数执行 job。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L275&quot;&gt;runDDLJob&lt;/a&gt; 函数里面会根据 job 的类型，然后调用对应的执行函数，对于 &lt;code class=&quot;inline&quot;&gt;create table&lt;/code&gt; 类型的 job，会调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/table.go#L31&quot;&gt;onCreateTable&lt;/a&gt; 函数，然后做一些 check 后，会调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/table.go#L56&quot;&gt;t.CreateTable&lt;/a&gt; 函数，将 &lt;code class=&quot;inline&quot;&gt;db_ID&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;table_ID&lt;/code&gt; 映射为 &lt;code class=&quot;inline&quot;&gt;key&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt; 作为 value 存到 TiKV 里面去，并更新 job 的状态。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L152&quot;&gt;finishDDLJob&lt;/a&gt; 函数将 job 从 DDL job 队列中移除，然后加入 history ddl job 队列中去。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl.go#L451&quot;&gt;doDDLJob&lt;/a&gt; 函数中检测到 history DDL job 队列中有对应的 job 后，返回。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Add index&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;add index&lt;/code&gt; 主要做 2 件事：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;修改 table 的元信息，把 &lt;code class=&quot;inline&quot;&gt;indexInfo&lt;/code&gt; 加入到 table 的元信息中去。&lt;/li&gt;&lt;li&gt;把 table 中已有了的数据行，把 &lt;code class=&quot;inline&quot;&gt;index columns&lt;/code&gt; 的值全部回填到 &lt;code class=&quot;inline&quot;&gt;index record&lt;/code&gt; 中去。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;具体执行流程的前部分的 SQL 解析、Compile 等流程，和 &lt;code class=&quot;inline&quot;&gt;create table&lt;/code&gt; 一样，可以直接从 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/ddl.go#L42&quot;&gt;DDLExec.Next&lt;/a&gt; 开始看，然后调用 &lt;code class=&quot;inline&quot;&gt;alter&lt;/code&gt; 语句的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/ddl.go#L78&quot;&gt;e.executeAlterTable(x)&lt;/a&gt; 函数，其实质调 ddl 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_api.go#L862&quot;&gt;AlterTable&lt;/a&gt; 函数，然后调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_api.go#L1536&quot;&gt;CreateIndex&lt;/a&gt; 函数，开始执行 add index 的主要工作，具体流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Check 一些限制，比如 table 是否存在，索引是否已经存在，索引名是否太长等。&lt;/li&gt;&lt;li&gt;封装成一个 job，包含了索引名，索引列等，并将 job 的 type 标记为 &lt;code class=&quot;inline&quot;&gt;ActionAddIndex&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;给 job 获取一个 global job ID 然后放到 DDL job 队列中去。&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;owner ddl worker&lt;/code&gt; 从 DDL job 队列中取出 job，根据 job 的类型调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/index.go#L177&quot;&gt;onCreateIndex&lt;/a&gt; 函数。&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;buildIndexInfo&lt;/code&gt; 生成 &lt;code class=&quot;inline&quot;&gt;indexInfo&lt;/code&gt;，然后更新 &lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt; 中的 &lt;code class=&quot;inline&quot;&gt;Indices&lt;/code&gt;，持久化到 TiKV 中去。&lt;/li&gt;&lt;li&gt;这里引入了 online schema change 的几个步骤，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/index.go#L237&quot;&gt;需要留意 indexInfo 的状态变化&lt;/a&gt;：&lt;code class=&quot;inline&quot;&gt;none -&amp;gt; delete only -&amp;gt; write only -&amp;gt; reorganization -&amp;gt;  public&lt;/code&gt;。在 &lt;code class=&quot;inline&quot;&gt;reorganization -&amp;gt; public&lt;/code&gt; 时，首先调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/reorg.go#L147&quot;&gt;getReorgInfo&lt;/a&gt; 获取 &lt;code class=&quot;inline&quot;&gt;reorgInfo&lt;/code&gt;，主要包含需要 &lt;code class=&quot;inline&quot;&gt;reorganization&lt;/code&gt; 的 range，即从表的第一行一直到最后一行数据都需要回填到 &lt;code class=&quot;inline&quot;&gt;index record&lt;/code&gt; 中。然后调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/reorg.go#L72&quot;&gt;runReorgJob&lt;/a&gt; , &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/index.go#L554&quot;&gt;addTableIndex&lt;/a&gt;函数开始填充数据到 &lt;code class=&quot;inline&quot;&gt;index record&lt;/code&gt;中去。&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/reorg.go#L112&quot;&gt;runReorgJob&lt;/a&gt; 函数会定期保存回填数据的进度到 TiKV。&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/index.go#L566&quot;&gt;addTableIndex&lt;/a&gt; 的流程如下：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;启动多个 &lt;code class=&quot;inline&quot;&gt;worker&lt;/code&gt; 用于并发回填数据到 &lt;code class=&quot;inline&quot;&gt;index record&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;把 &lt;code class=&quot;inline&quot;&gt;reorgInfo&lt;/code&gt; 中需要 &lt;code class=&quot;inline&quot;&gt;reorganization&lt;/code&gt; 分裂成多个 range。扫描的默认范围是 &lt;code class=&quot;inline&quot;&gt;[startHandle , endHandle]&lt;/code&gt;，然后默认以 128 为间隔分裂成多个 range，之后并行扫描对应数据行。在 master 分支中，range 范围信息是从 PD 中获取。&lt;/li&gt;&lt;li&gt;把 range 包装成多个 task，发给 &lt;code class=&quot;inline&quot;&gt;worker&lt;/code&gt; 并行回填 &lt;code class=&quot;inline&quot;&gt;index record&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;等待所有 &lt;code class=&quot;inline&quot;&gt;worker&lt;/code&gt; 完成后，更新 &lt;code class=&quot;inline&quot;&gt;reorg&lt;/code&gt; 进度，然后持续第 3 步直到所有的 task 都做完。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;5. 后续执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L152&quot;&gt;finishDDLJob&lt;/a&gt;，检测 history ddl job 流程和 &lt;code class=&quot;inline&quot;&gt;create table&lt;/code&gt; 类似。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Drop Column&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;drop Column&lt;/code&gt; 只要修改 table 的元信息，把 table 元信息中对应的要删除的 column 删除。&lt;code class=&quot;inline&quot;&gt;drop Column&lt;/code&gt; 不会删除原有 table 数据行中的对应的 Column 数据，在 decode 一行数据时，会根据 table 的元信息来 decode。&lt;/p&gt;&lt;p&gt;具体执行流程的前部分都类似，直接跳到 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_api.go#L1093&quot;&gt;DropColumn&lt;/a&gt; 函数开始，具体执行流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Check table 是否存在，要 drop 的 column 是否存在等。&lt;/li&gt;&lt;li&gt;封装成一个 job, 将 job 类型标记为 &lt;code class=&quot;inline&quot;&gt;ActionDropColumn&lt;/code&gt;，然后放到 DDL job 队列中去&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;owner ddl worker&lt;/code&gt; 从 DDL job 队列中取出 job，根据 job 的类型调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/column.go#L174&quot;&gt;onDropColumn&lt;/a&gt; 函数：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;这里 &lt;code class=&quot;inline&quot;&gt;column info&lt;/code&gt; 的状态变化和 &lt;code class=&quot;inline&quot;&gt;add index&lt;/code&gt; 时的变化几乎相反：&lt;code class=&quot;inline&quot;&gt;public -&amp;gt; write only -&amp;gt; delete only -&amp;gt; reorganization -&amp;gt; absent&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/table.go#L362&quot;&gt;updateVersionAndTableInfo&lt;/a&gt; 更新 table 元信息中的 Columns。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;4. 后续执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L152&quot;&gt;finishDDLJob&lt;/a&gt;，检测 history ddl job 流程和 &lt;code class=&quot;inline&quot;&gt;create table&lt;/code&gt; 类似。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Drop table&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;drop table&lt;/code&gt; 需要删除 table 的元信息和 table 中的数据。&lt;/p&gt;&lt;p&gt;具体执行流程的前部分都类似，&lt;code class=&quot;inline&quot;&gt;owner ddl worker&lt;/code&gt; 从 DDL job 队列中取出 job 后执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/table.go#L76&quot;&gt;onDropTable&lt;/a&gt; 函数：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt; 的状态变化是：&lt;code class=&quot;inline&quot;&gt;public -&amp;gt; write only -&amp;gt; delete only -&amp;gt; none&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt; 的状态变为 &lt;code class=&quot;inline&quot;&gt;none&lt;/code&gt; 之后，会调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/meta/meta.go#L306&quot;&gt; DropTable&lt;/a&gt; 将 table 的元信息从 TiKV 上删除。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;至于删除 table 中的数据，后面在调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L152&quot;&gt;finishDDLJob&lt;/a&gt; 函数将 job 从 job queue 中移除，加入 history ddl job queue 前，会调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/ddl/ddl_worker.go#L160&quot;&gt;delRangeManager.addDelRangeJob(job)&lt;/a&gt;，将要删除的 table 数据范围插入到表 &lt;code class=&quot;inline&quot;&gt;gc_delete_range&lt;/code&gt; 中，然后由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/store/tikv/gcworker/gc_worker.go&quot;&gt;GC worker&lt;/a&gt; 根据 &lt;code class=&quot;inline&quot;&gt;gc_delete_range&lt;/code&gt; 中的信息在 GC 过程中做真正的删除数据操作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;New Parallel DDL&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前 TiDB 最新的 Master 分支的 DDL 引入了并行 DDL，用来加速多个 DDL 语句的执行速度。因为串行执行 DDL 时，&lt;code class=&quot;inline&quot;&gt;add index&lt;/code&gt; 操作需要把 table 中已有的数据回填到 &lt;code class=&quot;inline&quot;&gt;index record&lt;/code&gt; 中，如果 table 中的数据较多，回填数据的耗时较长，就会阻塞后面 DDL 的操作。目前并行 DDL 的设计是将 &lt;code class=&quot;inline&quot;&gt;add index job&lt;/code&gt; 放到新增的 &lt;code class=&quot;inline&quot;&gt;add index job queue&lt;/code&gt; 中去，其它类型的 DDL job 还是放在原来的 job queue。相应的，也增加一个 &lt;code class=&quot;inline&quot;&gt;add index worker&lt;/code&gt; 来处理 &lt;code class=&quot;inline&quot;&gt;add index job queue&lt;/code&gt; 中的 job。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c2a566a46f5c077f474a4e17ccce2b6b_r.jpg&quot; data-caption=&quot;图 2：并行 DDL 处理流程&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1121&quot; data-rawheight=&quot;676&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c2a566a46f5c077f474a4e17ccce2b6b&quot; data-watermark-src=&quot;v2-6b88067473e2e6254b3b8cf922b0de11&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;并行 DDL 同时也引入了 job 依赖的问题。job 依赖是指同一 table 的 DDL job，job ID 小的需要先执行。因为对于同一个 table 的 DDL 操作必须是顺序执行的。比如说，&lt;code class=&quot;inline&quot;&gt;add column a&lt;/code&gt;，然后 &lt;code class=&quot;inline&quot;&gt;add index on column a&lt;/code&gt;, 如果 &lt;code class=&quot;inline&quot;&gt;add index&lt;/code&gt; 先执行，而 &lt;code class=&quot;inline&quot;&gt;add column&lt;/code&gt; 的 DDL 假设还在排队未执行，这时 &lt;code class=&quot;inline&quot;&gt;add index on column a&lt;/code&gt; 就会报错说找不到 &lt;code class=&quot;inline&quot;&gt;column a&lt;/code&gt;。所以当 &lt;code class=&quot;inline&quot;&gt;add index job queue&lt;/code&gt; 中的 job2 执行前，需要检测 job queue 是否有同一 table 的 job1 还未执行，通过对比 job 的 job ID 大小来判断。执行 job queue 中的 job 时也需要检查 &lt;code class=&quot;inline&quot;&gt;add index job queue&lt;/code&gt; 中是否有依赖的 job 还未执行。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;End&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 目前一共支持 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/model/ddl.go#L32&quot;&gt;十多种 DDL&lt;/a&gt;，具体以及和 MySQL 兼容性对比可以看 &lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/master/sql/ddl.md&quot;&gt;这里&lt;/a&gt;。剩余其它类型的 DDL 源码实现读者可以自行阅读，流程和上述几种 DDL 类似。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-27-43088324</guid>
<pubDate>Mon, 27 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 2.1 RC1 Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-24-42900414.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42900414&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-547ba61d15cf1a27d999b7155098de96_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 8 月 24 日，TiDB 发布 2.1 RC1 版。相比 2.1 Beta 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;修复某些情况下关联子查询去关联后结果不正确的问题 &lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Explain&lt;/code&gt; 输出结果 &lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;IndexJoin&lt;/code&gt; 驱动表选择策略&lt;/li&gt;&lt;li&gt;去掉非 &lt;code class=&quot;inline&quot;&gt;PREPARE&lt;/code&gt; 语句的 Plan Cache&lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;INSERT&lt;/code&gt; 语句无法正常解析执行的问题&lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;IndexJoin&lt;/code&gt; 结果不正确的问题&lt;/li&gt;&lt;li&gt;修复某些情况下使用唯一索引不能查询到 &lt;code class=&quot;inline&quot;&gt;NULL&lt;/code&gt; 值的问题 &lt;/li&gt;&lt;li&gt;修复 UTF-8 编码情况下前缀索引的范围计算不正确的问题 &lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;Project&lt;/code&gt; 算子消除导致的结果不正确的问题 &lt;/li&gt;&lt;li&gt;修复主键为整数类型时无法使用 &lt;code class=&quot;inline&quot;&gt;USE INDEX(PRIMARY)&lt;/code&gt; 的问题 &lt;/li&gt;&lt;li&gt;修复某些情况下使用关联列无法计算索引范围的问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. SQL 执行引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复某些情况下夏令时时间计算结果不正确的问题&lt;/li&gt;&lt;li&gt;重构聚合函数框架，提升 &lt;code class=&quot;inline&quot;&gt;Stream&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;Hash&lt;/code&gt; 聚合算子的执行效率&lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;Hash&lt;/code&gt; 聚合算子不能正常退出的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;BIT_AND&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;BIT_OR&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;BIT_XOR&lt;/code&gt; 没有正确处理非整型数据的问题&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;REPLACE INTO&lt;/code&gt; 语句的执行速度，性能提升近 10 倍&lt;/li&gt;&lt;li&gt;优化时间类型的内存占用，时间类型数据的内存使用降低为原来的一半&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;UNION&lt;/code&gt; 语句整合有符号和无符号型整数结果时与 MySQL 不兼容的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;LPAD&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;RPAD&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;TO_BASE64&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;FROM_BASE64&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;REPEAT&lt;/code&gt; 因为申请过多内存导致 TiDB panic 的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;MergeJoin&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;IndexJoin&lt;/code&gt; 在处理 &lt;code class=&quot;inline&quot;&gt;NULL&lt;/code&gt; 值时结果不正确的问题&lt;/li&gt;&lt;li&gt;修复某些情况下 Outer Join 结果不正确的问题&lt;/li&gt;&lt;li&gt;增强 &lt;code class=&quot;inline&quot;&gt;Data Truncated&lt;/code&gt; 的报错信息，便于定位出错的数据和表中对应的字段&lt;/li&gt;&lt;li&gt;修复某些情况下 Decimal 计算结果不正确的问题&lt;/li&gt;&lt;li&gt;优化点查的查询性能&lt;/li&gt;&lt;li&gt;禁用 &lt;code class=&quot;inline&quot;&gt;Read Commited&lt;/code&gt; 隔离级别，避免潜在的问题 &lt;/li&gt;&lt;li&gt;修复某些情况下 &lt;code class=&quot;inline&quot;&gt;LTRIM&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;RTRIM&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;TRIM&lt;/code&gt; 结果不正确的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;MaxOneRow&lt;/code&gt; 算子无法保证返回结果不超过 1 行的问题&lt;/li&gt;&lt;li&gt;拆分 range 个数过多的 Coprocessor 请求&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 统计信息&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;优化统计信息动态收集机制&lt;/li&gt;&lt;li&gt;解决数据频繁更新场景下 &lt;code class=&quot;inline&quot;&gt;Auto Analyze&lt;/code&gt; 不工作的问题&lt;/li&gt;&lt;li&gt;减少统计信息动态更新过程中的写入冲突 &lt;/li&gt;&lt;li&gt;优化统计信息不准确情况下的代价估算&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;AccessPath&lt;/code&gt; 的代价估算策略 &lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. Server&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复加载权限信息时的 bug&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;Kill&lt;/code&gt; 命令对权限的检查过严问题&lt;/li&gt;&lt;li&gt;解决 Binary 协议中某些数值类型移除的问题&lt;/li&gt;&lt;li&gt;精简日志输出 &lt;/li&gt;&lt;li&gt;处理 &lt;code class=&quot;inline&quot;&gt;mismatchClusterID&lt;/code&gt; 问题&lt;/li&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;advertise-address&lt;/code&gt; 配置项&lt;/li&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;GrpcKeepAlive&lt;/code&gt; 选项&lt;/li&gt;&lt;li&gt;增加连接或者 &lt;code class=&quot;inline&quot;&gt;Token&lt;/code&gt; 时间监控&lt;/li&gt;&lt;li&gt;优化数据解码性能 &lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INFORMMATION_SCHEMA&lt;/code&gt; 中增加 &lt;code class=&quot;inline&quot;&gt;PROCESSLIST&lt;/code&gt; 表&lt;/li&gt;&lt;li&gt;解决权限验证时多条规则可以命中情况下的顺序问题&lt;/li&gt;&lt;li&gt;将部分编码相关的系统变量默认值改为 UTF-8 &lt;/li&gt;&lt;li&gt;慢查询日志显示更详细的信息&lt;/li&gt;&lt;li&gt;支持在 PD 注册 tidb-server 的相关信息并通过 HTTP API 获取 &lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;5. 兼容性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;Session&lt;/code&gt; 变量 &lt;code class=&quot;inline&quot;&gt;warning_count&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;error_count&lt;/code&gt; &lt;/li&gt;&lt;li&gt;读取系统变量时增加 Scope 检查&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;MAX_EXECUTION_TIME&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持更多的 &lt;code class=&quot;inline&quot;&gt;SET&lt;/code&gt; 语法 &lt;/li&gt;&lt;li&gt;Set 系统变量值过程中增加合法性校验&lt;/li&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;Prepare&lt;/code&gt; 语句中 &lt;code class=&quot;inline&quot;&gt;PlaceHolder&lt;/code&gt; 数量的校验&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;set character_set_results = null&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;flush status&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;SET&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;ENUM&lt;/code&gt;  类型在 &lt;code class=&quot;inline&quot;&gt;information_schema&lt;/code&gt; 里的 column size&lt;/li&gt;&lt;li&gt;支持建表语句里的 &lt;code class=&quot;inline&quot;&gt;NATIONAL CHARACTER&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;CHARACTER SET&lt;/code&gt; 语法 &lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;SET&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;ENUM&lt;/code&gt; 类型的 column info&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;CREATE USER&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;IDENTIFIED WITH&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;TIMESTAMP&lt;/code&gt; 类型计算过程中丢失精度的问题 &lt;/li&gt;&lt;li&gt;支持更多 &lt;code class=&quot;inline&quot;&gt;SYSTEM&lt;/code&gt; 变量的合法性验证&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;CHAR_LENGTH&lt;/code&gt; 函数在计算 binary string 时结果不正确的问题&lt;/li&gt;&lt;li&gt;修复在包含 &lt;code class=&quot;inline&quot;&gt;GROUP BY&lt;/code&gt; 的语句里 &lt;code class=&quot;inline&quot;&gt;CONCAT&lt;/code&gt; 结果不正确的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;DECIMAL&lt;/code&gt; 类型 CAST 到 &lt;code class=&quot;inline&quot;&gt;STRING&lt;/code&gt; 类型时，类型长度不准确的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;6. DML&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;解决 &lt;code class=&quot;inline&quot;&gt;Load Data&lt;/code&gt; 语句的稳定性 &lt;/li&gt;&lt;li&gt;解决一些 &lt;code class=&quot;inline&quot;&gt;Batch&lt;/code&gt; 操作情况下的内存使用问题 &lt;/li&gt;&lt;li&gt;提升 &lt;code class=&quot;inline&quot;&gt;Replace Into&lt;/code&gt; 语句的性能&lt;/li&gt;&lt;li&gt;修复写入 &lt;code class=&quot;inline&quot;&gt;CURRENT_TIMESTAMP&lt;/code&gt; 时，精度不一致的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;7. DDL&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;改进 DDL 判断 &lt;code class=&quot;inline&quot;&gt;Schema&lt;/code&gt; 是否已经同步的方法, 避免某些情况下的误判&lt;/li&gt;&lt;li&gt;修复在 &lt;code class=&quot;inline&quot;&gt;ADD INDEX&lt;/code&gt; 过程中的 &lt;code class=&quot;inline&quot;&gt;SHOW CREATE TABLE&lt;/code&gt; 结果&lt;/li&gt;&lt;li&gt;非严格 &lt;code class=&quot;inline&quot;&gt;sql-mode&lt;/code&gt; 模式下, &lt;code class=&quot;inline&quot;&gt;text&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;blob&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;json&lt;/code&gt; 的默认值可以为空 &lt;/li&gt;&lt;li&gt;修复某些特定场景下 &lt;code class=&quot;inline&quot;&gt;ADD INDEX&lt;/code&gt; 的问题&lt;/li&gt;&lt;li&gt;大幅度提升添加 &lt;code class=&quot;inline&quot;&gt;UNIQUE-KEY&lt;/code&gt; 索引操作的速度&lt;/li&gt;&lt;li&gt;修复 Prefix-index 在 UTF-8 字符集的场景下的截断问题&lt;/li&gt;&lt;li&gt;增加环境变量 &lt;code class=&quot;inline&quot;&gt;tidb_ddl_reorg_priority&lt;/code&gt; 来控制 &lt;code class=&quot;inline&quot;&gt;add-index&lt;/code&gt; 操作的优先级&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;information_schema.tables&lt;/code&gt; 中 &lt;code class=&quot;inline&quot;&gt;AUTO-INCREMENT&lt;/code&gt; 的显示问题 &lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;admin show ddl jobs &amp;lt;number&amp;gt;&lt;/code&gt; 命令, 支持输出 number 个 DDL jobs&lt;/li&gt;&lt;li&gt;支持并行 DDL 任务执行&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;8. &lt;a href=&quot;https://github.com/pingcap/tidb/projects/6&quot;&gt;Table Partition&lt;/a&gt;（实验性）&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;支持一级分区&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;Range Partition&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;引入版本控制机制，支持集群滚动兼容升级&lt;/li&gt;&lt;li&gt;开启 &lt;code class=&quot;inline&quot;&gt;Region merge&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;GetPrevRegion&lt;/code&gt; 接口&lt;/li&gt;&lt;li&gt;支持批量 &lt;code class=&quot;inline&quot;&gt;split Region&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持存储 GC safepoint&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 功能改进&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;优化系统时间回退影响 TSO 分配的问题&lt;/li&gt;&lt;li&gt;优化处理 Region heartbeat 的性能&lt;/li&gt;&lt;li&gt;优化 Region tree 性能&lt;/li&gt;&lt;li&gt;优化计算热点统计的性能问题&lt;/li&gt;&lt;li&gt;优化 API 接口错误码返回&lt;/li&gt;&lt;li&gt;新增一些控制调度策略的开关&lt;/li&gt;&lt;li&gt;禁止在 label 中使用特殊字符&lt;/li&gt;&lt;li&gt;完善调度模拟器&lt;/li&gt;&lt;li&gt;pd-ctl 支持使用统计信息进行 Region split&lt;/li&gt;&lt;li&gt;pd-ctl 支持调用 &lt;code class=&quot;inline&quot;&gt;jq&lt;/code&gt; 来格式化 JSON 输出&lt;/li&gt;&lt;li&gt;新增 etcd Raft 状态机相关 metrics&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. Bug 修复&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复 leader 切换后 namespace 未重新加载的问题&lt;/li&gt;&lt;li&gt;修复 namespace 调度超出 schedule limit 配置的问题&lt;/li&gt;&lt;li&gt;修复热点调度超出 schedule limit 的问题&lt;/li&gt;&lt;li&gt;修复 PD client 关闭时输出一些错误日志的问题&lt;/li&gt;&lt;li&gt;修复 Region 心跳延迟统计有误的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;batch split&lt;/code&gt;，防止热点 Region 写入产生超大 Region&lt;/li&gt;&lt;li&gt;支持设置根据数据行数 split Region，提升 index scan 效率&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 性能优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code class=&quot;inline&quot;&gt;LocalReader&lt;/code&gt; 将 Read 操作从 raftstore 线程分离，减少 Read 延迟&lt;/li&gt;&lt;li&gt;重构 MVCC 框架，优化 memory 使用，提升 scan read 性能&lt;/li&gt;&lt;li&gt;支持基于统计估算进行 Region split，减少 I/O 开销&lt;/li&gt;&lt;li&gt;优化连续写入 Rollback 记录后影响读性能的问题&lt;/li&gt;&lt;li&gt;减少下推聚合计算的内存开销&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 功能改进&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;增加大量内建函数下推支持，更完善的 charset 支持&lt;/li&gt;&lt;li&gt;优化 GC 流程，提升 GC 速度并降低 GC 对系统的影响&lt;/li&gt;&lt;li&gt;开启 &lt;code class=&quot;inline&quot;&gt;prevote&lt;/code&gt;，加快网络异常时的恢复服务速度&lt;/li&gt;&lt;li&gt;增加 RocksDB 日志文件相关的配置项&lt;/li&gt;&lt;li&gt;调整 &lt;code class=&quot;inline&quot;&gt;scheduler latch&lt;/code&gt; 默认配置&lt;/li&gt;&lt;li&gt;使用 tikv-ctl 手动 compact 时可设定是否 compact RocksDB 最底层数据&lt;/li&gt;&lt;li&gt;增加启动时的环境变量检查&lt;/li&gt;&lt;li&gt;支持基于已有数据动态设置 &lt;code class=&quot;inline&quot;&gt;dynamic_level_bytes&lt;/code&gt; 参数&lt;/li&gt;&lt;li&gt;支持自定义日志格式&lt;/li&gt;&lt;li&gt;tikv-ctl 整合 tikv-fail 工具&lt;/li&gt;&lt;li&gt;增加 threads IO metrics&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. Bug 修复&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;修复 decimal 相关问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;gRPC max_send_message_len&lt;/code&gt; 设置有误的问题&lt;/li&gt;&lt;li&gt;修复 &lt;code class=&quot;inline&quot;&gt;region_size&lt;/code&gt; 配置不当时产生的问题&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如今，在社区和 PingCAP 技术团队的共同努力下，TiDB 2.1 RC1 版已发布，在此感谢社区小伙伴们长久以来的参与和贡献。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;作为明星级开源的分布式关系型数据库，TiDB 灵感来自于 Google Spanner/F1，具备『分布式强一致性事务、在线弹性水平扩展、故障自恢复的高可用、跨数据中心多活』等核心特性。TiDB 于 2015 年 5 月在 GitHub 创建，同年 12 月发布 Alpha 版本，而后于 2016 年 6 月发布 Beta 版，12 月发布 RC1 版， 2017 年 3 月发布 RC2 版，6 月发布 RC3 版，8 月发布 RC4 版，10 月发版 TiDB 1.0，2018 年 3 月发版 2.0 RC1，4 月发版 2.0 GA。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-24-42900414</guid>
<pubDate>Fri, 24 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>【详解】What’s New in TiDB 2.1 RC1</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-24-42900183.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42900183&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c5471d4c277c4314ece59344787b7a49_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 4 月底，我们发布了 TiDB 2.0 GA 版本，过去的几个月中，这个版本在上百家用户的生产环境中上线，覆盖了多个行业，包括大型互联网、银行、教育、电信、制造业等。与此同时，我们也开始了 2.1 版本的开发，经过 4 个月时间、1058 次代码提交，2.1 RC1 带着更全面的功能和大幅性能提升来到这里，与大家见面。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;新增特性&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Raft 新特性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Raft 是整个 TiKV 存储引擎的基础，2.1 版本中我们引入了 PreVote、Learner、Region Merge、Region Batch Split 这样四个特性，提升这一基础组件的性能和稳定性。其中 Learner 也是由我们贡献给 Etcd 的新特性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;热点调度&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;热点是分布式系统最大的敌人之一，并且大家的业务场景复杂多变，让热点问题捉摸不定，也是最狡猾的敌人。2.1 版本中，我们一方面增强热点检测能力，尽可能详细地统计系统负载，更快的发现热点；另一方面优化热点调度策略，用尽可能小的代价，尽快地打散热点。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;并行 DDL&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DDL 是 SQL 的基础。在 2.1 版本之前，所有的 DDL 操作的都是串行进行，比如在对一张大表进行 Add Index 操作时，所有的 Create Table、Create Database 语句都会被阻塞，我们在 2.1 版本中对此进行了优化。Add Index 操作和其他 DDL 操作的处理分离，不相关的表上面的操作不会相互阻塞。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Table Partition（实验性）&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;分布式数据库可以很容易的存储海量数据，但是 Table Parition 也能找到用武之地。比如在存储日志并定期进行数据归档的场景下，可以通过 Drop Partition 来方便的清理历史数据。在高并发写入的场景下，将单表数据分成多个 Parition 也有助于将写入流量打散在集群上。我们期望这个特性能够在 2.2 或者 3.0 版本中稳定下来。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;统计信息动态更新&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 OLTP 场景中，数据的统计分布决定了查询计划的合理性，在数据变化频繁的场景下，维护统计信息的实时性和准确性非常重要。2.1 版本中我们重点优化了统计信息的实时更新，通过执行查询过程中的反馈信息，不断地纠正已有的统计信息。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;并行聚合算子&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 OLAP 场景中，聚合和 Join 是最重要的两个算子，其性能决定了语句的处理速度，Join 算子在 2.0 版本中已经是并行模式，2.1 版本中我们对聚合算子做了重点优化，一方面将单线程变成多线程模式，另一方面对聚合的框架做了重构，聚合算子的运行速度、内存使用效率都有极大地提升。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;性能优化&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的定位是一个 HTAP 数据库，OLTP 和 OLAP 都是目标场景。2.1 RC1 版本中，我们对点查、区间扫描、聚合运算这些通用场景进行了优化，也对 “replace into” 语句， Add Index 这些特定场景做了优化。这些场景都有很好的性能提升，有的甚至有数量级的提升。&lt;/p&gt;&lt;p&gt;我们将会在 2.1 GA 版本中发布相比 2.0 GA 的 Benchmark 结果，也希望大家在自己的业务场景中实测对比，然后告诉我们在实际业务上的表现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;开源社区&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在这些激动人心的特性背后，一方面是 PingCAP 开发团队的辛勤工作，另一方面是日益壮大的 TiDB 全球社区。我们欣喜地看到，从 TiDB 2.1 Beta 版发布到现在的短短两个月时间，新增 30 多位 Contributor，其中杜川成为了 TiDB Committer。在这里对社区贡献者表示由衷的感谢，也希望更多志同道合的人能加入进来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;做分布式关系型数据库这样一个通用基础软件如同在夜晚的茫茫大海中航行，充满无数的未知和挑战，社区就是照亮我们前进路线的满天星斗。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;TiDB 2.1 Beta 版到 RC1 版期间新增 Contributor List&lt;/b&gt;&lt;br&gt;mz1999&lt;br&gt;liuzhengyang&lt;br&gt;cityonsky&lt;br&gt;mail2fish&lt;br&gt;ceohockey60&lt;br&gt;crazycs520&lt;br&gt;zbdba&lt;br&gt;laidahe&lt;br&gt;birdstorm&lt;br&gt;gregwebs&lt;br&gt;hhxcc&lt;br&gt;liukun4515&lt;br&gt;morgo&lt;br&gt;supernan1994&lt;br&gt;bb7133&lt;br&gt;maninalift&lt;br&gt;kbacha&lt;br&gt;ceohockey60&lt;br&gt;DorianZheng&lt;br&gt;GuillaumeGomez&lt;br&gt;TennyZhuang&lt;br&gt;lerencao&lt;br&gt;smallyard&lt;br&gt;sweetIan&lt;br&gt;arosspope&lt;br&gt;York Xiang&lt;br&gt;Mason Hua&lt;br&gt;ice1000&lt;br&gt;opensourcegeek&lt;br&gt;xiangyuf&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-24-42900183</guid>
<pubDate>Fri, 24 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Operator 开源技术细节详解</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-23-42752388.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42752388&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-48f8f9e31ea70d19e831ccc983565e3b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;原标题：TiDB Operator，让 TiDB 成为真正的 Cloud-Native 数据库&lt;/i&gt;&lt;/p&gt;&lt;p&gt;TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具。目前，TiDB Operator 已正式开源（&lt;a href=&quot;https://github.com/pingcap/tidb-operator/&quot;&gt;pingcap/tidb-operator&lt;/a&gt;）。借助 TiDB Operator，TiDB 可以无缝运行在公有云厂商提供的 Kubernetes 平台上，让 TiDB 成为真正的 Cloud-Native 数据库。&lt;/p&gt;&lt;p&gt;要了解 TiDB Operator，首先需要对 TiDB 和 Kubernetes 有一定了解，相信长期以来一直关注 TiDB 的同学可能对 TiDB 已经比较熟悉了。本文将首先简单介绍一下 TiDB 和 Kubernetes，聊一聊为什么我们要做 TiDB Operator，然后讲讲如何快速体验 TiDB Operator，以及如何参与到 TiDB Operator 项目中来成为 Contributor。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 和 Kubernetes 简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 作为一个开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。&lt;/li&gt;&lt;li&gt;TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。&lt;/li&gt;&lt;li&gt;PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ad51136bfaadda2d121e2f0c54d171e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;312&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2ad51136bfaadda2d121e2f0c54d171e&quot; data-watermark-src=&quot;v2-631273bf6d410f73038521245f886545&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Kubernetes 最早是作为一个纯粹的容器编排系统而诞生的，用户部署好 Kubernetes 集群之后，直接使用其内置的各种功能部署应用服务。&lt;/p&gt;&lt;p&gt;由于这个 PaaS 平台使用起来非常便利，吸引了很多用户，不同用户也提出了各种不同的需求。有些特性需求 Kubernetes 直接在其核心代码里面实现了，但是有些特性并不适合合并到主干分支。&lt;/p&gt;&lt;p&gt;为满足这类需求，Kubernetes 开放出一些 API 供用户自己扩展，实现自己的需求。当前 Kubernetes 内部的 API 变得越来越开放，使其更像是一个跑在云上的操作系统。用户可以把它当作一套云的 SDK 或 Framework 来使用，而且可以很方便地开发组件来扩展满足自己的业务需求。对有状态服务的支持就是一个很有代表性的例子。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么我们要做 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第一，使用传统的自动化工具带来了很高的部署和运维成本。TiDB 的分层架构对于分布式系统是比较常见的，各个组件都可以根据业务需求独立水平伸缩，并且 TiKV 和 TiDB 都可以独立使用。比如，在 TiKV 之上可以构建兼容 Redis 协议的 KV 数据库，而 TiDB 也可以对接 LevelDB 这样的 KV 存储引擎。&lt;/p&gt;&lt;p&gt;但是，这种多组件的分布式系统增加了手工部署和运维的成本。一些传统的自动化部署和运维工具如 Puppet/Chef/SaltStack/Ansible，由于缺乏全局状态管理，不能及时对各种异常情况做自动故障转移，并且很难发挥分布式系统的弹性伸缩能力。其中有些还需要写大量的 DSL 甚至与 Shell 脚本一起混合使用，可移植性较差，维护成本比较高。&lt;/p&gt;&lt;p&gt;第二，在云时代，容器成为应用分发部署的基本单位，而谷歌基于内部使用数十年的容器编排系统 Borg 经验推出的开源容器编排系统 Kubernetes 成为当前容器编排技术事实上的标准。如今各大云厂商都开始提供托管的 Kubernetes 集群，部署在 Kubernetes 平台的应用可以不用绑定在特定云平台，轻松实现在各种云平台之间的迁移，其容器化打包和发布方式也解决了对操作系统环境的依赖。&lt;/p&gt;&lt;p&gt;Kubernetes 项目最早期只支持无状态服务（Stateless Service）的管理。无状态服务通过 ReplicationController 定义多个副本，由 Kubernetes 调度器来决定在不同节点上启动多个 Pod，实现负载均衡和故障转移。对于无状态服务，多个副本对应的 Pod 是等价的，所以在节点出现故障时，在新节点上启动一个 Pod 与失效的 Pod 是等价的，不会涉及状态迁移问题，因而管理非常简单。&lt;/p&gt;&lt;p&gt;但是对于有状态服务（Stateful Service），由于需要将数据持久化到磁盘，使得不同 Pod 之间不能再认为成等价，也就不能再像无状态服务那样随意进行调度迁移。&lt;/p&gt;&lt;p&gt;Kubernetes v1.3 版本提出 PetSet 的概念，用来管理有状态服务并于 v1.5 将其更名为 StatefulSet。StatefulSet 明确定义一组 Pod 中每个的身份，启动和升级都按特定顺序来操作。另外使用持久化卷存储（PersistentVolume）来作为存储数据的载体，当节点失效 Pod 需要迁移时，对应的 PV 也会重新挂载，而 PV 的底层依托于分布式文件系统，所以 Pod 仍然能访问到之前的数据。同时 Pod 在发生迁移时，其网络身份例如 IP 地址是会发生变化的，很多分布式系统不能接受这种情况。所以 StatefulSet 在迁移 Pod 时可以通过绑定域名的方式来保证 Pod 在集群中网络身份不发生变化。&lt;/p&gt;&lt;p&gt;但是由于有状态服务的特殊性，当节点出现异常时，出于数据安全性考虑，Kubernetes 并不会像无状态服务那样自动做故障转移。尽管网络存储能挂载到不同的节点上供其上的 Pod 使用，但是如果出现节点故障时，简单粗暴地将网络 PV 挂载到其它节点上是比较危险的。&lt;/p&gt;&lt;p&gt;Kubernetes 判断节点故障是基于部署在每个节点上的 Kubelet 服务是否能正常上报节点状态，Kubelet 能否正常工作与用户应用并没有必然联系，在一些特殊情况下，Kubelet 服务进程可能无法正常启动，但是节点上的业务容器还在运行，将 PV 再挂载到其它节点可能会出现双写问题。&lt;/p&gt;&lt;p&gt;为了在 Kubernetes 上部署和管理 TiDB 这种有状态的服务，我们需要扩展 StatefulSet 的功能。TiDB Operator 正是基于 Kubernetes 内置的 StatefulSet 开发的 TiDB 集群管理和运维工具。&lt;/p&gt;&lt;p&gt;Kubernetes 直到 v1.7 才试验性引入本地 PV，在这之前只有网络 PV，TiKV 自身在存储数据时就是多副本的，网络 PV 的多副本会增加数据冗余，降低 TiDB 的性能。在这之前我们基于 Kubernetes 内置的 hostPath volume 实现了本地 PV 满足 TiKV 对磁盘 IO 的要求。官方本地 PV 方案直到最近的 Kubernetes v1.10 才相对稳定地支持调度功能，满足用户对本地 PV 的需求。为了降低用户的使用和管理成本并且拥抱 Kubernetes 开源社区，我们又重新基于官方的本地 PV 方案实现了对数据的管理。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Operator 原理解析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Operator 本质上是 Kubernetes 的控制器（Controller），其核心思想是用户给定一个 Spec 描述文件，Controller 根据 Spec 的变化，在 Kubernetes 集群中创建对应资源，并且不断调整资源使其状态满足用户预期的 Spec。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-78ccc29e59b2fb801becd9a21a21f2c4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;326&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-78ccc29e59b2fb801becd9a21a21f2c4&quot; data-watermark-src=&quot;v2-ef84de5460a9792d5e27f7800786473c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图是 TiDB Operator 工作流程原理图，其中 TidbCluster 是通过 CRD（Custom Resource Definition）扩展的内置资源类型：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户通过 Helm 往 Kubernetes API Server 创建或更新 TidbCluster 对象。&lt;/li&gt;&lt;li&gt;TiDB Operator 通过 watch API Server 中的 TidbCluster 对象创建更新或删除，维护 PD/TiKV/TiDB StatefulSet, Service 和 Deployment 对象更新。&lt;/li&gt;&lt;li&gt;Kubernetes 根据 StatefulSet, Service 和 Deployment 对象创建更新或删除对应的容器和服务。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在第 2 步中，TiDB Operator 在更新 StatefulSet 等对象时会参考 PD API 给出的集群状态来做出 TiDB 集群的运维处理。通过 TiDB Operator 和 Kubernetes 的动态调度处理，创建出符合用户预期的 TiDB 集群。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;快速体验 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB Operator 需要运行在 Kubernetes v1.10 及以上版本。TiDB Operator 和 TiDB 集群的部署和管理是通过 Kubernetes 平台上的包管理工具 Helm 实现的。运行 TiDB Operator 前请确保 Helm 已经正确安装在 Kubernetes 集群里。&lt;/p&gt;&lt;p&gt;如果没有 Kubernetes 集群，可以通过 TiDB Operator 提供的脚本快速在本地启动一个多节点的 Kubernetes 集群：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;git clone https://github.com/pingcap/tidb-operator
cd tidb-operator
NUM_NODES=3    # the default node number is 2
KUBE_REPO_PREFIX=uhub.ucloud.cn/pingcap manifests/local-dind/dind-cluster-v1.10.sh up&lt;/code&gt;&lt;p&gt;等 Kubernetes 集群准备好，就可以通过 Helm 和 Kubectl 安装部署 TiDB Operator 和 TiDB 集群了。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;安装 TiDB Operator&lt;/li&gt;&lt;/ol&gt;&lt;code lang=&quot;text&quot;&gt;kubectl apply -f manifests/crd.yaml
helm install charts/tidb-operator --name=tidb-operator --namespace=tidb-admin&lt;/code&gt;&lt;p&gt;2. 部署 TiDB 集群&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;helm install charts/tidb-cluster --name=demo-tidb --namespace=tidb --set clusterName=demo&lt;/code&gt;&lt;p&gt;集群默认使用 local-storage 作为 PD 和 TiKV 的数据存储，如果想使用其它持久化存储，需要修改 charts/tidb-cluster/values.yaml 里面的 storageClassName。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参与 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB Operator 让 TiDB 成为真正意义上的 Cloud-Native 数据库，开源只是一个起点，需要 TiDB 社区和 Kubernetes 社区的共同参与。&lt;/p&gt;&lt;p&gt;大家在使用过程发现 bug 或缺失什么功能，都可以直接在 GitHub 上面提 issue 或 PR，一起参与讨论。要想成为 Contributor 具体可以参考 &lt;a href=&quot;https://github.com/pingcap/tidb-operator/blob/master/docs/CONTRIBUTING.md&quot;&gt;这个文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;作者：邓栓&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-23-42752388</guid>
<pubDate>Thu, 23 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十六）INSERT 语句详解</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-17-42287696.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42287696&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-dbb96df5fd6db3b140bfbe6de5aaf9c0_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：于帅鹏&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在之前的一篇文章 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;《TiDB 源码阅读系列文章（四）INSERT 语句概览》&lt;/a&gt; 中，我们已经介绍了 INSERT 语句的大体流程。为什么需要为 INSERT 单独再写一篇？因为在 TiDB 中，单纯插入一条数据是最简单的情况，也是最常用的情况；更为复杂的是在 INSERT 语句中设定各种行为，比如，对于 Unique Key 冲突的情况应如何处理：是报错？是忽略当前插入的数据？还是覆盖已有数据？所以，这篇会为大家继续深入介绍 INSERT 语句。&lt;/p&gt;&lt;p&gt;本文将首先介绍在 TiDB 中的 INSERT 语句的分类，以及各语句的语法和语义，然后分别介绍五种 INSERT 语句的源码实现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT 语句的种类&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;从广义上讲，TiDB 有以下六种 INSERT 语句：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;REPLACE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这六种语句理论上都属于 INSERT 语句。&lt;/p&gt;&lt;p&gt;第一种，&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;，即是最普通的 INSERT 语句，语法 &lt;code class=&quot;inline&quot;&gt;INSERT INTO VALUES ()&lt;/code&gt;，语义为插入一条语句，若发生唯一约束冲突（主键冲突、唯一索引冲突），则返回执行失败。&lt;/p&gt;&lt;p&gt;第二种，语法 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE INTO VALUES ()&lt;/code&gt;，是当 INSERT 的时候遇到唯一约束冲突后，忽略当前 INSERT 的行，并记一个 warning。当语句执行结束后，可以通过 &lt;code class=&quot;inline&quot;&gt;SHOW WARNINGS&lt;/code&gt; 看到哪些行没有被插入。&lt;/p&gt;&lt;p&gt;第三种，语法 &lt;code class=&quot;inline&quot;&gt;INSERT INTO VALUES () ON DUPLICATE KEY UPDATE&lt;/code&gt;，是当冲突后，更新冲突行后插入数据。如果更新后的行跟表中另一行冲突，则返回错误。&lt;/p&gt;&lt;p&gt;第四种，是在上一种情况，更新后的行又跟另一行冲突后，不插入该行并显示为一个 warning。&lt;/p&gt;&lt;p&gt;第五种，语法 &lt;code class=&quot;inline&quot;&gt;REPLACE INTO VALUES ()&lt;/code&gt;，是当冲突后，删除表上的冲突行，并继续尝试插入数据，如再次冲突，则继续删除标上冲突数据，直到表上没有与改行冲突的数据后，插入数据。&lt;/p&gt;&lt;p&gt;最后一种，语法 &lt;code class=&quot;inline&quot;&gt;LOAD DATA INFILE INTO&lt;/code&gt; 的语义与 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 相同，都是冲突即忽略，不同的是 &lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 的作用是将数据文件导入到表中，也就是其数据来源于 csv 数据文件。&lt;/p&gt;&lt;p&gt;由于 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt; 是在 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 上做了些特殊处理，将不再单独详细介绍，而是放在同一小节中介绍；&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 由于其自身的特殊性，将留到其他篇章介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Basic INSERT 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;几种 INSERT 语句的最大不同在于执行层面，这里接着 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;《TiDB 源码阅读系列文章（四）INSERT 语句概览》&lt;/a&gt; 来讲语句执行过程。不记得前面内容的同学可以返回去看原文章。&lt;/p&gt;&lt;p&gt;INSERT 的执行逻辑在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert.go&quot;&gt;executor/insert.go&lt;/a&gt; 中。其实前面讲的前四种 INSERT 的执行逻辑都在这个文件里。这里先讲最普通的 &lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;InsertExec&lt;/code&gt; 是 INSERT 的执行器实现，其实现了 Executor 接口。最重要的是下面三个接口：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Open：进行一些初始化&lt;/li&gt;&lt;li&gt;Next：执行写入操作&lt;/li&gt;&lt;li&gt;Close：做一些清理工作&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中最重要也是最复杂的是 Next 方法，根据是否通过一个 SELECT 语句来获取数据（&lt;code class=&quot;inline&quot;&gt;INSERT SELECT FROM&lt;/code&gt;），将 Next 流程分为，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L180:24&quot;&gt;insertRows&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L277:24&quot;&gt;insertRowsFromSelect&lt;/a&gt; 两个流程。两个流程最终都会进入 &lt;code class=&quot;inline&quot;&gt;exec&lt;/code&gt; 函数，执行 INSERT。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;exec&lt;/code&gt; 函数里处理了前四种 INSERT 语句，其中本节要讲的普通 INSERT 直接进入了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在讲 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 之前，我们先看一段 SQL。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (i INT UNIQUE);
INSERT INTO t VALUES (1);
BEGIN;
INSERT INTO t VALUES (1);
COMMIT;&lt;/code&gt;&lt;p&gt;把这段 SQL 分别一行行地粘在 MySQL 和 TiDB 中看下结果。&lt;/p&gt;&lt;p&gt;MySQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;mysql&amp;gt; CREATE TABLE t (i INT UNIQUE);
Query OK, 0 rows affected (0.15 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;i&#39;
mysql&amp;gt; COMMIT;
Query OK, 0 rows affected (0.11 sec)&lt;/code&gt;&lt;p&gt;TiDB：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;mysql&amp;gt; CREATE TABLE t (i INT UNIQUE);
Query OK, 0 rows affected (1.04 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.12 sec)

mysql&amp;gt; BEGIN;
Query OK, 0 rows affected (0.01 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; COMMIT;
ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;i&#39;&lt;/code&gt;&lt;p&gt;可以看出来，对于 INSERT 语句 TiDB 是在事务提交的时候才做冲突检测而 MySQL 是在语句执行的时候做的检测。这样处理的原因是，TiDB 在设计上，与 TiKV 是分层的结构，为了保证高效率的执行，在事务内只有读操作是必须从存储引擎获取数据，而所有的写操作都事先放在单 TiDB 实例内事务自有的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/kv/memdb_buffer.go#L31&quot;&gt;memDbBuffer&lt;/a&gt; 中，在事务提交时才一次性将事务写入 TiKV。在实现中是在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 中设置了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/e28a81813cfd290296df32056d437ccd17f321fe/kv/kv.go#L23&quot;&gt;PresumeKeyNotExists&lt;/a&gt; 选项，所有的 INSERT 操作如果在本地检测没发现冲突，就先假设插入不会发生冲突，不需要去 TiKV 中检查冲突数据是否存在，只将这些数据标记为待检测状态。最后到提交过程中，统一将整个事务里待检测数据使用 &lt;code class=&quot;inline&quot;&gt;BatchGet&lt;/code&gt; 接口做一次批量检测。&lt;/p&gt;&lt;p&gt;当所有的数据都通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 执行完插入后，INSERT 语句基本结束，剩余的工作为设置一下 lastInsertID 等返回信息，并最终将其结果返回给客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT IGNORE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 的语义在前面已经介绍了。之前介绍了普通 INSERT 在提交的时候才检查，那 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 是否可以呢？答案是不行的。因为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 如果在提交时检测，那事务模块就需要知道哪些行需要忽略，哪些直接报错回滚，这无疑增加了模块间的耦合。&lt;/li&gt;&lt;li&gt;用户希望立刻获取 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 有哪些行没有写入进去。即，立刻通过 &lt;code class=&quot;inline&quot;&gt;SHOW WARNINGS&lt;/code&gt; 看到哪些行实际没有写入。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这就需要在执行 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 的时候，及时检查数据的冲突情况。一个显而易见的做法是，把需要插入的数据试着读出来，当发现冲突后，记一个 warning，再继续下一行。但是对于一个语句插入多行的情况，就需要反复从 TiKV 读取数据来进行检测，显然，这样的效率并不高。于是，TiDB 实现了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt;，代码在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/batch_checker.go&quot;&gt;executor/batch_checker.go&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt; 中，首先，拿待插入的数据，将其中可能冲突的唯一约束在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L85:24&quot;&gt;getKeysNeedCheck&lt;/a&gt; 中构造成 Key（TiDB 是通过构造唯一的 Key 来实现唯一约束的，详见 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-2/&quot;&gt;《三篇文章了解 TiDB 技术内幕——说计算》&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;然后，将构造出来的 Key 通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 一次性读上来，得到一个 Key-Value map，能被读到的都是冲突的数据。&lt;/p&gt;&lt;p&gt;最后，拿即将插入的数据的 Key 到 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 的结果中进行查询。如果查到了冲突的行，构造好 warning 信息，然后开始下一行，如果查不到冲突的行，就可以进行安全的 INSERT 了。这部分的实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L490:24&quot;&gt;batchCheckAndInsert&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;同样，在所有数据执行完插入后，设置返回信息，并将执行结果返回客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT ON DUPLICATE KEY UPDATE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 是几种 INSERT 语句中最为复杂的。其语义的本质是包含了一个 INSERT 和 一个 UPDATE。较之与其他 INSERT 复杂的地方就在于，UPDATE 语义是可以将一行更新成任何合法的样子。&lt;/p&gt;&lt;p&gt;在上一节中，介绍了 TiDB 中对于特殊的 INSERT 语句采用了 batch 的方式来实现其冲突检查。在处理 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 的时候我们采用了同样的方式，但由于语义的复杂性，实现步骤也复杂了不少。&lt;/p&gt;&lt;p&gt;首先，与 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 相同，首先将待插入数据构造出来的 Key，通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 一次性地读出来，得到一个 Key-Value map。再把所有读出来的 Key 对应的表上的记录也通过一次 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 读出来，这部分数据是为了将来做 UPDATE 准备的，具体实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L225:24&quot;&gt;initDupOldRowValue&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;然后，在做冲突检查的时候，如果遇到冲突，则首先进行一次 UPDATE。我们在前面 Basic INSERT 小节中已经介绍了，TiDB 的 INSERT 是提交的时候才去 TiKV 真正执行。同样的，UPDATE 语句也是在事务提交的时候才真正去 TiKV 执行的。在这次 UPDATE 中，可能还是会遇到唯一约束冲突的问题，如果遇到了，此时即报错返回，如果该语句是 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt; 则会忽略这个错误，继续下一行。&lt;/p&gt;&lt;p&gt;在上一步的 UPDATE 中，还需要处理以下场景，如下面这个 SQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (i INT UNIQUE);
INSERT INTO t VALUES (1), (1) ON DUPLICATE KEY UPDATE i = i;&lt;/code&gt;&lt;p&gt;可以看到，这个 SQL 中，表中原来并没有数据，第二句的 INSERT 也就不可能读到可能冲突的数据，但是，这句 INSERT 本身要插入的两行数据之间冲突了。这里的正确执行应该是，第一个 1 正常插入，第二个 1 插入的时候发现有冲突，更新第一个 1。此时，就需要做如下处理。将上一步被 UPDATE 的数据对应的 Key-Value 从第一步的 Key-Value map 中删掉，将 UPDATE 出来的数据再根据其表信息构造出唯一约束的 Key 和 Value，把这个 Key-Value 对放回第一步读出来 Key-Value map 中，用于后续数据进行冲突检查。这个细节的实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/2fba9931c7ffbb6dd939d5b890508eaa21281b4f/executor/batch_checker.go#L232&quot;&gt;fillBackKeys&lt;/a&gt;。这种场景同样出现在，其他 INSERT 语句中，如 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;REPLACE&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt;。之所以在这里介绍是因为，&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 是最能完整展现 &lt;code class=&quot;inline&quot;&gt;batchChecker&lt;/code&gt; 的各方面的语句。&lt;/p&gt;&lt;p&gt;最后，同样在所有数据执行完插入/更新后，设置返回信息，并将执行结果返回客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;REPLACE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;REPLACE 语句虽然它看起来像是独立的一类 DML，实际上观察语法的话，它与 &lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt; 只是把 INSERT 换成了 REPLACE。与之前介绍的所有 INSERT 语句不同的是，REPLACE 语句是一个一对多的语句。简要说明一下就是，一般的 INSERT 语句如果需要 INSERT 某一行，那将会当遭遇了唯一约束冲突的时候，出现以下几种处理方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;放弃插入，报错返回：&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;&lt;/li&gt;&lt;li&gt;放弃插入，不报错：&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;放弃插入，改成更新冲突的行，如果更新的值再次冲突&lt;/li&gt;&lt;li&gt;报错：&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;不报错：&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;他们都是处理一行数据跟表中的某一行冲突时的不同处理。但是 REPLACE 语句不同，它将会删除遇到的所有冲突行，直到没有冲突后再插入数据。如果表中有 5 个唯一索引，那有可能有 5 条与等待插入的行冲突的行。那么 REPLACE 语句将会一次性删除这 5 行，再将自己插入。看以下 SQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (
i int unique, 
j int unique, 
k int unique, 
l int unique, 
m int unique);

INSERT INTO t VALUES 
(1, 1, 1, 1, 1), 
(2, 2, 2, 2, 2), 
(3, 3, 3, 3, 3), 
(4, 4, 4, 4, 4);

REPLACE INTO t VALUES (1, 2, 3, 4, 5);

SELECT * FROM t;
i j k l m
1 2 3 4 5&lt;/code&gt;&lt;p&gt;在执行完之后，实际影响了 5 行数据。&lt;/p&gt;&lt;p&gt;理解了 REPLACE 语句的特殊性以后，我们就可以更容易理解其具体实现。&lt;/p&gt;&lt;p&gt;与 INSERT 语句类似，REPLACE 语句的主要执行部分也在其 Next 方法中，与 INSERT 不同的是，其中的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L277:24&quot;&gt;insertRowsFromSelect&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L180:24&quot;&gt;insertRows&lt;/a&gt; 传递了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L27&quot;&gt;ReplaceExec&lt;/a&gt; 自己的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L160&quot;&gt;exec&lt;/a&gt; 方法。在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L160&quot;&gt;exec&lt;/a&gt; 中调用了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L95&quot;&gt;replaceRow&lt;/a&gt;，其中同样使用了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt; 中的批量冲突检测，与 INSERT 有所不同的是，这里会删除一切检测出的冲突，最后将待插入行写入。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;INSERT 语句是所有 DML 语句中最复杂，功能最强大多变的一个。其既有像 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE UPDATE&lt;/code&gt; 这种能执行 INSERT 也能执行 UPDATE 的语句，也有像 REPLACE 这种一行数据能影响许多行数据的语句。INSERT 语句自身都可以连接一个 SELECT 语句作为待插入数据的输入，因此，其又受到了来自 planner 的影响（关于 planner 的部分详见相关的源码阅读文章： &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt; 和 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt; ）。熟悉 TiDB 的 INSERT 各个语句实现，可以帮助各位读者在将来使用这些语句时，更好地根据其特色使用最为合理、高效语句。另外，如果有兴趣向 TiDB 贡献代码的读者，也可以通过本文更快的理解这部分的实现。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-17-42287696</guid>
<pubDate>Fri, 17 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读（十五） Sort Merge Join</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-08-41535500.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41535500&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e445e0a331d683cab8f11fda36478022_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/5202d0b6a9c623e0674ff36891c8ab52&quot; data-hash=&quot;5202d0b6a9c623e0674ff36891c8ab52&quot; data-hovercard=&quot;p$b$5202d0b6a9c623e0674ff36891c8ab52&quot;&gt;@姚维&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是 Sort Merge Join&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在开始阅读源码之前, 我们来看看什么是 Sort Merge Join (SMJ)，定义可以看 &lt;a href=&quot;https://en.wikipedia.org/wiki/Sort-merge_join&quot;&gt;wikipedia&lt;/a&gt;。简单说来就是将 Join 的两个表，首先根据连接属性进行排序，然后进行一次扫描归并, 进而就可以得出最后的结果。这个算法最大的消耗在于对内外表数据进行排序，而当连接列为索引列时，我们可以利用索引的有序性避免排序带来的消耗, 所以通常在查询优化器中，连接列为索引列的情况下可以考虑选择使用 SMJ。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Sort Merge Join 实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;执行过程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的实现代码在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/merge_join.go&quot;&gt;tidb/executor/merge_join.go&lt;/a&gt; 中 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.NextChunk&lt;/code&gt; 是这个算子的入口。下面以 &lt;code class=&quot;inline&quot;&gt;SELECT * FROM A JOIN B ON A.a = B.a&lt;/code&gt; 为例，对 SMJ 执行过程进行简述，假设此时外表为 A，内表为 B，join-keys 为 a，A，B 表的 a 列上都有索引：&lt;/p&gt;&lt;p&gt;1.顺序读取外表 A 直到 join-keys 中出现另外的值，把相同 keys 的行放入数组 a1，同样的规则读取内表 B，把相同 keys 的行放入数组 a2。如果外表数据或者内表数据读取结束，退出。&lt;/p&gt;&lt;p&gt;2. 从 a1 中读取当前第一行数据，设为 v1。从 a2 中读取当前第一行数据，设为 v2。&lt;/p&gt;&lt;p&gt;3. 根据 join-keys 比较 v1，v2，结果分为几种情况：&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0, 表示 v1 大于 v2，把当前 a2 的数据丢弃，从内表读取下一批数据，读取方法同 1。重复 2。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0, 表示 v1 小于 v2，说明外表的 v1 没有内表的值与之相同，把外表数据输出给 resultGenerator（不同的连接类型会有不同的结果输出，例如外连接会把不匹配的外表数据输出）。&lt;/li&gt;&lt;li&gt;cmpResult == 0, 表示 v1 等于 v2。那么遍历 a1 里面的数据，跟 a2 的数据，输出给 resultGenerator 作一次连接。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;4. 回到步骤 1。&lt;/p&gt;&lt;p&gt;下面的图展示了 SMJ 的过程：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b72f20067fcc79e607e567fbc8711bad_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;942&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b72f20067fcc79e607e567fbc8711bad&quot; data-watermark-src=&quot;v2-08f69ef7725298bf5d409e0fc691037f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;读取内表 / 外表数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们分别通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取内表和外表的数据。这两个函数实现的功能类似，这里只详述函数 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 的实现。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子读取数据，是通过迭代器 &lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 完成，&lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 可以顺序读取数据。&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子维护两个 readerIterator：&lt;code class=&quot;inline&quot;&gt;outerIter&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;innerIter&lt;/code&gt;，它们在 &lt;code class=&quot;inline&quot;&gt;buildMergeJoin&lt;/code&gt; 函数中被构造。&lt;/p&gt;&lt;p&gt;真正读取数据的操作是在 &lt;code class=&quot;inline&quot;&gt;readerIterator.nextSelectedRow&lt;/code&gt; 中完成, 这里会通过 &lt;code class=&quot;inline&quot;&gt;ri.reader.NextChunk&lt;/code&gt; 每次读取一个 Chunk 的数据，关于 Chunk 的相关内容，可以查看我们之前的文章 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;TiDB 源码阅读系列文章（十）Chunk 和执行框架简介&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;这里值得注意的是，我们通过 &lt;code class=&quot;inline&quot;&gt;expression.VectorizedFilter&lt;/code&gt; 对外表数据进行过滤，返回一个 curSelected 布尔数组，用于外表的每一行数据是否是满足 filter 过滤条件。以 &lt;code class=&quot;inline&quot;&gt;select * from t1 left outer join t2 on t1.a=100;&lt;/code&gt; 为例, 这里的 filter 是 &lt;code class=&quot;inline&quot;&gt;t1.a=100&lt;/code&gt;, 对于没有通过这个过滤条件的行，我们通过 &lt;code class=&quot;inline&quot;&gt;ri.joinResultGenerator.emitToChunk&lt;/code&gt; 函数发送给 resultGenerator, 这个 resultGenerator 是一个 interface，具体是否输出这行数据，会由 join 的类型决定，比如外连接则会输出，内连接则会忽略。具体关于 resultGenerator, 可以参考之前的文章：&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-9/&quot;&gt;TiDB 源码阅读系列文章（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;rowsWithSameKey&lt;/code&gt; 通过 &lt;code class=&quot;inline&quot;&gt;nextSelectedRow&lt;/code&gt; 不断读取下一行数据，并通过对每行数据的 join-keys 进行判断是不是属于同一个 join-keys，如果是，会把相同 join-keys 的行分别放入到 &lt;code class=&quot;inline&quot;&gt;innerChunkRows&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;outerIter4Row&lt;/code&gt; 数组中。然后对其分别建立迭代器 innerIter4Row 和 outerIter4Row。在 SMJ 中的执行过程中，会利用这两个迭代器来获取数据进行真正的比较得出 join result。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Merge-Join&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实现 Merge-Join 逻辑的代码在函数 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.joinToChunk&lt;/code&gt;, 对内外表迭代器的当前数据根据各自的 join-keys 作对比，有如下几个结果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0，代表外表当前数据大于内表数据，那么通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 直接读取下一个内表数据，然后重新比较即可。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0，代表外表当前数据小于内表数据，这个时候就分几种情况了，如果是外连接，那么需要输出外表数据 + NULL，如果是内连接，那么这个外表数据就被忽略，对于这个不同逻辑的处理，统一由 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator&lt;/code&gt; 来控制，我们只需要把外表数据通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 调用它即可。然后通过 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取下一个外表数据，重新比较。&lt;/li&gt;&lt;li&gt;cmpResult == 0，代表外表当前数据等于内表当前数据，这个时候就把外表数据跟内表当前数据做一次连接，通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 生成结果。之后外表跟内表分别获取下一个数据，重新开始比较。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;重复上面的过程，直到外表或者内表数据被遍历完，退出 Merge-Join 的过程。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们上面的分析代码基于 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/source-code&quot;&gt;Source-code&lt;/a&gt; 分支，可能大家已经发现了一些问题，比如我们会一次性读取内外表的 Join group（相同的 key）。这里如果相同的 key 比较多，是有内存 OOM 的风险的。针对这个问题，我们在最新的 master 分支做了几个事情来优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;外表其实不需要把相同的 keys 一次性都读取上来， 它只需要按次迭代外表数据，再跟内表逐一对比作连接即可。这里至少可以减少外表发生 OOM 的问题，可以大大减少 OOM 的概率。&lt;/li&gt;&lt;li&gt;对于内表，我们对 OOM 也不是没有办法，我们用 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 这个内存追踪器来记录当前内表已经使用的中间结果的内存大小，如果它超过我们设置的阈值，我们会采取输出日志或者终止 SQL 继续运行的方法来规避 OOM 的发生。关于 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 我们不在此展开，可以留意我们后续的源码分析文章。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续我们还会在 Merge-Join 方面做一些优化， 比如我们可以做多路归并，中间结果存外存等等，敬请期待。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-08-41535500</guid>
<pubDate>Wed, 08 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>30 分钟成为 TiKV Contributor</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-02-41103417.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41103417&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3e6973721ffe23e838d18d1d6cebc858_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;作者：吴雪莲&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;背景知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;SQL 语句发送到 TiDB 后经过 parser 生成 AST（抽象语法树），再经过 Query Optimizer 生成执行计划，执行计划切分成很多子任务，这些子任务以表达式的方式最后下推到底层的各个 TiKV 来执行。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d54ea1017d24caf90ab9d7f987f40fae_r.jpg&quot; data-caption=&quot;图 1&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;860&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d54ea1017d24caf90ab9d7f987f40fae&quot; data-watermark-src=&quot;v2-d826905412f823c66e227f7c2ec3f603&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;如图 1，当 TiDB 收到来自客户端的查询请求&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;select count(*) from t where a + b &amp;gt; 5&lt;/code&gt;&lt;/p&gt;&lt;p&gt;时，执行顺序如下：&lt;/p&gt;&lt;p&gt;1.TiDB 对 SQL 进行解析，组织成对应的表达式，下推给 TiKV&lt;/p&gt;&lt;p&gt;2. TiKV 收到请求后，循环以下过程&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;获取下一行完整数据，并按列解析&lt;/li&gt;&lt;li&gt;使用参数中的 where 表达式对数据进行过滤&lt;/li&gt;&lt;li&gt;若上一条件符合，进行聚合计算&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;3. TiKV 向 TiDB 返回聚合计算结果&lt;/p&gt;&lt;p&gt;4. TiDB 对所有涉及的结果进行二次聚合，返回给客户端&lt;/p&gt;&lt;p&gt;这里的 where 条件便是以表达式树的形式下推给 TiKV。在此之前 TiDB 只会向 TiKV 下推一小部分简单的表达式，比如取出某一个列的某个数据类型的值，简单数据类型的比较操作，算术运算等。为了充分利用分布式集群的资源，进一步提升 SQL 在整个集群的执行速度，我们需要将更多种类的表达式下推到 TiKV 来运行，其中的一大类就是 MySQL built-in 函数。&lt;br&gt;目前，由于 TiKV 的 built-in 函数尚未全部实现，对于无法下推的表达式，TiDB 只能自行解决。这无疑将成为提升 TiDB 速度的最大绊脚石。好消息是，TiKV 在实现 built-in 函数时，可以直接参考 TiDB 的对应函数逻辑（顺便可以帮 TiDB 找找 Bug），为我们减少了不少工作量。&lt;/p&gt;&lt;p&gt;Built-in 函数无疑是 TiDB 和 TiKV 成长道路上不可替代的一步，如此艰巨又庞大的任务，我们需要广大社区朋友们的支持与鼓励。亲爱的朋友们，想玩 Rust 吗？想给 TiKV 提 PR 吗？想帮助 TiDB 跑得更快吗？动动您的小手指，拿 PR 来砸我们吧。您的 PR 一旦被采用，将会有小惊喜哦。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;手把手教你实现 built-in 函数&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Step 1：准备下推函数&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiKV 的 &lt;a href=&quot;https://github.com/pingcap/tikv/issues/3275&quot;&gt;https://github.com/pingcap/tikv/issues/3275&lt;/a&gt; issue 中，找到未实现的函数签名列表，选一个您想要实现的函数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 2：获取 TiDB 中可参考的逻辑实现&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下查找相关 builtinXXXSig 对象，这里 XXX 为您要实现的函数签名，本例中以 &lt;a href=&quot;https://github.com/pingcap/tikv/pull/3277&quot;&gt;MultiplyIntUnsigned&lt;/a&gt; 为例，可以在 TiDB 中找到其对应的函数签名（&lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;）及 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;实现&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 3：确定函数定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1.built-in 函数所在的文件名要求与 TiDB 的名称对应，如 TiDB 中，&lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下的下推文件统一以 builtin_XXX 命名，对应到 TiKV 这边，就是 &lt;code class=&quot;inline&quot;&gt;builtin_XXX.rs&lt;/code&gt;。若同名对应的文件不存在，则需要自行在同级目录下新建。对于本例，当前函数存放于 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;builtin_arithmetic.go&lt;/a&gt; 文件里，对应到 TiKV 便是存放在 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;2. 函数名称：函数签名转为 Rust 的函数名称规范，这里 &lt;code class=&quot;inline&quot;&gt;MultiplyIntUnsigned&lt;/code&gt; 将会被定义为 &lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;3. 函数返回值，可以参考 TiDB 中实现的 &lt;code class=&quot;inline&quot;&gt;Eval&lt;/code&gt; 函数，对应关系如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4fb256c456c3220224e6055ca6ab6bf6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1158&quot; data-rawheight=&quot;838&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4fb256c456c3220224e6055ca6ab6bf6&quot; data-watermark-src=&quot;v2-6781bac667ad6b94c4a8b7ec58af83eb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;  对象实现了 evalInt 方法，故当前函数（&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;）的返回类型应该为 &lt;code class=&quot;inline&quot;&gt;Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;4. 函数的参数, 所有 builtin-in 的参数都与 Expression 的 &lt;code class=&quot;inline&quot;&gt;eval&lt;/code&gt; 函数一致，即：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;环境配置量 (ctx:&amp;amp;StatementContext)&lt;/li&gt;&lt;li&gt;该行数据每列具体值 (row:&amp;amp;[Datum])&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上，&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt; 的下推函数定义为：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 4：实现函数逻辑&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一块相对简单，直接对照 TiDB 的相关逻辑实现即可。这里，我们可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt; 的具体实现如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;func (s *builtinArithmeticMultiplyIntUnsignedSig) evalInt(row types.Row) (val int64, isNull bool, err error) {
  a, isNull, err := s.args[0].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedA := uint64(a)
  b, isNull, err := s.args[1].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedB := uint64(b)
  result := unsignedA * unsignedB
  if unsignedA != 0 &amp;amp;&amp;amp; result/unsignedA != unsignedB {
     return 0, true, types.ErrOverflow.GenByArgs(&quot;BIGINT UNSIGNED&quot;, fmt.Sprintf(&quot;(%s * %s)&quot;, s.args[0].String(), s.args[1].String()))
  }
  return int64(result), false, nil
}&lt;/code&gt;&lt;p&gt;参考以上代码，翻译到 TiKV 即可，如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt; {
       let lhs = try_opt!(self.children[0].eval_int(ctx, row));
       let rhs = try_opt!(self.children[1].eval_int(ctx, row));
       let res = (lhs as u64).checked_mul(rhs as u64).map(|t| t as i64);
       // TODO: output expression in error when column&#39;s name pushed down.
       res.ok_or_else(|| Error::overflow(&quot;BIGINT UNSIGNED&quot;, &amp;amp;format!(&quot;({} * {})&quot;, lhs, rhs)))
           .map(Some)
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 5：添加参数检查&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在收到下推请求时，首先会对所有的表达式进行检查，表达式的参数个数检查就在这一步进行。&lt;/p&gt;&lt;p&gt;TiDB 中对每个 built-in 函数的参数个数有严格的限制，这一部分检查可参考 TiDB 同目录下 builtin.go 相关代码。&lt;/p&gt;&lt;p&gt;在 TiKV 同级目录的 scalar_function.rs 文件里，找到 ScalarFunc 的 check_args 函数，按照现有的模式，加入参数个数的检查即可。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 6：添加下推支持&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在对一行数据执行具体的 expression 时，会调用 eval 函数，eval 函数又会根据具体的返回类型，执行具体的子函数。这一部分工作在 scalar_function.rs 中以宏（dispatch_call）的形式完成。&lt;/p&gt;&lt;p&gt;对于 MultiplyIntUnsigned, 我们最终返回的数据类型为 Int，所以可以在 dispatch_call 中找到 INT_CALLS，然后照着加入 MultiplyIntUnsigned =&amp;gt; multiply_int_unsigned , 表示当解析到函数签名 MultiplyIntUnsigned 时，调用上述已实现的函数 multiply_int_unsigned。&lt;/p&gt;&lt;p&gt;至此 MultiplyIntUnsigned 下推逻辑已完全实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 7：添加测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在函数 multiply_int_unsigned 所在文件 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 底部的 test 模块中加入对该函数签名的单元测试，要求覆盖到上述添加的所有代码，这一部分也可以参考 TiDB 中相关的测试代码。本例在 TiKV 中实现的测试代码如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;#[test]
   fn test_multiply_int_unsigned() {
       let cases = vec![
           (Datum::I64(1), Datum::I64(2), Datum::U64(2)),
           (
               Datum::I64(i64::MIN),
               Datum::I64(1),
               Datum::U64(i64::MIN as u64),
           ),
           (
               Datum::I64(i64::MAX),
               Datum::I64(1),
               Datum::U64(i64::MAX as u64),
           ),
           (Datum::U64(u64::MAX), Datum::I64(1), Datum::U64(u64::MAX)),
       ];

       let mut ctx = EvalContext::default();
       for (left, right, exp) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap();
           assert_eq!(got, exp);
       }

       // test overflow
       let cases = vec![
           (Datum::I64(-1), Datum::I64(2)),
           (Datum::I64(i64::MAX), Datum::I64(i64::MAX)),
           (Datum::I64(i64::MIN), Datum::I64(i64::MIN)),
       ];

       for (left, right) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap_err();
           assert!(check_overflow(got).is_ok());
       }
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 8：运行测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;运行 make expression，确保所有的 test case 都能跑过。&lt;/p&gt;&lt;p&gt;完成以上几个步骤之后，就可以给 TiKV 项目提 PR 啦。想要了解提 PR 的基础知识，尝试移步 &lt;a href=&quot;https://pingcap.com/blog-how-to-contribute-zh&quot;&gt;此文&lt;/a&gt;，看看是否有帮助。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;欢迎大家踊跃贡献代码，加入 TiDB community ！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://github.com/pingcap.com&quot;&gt;http://github.com/pingcap.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-02-41103417</guid>
<pubDate>Thu, 02 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>社区 | 如何优雅降落到 TiDB 星球？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-25-40529913.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40529913&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74fe289237a86bdb2092bfb84524db33_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;提到「开源项目 TiDB」人们总是习惯性反应：它在 GitHub 上 Star 数已经超过 17000，并拥有 260+ 位全球各地的 Contributors 。但数据总归是冷冰冰的，不能生动的展现 TiDB 社区的魅力。所以今天推送一篇 &lt;b&gt;TiDB contributor&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;杜川&lt;/b&gt;同学加入 TiDB 社区前后的「心路历程」，他从亲历者的角度告诉你——&lt;/i&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;PingCAPer 够 nice 么？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;积极参与 TiDB 社区对自己的能力提升有何帮助？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;如何在 TiDB 星球上找到最适合自己的落点？（ 或者在大树上找到自己最擅长的“小树杈”hhhhhh）&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;&lt;b&gt;以及…利用好碎片时间，你也可以一年给 TiDB 提&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;70&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;个 PR！&lt;/b&gt;&lt;/i&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;🚀&lt;/b&gt; 作者：杜川，TiDB contributor&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;最近这一年多断断续续一直在往 TiDB 中提交一些修改，前两天看了一些 GitHub  提交记录，发现竟然已经累计了 70 来个 PR 了。考虑到最近这一年基本处于疯狂加班的节奏，另外忙里偷闲还基本上刷完了之前列的十几本书的读书清单，我觉得这也算一个不大不小的成就吧，值得 mark 一下。&lt;/p&gt;&lt;p&gt;话说回来，虽然我 17 年年中才开始给 TiDB 提交 PR，其实在之前一年多以前，大概在 2016 年 4 月份左右, 就听说过 TiDB 这个项目了。当时我的主要工作也是车一个 SQL 执行引擎，所以对分布式数据库业界的相关新闻还是比较关注的。&lt;/p&gt;&lt;p&gt;虽然数据库是一个轮子高发领域，各种轮子五花八门，但是在国内，数据库，特别是分布式数据库这块的轮子，基本还是几个大厂在车，要么不开源，要么开源了社区也不甚活跃。像 TiDB 这样要从头车一个分布式数据库，并且还是完全开源的方式来搞，确实让我印象深刻。后来组里一个小哥离职投奔 PingCAP，我借着面基的名义陆陆续续参加了 TiDB 几次线下 Meetup，也由此认识了很多 TiDB 社区的小伙伴。&lt;/p&gt;&lt;p&gt;16 年底从北京回到成都以后，工作重心发生了一些变化，从之前的纯做 infra，转变为更多地要面对业务层面的需求。不过做了几年 infra，自己本身对数据库内核还是很感兴趣的，所以工作之余，开始研究 TiDB 的实现，并且搭了一套 TiDB，在开发环境里代替 MySQL。我们都知道，MySQL 经过多年的发展，其 SQL 语法是比较复杂的。TiDB 虽然全面兼容 MySQL 的语法和协议，但是因为没有复用 MySQL 代码，肯定不可能做到 100% 兼容，落实到一些具体的语句上，肯定会和 MySQL 有一些区别。因为之前我也一直在做 OLAP 系统的 SQL 引擎的开发工作，对这一块比较熟悉，在遇到这方面问题后，感觉解决起来也并不很麻烦，因此慢慢开始在这个方面给 TiDB 提一些 PR。到后面熟悉了以后，有时间的话也会到 TiDB 的 issue list 上捞相关的 issue 解决，主要集中于 SQL Parser, 表达式计算和 MySQL 兼容性等方面。最近抽空在做的是和聚合函数相关的一些 Feature。&lt;/p&gt;&lt;p&gt;因为平时工作还是比较忙，加班也是家常便饭，因此给 TiDB 提交 PR，回复 Review 意见的时间段基本都集中在周末，晚上老婆睡觉以后，或者午休间隙。这样有一个问题是时间段比较离散，很难有长时间的连贯思考的时间。因此现阶段一方面我在提 PR 的时候会选择一些相对较小，独立一些的 Feature。&lt;b&gt;另一方面，我尽量把开发放在时间相对充裕的周末，把晚上和其他零碎时间用来查看和回复 Review 意见，Update 代码和跑回归测试。这样算下来，平均提交一个 PR，算上开发，测试，和社区小伙伴沟通，大概要消耗 3 到 5 个工时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不过这个时间投入我觉得倒是非常划算，一是因为我本身对数据库就非常感兴趣，把参与 TiDB 社区开发当成了一种兴趣，可以看做是工作之余的一种放松，二是我一直在从事数据库相关的工作，包括之前 OLAP SQL 引擎的运行时优化相关工作，和现在云数据库相关的工作，其实和在社区所做的事情都是密切相关的。比如一个 MySQL Builtin 函数, 在各种极端输入下的表现是怎样的，或是 SQL_MODE 的各种组合对这个 Builtin 函数的行为有什么样的影响，这些问题在平时工作中，我可能很难考虑得非常周全；但是要在社区中提一个 PR 实现这个 Builtin 函数，我就非得把这些问题考虑清楚，并经受社区小伙伴各种 Case 的轰炸考验。等这个 PR 顺利被 Commit，这些细节我也烂熟于心了。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-13d78a931d43996617464c58e89c8b85_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2006&quot; data-rawheight=&quot;1034&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-13d78a931d43996617464c58e89c8b85&quot; data-watermark-src=&quot;v2-2370357a5b7bf01a8e24495f78b5f21b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;说到社区，我觉得 TiDB 做得相当不错。一方面 PingCAPers 都很活跃，在 GitHub 上提的 Issue 一般很快就能得到回复, 有什么疑问通过 GitHub, 微信群甚至知乎提问等很快都能得到反馈；另一方面更重要的是在 Review PR 的时候社区小伙伴能保持比较严谨的态度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就我的经历而言，我在开发过程中没有注意到的一些 Corner Case 和细节错误，基本都能在 Review PR 过程被翻出来，这不仅需要 Reviewer 理清楚 PR 对应 Feature 的相关细节，构造出可能有问题的场景，还需要 Reviewer 理解 PR 作者的开发思路。其中需要花费的精力，常常不低于开发这个 Feature 本身。此外，还有一个我觉得很赞的方面是 TiDB 花了很多心思来构建从 UT，FT 到集成测试的一系列测试框架，让我在参与开发工程中比较容易对自己开发的 Feature 进行各个方位的测试，节省了很多来回捣腾的麻烦。&lt;/p&gt;&lt;p&gt;总的来说，参与 TiDB 社区是一件非常有意思的事情，给我带来很多收获，我也会继续关注 TiDB 项目的进展。短时间来看，我的计划主要还是抽空完成手头聚合函数相关的一些 Feature，包括对 MySQL 聚合函数 STDDEV，VARIANCE 等的支持，以及在 TiKV Coprocessor 侧的对应改动。之后，我打算看看能不能够结合我之前在 OLAP SQL 引擎的运行时优化方面的经验，提升 TiDB 在 OLAP 领域的能力。不过这个是一个比较大的目标了，到时候还要和社区的小伙伴多多讨论。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;TiDB 社区大事件&lt;/b&gt;&lt;/i&gt; &lt;/p&gt;&lt;p&gt;&lt;i&gt;TiDB TechDay2018 即将于 7 月 28 日在深圳举办，目前报名已满，我们周六见哦！点击&lt;u&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486395&amp;amp;idx=1&amp;amp;sn=bfa0227d14a27e02dcd0e26939125c24&amp;amp;chksm=eb162cd1dc61a5c7d6da2bc2e3dc8e6413e28c1085a69cb0518adb1dc27cd38c8bdc64ec1fbb&amp;amp;scene=21#wechat_redirect&quot;&gt;【这里】&lt;/a&gt;&lt;/u&gt;查看活动详情。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;P.S 欢迎踊跃勾搭 &lt;b&gt;TiDB Robot （微信号：tidbai）&lt;/b&gt;加入 TiDB 星球～&lt;/i&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-84bfe17ec8227fa695e364a4815dfe35_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;3515&quot; data-rawheight=&quot;1758&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-84bfe17ec8227fa695e364a4815dfe35&quot; data-watermark-src=&quot;v2-15585058505faf294ec8f410cce97ab5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-25-40529913</guid>
<pubDate>Wed, 25 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十四）统计信息（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-19-40079139.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40079139&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c34786efbf579d9eef6f636c5afda076_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：谢海滨&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价，本篇将会结合原理介绍 TiDB 的源码实现。&lt;/p&gt;&lt;p&gt;文内会先介绍直方图和 Count-Min(CM) Sketch 的数据结构，然后介绍 TiDB 是如何实现统计信息的查询、收集以及更新的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据结构定义&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;直方图的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L40&quot;&gt;histograms.go&lt;/a&gt; 中找到，值得注意的是，对于桶的上下界，我们使用了在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;《TiDB 源码阅读系列文章（十）Chunk 和执行框架简介》&lt;/a&gt; 中介绍到 Chunk 来存储，相比于用 Datum 的方式，可以减少内存分配开销。&lt;/p&gt;&lt;p&gt;CM Sketch 的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L31&quot;&gt;cmsketch.go&lt;/a&gt; 中找到，比较简单，包含了 CM Sketch 的核心——二维数组 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt;，并存储了其深度与宽度，以及总共插入的值的数量，当然这些都可以直接从 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt; 中得到。&lt;/p&gt;&lt;p&gt;除此之外，对列和索引的统计信息，分别使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L699&quot;&gt;Column&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L773&quot;&gt;Index&lt;/a&gt; 来记录，主要包含了直方图，CM Sketch 等。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息创建&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在执行 analyze 语句时，TiDB 会收集直方图和 CM Sketch 的信息。在执行 analyze 命令时，会先将需要 analyze 的列和索引在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/master/plan/planbuilder.go#L609&quot;&gt;builder.go&lt;/a&gt; 中切分成不同的任务，然后在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/executor/analyze.go#L114&quot;&gt;analyze.go&lt;/a&gt; 中将任务下推至 TiKV 上执行。由于在 TiDB 中也包含了 TiKV 部分的实现，因此在这里还是会以 TiDB 的代码来介绍。在这个部分中，我们会着重介绍直方图的创建。&lt;/p&gt;&lt;p&gt;&lt;b&gt;列直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在统计信息（上）中提到，在建立列直方图的时候，会先进行抽样，然后再建立直方图。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/sample.go#L113&quot;&gt;collect&lt;/a&gt; 函数中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。由于其原理和代码都比较简单，在这里不再介绍。&lt;/p&gt;&lt;p&gt;采样完成后，在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L97&quot;&gt;BuildColumn&lt;/a&gt; 中，我们实现了列直方图的创建。首先将样本排序，确定每个桶的高度，然后顺序遍历每个值 V：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如果 V 等于上一个值，那么把 V 放在与上一个值同一个桶里，无论桶是不是已经满，这样可以保证每个值只存在于一个桶中。&lt;/li&gt;&lt;li&gt;如果不等于上一个值，那么判断当前桶是否已经满，就直接放入当前桶，并用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L146&quot;&gt;updateLastBucket&lt;/a&gt; 更改桶的上界和深度。&lt;/li&gt;&lt;li&gt;否则的话，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L151&quot;&gt;AppendBucket&lt;/a&gt; 放入一个新的桶。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;索引直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在建立索引列直方图的时候，我们使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L24&quot;&gt;SortedBuilder&lt;/a&gt; 来维护建立直方图的中间状态。由于不能事先知道有多少行的数据，也就不能确定每一个桶的深度，不过由于索引列的数据是已经有序的，因次我们在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L38&quot;&gt;NewSortedBuilder&lt;/a&gt; 中将每个桶的初始深度设为 1。对于每一个数据，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L50&quot;&gt;Iterate&lt;/a&gt; 会使用建立列直方图时类似的方法插入数据。如果在某一时刻，所需桶的个数超过了当前桶深度，那么用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L74&quot;&gt;mergeBucket&lt;/a&gt; 将之前的每两个桶合并为 1 个，并将桶深扩大一倍，然后继续插入。&lt;/p&gt;&lt;p&gt;在收集了每一个 Region 上分别建立的直方图后，还需要用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L609&quot;&gt;MergeHistogram&lt;/a&gt; 把每个 Region 上的直方图进行合并。在这个函数中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了保证每个值只在一个桶中，我们处理了处理一下交界处桶的问题，即如果交界处两个桶的上界和下界 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L623&quot;&gt;相等&lt;/a&gt;，那么需要先合并这两个桶；&lt;/li&gt;&lt;li&gt;在真正合并前，我们分别将两个直方图的平均桶深 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L642&quot;&gt;调整&lt;/a&gt; 至大致相等；&lt;/li&gt;&lt;li&gt;如果直方图合并之后桶的个数超过了限制，那么把两两相邻的桶 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L653&quot;&gt;合二为一&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息维护&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了 TiDB 是如何更新直方图和 CM Sketch 的。对于 CM Sketch 其更新比较简单，在这里不再介绍。这个部分主要介绍一下 TiDB 是如何收集反馈信息和维护直方图的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;反馈信息的收集&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，为了不去假设所有桶贡献的误差都是均匀的，需要收集每一个桶的反馈信息，因此需要先把查询的范围按照直方图桶的边界切分成不相交的部分。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L511&quot;&gt;SplitRange&lt;/a&gt; 中，我们按照直方图去切分查询的范围。由于目前直方图中的一个桶会包含上下界，为了方便，这里只按照上界去划分，即这里将第 i 个桶的范围看做 &lt;code class=&quot;inline&quot;&gt;(i-1 桶的上界，i 桶的上界]&lt;/code&gt;。特别的，对于最后一个桶，将其的上界视为无穷大。比方说一个直方图包含 ３ 个桶，范围分别是: [2，5]，[8，8]，[10，13]，查询的范围是 (3，20]，那么最终切分得到的查询范围就是 (3，5]，(5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;将查询范围切分好后，会被存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，以便在每个 Region 的结果返回时，调用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L165&quot;&gt;Update&lt;/a&gt; 函数来更新每个范围所包含的 key 数目。注意到这个函数需要两个参数：每个 Region 上扫描的 start key 以及 Region 上每一个扫描范围输出的 key 数目 output counts，那么要如何更新 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 中每个范围包含的 key 的数目呢？&lt;/p&gt;&lt;p&gt;继续以划分好的 (3，5]，(5，8]，(8，20] 为例，假设这个请求需要发送到两个 region 上，region1 的范围是 [0，6)，region2 的范围是 [6，30)，由于 coprocessor 在发请求的时候还会根据 Region 的范围切分 range，因此 region1 的请求范围是 (3，5]，(5，6)，region2 的请求范围是 [6，8]，(8，20]。为了将对应的 key 数目更新到 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，需要知道每一个 output count 对应的查询范围。注意到 coprocessor 返回的 output counts 其对应的 Range 都是连续的，并且同一个值只会对应一个 range，那么我们只需要知道第一个 output count 所对应的 range，即只需要知道这次扫描的 start key 就可以了。举个例子，对于 region1 来说，start key 是 3，那么 output counts 对应的 range 就是 (3，5]，(5，8]，对 region2 来说，start key 是 6，output countshangyipians 对应的 range 就是 (5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;&lt;b&gt;直方图的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在收集了 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 后，我们就可以去使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L536&quot;&gt;UpdateHistogram&lt;/a&gt; 来更新直方图了。其大体上可以分为分裂与合并。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L503&quot;&gt;splitBuckets&lt;/a&gt; 中，我们实现了直方图的分裂：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先，由于桶与桶之间的反馈信息不相关，为了方便，先将 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L504&quot;&gt;buildBucketFeedback&lt;/a&gt; 拆分了每一个桶的反馈信息，并存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L213&quot;&gt;BucketFeedback&lt;/a&gt; 中。&lt;/li&gt;&lt;li&gt;接着，使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L507&quot;&gt;getSplitCount&lt;/a&gt; 来根据可用的桶的个数和反馈信息的总数来决定分裂的数目。&lt;/li&gt;&lt;li&gt;对于每一个桶，将可以分裂的桶按照反馈信息数目的比例均分，然后用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;splitBucket&lt;/a&gt; 来分裂出需要的桶的数目：&lt;/li&gt;&lt;li&gt;首先，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;getBoundaries&lt;/a&gt; 会每隔几个点取一个作为边界，得到新的桶。&lt;/li&gt;&lt;li&gt;然后，对于每一个桶，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L32%201&quot;&gt;refineBucketCount&lt;/a&gt; 用与新生成的桶重合部分最多的反馈信息更新桶的深度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，在分裂的时候，如果一个桶过小，那么这个桶不会被分裂；如果一个分裂后生成的桶过小，那么它也不会被生成。&lt;/p&gt;&lt;p&gt;在桶的分裂完成后，我们会使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L467&quot;&gt;mergeBuckets&lt;/a&gt; 来合并桶，对于那些超过：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在分裂的时候，会记录每一个桶是不是新生成的，这样，对于原先就存在的桶，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L476&quot;&gt;getBucketScore&lt;/a&gt; 计算合并的之后产生的误差，令第一个桶占合并后桶的比例为 r，那么令合并后产生的误差为 abs（合并前第一个桶的高度 - r * 两个桶的高度和）/ 合并前第一个桶的高度。&lt;/li&gt;&lt;li&gt;接着，对每一桶的合并的误差进行排序。&lt;/li&gt;&lt;li&gt;最后，按照合并的误差从下到大的顺序，合并需要的桶。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在查询语句中，我们常常会使用一些过滤条件，而统计信息估算的主要作用就是估计经过这些过滤条件后的数据条数，以便优化器选择最优的执行计划。&lt;/p&gt;&lt;p&gt;由于在单列上的查询比较简单，这里不再赘述，代码基本是按照 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中的原理实现，感兴趣可以参考 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L408&quot;&gt;histogram.go/lessRowCount&lt;/a&gt;  以及 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L69&quot;&gt;cmsketch.go/queryValue&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L148&quot;&gt;Selectivity&lt;/a&gt; 是统计信息模块对优化器提供的最重要的接口，处理了多列查询的情况。Selectivity 的一个最重要的任务就是将所有的查询条件分成尽量少的组，使得每一组中的条件都可以用某一列或者某一索引上的统计信息进行估计，这样我们就可以做尽量少的独立性假设。&lt;/p&gt;&lt;p&gt;需要注意的是，我们将单列的统计信息分为 3 类：&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L42&quot;&gt;indexType&lt;/a&gt; 即索引列，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L43&quot;&gt;pkType&lt;/a&gt; 即 Int 类型的主键，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L44&quot;&gt;colType&lt;/a&gt; 即普通的列类型，如果一个条件可以同时被多种类型的统计信息覆盖，那么我们优先会选择 pkType 或者 indexType。&lt;/p&gt;&lt;p&gt;在 Selectivity 中，有如下几个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L230&quot;&gt;getMaskAndRange&lt;/a&gt; 为每一列和每一个索引计算了可以覆盖的过滤条件，用一个 int64 来当做一个 bitset，并把将该列可以覆盖的过滤条件的位置置为 1。&lt;/li&gt;&lt;li&gt;接下来在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L258&quot;&gt;getUsableSetsByGreedy&lt;/a&gt; 中，选择尽量少的 bitset，来覆盖尽量多的过滤条件。每一次在还没有使用的 bitset 中，选择一个可以覆盖最多尚未覆盖的过滤条件。并且如果可以覆盖同样多的过滤条件，我们会优先选择 pkType 或者 indexType。&lt;/li&gt;&lt;li&gt;用统计信息（上）提到的方法对每一个列和每一个索引上的统计信息进行估计，并用独立性假设将它们组合起来当做最终的结果。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;统计信息的收集和维护是数据库的核心功能，对于基于代价的查询优化器，统计信息的准确性直接影响了查询效率。在分布式数据库中，收集统计信息和单机差别不大，但是维护统计信息有比较大的挑战，比如怎样在多节点更新的情况下，准确及时的维护统计信息。&lt;/p&gt;&lt;p&gt;对于直方图的动态更新，业界一般有两种方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于每一次增删，都去更新对应的桶深。在一个桶的桶深过高的时候分裂桶，一般是把桶的宽度等分，不过这样很难准确的确定分界点，引起误差。&lt;/li&gt;&lt;li&gt;使用查询得到的真实数去反馈调整直方图，假定所有桶贡献的误差都是均匀的，用连续值假设去调整所有涉及到的桶。然而误差均匀的假设常常会引起问题，比如当当新插入的值大于直方图的最大值时，就会把新插入的值引起的误差分摊到直方图中，从而引起误差。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 TiDB 的统计信息还是以单列的统计信息为主，为了减少独立性假设的使用，在将来 TiDB 会探索多列统计信息的收集和维护，为优化器提供更准确的统计信息。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39649659&quot;&gt;（十三）索引范围计算简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;（十二）统计信息（上）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-19-40079139</guid>
<pubDate>Thu, 19 Jul 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
