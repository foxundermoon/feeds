<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 12 Dec 2018 23:21:56 +0800</lastBuildDate>
<item>
<title>TiDB 源码阅读系列文章（二十一）基于规则的优化 II</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-11-52138596.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/52138596&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-180de02d6f7269fdf95e2294d895caf8_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-7/&quot;&gt;TiDB 源码阅读系列文章（七）基于规则的优化&lt;/a&gt; 一文中，我们介绍了几种 TiDB 中的逻辑优化规则，包括列剪裁，最大最小消除，投影消除，谓词下推和构建节点属性，本篇将继续介绍更多的优化规则：聚合消除、外连接消除和子查询优化。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;聚合消除&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;聚合消除会检查 SQL 查询中 &lt;code class=&quot;inline&quot;&gt;Group By&lt;/code&gt; 语句所使用的列是否具有唯一性属性，如果满足，则会将执行计划中相应的 &lt;code class=&quot;inline&quot;&gt;LogicalAggregation&lt;/code&gt; 算子替换为 &lt;code class=&quot;inline&quot;&gt;LogicalProjection&lt;/code&gt; 算子。这里的逻辑是当聚合函数按照具有唯一性属性的一列或多列分组时，下层算子输出的每一行都是一个单独的分组，这时就可以将聚合函数展开成具体的参数列或者包含参数列的普通函数表达式，具体的代码实现在 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/rule_aggregation_elimination.go&quot;&gt;rule_aggregation_elimination.go&lt;/a&gt;&lt;/code&gt; 文件中。下面举一些具体的例子。&lt;/p&gt;&lt;p&gt;例一：&lt;/p&gt;&lt;p&gt;下面这个 Query 可以将聚合函数展开成列的查询：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select max(a) from t group by t.pk;&lt;/code&gt;&lt;p&gt;被等价地改写成：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select a from t;&lt;/code&gt;&lt;p&gt;例二：&lt;/p&gt;&lt;p&gt;下面这个 Query 可以将聚合函数展开为包含参数列的内置函数的查询：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select count(a) from t group by t.pk;&lt;/code&gt;&lt;p&gt;被等价地改写成：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select if(isnull(a), 0, 1) from t;&lt;/code&gt;&lt;p&gt;这里其实还可以做进一步的优化：如果列 &lt;code class=&quot;inline&quot;&gt;a&lt;/code&gt; 具有 &lt;code class=&quot;inline&quot;&gt;Not Null&lt;/code&gt; 的属性，那么可以将 &lt;code class=&quot;inline&quot;&gt;if(isnull(a), 0, 1)&lt;/code&gt; 直接替换为常量 1（目前 TiDB 还没做这个优化，感兴趣的同学可以来贡献一个 PR）。&lt;/p&gt;&lt;p&gt;另外提一点，对于大部分聚合函数，参数的类型和返回结果的类型一般是不同的，所以在展开聚合函数的时候一般会在参数列上构造 cast 函数做类型转换，展开后的表达式会保存在作为替换 &lt;code class=&quot;inline&quot;&gt;LogicalAggregation&lt;/code&gt; 算子的 &lt;code class=&quot;inline&quot;&gt;LogicalProjection&lt;/code&gt; 算子中。&lt;/p&gt;&lt;p&gt;这个优化过程中，有一点非常关键，就是如何知道 &lt;code class=&quot;inline&quot;&gt;Group By&lt;/code&gt; 使用的列是否满足唯一性属性，尤其是当聚合算子的下层节点不是 &lt;code class=&quot;inline&quot;&gt;DataSource&lt;/code&gt; 的时候？我们在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-7/&quot;&gt;基于规则的优化&lt;/a&gt; 一文中的“构建节点属性”章节提到过，执行计划中每个算子节点会维护这样一个信息：当前算子的输出会按照哪一列或者哪几列满足唯一性属性。因此，在聚合消除中，我们可以通过查看下层算子保存的这个信息，再结合 &lt;code class=&quot;inline&quot;&gt;Group By&lt;/code&gt; 用到的列判断当前聚合算子是否可以被消除。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;外连接消除&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不同于 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-7/&quot;&gt;基于规则的优化&lt;/a&gt; 一文中“谓词下推”章节提到的将外连接转换为内连接，这里外连接消除指的是将整个连接操作从查询中移除。&lt;/p&gt;&lt;p&gt;外连接消除需要满足一定条件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;条件 1 : &lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt; 的父亲算子只会用到 &lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt; 的 outer plan 所输出的列&lt;/li&gt;&lt;li&gt;条件 2 :&lt;/li&gt;&lt;ul&gt;&lt;li&gt;条件 2.1 : &lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt; 中的 join key 在 inner plan 的输出结果中满足唯一性属性&lt;/li&gt;&lt;li&gt;条件 2.2 : &lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt; 的父亲算子会对输入的记录去重&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;条件 1 和条件 2 必须同时满足，但条件 2.1 和条件 2.2 只需满足一条即可。&lt;/p&gt;&lt;p&gt;满足条件 1 和 条件 2.1 的一个例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select t1.a from t1 left join t2 on t1.b = t2.pk;&lt;/code&gt;&lt;p&gt;可以被改写成：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select t1.a from t1;&lt;/code&gt;&lt;p&gt;满足条件 1 和条件 2.2 的一个例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select distinct(t1.a) from t1 left join t2 on t1.b = t2.b;&lt;/code&gt;&lt;p&gt;可以被改写成：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select distinct(t1.a) from t1;&lt;/code&gt;&lt;p&gt;具体的原理是，对于外连接，outer plan 的每一行记录肯定会在连接的结果集里出现一次或多次，当 outer plan 的行不能找到匹配时，或者只能找到一行匹配时，这行 outer plan 的记录在连接结果中只出现一次；当 outer plan 的行能找到多行匹配时，它会在连接结果中出现多次；那么如果 inner plan 在 join key 上满足唯一性属性，就不可能存在 outer plan 的行能够找到多行匹配，所以这时 outer plan 的每一行都会且仅会在连接结果中出现一次。同时，上层算子只需要 outer plan 的数据，那么外连接可以直接从查询中被去除掉。同理就可以很容易理解当上层算子只需要 outer plan 的去重后结果时，外连接也可以被消除。&lt;/p&gt;&lt;p&gt;这部分优化的具体代码实现在 &lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/rule_join_elimination.go&quot;&gt;rule_join_elimination.go&lt;/a&gt; 文件中。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;子查询优化 / 去相关&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;子查询分为非相关子查询和相关子查询，例如：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;-- 非相关子查询
select * from t1 where t1.a &amp;gt; (select t2.a from t2 limit 1);
-- 相关子查询
select * from t1 where t1.a &amp;gt; (select t2.a from t2 where t2.b &amp;gt; t1.b limit 1);&lt;/code&gt;&lt;p&gt;对于非相关子查询， TiDB 会在 &lt;code class=&quot;inline&quot;&gt;expressionRewriter&lt;/code&gt; 的逻辑中做两类操作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;子查询展开&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;即直接执行子查询获得结果，再利用这个结果改写原本包含子查询的表达式；比如上述的非相关子查询，如果其返回的结果为一行记录 “1” ，那么整个查询会被改写为：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select * from t1 where t1.a &amp;gt; 1;&lt;/code&gt;&lt;p&gt;详细的代码逻辑可以参考&lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/expression_rewriter.go&quot;&gt;expression_rewriter.go&lt;/a&gt;中的&lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/expression_rewriter.go#L685&quot;&gt;handleScalarSubquery&lt;/a&gt;和&lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/expression_rewriter.go#L535&quot;&gt;handleExistSubquery&lt;/a&gt;函数。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;子查询转为 Join&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于包含 IN (subquery) 的查询，比如：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select * from t1 where t1.a in (select t2.a from t2);&lt;/code&gt;&lt;p&gt;会被改写成：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select t1.* from t1 inner join (select distinct(t2.a) as a from t2) as sub on t1.a = sub.a;&lt;/code&gt;&lt;p&gt;如果 &lt;code class=&quot;inline&quot;&gt;t2.a&lt;/code&gt; 满足唯一性属性，根据上面介绍的聚合消除规则，查询会被进一步改写成：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select t1.* from t1 inner join t2 on t1.a = t2.a;&lt;/code&gt;&lt;p&gt;这里选择将子查询转化为 inner join 的 inner plan 而不是执行子查询的原因是：以上述查询为例，子查询的结果集可能会很大，展开子查询需要一次性将 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 的全部数据从 TiKV 返回到 TiDB 中缓存，并作为 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 扫描的过滤条件；如果将子查询转化为 inner join 的 inner plan ，我们可以更灵活地对 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 选择访问方式，比如我们可以对 join 选择 &lt;code class=&quot;inline&quot;&gt;IndexLookUpJoin&lt;/code&gt; 实现方式，那么对于拿到的每一条 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 表数据，我们只需拿 &lt;code class=&quot;inline&quot;&gt;t1.a&lt;/code&gt; 作为 range 对 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 做一次索引扫描，如果 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 表很小，相比于展开子查询返回 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 全部数据，我们可能总共只需要从 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 返回很少的几条数据。&lt;/p&gt;&lt;p&gt;注意这个转换的结果不一定会比展开子查询更好，其具体情况会受 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 表和 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 表数据的影响，如果在上述查询中， &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt;表很大而 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 表很小，那么展开子查询再对 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 选择索引扫描可能才是最好的方案，所以现在有参数控制这个转化是否打开，详细的代码可以参考 &lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/expression_rewriter.go&quot;&gt;expression_rewriter.go&lt;/a&gt; 中的 &lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/expression_rewriter.go#L596&quot;&gt;handleInSubquery&lt;/a&gt; 函数。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;相关子查询&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于相关子查询，TiDB 会在&lt;code class=&quot;inline&quot;&gt;expressionRewriter&lt;/code&gt;中将整个包含相关子查询的表达式转化为&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;算子。&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;算子是一类特殊的&lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt;，特殊之处体现在执行逻辑上：对于 outer plan 返回的每一行记录，取出相关列的具体值传递给子查询，再执行根据子查询生成的 inner plan ，即&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;在执行时只能选择类似 循环嵌套连接的方式，而普通的&lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt;则可以在物理优化阶段根据代价模型选择最合适的执行方式，包括&lt;code class=&quot;inline&quot;&gt;HashJoin&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;MergeJoin&lt;/code&gt;和&lt;code class=&quot;inline&quot;&gt;IndexLookUpJoin&lt;/code&gt;，理论上后者生成的物理执行计划一定会比前者更优，所以在逻辑优化阶段我们会检查是否可以应用“去相关”这一优化规则，试图将&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;转化为等价的&lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt;。其核心思想是将&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;的 inner plan 中包含相关列的那些算子提升到&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;之中或之上，在算子提升后如果 inner plan 中不再包含任何的相关列，即不再引用任何 outer plan 中的列，那么&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;就会被转换为普通的&lt;code class=&quot;inline&quot;&gt;LogicalJoin&lt;/code&gt;，这部分代码逻辑实现在&lt;a href=&quot;https://github.com/eurekaka/tidb/blob/logical_rules_reading/planner/core/rule_decorrelate.go&quot;&gt;rule_decorrelate.go&lt;/a&gt;文件中。&lt;/p&gt;&lt;p&gt;具体的算子提升方式分为以下几种情况：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. inner plan 的根节点是&lt;code class=&quot;inline&quot;&gt;LogicalSelection&lt;/code&gt;&lt;/b&gt; &lt;/p&gt;&lt;p&gt;则将其过滤条件添加到 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 的 join condition 中，然后将该 &lt;code class=&quot;inline&quot;&gt;LogicalSelection&lt;/code&gt; 从 inner plan 中删除，再递归地对 inner plan 提升算子。&lt;/p&gt;&lt;p&gt;以如下查询为例：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select * from t1 where t1.a in (select t2.a from t2 where t2.b = t1.b);&lt;/code&gt;&lt;p&gt;其生成的最初执行计划片段会是：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a5982ed5121da2abdc05167506e48e09_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;383&quot; data-rawheight=&quot;277&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a5982ed5121da2abdc05167506e48e09&quot; data-watermark-src=&quot;v2-8a2d9d63bd08f8d908fd93ad370a140d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;LogicalSelection&lt;/code&gt; 提升后会变成如下片段：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-62f3075f148145ff308de465a07ff53b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;404&quot; data-rawheight=&quot;191&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-62f3075f148145ff308de465a07ff53b&quot; data-watermark-src=&quot;v2-62cff68b480f307f9001d16bba429797&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;到此 inner plan 中不再包含相关列，于是 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 会被转换为如下 LogicalJoin ：&lt;/p&gt;&lt;u&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-22d5560a1d5a1513063c1083de52c887_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;418&quot; data-rawheight=&quot;202&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-22d5560a1d5a1513063c1083de52c887&quot; data-watermark-src=&quot;v2-7bb00d9abf4fffa883e0ca832215cc93&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;/u&gt;&lt;p&gt;&lt;b&gt;2.inner plan 的根节点是&lt;code class=&quot;inline&quot;&gt;LogicalMaxOneRow&lt;/code&gt;&lt;/b&gt;&lt;br&gt;即要求子查询最多输出一行记录，比如这个例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select *, (select t2.a from t2 where t2.pk = t1.a) from t1;&lt;/code&gt;&lt;p&gt;因为子查询出现在整个查询的投影项里，所以 &lt;code class=&quot;inline&quot;&gt;expressionRewriter&lt;/code&gt; 在处理子查询时会对其生成的执行计划在根节点上加一个 &lt;code class=&quot;inline&quot;&gt;LogicalMaxOneRow&lt;/code&gt; 限制最多产生一行记录，如果在执行时发现下层输出多于一行记录，则会报错。在这个例子中，子查询的过滤条件是 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 表的主键上的等值条件，所以子查询肯定最多只会输出一行记录，而这个信息在“构建节点属性”这一步时会被发掘出来并记录在算子节点的 &lt;code class=&quot;inline&quot;&gt;MaxOneRow&lt;/code&gt; 属性中，所以这里的 &lt;code class=&quot;inline&quot;&gt;LogicalMaxOneRow&lt;/code&gt; 节点实际上是冗余的，于是我们可以将其从 inner plan 中移除，然后再递归地对 inner plan 做算子提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.inner plan 的根节点是&lt;code class=&quot;inline&quot;&gt;LogicalProjection&lt;/code&gt;&lt;/b&gt; &lt;/p&gt;&lt;p&gt;则首先将这个投影算子从 inner plan 中移除，再根据&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;的连接类型判断是否需要在&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;之上再加上一个&lt;code class=&quot;inline&quot;&gt;LogicalProjection&lt;/code&gt;，具体来说是：对于非 semi-join 这一类的连接（包括 inner join 和 left join ），inner plan 的输出列会保留在&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt;的结果中，所以这个投影操作需要保留，反之则不需要。最后，再递归地对删除投影后的 inner plan 提升下层算子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.inner plan 的根节点是&lt;code class=&quot;inline&quot;&gt;LogicalAggregation&lt;/code&gt;&lt;/b&gt; &lt;/p&gt;&lt;p&gt;&lt;b&gt;a.&lt;/b&gt;首先我们会检查这个聚合算子是否可以被提升到 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 之上再执行。以如下查询为例：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select *, (select sum(t2.b) from t2 where t2.a = t1.pk) from t1;&lt;/code&gt;&lt;p&gt;其最初生成的执行计划片段会是：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3a476443a3930e657a52023f7ec82983_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;427&quot; data-rawheight=&quot;414&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3a476443a3930e657a52023f7ec82983&quot; data-watermark-src=&quot;v2-2f0771f0f6b99f56ef089d61c847b1e0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;将聚合提升到 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 后的执行计划片段会是：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bcbb359b6fc8771c984fe21351e599bc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;385&quot; data-rawheight=&quot;331&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bcbb359b6fc8771c984fe21351e599bc&quot; data-watermark-src=&quot;v2-bab6573026a3946820f9e4b66b465ead&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;即先对 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 做连接，再在连接结果上按照 &lt;code class=&quot;inline&quot;&gt;t1.pk&lt;/code&gt; 分组后做聚合。这里有两个关键变化：第一是不管提升前 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 的连接类型是 inner join 还是 left join ，提升后必须被改为 left join ；第二是提升后的聚合新增了 &lt;code class=&quot;inline&quot;&gt;Group By&lt;/code&gt; 的列，即要按照 outer plan 传进 inner plan 中的相关列做分组。这两个变化背后的原因都会在后面进行阐述。因为提升后 inner plan 不再包含相关列，去相关后最终生成的执行计划片段会是：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3af11844da7786a930af425723d7ec90_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;383&quot; data-rawheight=&quot;343&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3af11844da7786a930af425723d7ec90&quot; data-watermark-src=&quot;v2-c2e2c8792666624bcfe5ae7b5c39813c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;聚合提升有很多限定条件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 的连接类型必须是 inner join 或者 left join 。 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 是根据相关子查询生成的，只可能有 3 类连接类型，除了 inner join 和 left join 外，第三类是 semi join （包括 &lt;code class=&quot;inline&quot;&gt;SemiJoin&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;LeftOuterSemiJoin&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;AntiSemiJoin&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;AntiLeftOuterSemiJoin&lt;/code&gt;），具体可以参考 &lt;code class=&quot;inline&quot;&gt;expression_rewriter.go&lt;/code&gt; 中的代码，限于篇幅在这里就不对此做展开了。对于 semi join 类型的 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; ，因为 inner plan 的输出列不会出现在连接的结果中，所以很容易理解我们无法将聚合算子提升到 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 之上。&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 本身不能包含 join condition 。以上面给出的查询为例，可以看到聚合提升后会将子查询中包含相关列的过滤条件 (&lt;code class=&quot;inline&quot;&gt;t2.a = t1.pk&lt;/code&gt;) 添加到 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 的 join condition 中，如果 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 本身存在 join condition ，那么聚合提升后聚合算子的输入（连接算子的输出）就会和在子查询中时聚合算子的输入不同，导致聚合算子结果不正确。&lt;/li&gt;&lt;li&gt;子查询中用到的相关列在 outer plan 输出里具有唯一性属性。以上面查询为例，如果 &lt;code class=&quot;inline&quot;&gt;t1.pk&lt;/code&gt; 不满足唯一性，假设 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 有两条记录满足 &lt;code class=&quot;inline&quot;&gt;t1.pk = 1&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 只有一条记录 &lt;code class=&quot;inline&quot;&gt;{ (t2.a: 1, t2.b: 2) }&lt;/code&gt; ，那么该查询会输出两行结果 &lt;code class=&quot;inline&quot;&gt;{ (sum(t2.b): 2), (sum(t2.b): 2) }&lt;/code&gt; ；但对于聚合提升后的执行计划，则会生成错误的一行结果&lt;code class=&quot;inline&quot;&gt;{ (sum(t2.b): 4) }&lt;/code&gt;。当 &lt;code class=&quot;inline&quot;&gt;t1.pk&lt;/code&gt; 满足唯一性后，每一行 outer plan 的记录都对应连接结果中的一个分组，所以其聚合结果会和在子查询中的聚合结果一致，这也解释了为什么聚合提升后需要按照 &lt;code class=&quot;inline&quot;&gt;t1.pk&lt;/code&gt; 做分组。&lt;/li&gt;&lt;li&gt;聚合函数必须满足当输入为 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; 时输出结果也一定是 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; 。这是为了在子查询中没有匹配的特殊情况下保证结果的正确性，以上面查询为例，当 &lt;code class=&quot;inline&quot;&gt;t2&lt;/code&gt; 表没有任何记录满足 &lt;code class=&quot;inline&quot;&gt;t2.a = t1.pk&lt;/code&gt; 时，子查询中不管是什么聚合函数都会返回 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; 结果，为了保留这种特殊情况，在聚合提升的同时， &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 的连接类型会被强制改为 left join（改之前可能是 inner join ），所以在这种没有匹配的情况下，&lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 输出结果中 inner plan 部分会是 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; ，而这个 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; 会作为新添加的聚合算子的输入，为了和提升前结果一致，其结果也必须是 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;b.&lt;/b&gt;对于根据上述条件判定不能提升的聚合算子，我们再检查这个聚合算子的子节点是否为 &lt;code class=&quot;inline&quot;&gt;LogicalSelection&lt;/code&gt; ，如果是，则将其从 inner plan 中移除并将过滤条件添加到 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 的 join condition 中。这种情况下 &lt;code class=&quot;inline&quot;&gt;LogicalAggregation&lt;/code&gt; 依然会被保留在 inner plan 中，但会将 &lt;code class=&quot;inline&quot;&gt;LogicalSelection&lt;/code&gt; 过滤条件中涉及的 inner 表的列添加到聚合算子的 &lt;code class=&quot;inline&quot;&gt;Group By&lt;/code&gt;中。比如对于查询：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select *, (select count(*) from t2 where t2.a = t1.a) from t1;&lt;/code&gt;&lt;p&gt;其生成的最初的执行计划片段会是：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7036cbfd4a1bd928df9b68a82ae2c39d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;404&quot; data-rawheight=&quot;402&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7036cbfd4a1bd928df9b68a82ae2c39d&quot; data-watermark-src=&quot;v2-1436664d60cbe58ed392024ac79a0d9d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;因为聚合函数是 &lt;code class=&quot;inline&quot;&gt;count(*)&lt;/code&gt; ，不满足当输入为 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; 时输出也为 &lt;code class=&quot;inline&quot;&gt;null&lt;/code&gt; 的条件，所以它不能被提升到 &lt;code class=&quot;inline&quot;&gt;LogicalApply&lt;/code&gt; 之上，但它可以被改写成：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fff11f20b805a30654aa08f8351c1c3e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;429&quot; data-rawheight=&quot;306&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fff11f20b805a30654aa08f8351c1c3e&quot; data-watermark-src=&quot;v2-59380836f03d5ed5d926d7465b523973&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;注意 &lt;code class=&quot;inline&quot;&gt;LogicalAggregation&lt;/code&gt; 的 &lt;code class=&quot;inline&quot;&gt;Group By&lt;/code&gt; 新加了 &lt;code class=&quot;inline&quot;&gt;t2.a&lt;/code&gt; ，这一步将原本的先做过滤再做聚合转换为了先按照 &lt;code class=&quot;inline&quot;&gt;t2.a&lt;/code&gt; 分组做聚合，再将聚合结果与 &lt;code class=&quot;inline&quot;&gt;t1&lt;/code&gt; 做连接。 &lt;code class=&quot;inline&quot;&gt;LogicalSelection&lt;/code&gt; 提升后 inner plan 已经不再依赖 outer plan 的结果了，整个查询去相关后将会变为：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eca50e9e7bf56e429defc6cf6a266a4c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;449&quot; data-rawheight=&quot;325&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-eca50e9e7bf56e429defc6cf6a266a4c&quot; data-watermark-src=&quot;v2-0d186aabdcfc7d5ecfb758a6cb92d7d3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这是基于规则优化的第二篇文章，后续我们还将介绍更多逻辑优化规则：聚合下推，TopN 下推和 Join Reorder 。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;更多 TiDB 源码阅读系列文章：&lt;/p&gt;&lt;a href=&quot;https://www.pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-60ab5bd867c2434d70c957a02a2169e1&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; data-image-size=&quot;ipico&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-11-52138596</guid>
<pubDate>Tue, 11 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在量化派风控系统中的应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-10-52046270.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/52046270&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ee0165e5af868a1f8bcd156e502cad0_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br&gt;&lt;b&gt;朱劲松&lt;/b&gt;，量化派研发中心系统架构师，主要参与了基础组件开发、API Gateway 等项目，现在致力于公司风控系统相关业务的架构设计和研发。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;公司简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;量化派（QuantGroup）创办于 2014 年，是数据驱动的科技公司，是国家高新技术企业。量化派以「MOVE THE WORLD WITH DATA, ENLIGHTEN LIFE WITH AI」（数据驱动世界，智能点亮生活）为愿景，利用人工智能、机器学习、大数据技术。为金融、电商、旅游、出行、汽车供应链等多个领域的合作伙伴提供定制化的策略和模型，帮助提升行业效率。量化派已与国内外超过 300 家机构和公司达成深度合作，致力于打造更加有活力的共赢生态，推动经济的可持续发展。&lt;/p&gt;&lt;p&gt;我司从 2017 年年中开始调研 TiDB，并在用户行为数据分析系统中搭建 TiDB 集群进行数据存储，经过一年多的应用和研究，积累了丰富的经验。同时，TiDB 官方推出 2.0 GA 版本，TiDB 愈发成熟，稳定性和查询效率等方面都有很大提升。我们于 2018 年 7 月部署 TiDB 2.0.5 版本，尝试将其应用于风控业务中。风控系统主要是在用户申请放款时，根据风控规则结合模型和用户特征进行实时计算并返回放款结果。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;业务背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;风控系统中用到的数据主要可以分为两部分：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一类是原始数据，用于分析用户当前的特征指标。&lt;/li&gt;&lt;li&gt;一类是快照数据，用于计算历史指定时间点的特征指标，供模型训练使用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;原始数据主要分为三种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;产生自公司内各个产品线的业务系统数据&lt;/li&gt;&lt;li&gt;爬虫组提供的用户联系人、运营商、消费记录等数据&lt;/li&gt;&lt;li&gt;经过处理后的用户特征数据&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;由于我们的风控策略中用到了大量的模型，包括神经网络模型，评分模型等，这些模型的训练需要依靠大量的历史订单以及相关的用户特征，为了训练出更多精准、优秀的模型，就需要更多维度的特征，此时特征的准确性就直接影响了模型的训练结果，为此我们在回溯每一个订单的用户在指定时间的特征表现时，就需要用到数据快照。&lt;/p&gt;&lt;p&gt;我们可以通过拉链表的方式来实现数据快照功能，简单说就是在每张表中增加三个字段，分别是 new_id、start_time、end_time，每一次记录的更新都会产生一条新的数据，同时变更原有记录的 end_time，以记录数据的变更历史。&lt;/p&gt;&lt;p&gt;通过上面的介绍可以看到，业务数据和爬虫数据本身数据量就很大，再加上需要产生对应的拉链数据，数据量更是成倍增长。假设每条数据自创建后仅变更一次，那拉链表的数据量就已经是原始表的两倍了，而实际生产环境下数据的变更远不止一次。&lt;/p&gt;&lt;p&gt;通过上述的介绍，我们总结风控系统下的数据存储需求应满足以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;业务数据&lt;/li&gt;&lt;li&gt;业务数据拉链表&lt;/li&gt;&lt;li&gt;爬虫数据，如联系人信息、运营商数据，消费记录等&lt;/li&gt;&lt;li&gt;爬虫数据拉链表&lt;/li&gt;&lt;li&gt;其他数据，如预处理数据等&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;当前方案&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以前方案主要是采用 HBase 进行数据存储。它的水平扩展很好的解决了数据量大的问题。但是在实际使用中，也存在着比较明显的问题，最明显的就是查询的 API 功能性较弱，只能通过 Key 来获取单条数据，或是通过 Scan API 来批量读取，这无疑在特征回溯时增加了额外的开发成本，无法实现代码复用。&lt;/p&gt;&lt;p&gt;在实时计算场景中，为了降低开发成本，对于业务数据的获取则是通过访问线上系统的 MySQL 从库来进行查询；爬虫数据由于统一存放在 HBase 中，计算时需要将用到的数据全量拉取在内存中再进行计算。&lt;/p&gt;&lt;p&gt;在回溯场景中，针对业务特征回溯，通过查询订单时间之前的数据进行特征计算，这种方式对于已经变更的数据是无能为力的，只能通过 HBase 里的数据快照来实现，但无形增加了很多的开发工作。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 为我们打开一片新视野&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过上面的介绍，我们知道要构建一个风控系统的实时数仓环境，需要满足下面几个特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高可用，提供健壮、稳定的服务。&lt;/li&gt;&lt;li&gt;支持水平弹性扩展，满足日益增长的数据需求。&lt;/li&gt;&lt;li&gt;性能好，支持高并发。&lt;/li&gt;&lt;li&gt;响应快。&lt;/li&gt;&lt;li&gt;支持标准 SQL，最好是 MySQL 语法和 MySQL 协议，避免回溯时的额外开发。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以发现，TiDB 完美契合我们的每个需求。经过 TiDB 在用户行为数据分析系统中的长期使用，我们已经积累了一定的经验，在此过程中 TiDB 官方也给予了长期的技术支持，遇到的问题在沟通时也能够及时的反馈，而且还与我司技术人员进行过多次技术交流及线下分享，在此我们深表感谢。伴随着风控系统需求的持续增长，我们对整体架构进行了新一轮的优化，新的数据接入及存储架构如图 1。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a717388d8270181928386125b5163963_r.jpg&quot; data-caption=&quot;图 1  优化后的架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1004&quot; data-rawheight=&quot;545&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a717388d8270181928386125b5163963&quot; data-watermark-src=&quot;v2-8e925539beecb0d3c99975e92584a69b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;通过图 1 可以看到，线上业务系统产生的数据统一存放在 MySQL 中，将这些孤立的数据归集在 TiDB 中，能够提供基于 SQL 的查询服务。通过 binlog 的方式直接从 MySQL 实例进行接入，接入后的数据以两种不同的形式分别存放：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一种是去分库分表后的源数据，降低了实时特征计算的实现及维护成本。&lt;/li&gt;&lt;li&gt;另一种是以拉链数据形式存储实现数据快照功能。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;经过调研，针对第一种场景，可以通过阿里的 otter 或者 TiDB 周边工具 Syncer 来快速实现，但对于第二个需求都没有现成的成熟解决方案。最终，我们基于阿里的 canal 进行客户端的定制化开发，分别按照不同的需求拼装合并 SQL 并写入到不同的 TiDB 集群中；同时还可以按需将部分表的数据进行组装并发送至 Kafka，用于准实时分析场景。&lt;/p&gt;&lt;p&gt;对于来自爬虫组的数据，我们采用直接消费 Kafka 的方式组装 SQL 写入到 TiDB 即可。&lt;/p&gt;&lt;p&gt;在实际是使用中，通过索引等优化，TiDB 完全可以支持线上实时查询的业务需求；在特征回溯时只需要通过增加查询条件就可以获得指定时间的特征结果，大大降低了开发成本。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;遇到的问题&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;风控业务中用户特征提取的 SQL 相对都比较复杂，在实际使用中，存在部分 SQL 执行时间比在 MySQL 中耗时高。通过 explain 我们发现，他并没有使用我们创建的索引，而是进行了全表扫描，在进一步分析后还发现 explain 的结果是不确定的。&lt;/p&gt;&lt;p&gt;经过与 TiDB 官方技术人员的沟通，我们进行了删除类似索引、analyze table 等操作，发现问题仍然存在。通过图 2 可以看到完全相同的 SQL 语句，其执行结果的差异性。最后按官方建议，我们采用添加 use index 的方式使其强制走索引，执行时间由 4 分钟变成了 &amp;lt; 1s，暂时解决了业务上的需求。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b456777e7bdb0d4610a70c40aab191d8_r.jpg&quot; data-caption=&quot;图 2  explain 示意图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1004&quot; data-rawheight=&quot;408&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b456777e7bdb0d4610a70c40aab191d8&quot; data-watermark-src=&quot;v2-7a247e9dec4e04853609cf215ab3dcc1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;同时 TiDB 技术人员也收集相关信息反馈给了研发人员。在整个问题的处理过程中，TiDB 的技术人员给予了高度的配合和及时的反馈，同时也表现出了很强的专业性，大大减少了问题排查的时间，我们非常感谢。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;目前我们已经搭建两个 TiDB 集群，几十个物理节点，百亿级特征数据，受益于 TiDB 的高可用构架，上线以来一直稳定运行。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如上，TiDB 在我们风控业务中的应用才只是开始，部分业务的迁移还有待进一步验证，但是 TiDB 给我们带来的好处不言而喻，为我们在数据存储和数据分析上打开了一片新视野。后续我们会继续加大对 TiDB 的投入，使其更好地服务于在线分析和离线分析等各个场景。我们也希望进一步增加与 PingCAP 团队的交流与合作，进行更深入的应用和研究，为 TiDB 的发展贡献一份力量。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;更多 TiDB 用户实践：&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-60ab5bd867c2434d70c957a02a2169e1&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; data-image-size=&quot;ipico&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-10-52046270</guid>
<pubDate>Mon, 10 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB EcoSystem Tools 原理解读（一）：TiDB-Binlog 架构演进与实现原理</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-10-51990591.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51990591&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f70e162f6471c2085dcc5b1d71405c89_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB-Binlog 组件用于收集 TiDB 的 binlog，并提供实时备份和同步功能。该组件在功能上类似于 MySQL 的主从复制，MySQL 的主从复制依赖于记录的 binlog 文件，TiDB-Binlog 组件也是如此，主要的不同点是 TiDB 是分布式的，因此需要收集各个 TiDB 实例产生的 binlog，并按照事务提交的时间排序后才能同步到下游。如果你需要部署 TiDB 集群的从库，或者想订阅 TiDB 数据的变更输出到其他的系统中，TiDB-Binlog 则是必不可少的工具。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;架构演进&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB-Binlog 这个组件已经发布了 2 年多时间，经历过几次架构演进，去年十月到现在大规模使用的是 Kafka 版本，架构图如下：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-df721303b9040c503599496dcf52d16b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;333&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-df721303b9040c503599496dcf52d16b&quot; data-watermark-src=&quot;v2-5119818836a0f90f06478a754c1d4d02&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Kafka 版本的 TiDB-Binlog 主要包括两个组件：&lt;/p&gt;&lt;p&gt;Pump：一个守护进程，在每个 TiDB 主机的后台运行。其主要功能是实时记录 TiDB 产生的 binlog 并顺序写入 Kafka 中。&lt;/p&gt;&lt;p&gt;Drainer： 从 Kafka 中收集 binlog，并按照 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句或者指定格式的数据，最后同步到目的数据库或者写到顺序文件。&lt;/p&gt;&lt;p&gt;这个架构的工作原理为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 需要与 Pump 绑定，即 TiDB 实例只能将它生成的 binlog 发送到一个指定的 Pump 中；&lt;/li&gt;&lt;li&gt;Pump 将 binlog 先写到本地文件，再异步地写入到 Kafka；&lt;/li&gt;&lt;li&gt;Drainer 从 Kafka 中读出 binlog，对 binlog 进行排序，对 binlog 解析后生成 SQL 或指定格式的数据再同步到下游。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;根据用户的反馈，以及我们自己做的一些测试，发现该版本主要存在一些问题。&lt;/p&gt;&lt;p&gt;首先，TiDB 的负载可能不均衡，部分 TiDB 业务较多，产生的 binlog 也比较多，对应的 Pump 的负载高，导致数据同步延迟高。&lt;/p&gt;&lt;p&gt;其次，依赖 Kafka 集群，增加了运维成本；而且 TiDB 产生的单条 binlog 的大小可达 2G（例如批量删除数据、批量写入数据），需要配置 Kafka 的消息大小相关设置，而 Kafka 并不太适合单条数据较大的场景。&lt;/p&gt;&lt;p&gt;最后，Drainer 需要读取 Kafka 中的 binlog、对 binlog 进行排序、解析 binlog，同步数据到下游等工作，可以看出 Drainer 的工作较多，而且 Drainer 是一个单点，所以往往同步数据的瓶颈都在 Drainer。&lt;/p&gt;&lt;p&gt;&lt;b&gt;以上这些问题我们很难在已有的框架下进行优化，因此我们对 TiDB-Binlog 进行了重构，最新版本的 TiDB-Binlog 的总体架构如下图所示：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e5e2bb0245f985f9f7f3b53b2f605c9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;391&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6e5e2bb0245f985f9f7f3b53b2f605c9&quot; data-watermark-src=&quot;v2-742a86727627f4e4ec5e5e9f68583501&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;新版本 TiDB-Binlog 不再使用 Kafka 存储 binlog，仍然保留了 Pump 和 Drainer 两个组件，但是对功能进行了调整：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pump 用于实时记录 TiDB 产生的 binlog，并将 binlog 按照事务的提交时间进行排序，再提供给 Drainer 进行消费。&lt;/li&gt;&lt;li&gt;Drainer 从各个 Pump 中收集 binlog 进行归并，再将 binlog 转化成 SQL 或者指定格式的数据，最终同步到下游。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该版本的主要优点为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;多个 Pump 形成一个集群，可以水平扩容，各个 Pump 可以均匀地承担业务的压力。&lt;/li&gt;&lt;li&gt;TiDB 通过内置的 Pump Client 将 binlog 分发到各个 Pump，即使有部分 Pump 出现故障也不影响 TiDB 的业务。&lt;/li&gt;&lt;li&gt;Pump 内部实现了简单的 kv 来存储 binlog，方便对 binlog 数据的管理。&lt;/li&gt;&lt;li&gt;原来 Drainer 的 binlog 排序逻辑移到了 Pump 来做，而 Pump 是可扩展的，这样就能提高整体的同步性能。&lt;/li&gt;&lt;li&gt;Drainer 不再需要像原来一样读取一批 binlog 到内存里进行堆排序，只需要依次读取各个 Pump 的 binlog 进行归并排序，这样可以大大节省内存的使用，同时也更容易做内存控制。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;由于该版本最大的特点是多个 Pump 组成了一个集群（cluster），因此该版本命名为 cluster 版本。下面我们以最新的 cluster 版本的架构来介绍 TiDB-Binlog 的实现原理。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;工作原理&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;binlog&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;首先我们先介绍一下 TiDB 中的 binlog，TiDB 的事务采用 2pc 算法，一个成功的事务会写两条 binlog，包括一条 Prewrite binlog 和 一条 Commit binlog；如果事务失败，会发一条 Rollback binlog。&lt;/p&gt;&lt;p&gt;binlog 的结构定义为：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// Binlog 记录事务中所有的变更，可以用 Binlog 构建 SQL
message Binlog {
    // Binlog 的类型，包括 Prewrite、Commit、Rollback 等
    optional BinlogType  tp = 1 [(gogoproto.nullable) = false];
    
    // Prewrite, Commit 和 Rollback 类型的 binlog 的 start_ts，记录事务开始的 ts
    optional int64  start_ts = 2 [(gogoproto.nullable) = false];
    
    // commit_ts 记录事务结束的 ts，只记录在 commit 类型的 binlog 中
    optional int64  commit_ts = 3 [(gogoproto.nullable) = false];
    
    // prewrite key 只记录在 Prewrite 类型的 binlog 中，
    // 是一个事务的主键，用于查询该事务是否提交
    optional bytes  prewrite_key = 4;
    
    // prewrite_value 记录在 Prewrite 类型的 binlog 中，用于记录每一行数据的改变
    optional bytes  prewrite_value = 5;
    
    // ddl_query 记录 ddl 语句
    optional bytes  ddl_query = 6;
    
    // ddl_job_id 记录 ddl 的 job id
    optional int64  ddl_job_id  = 7 [(gogoproto.nullable) = false];
}&lt;/code&gt;&lt;p&gt;binlog 及相关的数据结构定义见:&lt;a href=&quot;https://github.com/WangXiangUSTC/tipb/blob/master/proto/binlog/binlog.proto&quot;&gt;binlog.proto&lt;/a&gt;&lt;/p&gt;&lt;p&gt;其中 &lt;code class=&quot;inline&quot;&gt;start_ts&lt;/code&gt; 为事务开始时的 ts，&lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt; 为事务提交的 ts。ts 是由物理时间和逻辑时间转化而成的，在 TiDB 中是唯一的，由 PD 来统一提供。在开始一个事务时，TiDB 会请求 PD，获取一个 ts 作为事务的 &lt;code class=&quot;inline&quot;&gt;start_ts&lt;/code&gt;，在事务提交时则再次请求 PD 获取一个 ts 作为 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt;。 我们在 Pump 和 Drainer 中就是根据 binlog 的 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt; 来对 binlog 进行排序的。&lt;/p&gt;&lt;p&gt;TiDB 的 binlog 记录为 row 模式，即保存每一行数据的改变。数据的变化记录在  &lt;code class=&quot;inline&quot;&gt;prewrite_value&lt;/code&gt; 字段中，该字段的数据主要由序列化后的 TableMutation 结构的数据组成。TableMutation 的结构如下所示：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// TableMutation 存储表中数据的变化
message TableMutation {
    // 表的 id，唯一标识一个表
    optional int64 table_id = 1 [(gogoproto.nullable) = false];
    
    // 保存插入的每行数据
    repeated bytes inserted_rows = 2;
    
    // 保存修改前和修改后的每行的数据
    repeated bytes updated_rows = 3;
    
    // 已废弃
    repeated int64 deleted_ids = 4;
    
    // 已废弃
    repeated bytes deleted_pks = 5;
    
    // 删除行的数据
    repeated bytes deleted_rows  = 6;
    
    // 记录数据变更的顺序
    repeated MutationType sequence = 7;
}&lt;/code&gt;&lt;p&gt;下面以一个例子来说明 binlog 中是怎么存储数据的变化的。&lt;/p&gt;&lt;p&gt;例如 table 的结构为：&lt;/p&gt;&lt;p&gt;create table &lt;code class=&quot;inline&quot;&gt;test&lt;/code&gt; (&lt;code class=&quot;inline&quot;&gt;id&lt;/code&gt; int, &lt;code class=&quot;inline&quot;&gt;name&lt;/code&gt; varchar(24), primary key &lt;code class=&quot;inline&quot;&gt;id&lt;/code&gt;)&lt;/p&gt;&lt;p&gt;按照顺序执行如下 SQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;begin;
insert into test(id, name) values(1, &quot;a&quot;);
insert into test(id, name) values(2, &quot;b&quot;);
update test set name = &quot;c&quot; where id = 1;
update test set name = &quot;d&quot; where id = 2;
delete from test where id = 2;
insert into test(id, name) values(2, &quot;c&quot;);
commit;&lt;/code&gt;&lt;p&gt;则生成的 TableMutation 的数据如下所示：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;inserted_rows:
1, &quot;a&quot;
2, &quot;b&quot;
2, &quot;c&quot;
 
updated_rows:
1, &quot;a&quot;, 1, &quot;c&quot;
2, &quot;b&quot;, 2, &quot;d&quot;
 
deleted_rows:
2, &quot;d&quot;
 
sequence:
Insert, Insert, Update, Update, DeleteRow, Insert&lt;/code&gt;&lt;p&gt;可以从例子中看出，sequence 中保存的数据变更类型的顺序为执行 SQL 的顺序，具体变更的数据内容则保存到了相应的变量中。&lt;/p&gt;&lt;p&gt;Drainer 在把 binlog 数据同步到下游前，就需要把上面的这些数据还原成 SQL，再同步到下游。&lt;/p&gt;&lt;p&gt;另外需要说明的是，TiDB 在写 binlog 时，会同时向 TiKV 发起写数据请求和向 Pump 发送 Prewrite binlog，如果 TiKV 和 Pump 其中一个请求失败，则该事务失败。当 Prewrite 成功后，TiDB 向 TiKV 发起 Commit 消息，并异步地向 Pump 发送一条 Commit binlog。由于 TiDB 是同时向 TiKV 和 Pump 发送请求的，所以只要保证 Pump 处理 Prewrite binlog 请求的时间小于等于 TiKV 执行 Prewrite 的时间，开启 binlog 就不会对事务的延迟造成影响。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Pump Client&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从上面的介绍中我们知道由多个 Pump 组成一个集群，共同承担写 binlog 的请求，那么就需要保证 TiDB 能够将写 binlog 的请求尽可能均匀地分发到各个 Pump，并且需要识别不可用的 Pump，及时获取到新加入集群中 Pump 信息。这部分的工作是在 Pump Client 中实现的。&lt;/p&gt;&lt;p&gt;Pump Client 以包的形式集成在 TiDB 中，代码链接：&lt;a href=&quot;https://github.com/pingcap/tidb-tools/tree/v2.1.0/tidb-binlog/pump_client&quot;&gt;pump_client&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;Pump Client 维护 Pump 集群的信息，Pump 的信息主要来自于 PD 中保存的 Pump 的状态信息，状态信息的定义如下（代码链接：&lt;a href=&quot;https://github.com/pingcap/tidb-tools/blob/v2.1.0/tidb-binlog/node/node.go&quot;&gt;Status&lt;/a&gt;）：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;type Status struct {
    // Pump/Drainer 实例的唯一标识
    NodeID string `json:&quot;nodeId&quot;`
    
    // Pump/Drainer 的服务地址
    Addr string `json:&quot;host&quot;`
    
    // Pump/Drainer 的状态，值可以为 online、pausing、paused、closing、offline
    State string `json:&quot;state&quot;`
    
    // Pump/Drainer 是否 alive（目前没有使用该字段）
    IsAlive bool `json:&quot;isAlive&quot;`
    
    // Pump的分数，该分数是由节点的负载、磁盘使用率、存储的数据量大小等因素计算得来的，
    // 这样 Pump Client 可以根据分数来选取合适的 Pump 发送 binlog（待实现）
    Score int64 `json:&quot;score&quot;`
    
    // Pump 的标签，可以通过 label 对 TiDB 和 Pump 进行分组，
    // TiDB 只能将 binlog 发送到相同 label 的 Pump（待实现）
    Label *Label `json:&quot;label&quot;`
    
    // Pump： 保存的 binlog 的最大的 commit_ts
    // Drainer：已消费的 binlog 的最大的 commit_ts
    MaxCommitTS int64 `json:&quot;maxCommitTS&quot;`
    
    // 该状态信息的更新时间对应的 ts.
    UpdateTS int64 `json:&quot;updateTS&quot;`
}&lt;/code&gt;&lt;p&gt;Pump Client 根据 Pump 上报到 PD 的信息以及写 binlog 请求的实际情况将 Pump 划分为可用 Pump 与不可用 Pump 两个部分。&lt;/p&gt;&lt;p&gt;划分的方法包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;初始化时从 PD 中获取所有 Pump 的信息，将状态为 online 的 Pump 加入到可用 Pump 列表中，其他 Pump 加入到非可用列表中。&lt;/li&gt;&lt;li&gt;Pump 每隔固定的时间会发送心跳到 PD，并更新自己的状态。Pump Client 监控 PD 中 Pump 上传的状态信息，及时更新内存中维护的 Pump 信息，如果状态由非 online 转换为 online 则将该 Pump 加入到可用 Pump 列表；反之加入到非可用列表中。&lt;/li&gt;&lt;li&gt;在写 binlog 到 Pump 时，如果该 Pump 在重试多次后仍然写 binlog 失败，则把该 Pump 加入到非可用 Pump 列表中。&lt;/li&gt;&lt;li&gt;定时发送探活请求（数据为空的 binlog 写请求）到非可用 Pump 列表中的状态为 online 的 Pump，如果返回成功，则把该 Pump 重新加入到可用 Pump 列表中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过上面的这些措施，Pump Client 就可以及时地更新所维护的 Pump 集群信息，保证将 binlog 发送到可用的 Pump 中。&lt;/p&gt;&lt;p&gt;另外一个问题是，怎么保证 Pump Client 可以将 binlog 写请求均匀地分发到各个 Pump？我们目前提供了几种路由策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;range： 按照顺序依次选取 Pump 发送 binlog，即第一次选取第一个 Pump，第二次选取第二个 Pump…&lt;/li&gt;&lt;li&gt;hash：对 binlog 的 &lt;code class=&quot;inline&quot;&gt;start_ts&lt;/code&gt; 进行 hash，然后选取 hash 值对应的 Pump。&lt;/li&gt;&lt;li&gt;score：根据 Pump 上报的分数按照加权平均算法选取 Pump 发送 binlog（待实现）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要注意的地方是，以上的策略只是针对 Prewrite binlog，对于 Commit binlog，Pump Client 会将它发送到对应的 Prewrite binlog 所选择的 Pump，这样做是因为在 Pump 中需要将包含 Prewrite binlog 和 Commit binlog 的完整 binlog（即执行成功的事务的 binlog）提供给 Drainer，将 Commit binlog 发送到其他 Pump 没有意义。&lt;/p&gt;&lt;p&gt;Pump Client 向 Pump 提交写 binlog 的请求接口为 &lt;a href=&quot;https://github.com/WangXiangUSTC/tipb/blob/master/proto/binlog/pump.proto&quot;&gt;pump.proto&lt;/a&gt; 中的 WriteBinlog，使用 grpc 发送 binlog 请求。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Pump&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Pump 主要用来承担 binlog 的写请求，维护 binlog 数据，并将有序的 binlog 提供给 Drainer。我们将 Pump 抽象成了一个简单的 kv 数据库，key 为 binlog 的 &lt;code class=&quot;inline&quot;&gt;start _ts&lt;/code&gt;（Priwrite binlog） 或者 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt;（Commit binlog），value 为 binlog 的元数据，binlog 的数据则存在数据文件中。Drainer 像查数据库一样的来获取所需要的 binlog。&lt;/p&gt;&lt;p&gt;Pump 内置了 leveldb 用于存储 binlog 的元信息。在 Pump 收到 binlog 的写请求时，会首先将 binlog 数据以 append 的形式写到文件中，然后将 binlog 的 ts、类型、数据长度、所保存的文件以及在文件中的位置信息保存在 leveldb 中，如果为 Prewrite binlog，则以 &lt;code class=&quot;inline&quot;&gt;start_ts&lt;/code&gt;作为 key；如果是 Commit binlog，则以 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt; 作为 key。&lt;/p&gt;&lt;p&gt;当 Drainer 向 Pump 请求获取指定 ts 之后的 binlog 时，Pump 则查询 leveldb 中大于该 ts 的 binlog 的元数据，如果当前数据为 Prewrite binlog，则必须找到对应的 Commit binlog；如果为 Commit binlog 则继续向前推进。这里有个问题，在 binlog 一节中提到，如果 TiKV 成功写入了数据，并且 Pump 成功接收到了 Prewrite binlog，则该事务就提交成功了，那么如果在 TiDB 发送 Commit binlog 到 Pump 前发生了一些异常（例如 TiDB 异常退出，或者强制终止了 TiDB 进程），导致 Pump 没有接收到 Commit binlog，那么 Pump 中就会一直找不到某些 Prewrite binlog 对应的 Commit binlog。这里我们在 Pump 中做了处理，如果某个 Prewrite binlog 超过了十分钟都没有找到对应的 Commit binlog，则通过 binlog 数据中的 &lt;code class=&quot;inline&quot;&gt;prewrite_key&lt;/code&gt; 去查询 TiKV 该事务是否提交，如果已经提交成功，则 TiKV 会返回该事务的 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt;；否则 Pump 就丢弃该条 Prewrite binlog。&lt;/p&gt;&lt;p&gt;binlog 元数据中提供了数据存储的文件和位置，可以通过这些信息读取 binlog 文件的指定位置获取到数据。因为 binlog 数据基本上是按顺序写入到文件中的，因此我们只需要顺序地读 binlog 文件即可，这样就保证了不会因为频繁地读取文件而影响 Pump 的性能。最终，Pump 以 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt; 为排序标准将 binlog 数据传输给 Drainer。Drainer 向 Pump 请求 binlog 数据的接口为 &lt;a href=&quot;https://github.com/WangXiangUSTC/tipb/blob/master/proto/binlog/pump.proto&quot;&gt;pump.proto&lt;/a&gt; 中的 PullBinlogs，以 grpc streaming 的形式传输 binlog 数据。&lt;/p&gt;&lt;p&gt;值得一提的是，Pump 中有一个 fake binlog 机制。Pump 会定时（默认三秒）向本地存储中写入一条数据为空的 binlog，在生成该 binlog 前，会向 PD 中获取一个 ts，作为该 binlog 的 &lt;code class=&quot;inline&quot;&gt;start_ts&lt;/code&gt; 与 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt;，这种 binlog 我们叫作 fake binlog。这样做的原因在 Drainer 中介绍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Drainer&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Drainer 从各个 Pump 中获取 binlog，归并后按照顺序解析 binlog、生成 SQL 或者指定格式的数据，然后再同步到下游。&lt;/p&gt;&lt;p&gt;既然要从各个 Pump 获取数据，Drainer 就需要维护 Pump 集群的信息，及时获取到新增加的 Pump，并识别出不可用的 Pump，这部分功能与 Pump Client 类似，Drainer 也是通过 PD 中存储的 Pump 的状态信息来维护 Pump 信息。另外需要注意的是，如果新增加了一个 Pump，必须让该 Pump 通知 Drainer 自己上线了，这么做是为了保证不会丢数据。例如：&lt;/p&gt;&lt;p&gt;集群中已经存在 Pump1 和 Pump2，Drainer 读取 Pump1 和 Pump2 的数据并进行归并：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3cd607d2bdbee944445902c45d40e64c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;752&quot; data-rawheight=&quot;499&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3cd607d2bdbee944445902c45d40e64c&quot; data-watermark-src=&quot;v2-1988b173b06ddd67d5b8a6367b3ba589&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;Pump1 存储的 binlog 为｛ 1，3，5，7，9 ｝，Pump2 存储的 binlog 为｛2，4，6，10｝。Drainer 从两个 Pump 获取 binlog，假设当前已经读取到了｛1，2，3，4，5，6，7｝这些 binlog，已处理的 binlog 的位置为 7。此时 Pump3 加入集群，从 Pump3 上报自己的上线信息到 PD，到 Drainer 从 PD 中获取到 Pump3 信息需要一定的时间，如果 Pump3 没有通知 Drainer 就直接提供写 binlog 服务，写入了 binlog｛8，12｝，Drainer 在此期间继续读取 Pump1 和 Pump2 的 binlog，假设读取到了 9，之后才识别到了 Pump3 并将 Pump3 加入到归并排序中，此时 Pump3 的 binlog 8 就丢失了。为了避免这种情况，需要让 Pump3 通知 Drainer 自己已经上线，Drainer 收到通知后将 Pump3 加入到归并排序，并返回成功给 Pump3，然后 Pump3 才能提供写 binlog 的服务。&lt;/p&gt;&lt;p&gt;Drainer 通过如上所示的方式对 binlog 进行归并排序，并推进同步的位置。那么可能会存在这种情况：某个 Pump 由于一些特殊的原因一直没有收到 binlog 数据，那么 Drainer 中的归并排序就无法继续下去，正如我们用两条腿走路，其中一只腿不动就不能继续前进。我们使用 Pump 一节中提到的 fake binlog 的机制来避免这种问题，Pump 每隔指定的时间就生成一条 fake binlog，即使某些 Pump 一直没有数据写入，也可以保证归并排序正常向前推进。&lt;/p&gt;&lt;p&gt;Drainer 将所有 Pump 的数据按照 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt; 进行归并排序后，将 binlog 数据传递给 Drainer 中的数据解析及同步模块。通过上面的 binlog 格式的介绍，我们可以看出 binlog 文件中并没有存储表结构的信息，因此需要在 Drainer 中维护所有库和表的结构信息。在启动 Drainer 时，Drainer 会请求 TiKV，获取到所有历史的 DDL job 的信息，对这些 DDL job 进行过滤，使用 Drainer 启动时指定的 initial-commit-ts（或者 checkpoint 中保存的 &lt;code class=&quot;inline&quot;&gt;commit_ts&lt;/code&gt;）之前的 DDL 在内存中构建库和表结构信息。这样 Drainer 就有了一份 ts 对应时间点的库和表的快照，在读取到 DDL 类型的 binlog 时，则更新库和表的信息；读取到 DML 类型的 binlog 时，则根据库和表的信息来生成 SQL。&lt;/p&gt;&lt;p&gt;在生成 SQL 之后，就可以同步到下游了。为了提高 Drainer 同步的速度，Drainer 中使用多个协程来执行 SQL。在生成 SQL 时，我们会使用主键／唯一键的值作为该条 SQL 的 key，通过对 key 进行 hash 来将 SQL 发送到对应的协程中。当每个协程收集到了足够多的 SQL，或者超过了一定的时间，则将这一批的 SQL 在一个事务中提交到下游。&lt;/p&gt;&lt;p&gt;但是有些 SQL 是相关的，如果被分到了不同的协程，那 SQL 的执行顺序就不能得到保证，造成数据的不一致。例如：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;SQL1: delete from test.test where id = 1;

SQL2: replace into test.test (id, name ) values(1, &quot;a&quot;);&lt;/code&gt;&lt;p&gt;按照顺序执行后表中存在 id ＝ 1 该行数据，如果这两条 SQL 分别分配到了协程 1 和协程 2 中，并且协程 2 先执行了 SQL，则表中不再存在 id ＝ 1 的数据。为了避免这种情况的发生，Drainer 中加入了冲突检测的机制，如果检测出来两条 SQL 存在冲突（修改了同一行数据），则暂时不将后面的 SQL 发送到协程，而是生成一个 Flush 类型的 job 发送到所有的协程， 每个协程在遇到 Flush job 时就会马上执行所缓存的 SQL。接着才会把该条有冲突的 SQL 发送到对应的协程中。下面给出一个例子说明一下冲突检测的机制：&lt;/p&gt;&lt;p&gt;有以下这些 SQL，其中 id 为表的主键：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;SQL1: update itest set id = 4, name = &quot;c&quot;, age = 15 where id = 3;    key: 3, 4

SQL2:  update itest set id = 5, name = &quot;b&quot;, age = 14 where id = 2;   key：5, 2

SQL3：delete from itest where id = 3;                                key: 3&lt;/code&gt;&lt;ol&gt;&lt;li&gt;首先将 SQL1 发送到指定的协程，这时所有的 keys 为［3，4］；&lt;/li&gt;&lt;li&gt;SQL2 的 key［5，2］与 keys 中的［3，4］都没有冲突，将 SQL2 发送到指定的协程，这时 keys 为［3，4，5，2］；&lt;/li&gt;&lt;li&gt;SQL3 的 key［3］与 keys 中的［3］存在冲突，发送 Flush job 到所有协程，SQL1 和 SQL2 被执行，清空 keys；&lt;/li&gt;&lt;li&gt;将 SQL3 发送到指定的协程，同时更新 keys 为［3］。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Drainer 通过以上这些机制来高效地同步数据，并且保证数据的一致。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;更多技术干货：&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://www.pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-60ab5bd867c2434d70c957a02a2169e1&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; data-image-size=&quot;ipico&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-10-51990591</guid>
<pubDate>Mon, 10 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在小米的应用实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-03-51472404.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51472404&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-286ddf5e402ba98f9de8bfa95ce5eb57_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br&gt;张良，小米 DBA 负责人&lt;br&gt;潘友飞，小米 DBA&lt;br&gt;王必文，小米开发工程师&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;应用场景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;MIUI 是小米公司旗下基于 Android 系统深度优化、定制、开发的第三方手机操作系统，也是小米的第一个产品。MIUI 在 Android 系统基础上，针对中国用户进行了深度定制，在此之上孕育出了一系列的应用，比如主题商店、小米音乐、应用商店、小米阅读等。     &lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c4428dc7c80aea208ba650abba0f8079_r.jpg&quot; data-caption=&quot;图 1  MIUI Android 系统界面图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;595&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c4428dc7c80aea208ba650abba0f8079&quot; data-watermark-src=&quot;v2-acb05a51e9c3630558f4a6880d1ca2c1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;目前 TiDB 主要应用在：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;小米手机桌面负一屏的快递业务&lt;/li&gt;&lt;li&gt;商业广告交易平台素材抽审平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;这两个业务场景每天读写量均达到上亿级，上线之后，整个服务稳定运行；接下来我们计划逐步上线更多的业务场景，小米阅读目前正在积极的针对订单系统做迁移测试。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 特点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 结合了传统的 RDBMS 和 NoSQL 的最佳特性，兼容 MySQL 协议，支持无限的水平扩展，具备强一致性和高可用性。&lt;/p&gt;&lt;p&gt;具有如下的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL，大多数情况下无需修改代码即可从 MySQL 轻松迁移至 TiDB，即使已经分库分表的 MySQL 集群亦可通过 TiDB 提供的迁移工具进行实时迁移。&lt;/li&gt;&lt;li&gt;水平弹性扩展，通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。&lt;/li&gt;&lt;li&gt;分布式事务，TiDB 100% 支持标准的 ACID 事务。&lt;/li&gt;&lt;li&gt;真正金融级高可用，相比于传统主从（M-S）复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 的架构及原理官网有详细介绍（&lt;a href=&quot;https://pingcap.com/&quot;&gt;https://pingcap.com/&lt;/a&gt;），这里不再赘述。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2a500e631bf3062d721ce5cd2cd2c817_r.jpg&quot; data-caption=&quot;图 2  TiDB 基础架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;381&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2a500e631bf3062d721ce5cd2cd2c817&quot; data-watermark-src=&quot;v2-8169cc4855b1c15dc1d79afdb93854a4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;跟绝大数互联网公司一样，小米关系型存储数据库首选 MySQL，单机 2.6T 磁盘。由于小米手机销量的快速上升和 MIUI 负一屏用户量的快速增加，导致负一屏快递业务数据的数据量增长非常快，&lt;b&gt;每天的读写量级均分别达到上亿级别，数据快速增长导致单机出现瓶颈，比如性能明显下降、可用存储空间不断降低、大表 DDL 无法执行等，不得不面临数据库扩展的问题。&lt;/b&gt;比如，我们有一个业务场景（智能终端），需要定时从几千万级的智能终端高频的向数据库写入各种监控及采集数据，MySQL 基于 Binlog 的单线程复制模式，很容易造成从库延迟，并且堆积越来越严重。&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于 MySQL 来讲，最直接的方案就是采用分库分表的水平扩展方式，综合来看并不是最优的方案，比如对于业务来讲，对业务代码的侵入性较大；对于 DBA 来讲提升管理成本，后续需要不断的拆分扩容，即使有中间件也有一定的局限性。&lt;/b&gt;同样是上面的智能终端业务场景，从业务需求看，需要从多个业务维度进行查询，并且业务维度可能随时进行扩展，分表的方案基本不能满足业务的需求。&lt;/p&gt;&lt;p&gt;了解到 TiDB 特点之后，DBA 与业务开发沟通确认当前 MySQL 的使用方式，并与 TiDB 的兼容性做了详细对比，经过业务压测之后，根据压测的结果，决定尝试将数据存储从 MySQL 迁移到 TiDB。经过几个月的线上考验，TiDB 的表现达到预期。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;兼容性对比&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 支持包括跨行事务、JOIN、子查询在内的绝大多数 MySQL 的语法，可以直接使用 MySQL 客户端连接；对于已用 MySQL 的业务来讲，基本可以无缝切换到 TiDB。&lt;/b&gt;&lt;br&gt;二者简单对比如下几方面：&lt;/p&gt;&lt;p&gt;1. 功能支持&lt;/p&gt;&lt;p&gt;TiDB 尚不支持如下几项：&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;增加、删除主键&lt;/li&gt;&lt;li&gt;非 UTF8 字符集&lt;/li&gt;&lt;li&gt;视图（即将支持）、存储过程、触发器、部分内置函数&lt;/li&gt;&lt;li&gt;Event&lt;/li&gt;&lt;li&gt;全文索引、空间索引&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;2. 默认设置&lt;/p&gt;&lt;p&gt;字符集、排序规则、sql_mode、lower_case_table_names 几项默认值不同。&lt;/p&gt;&lt;p&gt;3. 事务&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;TiDB 使用乐观事务模型，提交后注意检查返回值。&lt;/li&gt;&lt;li&gt;TiDB 限制单个事务大小，保持事务尽可能的小。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;4. TiDB 支持绝大多数的 Online DDL。&lt;/p&gt;&lt;p&gt;5. 另，一些 MySQL 语法在 TiDB 中可以解析通过，不会产生任何作用，例如： create table 语句中 engine、partition 选项都是在解析后忽略。&lt;/p&gt;&lt;p&gt;6. 详细信息可以访问官网：https://pingcap.com/docs-cn/sql/mysql-compatibility/ 。&lt;/p&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;压测&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 目的&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过压测 TiDB 了解一下其 OLTP 性能，看是否满足业务要求。&lt;br&gt;&lt;br&gt;&lt;b&gt;2. 机器配置&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d7d319c1480a57e186b79e7bf2cd6ce_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;394&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5d7d319c1480a57e186b79e7bf2cd6ce&quot; data-watermark-src=&quot;v2-dbdd0864ecae8948d5ef342c9e5d6c78&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;3. 压测内容以及结果&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt; 标准 Select 压测&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3919bf10c952092538e4df79ee90caa2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;322&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3919bf10c952092538e4df79ee90caa2&quot; data-watermark-src=&quot;v2-1ab2200f75c089f9a9f3cade76c787b4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8d9269cdf30ac3f6bb7c846d4473a248_r.jpg&quot; data-caption=&quot;图 3  标准 Select 压测图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8d9269cdf30ac3f6bb7c846d4473a248&quot; data-watermark-src=&quot;v2-da683c683c19267c31a5e7fc3f07a732&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;标准 OLTP 压测&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c163a21feec655e19ab64dcb1b07f70a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;357&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c163a21feec655e19ab64dcb1b07f70a&quot; data-watermark-src=&quot;v2-a755b0a83bd7ddba182ba80a6ed66877&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fddec2f978f81acfee3a2d75b2d5ebcb_r.jpg&quot; data-caption=&quot;图 4  标准 OLTP  压测图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;541&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fddec2f978f81acfee3a2d75b2d5ebcb&quot; data-watermark-src=&quot;v2-847e24943021fd8f04ec9a6c907ff6a8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt; 标准 Insert 压测&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28457ad3a1997ddf3c1f2abb33d16fc4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;333&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-28457ad3a1997ddf3c1f2abb33d16fc4&quot; data-watermark-src=&quot;v2-36a16a1feb93e863164d2d83eb3c472a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-686f7602ce614f8e15fdb0ef388a009a_r.jpg&quot; data-caption=&quot;图 5  标准 Insert 压测图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-686f7602ce614f8e15fdb0ef388a009a&quot; data-watermark-src=&quot;v2-c687905215da14e1e3976f9a4196762f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;通过压测发现 TiDB 稳定性上与预期稍有差别，不过压测的 Load 会明显高于生产中的业务 Load，参考低 Threads 时 TiDB 的表现，基本可以满足业务对 DB 的性能要求，决定灰度一部分 MySQL 从库读流量体验一下实际效果。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;迁移过程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;整个迁移分为 2 大块：数据迁移、流量迁移。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 数据迁移&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据迁移分为增量数据、存量数据两部分。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于存量数据，可以使用逻辑备份、导入的方式，除了传统的逻辑导入外，官方还提供一款物理导入的工具 TiDB Lightning。&lt;/li&gt;&lt;li&gt;对于增量备份可以使用 TiDB 提供的 Syncer （新版已经更名为 DM - Data Migration）来保证数据同步。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Syncer 结构如图 6，主要依靠各种 Rule 来实现不同的过滤、合并效果，一个同步源对应一个 Syncer 进程，同步 Sharding 数据时则要多个 Syncer 进程。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-facfec2bcf6879a829017e0de8b94a38_r.jpg&quot; data-caption=&quot;图 6  Syncer 结构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;852&quot; data-rawheight=&quot;391&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-facfec2bcf6879a829017e0de8b94a38&quot; data-watermark-src=&quot;v2-fa999818be6d9fcd875987dfa5d194a8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;使用 Syncer 需要注意：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;做好同步前检查，包含 server-id、log_bin、binlog_format 是否为 ROW、binlog_row_image 是否为 FULL、同步相关用户权限、Binlog 信息等。&lt;/li&gt;&lt;li&gt;使用严格数据检查模式，数据不合法则会停止。数据迁移之前最好针对数据、表结构做检查。&lt;/li&gt;&lt;li&gt;做好监控，TiDB 提供现成的监控方案。&lt;/li&gt;&lt;li&gt;对于已经分片的表同步到同一个 TiDB 集群，要做好预先检查。确认同步场景是否可以用 route-rules 表达，检查分表的唯一键、主键在数据合并后是否冲突等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 流量迁移&lt;/b&gt;&lt;/p&gt;&lt;p&gt;流量切换到 TiDB 分为两部分：读、写流量迁移。每次切换保证灰度过程，观察周期为 1~2 周，做好回滚措施。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;读流量切换到 TiDB，这个过程中回滚比较简单，灰度无问题，则全量切换。&lt;/li&gt;&lt;li&gt;再将写入切换到 TiDB，需要考虑好数据回滚方案或者采用双写的方式（需要断掉 Syncer） 。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;集群状况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 配置&lt;/b&gt;&lt;/p&gt;&lt;p&gt;集群配置采用官方推荐的 7 节点配置，3 个 TiDB 节点，3 个 PD 节点，4 个 TiKV 节点，其中每个 TiDB 与 PD 为一组，共用一台物理机。后续随着业务增长或者新业务接入，再按需添加 TiKV 节点。&lt;br&gt;&lt;br&gt;&lt;b&gt;2. 监控&lt;/b&gt;&lt;/p&gt;&lt;p&gt;监控采用了 TiDB 的提供的监控方案，并且也接入了公司开源的 Falcon，目前整个集群运行比较稳定，监控如图 7。      &lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6288a303380a452fb7c0f8716e97d135_r.jpg&quot; data-caption=&quot;图 7  监控图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;314&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6288a303380a452fb7c0f8716e97d135&quot; data-watermark-src=&quot;v2-729e081c26da54cb02349deb61f1c839&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;遇到的问题、原因及解决办法&lt;/b&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-504342f9d0b3e7799d8dc657180e2083_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;928&quot; data-rawheight=&quot;1638&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-504342f9d0b3e7799d8dc657180e2083&quot; data-watermark-src=&quot;v2-041e4d6ecb39bebe13289f22f6f275b9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;后续和展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前 TiDB 在小米主要提供 OLTP 服务，小米手机负一屏快递业务为使用 TiDB 做了一个良好的开端，而后商业广告也有接入，2 个业务均已上线数月，TiDB 的稳定性经受住了考验，带来了很棒的体验，对于后续大体的规划如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;MIUI 生态业务中存在大量的类似场景的业务，后续将会与业务开发积极沟通，从 MySQL 迁移到 TiDB。&lt;/li&gt;&lt;li&gt;针对某些业务场景，以资源合理利用为目标，推出归档集群，利用 Syncer 实现数据归档的功能。&lt;/li&gt;&lt;li&gt;数据分析，结合 TiDB 提供的工具，将支持离线、实时数据分析支持。&lt;/li&gt;&lt;li&gt;将 TiDB 的监控融合到小米公司开源的监控系统 Falcon 中。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;致谢&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;非常感谢 TiDB 官方在迁移及业务上线期间给予我们的支持，为每一个 TiDB 人专业的精神、及时负责的响应点赞。&lt;br&gt;&lt;br&gt;&lt;br&gt;更多 TiDB 用户实践：&lt;/p&gt;&lt;a href=&quot;https://www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-60ab5bd867c2434d70c957a02a2169e1&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; data-image-size=&quot;ipico&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-03-51472404</guid>
<pubDate>Mon, 03 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 2.1 GA Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-01-51304843.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f5709477c7ad0dcb8de138272df091a1_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 11 月 30 日，TiDB 发布 2.1 GA 版。相比 2.0 版本，该版本对系统稳定性、性能、兼容性、易用性做了大量改进。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Index Join&lt;/code&gt; 选择范围，提升执行性能&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Index Join&lt;/code&gt; 外表选择，使用估算的行数较少的表作为外表&lt;/li&gt;&lt;li&gt;扩大 Join Hint &lt;code class=&quot;inline&quot;&gt;TIDB_SMJ&lt;/code&gt; 的作用范围，在没有合适索引可用的情况下也可使用 Merge Join&lt;/li&gt;&lt;li&gt;加强 Join Hint &lt;code class=&quot;inline&quot;&gt;TIDB_INLJ&lt;/code&gt; 的能力，可以指定 Join 中的内表&lt;/li&gt;&lt;li&gt;优化关联子查询，包括下推 Filter 和扩大索引选择范围，部分查询的效率有数量级的提升&lt;/li&gt;&lt;li&gt;支持在 &lt;code class=&quot;inline&quot;&gt;UPDATE&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;DELETE&lt;/code&gt; 语句中使用 Index Hint 和 Join Hint&lt;/li&gt;&lt;li&gt;支持更多函数下推：&lt;code class=&quot;inline&quot;&gt;ABS&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;CEIL&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;FLOOR&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;IS TRUE&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;IS FALSE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;优化内建函数 &lt;code class=&quot;inline&quot;&gt;IF&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;IFNULL&lt;/code&gt; 的常量折叠算法&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;EXPLAIN&lt;/code&gt; 语句输出格式, 使用层级结构表示算子之间的上下游关系&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;SQL 执行引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;重构所有聚合函数，提升 &lt;code class=&quot;inline&quot;&gt;Stream&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;Hash&lt;/code&gt; 聚合算子的执行效率&lt;/li&gt;&lt;li&gt;实现并行 &lt;code class=&quot;inline&quot;&gt;Hash Aggregate&lt;/code&gt; 算子，部分场景下有 350% 的性能提升&lt;/li&gt;&lt;li&gt;实现并行 &lt;code class=&quot;inline&quot;&gt;Project&lt;/code&gt; 算子，部分场景有 74% 的性能提升&lt;/li&gt;&lt;li&gt;并发地读取 &lt;code class=&quot;inline&quot;&gt;Hash Join&lt;/code&gt; 的 &lt;code class=&quot;inline&quot;&gt;Inner&lt;/code&gt; 表和 &lt;code class=&quot;inline&quot;&gt;Outer&lt;/code&gt; 表的数据，提升执行性能&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;REPLACE INTO&lt;/code&gt; 语句的执行速度，性能提升 10x&lt;/li&gt;&lt;li&gt;优化时间类型的内存占用，时间类型数据的内存使用降低为原来的一半&lt;/li&gt;&lt;li&gt;优化点查的查询性能, Sysbench 点查效率提升 60%&lt;/li&gt;&lt;li&gt;TiDB 插入和更新宽表，性能提升接近 20 倍&lt;/li&gt;&lt;li&gt;支持在配置文件中设置单个查询的内存使用上限&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Hash Join&lt;/code&gt; 的执行过程，当 Join 类型为 &lt;code class=&quot;inline&quot;&gt;Inner Join&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;Semi Join&lt;/code&gt; 时，如果内表为空，不再读取外表数据，快速返回结果&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://github.com/pingcap/docs/blob/master/sql/understanding-the-query-execution-plan.md#explain-analyze-output-format&quot;&gt;EXPLAIN ANALYZE&lt;/a&gt;&lt;/code&gt; 语句，用于查看 Query 执行过程中各个算子的运行时间，返回结果行数等运行时统计信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;统计信息&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持只在一天中的某个时间段开启统计信息自动 ANALYZE 的功能&lt;/li&gt;&lt;li&gt;支持根据查询的反馈自动更新表的统计信息&lt;/li&gt;&lt;li&gt;支持通过 &lt;code class=&quot;inline&quot;&gt;ANALYZE TABLE WITH BUCKETS&lt;/code&gt; 语句配置直方图中桶的个数&lt;/li&gt;&lt;li&gt;优化等值查询和范围查询混合的情况下使用直方图估算 Row Count 的算法&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;表达式&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持内建函数：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;json_contains&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;json_contains_path&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;encode/decode&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Server&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持在单个 tidb-server 实例内部对冲突事务排队，优化事务间冲突频繁的场景下的性能&lt;/li&gt;&lt;li&gt;支持 Server Side Cursor&lt;/li&gt;&lt;li&gt;新增 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot;&gt;HTTP 管理接口&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;打散 table 的 regions 在 TiKV 集群中的分布&lt;/li&gt;&lt;li&gt;控制是否打开 &lt;code class=&quot;inline&quot;&gt;general log&lt;/code&gt;&lt;/li&gt;&lt;li&gt;在线修改日志级别&lt;/li&gt;&lt;li&gt;查询 TiDB 集群信息&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/FAQ/#3-3-11-%E5%9C%A8-tidb-%E4%B8%AD-auto-analyze-%E7%9A%84%E8%A7%A6%E5%8F%91%E7%AD%96%E7%95%A5%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84&quot;&gt;添加 auto_analyze_ratio 系统变量控制自动 Analyze 的阈值&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb-retry-limit&quot;&gt;添加 tidb_retry_limit 系统变量控制事务自动重试的次数&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb-disable-txn-auto-retry&quot;&gt;添加 tidb_disable_txn_auto_retry 系统变量控制事务是否自动重试&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/slow-query/#admin-show-slow-%E5%91%BD%E4%BB%A4&quot;&gt;支持使用 admin show slow 语句来获取慢查询语句&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb_slow_log_threshold&quot;&gt;增加环境变量 tidb_slow_log_threshold 动态设置 slow log 的阈值&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb_query_log_max_len&quot;&gt;增加环境变量 tidb_query_log_max_len 动态设置日志中被截断的原始 SQL 语句的长度&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持 Add Index 语句与其他 DDL 语句并行执行，避免耗时的 Add Index 操作阻塞其他操作&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Add Index&lt;/code&gt; 的速度，在某些场景下速度大幅提升&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;select tidb_is_ddl_owner()&lt;/code&gt; 语句，方便判断 TiDB 是否为 &lt;code class=&quot;inline&quot;&gt;DDL Owner&lt;/code&gt;&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;ALTER TABLE FORCE&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;ALTER TABLE RENAME KEY TO&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;Admin Show DDL Jobs&lt;/code&gt; 输出结果中添加表名、库名等信息&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot;&gt;支持使用 ddl/owner/resign HTTP 接口释放 DDL Owner 并开启新一轮 DDL Owner 选举&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持更多 MySQL 语法&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;BIT&lt;/code&gt; 聚合函数支持 &lt;code class=&quot;inline&quot;&gt;ALL&lt;/code&gt; 参数&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;SHOW PRIVILEGES&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;CHARACTER SET&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;CREATE USER&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;IDENTIFIED WITH&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;LOAD DATA IGNORE LINES&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;Show ProcessList&lt;/code&gt; 语句返回更准确信息&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;可用性优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引入 TiKV 版本控制机制，支持集群滚动兼容升级&lt;/li&gt;&lt;li&gt;PD 节点间 &lt;a href=&quot;https://github.com/pingcap/pd/blob/5c7b18cf3af91098f07cf46df0b59fbf8c7c5462/conf/config.toml#L22&quot;&gt;开启 Raft PreVote&lt;/a&gt;，避免网络隔离后恢复时产生的重新选举，避免网络隔离后恢复时产生的重新选举&lt;/li&gt;&lt;li&gt;开启 &lt;code class=&quot;inline&quot;&gt;raft learner&lt;/code&gt; 功能，降低调度时出现宕机导致数据不可用的风险&lt;/li&gt;&lt;li&gt;TSO 分配不再受系统时间回退影响&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;Region merge&lt;/code&gt; 功能，减少元数据带来的开销&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;调度器优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 Down Store 的处理流程，加快发生宕机后补副本的速度&lt;/li&gt;&lt;li&gt;优化热点调度器，在流量统计信息抖动时适应性更好&lt;/li&gt;&lt;li&gt;优化 Coordinator 的启动，减少重启 PD 时带来的不必要调度&lt;/li&gt;&lt;li&gt;优化 Balance Scheduler 频繁调度小 Region 的问题&lt;/li&gt;&lt;li&gt;优化 Region merge，调度时考虑 Region 中数据的行数&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/master/tools/pd-control.md#config-show--set--&quot;&gt;新增一些控制调度策略的开关&lt;/a&gt;&lt;/li&gt;&lt;li&gt;完善&lt;a href=&quot;https://github.com/pingcap/pd/tree/release-2.1/tools/pd-simulator&quot;&gt;调度模拟器&lt;/a&gt;，添加调度场景模拟&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;API 及运维工具&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843/http%3C/code%3Es://github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L40&quot;&gt;GetPrevRegion 接口&lt;/a&gt;，用于支持 TiDB reverse scan 功能&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/%3C/code%3E/github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L54&quot;&gt;BatchSplitRegion 接口&lt;/a&gt;，用于支持 TiKV 快速 Region 分裂&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843/ht%3C/code%3Etps://github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L64-L66&quot;&gt;GCSafePoint 接口&lt;/a&gt;，用于支持 TiDB 并发分布式 GC&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843/htt%3C/code%3Eps://github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L32&quot;&gt;GetAllStores 接口&lt;/a&gt;，用于支持 TiDB 并发分布式 GC&lt;/code&gt;&lt;/li&gt;&lt;li&gt;pd-ctl 新增：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#operator-show--add--remove&quot;&gt;使用统计信息进行 Region split&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#jq-%E6%A0%BC%E5%BC%8F%E5%8C%96-json-%E8%BE%93%E5%87%BA%E7%A4%BA%E4%BE%8B&quot;&gt;调用 jq 来格式化 JSON 输出&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#region-store-store_id&quot;&gt;查询指定 store 的 Region 信息&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#region-topconfver-limit&quot;&gt;查询按 version 排序的 topN 的 Region 列表&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#region-topsize-limit&quot;&gt;查询按 size 排序的 topN 的 Region 列表&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#tso&quot;&gt;更精确的 TSO 解码&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-recover.md&quot;&gt;pd-recover&lt;/a&gt; 不再需要提供 max-replica 参数&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;监控&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;Filter&lt;/code&gt;相关的监控&lt;/li&gt;&lt;li&gt;新增 etcd Raft 状态机相关监控&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;性能优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化处理 Region heartbeat 的性能，减少 heartbeat 带来的内存开销&lt;/li&gt;&lt;li&gt;优化 Region tree 性能&lt;/li&gt;&lt;li&gt;优化计算热点统计的性能问题&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Coprocessor&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;新增支持大量内建函数&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/rfcs/blob/master/text/2017-12-22-read-pool.md&quot;&gt;新增 Coprocessor ReadPool，提高请求处理并发度&lt;/a&gt;&lt;/li&gt;&lt;li&gt;修复时间函数解析以及时区相关问题&lt;/li&gt;&lt;li&gt;优化下推聚合计算的内存使用&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Transaction&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 MVCC 读取逻辑以及内存使用效率，提高扫描操作的性能，Count 全表性能比 2.0 版本提升 1 倍&lt;/li&gt;&lt;li&gt;折叠 MVCC 中连续的 Rollback 记录，保证记录的读取性能&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/rfcs/blob/master/text/2018-08-29-unsafe-destroy-range.md&quot;&gt;新增 UnsafeDestroyRange API 用于在 drop table/index 的情况下快速回收空间&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GC 模块独立出来，减少对正常写入的影响&lt;/li&gt;&lt;li&gt;kv_scan 命令支持设置 upper bound&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Raftstore&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 snapshot 文件写入流程避免导致 RocksDB stall&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/rfcs/pull/17&quot;&gt;增加 LocalReader 线程专门处理读请求，降低读请求的延迟&lt;/a&gt;&lt;/li&gt;&lt;li&gt;href=&quot;https://github.com/tikv/rfcs/pull/6&quot;&amp;gt;支持 BatchSplit 避免大量写入导致产生特别大的 Region&lt;/li&gt;&lt;li&gt;支持按照统计信息进行 Region Split，减少 IO 开销&lt;/li&gt;&lt;li&gt;支持按照 Key 的数量进行 Region Split，提高索引扫描的并发度&lt;/li&gt;&lt;li&gt;优化部分 Raft 消息处理流程，避免 Region Split 带来不必要的延迟&lt;/li&gt;&lt;li&gt;启用 &lt;code class=&quot;inline&quot;&gt;PreVote&lt;/code&gt; 功能，减少网络隔离对服务的影响&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;存储引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;修复 RocksDB &lt;code class=&quot;inline&quot;&gt;CompactFiles&lt;/code&gt; 的 bug，可能影响 Lightning 导入的数据&lt;/li&gt;&lt;li&gt;升级 RocksDB 到 v5.15，解决 snapshot 文件可能会被写坏的问题&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;IngestExternalFile&lt;/code&gt;，避免 flush 卡住写入的问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;tikv-ctl&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/tikv/blob/master/docs/tools/tikv-control.md#ldb-command&quot;&gt;新增 ldb 命令，方便排查 RocksDB 相关问题&lt;/a&gt;&lt;/li&gt;&lt;li&gt;compact 命令支持指定是否 compact bottommost 层的数据&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;全量数据快速导入工具 &lt;a href=&quot;https://pingcap.github.io/docs-cn/tools/lightning-overview-architecture&quot;&gt;TiDB-Lightning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;支持新版本 &lt;a href=&quot;https://pingcap.github.io/docs-cn/tools/tidb-binlog-cluster/&quot;&gt;TiDB-Binlog&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;升级兼容性说明&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;由于新版本存储引擎更新，不支持在升级后回退至 2.0.x 或更旧版本&lt;/li&gt;&lt;li&gt;新版本默认开启 &lt;code class=&quot;inline&quot;&gt;raft learner&lt;/code&gt; 功能，如果从 1.x 版本集群升级至 2.1 版本，须停机升级或者先滚动升级 TiKV，完成后再滚动升级 PD&lt;/li&gt;&lt;li&gt;从 2.0.6 之前的版本升级到 2.1.0 之前，最好确认集群中是否存在正在运行中的 DDL 操作，特别是耗时的 Add Index 操作&lt;/li&gt;&lt;li&gt;因为 2.1 版本启用了并行 DDL，对于早于 2.0.1 版本的集群，无法滚动升级到 2.1，可以选择下面两种方案：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;停机升级，直接从早于 2.0.1 的 TiDB 版本升级到 2.1&lt;/li&gt;&lt;li&gt;先滚动升级到 2.0.1 或者之后的 2.0.x 版本，再滚动升级到 2.1 版本&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-01-51304843</guid>
<pubDate>Sat, 01 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 2.1：Battle-Tested for an Unpredictable World</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-01-51304475.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304475&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-149ede427e4c2ab2ec61f20036bb4523_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;TiDB 是由 PingCAP 开发的分布式关系型数据库，今天我们很高兴地推出 TiDB 2.1 正式版，提供更丰富的功能、更好的性能以及更高的可靠性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;回顾 2.0 版本&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;今年 4 月份我们发布了 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/&quot;&gt;TiDB 2.0 版本&lt;/a&gt;，提升了稳定性、性能以及可运维性，这个版本在接下来的半年中得到了广泛的关注和使用。&lt;/p&gt;&lt;p&gt;迄今为止 TiDB 已经在 &lt;a href=&quot;https://pingcap.com/cases-cn/&quot;&gt;数百家用户&lt;/a&gt; 的生产环境中稳定运行，涉及互联网、游戏、金融、保险、制造业、银行、证券等多个行业，最大集群包含数百个节点及数百 TB 数据，业务场景包含纯 OLTP、纯 OLAP 以及混合负载。另外，既有使用 TiDB 当做关系数据库的场景，也有只用 TiKV 作为分布式 Key Value 存储的场景。&lt;/p&gt;&lt;p&gt;这几个月，在这些场景中，我们亲历了跨机房容灾需求、亲历了几十万级别的高吞吐业务、亲历了双十一的流量激增、亲历了高并发点查、高并发写入与上百行复杂 SQL 的混合负载、见到过多次的硬件/网络故障、见到过操作系统内核/编译器的 Bug。&lt;/p&gt;&lt;p&gt;简而言之，我们的世界充满了未知，而分布式关系型数据库这样一种应用广泛、功能丰富且非常关键的基础软件，最大的困难就是这些“未知”。在 2.1 版本中，我们引入了不少新的特性来抵御这些未知，适配各种复杂的场景，提升性能和稳定性，帮助我们的用户更好地支撑复杂的业务。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;更全面的 Optimizer&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2.1 版本中，我们对 TiDB 的 Cost-based Optimizer 做了改进，希望这个优化器能够处理各种复杂的 Query，尽量少的需要人工介入去处理慢 SQL。例如对 Index Join 选择索引、外表的优化，对关联子查询的优化，显著地提升了复杂 SQL 的查询效率。&lt;/p&gt;&lt;p&gt;当然，除了自动的查询优化之外，2.1 也增加了更多的手动干预机制，比如对 Join 算子的 Hint、Update/Delete 语句的 Hint。用户可以在优化器没有指定合适的计划时，手动干预结果或者是用来确保查询计划稳定。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更强大的执行引擎&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2.1 版本中，我们对部分物理算子的执行效率进行了优化，特别是对 Hash Aggregation 和 Projection 这两个算子进行了并行化改造，另外重构了聚合算子的运行框架，支持向量化计算。&lt;/p&gt;&lt;p&gt;得益于这些优化，在 TPC-H 这种 OLAP 的测试集上，2.1 比 2.0 版本有了显著的性能提升，让 2.1 版本更好的面对 HTAP 应用场景。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft 新特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2.1 版本中，我们引入了 Raft PreVote、Raft Learner、Raft Region Merge 三个新特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PreVote 是在 Raft Group Member 发起投票之前，预先检查是否能被其他成员所支持，以避免集群中被网络隔离的节点重新接入集群中的时候引发性能抖动，提升集群稳定性。2.1 版本已经支持 PreVote 功能，并默认打开。&lt;/li&gt;&lt;li&gt;Learner 是只同步数据不参与投票的 Raft Group Member。在新加副本的时候，首先增加 Learner 副本，以避免添加副本过程中，部分 TiKV 节点故障引发丢失多数副本的情况发生，以提升集群的安全性。2.1 版本已经支持 Learner 功能，并默认打开。&lt;/li&gt;&lt;li&gt;Region Merge 用于将多个过小的 Region 合并为一个大的 Region，降低集群的管理成本，对于长期运行的集群以及数据规模较大的集群的性能、稳定性有帮助。2.1 版本已经支持 Region Merge 功能，尚未默认打开。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些新特性的引入，有助于提升存储集群尤其是大规模集群的稳定性和性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;自动更新统计信息&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息的及时性对查询计划的正确性非常重要。在 2.1 版本中，我们提供了基于 Query Feedback 的动态增量更新机制。&lt;/p&gt;&lt;p&gt;在制定查询计划时，会根据现有的统计信息估算出需要处理的数据量；在执行查询计划时，会统计出真实处理的数据量。TiDB 会根据这两个值之间的差距来更新统计信息，包括直方图和 CM-Sketch。在我们的测试中，对于一个完全没有统计信息的表，经过十轮左右的更新，可以达到统计信息基本稳定的状态。这对于维持正确的查询计划非常重要。&lt;/p&gt;&lt;p&gt;除了动态增量更新之外，我们对自动全量 Analyze 也提供了更多支持，可以通过 &lt;a href=&quot;https://www.pingcap.com/docs-cn/sql/statistics/#%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0&quot;&gt;系统变量&lt;/a&gt; 指定做自动 Analyze 的时间段。&lt;/p&gt;&lt;p&gt;&lt;b&gt;并行 DDL&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 所有的 DDL 操作都是 Online 进行，不过在 2.0 以及之前的版本中，所有的 DDL 操作都是串行执行，即使 DDL 所操作的表之间没有关联。比如在对 A 表 Add Index 时候，想创建一个 B 表，需要等待 Add Index 操作结束。这在一些场景下对用户使用造成了困扰。&lt;br&gt;在 2.1 版本中，我们对 DDL 流程进行拆分，将 Add Index 操作和其他的 DDL 操作的处理分开。由于在 TiDB 的 DDL 操作中，只有 Add Index 操作需要去回填数据，耗时较长，其他的 DDL 操作正常情况下都可以在秒级别完成，所以经过这个拆分，可以保证大多数 DDL 操作能够不需要等待，直接执行。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Explain 和 Explain Analyze&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Explain 对于理解查询计划至关重要，2.1 之前的版本，TiDB 追随 MySQL 的 Explain 输出格式来展示查询计划。但是当 SQL 比较复杂时，MySQL 的格式并不利于展示算子之间的层级关系，不利于用户定位问题。&lt;/p&gt;&lt;p&gt;2.1 版本中，我们使用缩进来展示算子之间的层级关系，对每个算子的详细信息也做了优化，希望整个查询计划一目了然，帮助用户尽快定位问题。&lt;a href=&quot;https://www.pingcap.com/docs/sql/understanding-the-query-execution-plan/&quot;&gt;这篇文档&lt;/a&gt; 可以帮助用户了解 TiDB 的查询计划。&lt;/p&gt;&lt;p&gt;用户除了通过 Explain 语句查看查询计划之外，在 2.1 版本中还可以通过 Explain Analyze 语句查看语句的运行时信息，包括每个算子运行时的处理时间以及处理的数据量。这样可以通过实际的运行结果，拿到更加精确的信息。&lt;/p&gt;&lt;p&gt;&lt;b&gt;热点调度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;热点是分布式系统最大的敌人之一，并且用户的业务场景复杂多变，让热点问题捉摸不定，也是最狡猾的敌人。2.1 版本中，我们一方面增强热点检测能力，尽可能详细地统计系统负载，更快的发现热点；另一方面优化热点调度策略，用尽可能小的代价，尽快地打散热点。同时我们也提供了手动分裂 Region 的接口，让用户在特殊场景下将单点瓶颈手动分裂开，再由 PD 进行负载均衡。&lt;/p&gt;&lt;p&gt;&lt;b&gt;高效的 GC 机制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2.1 版本对 GC（垃圾回收） 模块进行优化。一方面减少对线上的写入的影响，另一方面加快了空间回收速度。在内部测试场景中，删除一个 1TB 的表，新的 GC 机制能够在 10 秒内回收 99% 左右的空间。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;更好的性能&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;OLTP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们针对 OLTP 场景中，点查占多数的特点进行了针对性的优化。当通过 Unique Key 或者 Primary Key 进行数据访问时，在优化器和执行引擎中都做了改进，使得语句的执行效率更高，通过 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/benchmark/sysbench-v3.md&quot;&gt;2.1 和 2.0 版本的 Sysbench 对比&lt;/a&gt; 可以看到，点查性能提升 50%。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-135377cc39aac37746c4852e8761f9a8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;937&quot; data-rawheight=&quot;579&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-135377cc39aac37746c4852e8761f9a8&quot; data-watermark-src=&quot;v2-15ef32935b3deb5c82daa52ef0bca23f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;OLAP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;发布 2.0 的时候，我们同时发布了在 TPC-H Scale 50 的场景中 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/benchmark/tpch.md&quot;&gt;2.0 和 1.0 的对比结果&lt;/a&gt;。其中大多数 Query 都有数量级的提升，部分 Query 在 1.0 中跑不出结果，在 2.0 中可以顺利运行。不过对于 Query17 和 Query18，运行时间依然很长。&lt;/p&gt;&lt;p&gt;我们在相同的场景下，对 2.1 和 2.0 进行了 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/benchmark/tpch-v2.md&quot;&gt;对比测试&lt;/a&gt;。从下图可以看到（纵坐标是 Query 的响应时间，越低越好），之前的两个慢 Query 的运行时间大幅缩短，其他的 Query 也有一定程度的提升。这些提升一方面得益于查询优化器以及执行引擎的改进，另一方面 得益于 TiKV 对连续数据扫描的性能优化。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61efde2ac32bc3c281332b498558a5d9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;581&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-61efde2ac32bc3c281332b498558a5d9&quot; data-watermark-src=&quot;v2-9dab87e5d7d6e756217b14e7c7db7918&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;完善的生态工具&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了让用户更方便的使用 TiDB，我们提供了三个工具：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs/tools/lightning/overview-architecture/&quot;&gt;TiDB Lightning&lt;/a&gt; 用于将全量数据导入到 TiDB 中，这个工具可以提升全量数据导入速度，目前内部测试场景中，一小时可以导入 100GB 数据。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs/tools/tidb-binlog-cluster/&quot;&gt;TiDB Binlog&lt;/a&gt; 用于将 TiDB 中的数据更新实时同步到下游系统中，可以用于做主从集群同步或者是将 TiDB 中的数据同步回 MySQL。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs/tools/data-migration-overview/&quot;&gt;TiDB DM&lt;/a&gt;（Data-Migration）用于将 MySQL/MariaDB 中的数据通过 Binlog 实时同步到 TiDB 集群中，并且提供 Binlog 数据转换功能，可以将 Binlog 中的表/库名称进行修改，或者是对数据内容本身做修改和裁剪。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上述三个工具可以将 TiDB 和周边的系统打通，既能将数据同步进 TiDB，又可以将数据同步出来。所以无论是迁移、回退还是做数据热备，都有完整的解决方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Open Source Community&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们相信战胜“未知”最好的武器就是社区的力量，基础软件需要坚定地走开源路线。为了让社区更深入的了解 TiDB 的技术细节并且更好地参与到项目中来，我们今年已经完成超过 20 篇源码阅读文章，项目的设计文档（&lt;a href=&quot;https://github.com/pingcap/tidb/wiki/Design-Documents&quot;&gt;TiDB&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/tikv/rfcs&quot;&gt;TiKV&lt;/a&gt;）已经在 GitHub 上面公开出来，项目的开发过程也尽量通过 GitHub Issue/Project 向社区展示。一些 Feature 设计方案的讨论也会通过在线视频会议的方式方便社区参与进来，&lt;a href=&quot;https://github.com/pingcap/community/blob/master/proposals.md&quot;&gt;这里&lt;/a&gt; 可以看到会议安排。&lt;/p&gt;&lt;p&gt;从 TiDB 2.0 版发布到现在的半年多时间，TiDB 开源社区新增了 87 位 Contributor，其中 &lt;a href=&quot;https://github.com/spongedu&quot;&gt;杜川&lt;/a&gt; 成为了 TiDB Committer，他已经贡献了 &lt;a href=&quot;https://github.com/pingcap/tidb/commits?author=spongedu&quot;&gt;76 次 PR&lt;/a&gt;，还有一些活跃的 Contributor 有希望成为下一批 Committer。&lt;/p&gt;&lt;p&gt;在这里我们对社区贡献者表示由衷的感谢，希望更多志同道合的人能加入进来，也希望大家在 TiDB 这个开源社区能够有所收获！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-01-51304475</guid>
<pubDate>Sat, 01 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>捕获和增强原生系统的可观测性来发现错误</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-23-50671185.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/50671185&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3c69c2bd32515795a24a4c954c0e428d_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘&lt;/p&gt;&lt;p&gt;在对 TiDB 进行 Chaos 实践的时候，我一直在思考如何更好的发现 TiDB 整个系统的故障。最开始，我们参考的就是 Chaos Engineering 里面的方式，观察系统的稳定状态，注入一个错误，然后看 metrics 上面有啥异常，这样等实际环境中出现类似的 metrics，我们就知道发现了什么故障。&lt;/p&gt;&lt;p&gt;但这套机制其实依赖于如何去注入错误，虽然现在我们已经有了很多种错误注入的方式，但总有一些实际的情况我们没有料到。所以后来我们又考虑了另外的一种方式，也就是直接对 metrics 历史进行学习，如果某一段时间 metrics 出现了不正常的波动，那么我们就能报警。但这个对我们现阶段来说难度还是有点大，只使用了几种策略，对 QPS，Latency 这些进行了学习，并不能很好的定位到具体出了什么样的问题。&lt;/p&gt;&lt;p&gt;所以我一直在思考如何更好的去发现系统的故障。最近，刚好看到了OSDI 2018 一篇 Paper， &lt;a href=&quot;https://www.usenix.org/system/files/osdi18-huang.pdf&quot;&gt;Capturing and Enhancing In Situ System Observability for Failure Detection&lt;/a&gt;，眼睛一亮，觉得这种方式也是可以来实践的。&lt;/p&gt;&lt;p&gt;大家都知道，在生产环境中，故障是无处不在，随时可能发生的，譬如硬件问题，软件自身的 bug，或者运维使用了一个错误的配置这些。虽然多数时候，我们的系统都做了容错保护，但我们还是需要能尽快的发现故障，才好进行故障转移。&lt;/p&gt;&lt;p&gt;但现实世界并没有那么美好，很多时候，故障并不是很明显的，譬如整个进程挂掉，机器坏掉这些，它们处于一种时好时坏的状态，我们通常称为『Gray Failure』，譬如磁盘变慢了，网络时不时丢包。这些故障都非常隐蔽，很难被发现。如果单纯的依赖外部的工具，其实很难检测出来。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b3291c8c8e60ecbc9c96aad2b353d60_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1090&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8b3291c8c8e60ecbc9c96aad2b353d60&quot; data-watermark-src=&quot;v2-068dd0bd73f4851f887d506a77a0019e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上面是作者举得一个 Zookeeper 的例子，client 已经完全不能跟 Leader 进行交互了，但是 Leader 却仍然能够给 Follower 发送心跳，同时也能响应外面 Monitor 发过来的探活命令。&lt;br&gt; 如果从外面的 Monitor 看来，这个 Zookeeper 集群还是正常的，但其实它已经有故障了。而这个故障其实 client 是知道的，所以故障检测的原理很简单，从发起请求的这一端来观察，如果发现有问题，那就是有故障了。而这也是这篇论文的中心思想。&lt;/p&gt;&lt;p&gt;在论文里面，作者认为，任何严重的 Gray Failure 都是能够被观察到的，如果发起请求的这边遇到了错误，自然下一件事情就是将这个错误给汇报出去，这样我们就知道某个地方出现了故障。于是作者开发了 &lt;a href=&quot;https://github.com/ryanphuang/panorama&quot;&gt;Panorama&lt;/a&gt; 这套系统，来对故障进行检测。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;整体架构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;先来说说 Panorama 一些专业术语。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4f53fe8c77b8a65ddfcfd80caca665fa_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;634&quot; data-rawheight=&quot;329&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4f53fe8c77b8a65ddfcfd80caca665fa&quot; data-watermark-src=&quot;v2-87ba341924b4bfd8985d1e250208885b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Panorama 整体结构如下：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-be3c0f34afb5db8ec6b663f3c9994e06_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1148&quot; data-rawheight=&quot;696&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-be3c0f34afb5db8ec6b663f3c9994e06&quot; data-watermark-src=&quot;v2-7f7ad761ff2cc070637b9ded88f1bc04&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Panorama 通过一些方式，譬如静态分析代码进行代码注入等，将 Observer 跟要观察的 Subject 进行绑定，Observer 会将 Subject 的一些信息记录并且汇报给本地的一个 Local Observation Store（LOS）。本地一个决策引擎就会分析 LOS 里面的数据来判断这个组件的状态。如果多个 LOS 里面都有对某个 Subject 的 observation，那么 LOS 会相互交换，用来让中央的 verdict 更好的去判断这个 component 的状态。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;故障判定&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;而用来判断一个 component 是不是有故障也比较容易，采用的是一种大多数 bounded-look-back 算法。对于一个 subject，它可能会有很多 observations，首先我们会对这些 observations 按照 observer 进行分组，对每组单独进行分析。在每个组里面，Observations 会按照时间从后往前检查，并且按照 context 进行聚合。如果一个被观察的 observation 的 status 跟记录前面相同 context 的 observation status 状态不一样，就继续 loop-back，直到遇到一个新的 status。对于一个 context，如果最后的状态是 unhealthy 或者 healthy 的状态没有达到多数，就会被认为是 unhealthy 的。&lt;/p&gt;&lt;p&gt;通过这种方式，我们在每组里面得到了每个 context 的状态，然后又会在多个组里面进行决策，也就是最常用的大多数原则，哪个状态最多，那么这个 context 对应的状态就是哪一个。这里我们需要额外处理下 PENDING 这个状态，如果当前状态是 HEALTHY 而之前老的状态是 PENDING，那么 PENDING 就会变成 HEALTHY，而如果一直是 PENDING 状态并超过了某个阈值，就会退化成 UNHEALTHY。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Observability&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这里再来说说 Observability 的模式。对于分布式系统来说，不同 component 之间的交互并不是同步的，我们会面临如下几种情况：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fb41105f1ecc32a94800ea06a1c8aa53_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;992&quot; data-rawheight=&quot;282&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fb41105f1ecc32a94800ea06a1c8aa53&quot; data-watermark-src=&quot;v2-e471aea1424c2115bf962e335f755348&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如果两个组件 C1 和 C2 是同步交互，那么当 C1 给 C2 发送请求，我们就完全能在 C1 这一端知道这次请求成功还是失败了，但是对于非同步的情况，我们可能面临一个问题，就是 C1 给 C2 发了请求，但其实这个请求是放到了异步消息队列里面，但 C1 觉得是成功了，可是后面的异步队列却失败了。所以 Panorama 需要有机制能正确处理上面多种情况。&lt;/p&gt;&lt;p&gt;为了能更好的从 component 上面得到有用的 observations，Panorama 会用一个离线工具对代码进行静态分析，发现一些关键的地方，注入钩子，这样就能去汇报 observations 了。&lt;/p&gt;&lt;p&gt;通常运行时错误是非常有用能证明有故障的证据，但是，并不是所有的错误都需要汇报，Panorama 仅仅会关系跨 component 边界产生的错误，因为这也是通过发起请求端能观察到的。Panorama 对于这种跨域的函数调用称为 observation boundaries。对于 Panorama 来说，第一件事情就是定位 observation boundaries。通常有两种 boundaries，进程间交互和线程间交互。进程间交互通常就是 socket I/O，RPC，而线程间则是在一个进程里面跨越线程的调用。这些 Panorama 都需要分析出来。&lt;/p&gt;&lt;p&gt;当定位了 observation boundaries 之后，下一件事情就是确定 observer 和 subject 的标识。譬如对于进程间交互的 boundaries，observer 的标识就可能是这个进程在系统里面的唯一标识，而对于 subject，我们可以用 method 名字，或者是函数的一个参数，类里面的一个字段来标识。&lt;/p&gt;&lt;p&gt;然后我们需要去确定 observation points，也就是观测点。通常这些点就是代码处理异常的地方，另外可能就是一些正常处理返回结果但会对外报错的地方。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3155f69432096b54c29da20ebf74c276_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;720&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3155f69432096b54c29da20ebf74c276&quot; data-watermark-src=&quot;v2-9a7ca500a7eef87bb3f07c69caf9e79f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上面就是一个简单分析代码得到 observation points 的例子，但这个仍然是同步的，对于 indirection 的，还需要额外处理。&lt;/p&gt;&lt;p&gt;对于异步请求，我们知道，通过发出去之后，会异步的处理结果，所以这里分为了两步，叫做 ob-origin 和 ob-sink。如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-60616ccca52710a6a69b13c602821e09_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;746&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-60616ccca52710a6a69b13c602821e09&quot; data-watermark-src=&quot;v2-225b009ea1fc63f50a6b03ca46844f98&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 ob-origin，代码分析的时候会先给这个 observation 设置成 PENDING 状态，只有对应的 ob-sink 调用并且返回了正确的结果，才会设置成 HEALTHY。因为 ob-origin 和 ob-sink 是异步的，所以代码分析的时候会加上一个特殊的字段，包含 subject 的标识和 context，这样就能让 ob-origin 和 ob-sink 对应起来。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面大概介绍了 Panorama 的架构以及一些关键的知识点是如何实现的，简单来说，就是在一些关键代码路径上面注入 hook，然后通过 hook 对外将相关的状态给汇报出去，在外面会有其他的分析程序对拿到的数据进行分析从而判定系统是否在正常工作。它其实跟加 metrics 很像，但 metrics 只能看出哪里出现了问题，对于想更细致定位具体的某一个问题以及它的上下文环境，倒不是特别的方便。这点来说 Panorama 的价值还是挺大的。&lt;/p&gt;&lt;p&gt;Panorama 的代码已经开源，总的来说还是挺简单的，但我没找到核心的代码分析，注入 hook 这些，有点遗憾。但理解了大概原理，其实先强制在代码写死也未尝不可。另一个比较可行的办法就是进行在代码里面把日志添加详细，这样就不用代码注入了，而是在外面写一个程序来分析日志，其实 Panorama 代码里面提供了日志分析的功能，为 Zookeeper 来设计的，但作者自己也说到，分析日志的效果比不上直接在代码里面进行注入。&lt;/p&gt;&lt;p&gt;那对我们来说，有啥可以参考的呢？首先当然是这一套故障检查的理念，既然 Panorama 已经做出来并且能发现故障量，自然我们也可以在 TiDB 里面实施。因为我们已经有在 Go 和 Rust 代码里面使用 fail 来进行错误注入的经验，所以早起手写监控代码也未尝不可，但也可以直接完善日志，提供一个程序来分析日志就成。如果你对这块感兴趣，想把 Panorama 相关的东西应用到 TiDB 中来，欢迎联系我 &lt;a href=&quot;mailto:tl@pingcap.com&quot;&gt;tl@pingcap.com&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://www.jianshu.com/p/de53ff95d697&quot;&gt;捕获和增强原生系统的可观测性来发现错误&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-23-50671185</guid>
<pubDate>Fri, 23 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>拿奖秘诀泄露，TiDB Hackathon 等你来挑战！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-16-50103243.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/50103243&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-507a9d1aeff2b774624b5be2cf38c312_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;i&gt;TiDB Hackathon 2018 开启报名已有半月有余，作为本场 Hackathon &lt;b&gt;唯一的“小可爱”——我，TiDB Robot&lt;/b&gt;，这段时间受到了小伙伴们的问题轰炸，包括但不限于怎么组队选题、怎么和队友合作、住哪儿、吃啥……还有求划重点拿大奖的。所以今天我总结了一些常见 QA，&lt;b&gt;分为报名篇 / 选题篇 / 实操篇 / 吃住篇&lt;/b&gt;，顺便也划了一下重点，希望对大家有所帮助～&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;报名篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：对参赛者本身有什么门槛吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：没有门槛，不限年龄，不限职业，唯一的要求是&lt;b&gt;来现场参赛（北京）&lt;/b&gt;。Hackathon 注重现场的团队配合和竞技氛围，不接受线上参与哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：如何组建一支“梦之队”？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：Hackathon 精髓之一是团队协作，&lt;b&gt;队员配合和角色分配&lt;/b&gt;很重要。谁来选题谁来设计，是否需要前端等等都是组队时要考虑的因素。还有一个容易被忽视的重要角色是&lt;b&gt;演讲人&lt;/b&gt;，两天一夜的比赛最后的决定性时刻就在展示的几分钟，如何条理清晰的把做的东西讲清楚，以及这个项目解决了什么实质性的问题很关键。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：一个人也可以成队报名吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：当然可以，我们非常欢迎技能值满点的小伙伴以个人身份参赛（传说中的“一个人活成一支队伍”），也欢迎暂时没有选题或队友的个人参赛者报名，主办方会协调大家进行赛前组队。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;选题篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：对选题毫无思路怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：本场 Hackathon 主题为 &lt;b&gt;TiDB Ecosystem。&lt;/b&gt;如果想参赛但不知从何入手，可以&lt;b&gt;勾搭我（微信号：tidbai）&lt;/b&gt;获取我们的选题参考方向哦～希望大家可以举一反三，think out of the box，做出令人眼前一亮的作品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：已有选题的队伍可以提前写代码了吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：&lt;b&gt;不可以&lt;/b&gt;。为了公平起见，参赛作品的所有代码必须在 Hackathon 现场完成，前期准备仅限于资料搜集、架构设计、环境配置与测试。我们不就是为了在有限的时间里做最有挑战的事情，对吗？&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0f0b9fbaf639866ad88b6d5e46c00085_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;370&quot; data-rawheight=&quot;366&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0f0b9fbaf639866ad88b6d5e46c00085&quot; data-watermark-src=&quot;v2-ba2d9f4a5a6f5e5243169f6ed2a2148f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;实操篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：当天如何与队友合作呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：指定团队协作平台—— &lt;b&gt;GitHub&lt;/b&gt;。GitHub 上的提交记录，也方便于评审团审核参赛作品的完整度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：还不会使用 GitHub 怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：五分钟学会使用 GitHub——&lt;/p&gt;&lt;p&gt;    - What is GitHub：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=w3jLJU7DT5E&quot;&gt;https://www.youtube.com/watch?v=w3jLJU7DT5E&lt;/a&gt;&lt;/p&gt;&lt;p&gt;    - GitHub Tutorial For Beginners：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0fKg7e37bQE&quot;&gt;https://www.youtube.com/watch?v=0fKg7e37bQE&lt;/a&gt;&lt;/p&gt;&lt;p&gt;    - 知乎 GitHub 话题助攻&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/20070065&quot;&gt;https://www.zhihu.com/question/20070065&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：TiDB 的代码对于新手来说好复杂啊，哪里可以找到更多的参考资料？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：&lt;b&gt;官方文档&lt;/b&gt;（github.com/pingcap/docs-cn）中有详细的安装部署及运用指导，另外，&lt;b&gt;官方微信公众号&lt;/b&gt;中有宝藏哦。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;推荐阅读：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27275483&quot;&gt;三篇文章了解 TiDB 技术内幕系列&lt;/a&gt;&lt;/u&gt; |   &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46524530&quot;&gt;TiKV 是如何存储数据的&lt;/a&gt;&lt;/u&gt;  | &lt;u&gt;&lt;a href=&quot;https://pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;我们定期举办的 Infra Meetup 常常有 TiDB 相关议题，大家可以在微信公众号（ID: pingcap2015）菜单栏“社区活动-&amp;gt;往期 Meetup”中翻阅视频&amp;amp;文字回顾。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外悄悄的说，我们&lt;b&gt;官网&lt;/b&gt;的搜索很强大，大家可以搜索关键词找到相关资料。除此之外，也可以求助导师团（&lt;a href=&quot;https://mp.weixin.qq.com/s/C5FbZ7HEG3Sr6l_oqCxNng&quot;&gt;七龙珠导师团介绍在此，大家现场“照图抓人”即可&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：如何更好的展示成果？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：Hackathon 不仅是一场代码技术的比拼，临场发挥和演讲技巧也很重要，最后需要在短短几分钟内让大家明白你做了什么以及这个项目的价值。&lt;/p&gt;&lt;p&gt;我们见过花了大量时间介绍项目背景而正题只进行到一半就草草结束的团队，也见过测试时完美运行的项目在演示时却频频报错、选手满头大汗的场景。所以我们建议：&lt;b&gt;演讲时逻辑清晰，开门见山，在有限的时间里阐述项目的重点，并预留出一部分时间进行程序演示，&lt;/b&gt;而现场跑 demo 是一门&lt;b&gt;玄学&lt;/b&gt;，如果不想冒险可以预先录制一个 Demo 视频。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：奖金好诱人，好想拿奖！求划重点！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：和有趣的人一起做有趣的事很重要，顺便拿个大奖当然就更好啦～本次比赛的评判标准是实用性、完成度和创新性。&lt;b&gt;其中，权重最大的是实用性，我们希望 Hackathon 中产出的项目可以长久的在社区运行下去，因此解决实际问题和提高效率是比较重要的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;吃住篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：主办方提供餐饮和住宿吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：我们提供参赛者和志愿者比赛期间的餐饮（正餐包括 12 月 1 日午餐、晚餐，12 月 2 日早餐、午餐），参赛选手可留在比赛场地过夜，如需在场地附近租住宾馆需要自己解决哟～&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：比赛两天都需要呆在活动场地吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：如果没有特殊需求请不要离开场地，需要回自己住处过夜的小伙伴需要提前告知工作人员，并于第二天早晨 8 点前返回场地。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;最后也是最最重要的建议：&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;合理规划项目时间，选定主题之后不要轻易改动，要有团队精神，&lt;b&gt;不能轻易抛弃队友。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;一定、一定要&lt;b&gt;慎用 rm-rf/ &lt;/b&gt; （这是往年 Hackathon 真实发生过的“惨案”……）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;赛程重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;奖项设置&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;一等奖（1 支队伍）：¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;除此之外还设有最佳创意奖和最佳贡献奖。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名时间&lt;/b&gt;：即日起至 11 月 23 日 17:00&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名审核&lt;/b&gt;：5 个工作日内反馈审核结果&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名链接&lt;/b&gt;：点击【&lt;a href=&quot;http://nc9hsk15y2xczuor.mikecrm.com/3AarNns&quot;&gt;这里&lt;/a&gt;】报名&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-16-50103243</guid>
<pubDate>Fri, 16 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在美团点评的深度实践之旅</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-14-49826990.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49826990&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ef8c60fcae0adc633941847ade639a5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;一. 背景和现状&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在美团，基于 MySQL 构建的传统关系型数据库服务已经难于支撑公司业务的爆发式增长，促使我们去探索更合理的数据存储方案和实践新的运维方式。随着近一两年来分布式数据库大放异彩，美团 DBA 团队联合架构存储团队，于 2018 年初启动了分布式数据库项目。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0420b47ac623a455b3f47c455151dd80_r.jpg&quot; data-caption=&quot;图 1 美团点评产品展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;733&quot; data-rawheight=&quot;481&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0420b47ac623a455b3f47c455151dd80&quot; data-watermark-src=&quot;v2-7d98566cf142d5882069e5f7d874d85c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;立项之初，我们进行了大量解决方案的对比，深入了解了业界多种 scale-out、scale-up 方案，考虑到技术架构的前瞻性、发展潜力、社区活跃度、以及服务本身与 MySQL 的兼容性，最终敲定了基于 TiDB 数据库进行二次开发的整体方案，并与 PingCAP 官方和开源社区进行深入合作的开发模式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;美团业务线众多，我们根据业务特点及重要程度逐步推进上线，到截稿为止，已经上线 10 个集群，近 200 个物理节点，大部分是 OLTP 类型的应用，除了上线初期遇到了一些小问题，目前均已稳定运行。初期上线的集群，已经分别服务于配送、出行、闪付、酒旅等业务。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 架构分层清晰，服务平稳流畅，但在美团当前的数据量规模和已有稳定的存储体系的基础上，推广新的存储服务体系，需要对周边工具和系统进行一系列改造和适配，从初期探索到整合落地需要走很远的路。下面从几个方面分别介绍：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一是从 0 到 1 的突破，重点考虑做哪些事情；&lt;/li&gt;&lt;li&gt;二是如何规划实施不同业务场景的接入和已有业务的迁移；&lt;/li&gt;&lt;li&gt;三是上线后遇到的一些典型问题介绍；&lt;/li&gt;&lt;li&gt;四是后续规划和对未来的展望。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;二. 前期调研测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1  对 TiDB 的定位&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们对于 TiDB 的定位，前期在于重点解决 MySQL 的单机性能和容量无法线性和灵活扩展的问题，与 MySQL 形成互补。业界分布式方案很多，我们为何选择了 TiDB 呢？考虑到公司业务规模的快速增长，以及公司内关系数据库以 MySQL 为主的现状，因此我们在调研阶段，对以下技术特性进行了重点考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;协议兼容 MySQL&lt;/b&gt;：这个是必要项。&lt;/li&gt;&lt;li&gt;&lt;b&gt;可在线扩展&lt;/b&gt;：数据通常要有分片，分片要支持分裂和自动迁移，并且迁移过程要尽量对业务无感知。&lt;/li&gt;&lt;li&gt;&lt;b&gt;强一致的分布式事务&lt;/b&gt;：事务可以跨分片、跨节点执行，并且强一致。&lt;/li&gt;&lt;li&gt;&lt;b&gt;支持二级索引&lt;/b&gt;：为兼容 MySQL 的业务，这个是必须的。&lt;/li&gt;&lt;li&gt;&lt;b&gt;性能&lt;/b&gt;：MySQL 的业务特性，高并发的 OLTP 性能必须满足。&lt;/li&gt;&lt;li&gt;&lt;b&gt;跨机房服务&lt;/b&gt;：需要保证任何一个机房宕机，服务能自动切换。&lt;/li&gt;&lt;li&gt;&lt;b&gt;跨机房双写&lt;/b&gt;：支持跨机房双写是数据库领域一大难题，是我们对分布式数据库的一个重要期待，也是美团下一阶段重要的需求。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;业界的一些传统方案虽然支持分片，但无法自动分裂、迁移，不支持分布式事务，还有一些在传统 MySQL 上开发一致性协议的方案，但它无法实现线性扩展，最终我们选择了与我们的需求最为接近的 TiDB。与 MySQL 语法和特性高度兼容，具有灵活的在线扩容缩容特性，支持 ACID 的强一致性事务，可以跨机房部署实现跨机房容灾，支持多节点写入，对业务又能像单机 MySQL 一样使用。&lt;br&gt;&lt;br&gt;&lt;b&gt;2.2  测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对官方声称的以上优点，我们进行了大量的研究、测试和验证。&lt;/p&gt;&lt;p&gt;首先，我们需要知道扩容、Region 分裂转移的细节、Schema 到 kv 的映射、分布式事务的实现原理。而 TiDB 的方案，参考了较多的 Google 论文，我们进行了阅读，这有助于我们理解 TiDB 的存储结构、事务算法、安全性等，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Spanner: Google’s Globally-Distributed Database&lt;/li&gt;&lt;li&gt;Large-scale Incremental Processing Using Distributed Transactions and Notifications&lt;/li&gt;&lt;li&gt;In Search of an Understandable Consensus Algorithm&lt;/li&gt;&lt;li&gt;Online, Asynchronous Schema Change in F1&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们也进行了常规的性能和功能测试，用来与 MySQL 的指标进行对比，其中一个比较特别的测试，是证明 3 副本跨机房部署，确实能保证每个机房分布一个副本，从而保证任何一个机房宕机不会导致丢失超过半数副本。&lt;/b&gt;从以下几个点进行测试：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Raft 扩容时是否支持 learner 节点，从而保证单机房宕机不会丢失 2/3 的副本。&lt;/li&gt;&lt;li&gt;TiKV 上的标签优先级是否可靠，保证当机房的机器不平均时，能否保证每个机房的副本数依然是绝对平均的。&lt;/li&gt;&lt;li&gt;实际测试，单机房宕机，TiDB 在高并发下，QPS、响应时间、报错数量，以及最终数据是否有丢失。&lt;/li&gt;&lt;li&gt;手动 Balance 一个 Region 到其他机房，是否会自动回来。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从测试结果来看，一切都符合预期。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三. 存储生态建设&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;美团的产品线丰富，业务体量大，业务对在线存储的服务质量要求也非常高。因此，从早期做好服务体系的规划非常重要。下面从业务接入层、监控报警、服务部署，来分别介绍一下我们所做的工作。&lt;br&gt;&lt;br&gt;&lt;b&gt;3.1  业务接入层&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当前 MySQL 的业务接入方式主要有两种，DNS 接入和 Zebra 客户端接入。在前期调研阶段，我们选择了 DNS + 负载均衡组件的接入方式，TiDB-Server 节点宕机，15s 可以被负载均衡识别到，简单有效。业务架构如图 2：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fd9faed3064e8efeb78f8224f74bdfb3_r.jpg&quot; data-caption=&quot;图 2 业务架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;347&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fd9faed3064e8efeb78f8224f74bdfb3&quot; data-watermark-src=&quot;v2-9270cf0e10e6e142bd0dea62eb54aa26&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;后面我们会逐渐过渡到当前大量使用的 Zebra 接入方式来访问 TiDB，从而保持与访问 MySQL 的方式一致，一方面减少业务改造的成本，另一方面尽量实现从 MySQL 到 TiDB 的透明迁移。&lt;br&gt;&lt;b&gt;3.2  监控报警&lt;/b&gt;&lt;/p&gt;&lt;p&gt;美团目前使用 Mt-Falcon 平台负责监控报警，通过在 Mt-Falcon 上配置不同的插件，可以实现对多种组件的自定义监控。另外也会结合 Puppet 识别不同用户的权限、文件的下发。这样，只要我们编写好插件脚本、需要的文件，装机和权限控制就可以完成了。监控架构如图 3：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d329d5862cd00f9d6f10e0ecf7b9073c_r.jpg&quot; data-caption=&quot;图 3 监控架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;804&quot; data-rawheight=&quot;483&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d329d5862cd00f9d6f10e0ecf7b9073c&quot; data-watermark-src=&quot;v2-f7fb49c3f75488a38be205b05835e2ae&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;而 TiDB 有丰富的监控指标，使用流行的 Prometheus + Grafana，一套集群有 700+ 的 Metric。从官方的架构图可以看出，每个组件会推送自己的 Metric 给 PushGateWay，Prometheus 会直接到 PushGateWay 去抓数据。&lt;/p&gt;&lt;p&gt;由于我们需要组件收敛，原生的 TiDB 每个集群一套 Prometheus 的方式不利于监控的汇总、分析、配置，而报警已经在 Mt-Falcon 上实现的比较好了，在 AlertManager 上再造一个也没有必要。因此我们需要想办法把监控和报警汇总到 Mt-Falcon 上面，有如下几种方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;方案一：修改源代码，将 Metric 直接推送到 Falcon，由于 Metric 散落在代码的不同位置，而且 TiDB 代码迭代太快，把精力消耗在不停调整监控埋点上不太合适。&lt;/li&gt;&lt;li&gt;方案二：在 PushGateWay 是汇总后的，可以直接抓取，但 PushGateWay 是个单点，不好维护。&lt;/li&gt;&lt;li&gt;方案三：通过各个组件（TiDB、PD、TiKV）的本地 API 直接抓取，优点是组件宕机不会影响其他组件，实现也比较简单。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们最终选择了方案三。该方案的难点是需要把 Prometheus 的数据格式转化为 Mt-Falcon 可识别的格式，因为 Prometheus 支持 Counter、Gauge、Histogram、Summary 四种数据类型，而 Mt-Falcon 只支持基本的 Counter 和 Gauge，同时 Mt-Falcon 的计算表达式比较少，因此需要在监控脚本中进行转换和计算。&lt;br&gt;&lt;br&gt;&lt;b&gt;3.3  批量部署&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 使用 Ansible 实现自动化部署。迭代快，是 TiDB 的一个特点，有问题快速解决，但也造成 Ansible 工程、TiDB 版本更新过快，我们对 Ansible 的改动，也只会增加新的代码，不会改动已有的代码。因此线上可能同时需要部署、维护多个版本的集群。如果每个集群一个 Ansible 目录，造成空间的浪费。我们采用的维护方式是，在中控机中，每个版本一个 Ansible 目录，每个版本中通过不同 inventory 文件来维护。这里需要跟 PingCAP 提出的是，Ansible 只考虑了单集群部署，大量部署会有些麻烦，像一些依赖的配置文件，都不能根据集群单独配置（咨询官方得知，PingCAP 目前正在基于 Cloud TiDB 打造一站式 HTAP 平台，会提供批量部署、多租户等功能，能比较好的解决这个问题）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.4  自动化运维平台&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着线上集群数量的增加，打造运维平台提上了日程，而美团对 TiDB 和 MySQL 的使用方式基本相同，因此 MySQL 平台上具有的大部分组件，TiDB 平台也需要建设。典型的底层组件和方案：SQL 审核模块、DTS、数据备份方案等。自动化运维平台展示如图 4：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb534e712cfff40c4dd8a4d086bb851e_r.jpg&quot; data-caption=&quot;图 4 自动化运维平台展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;531&quot; data-rawheight=&quot;481&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bb534e712cfff40c4dd8a4d086bb851e&quot; data-watermark-src=&quot;v2-1d7fc5cce8af85f15bcd16c544b8f7cb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;3.5  上下游异构数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是在线存储体系中的一环，它同时也需要融入到公司现有的数据流中，因此需要一些工具来做衔接。PingCAP 官方标配了相关的组件。&lt;/p&gt;&lt;p&gt;公司目前 MySQL 和 Hive 结合的比较重，而 TiDB 要代替 MySQL 的部分功能，需要解决 2 个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;MySQL to TiDB&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MySQL 到 TiDB 的迁移，需要解决数据迁移以及增量的实时同步，也就是 DTS，Mydumper + Loader 解决存量数据的同步，官方提供了 DM 工具可以很好的解决增量同步问题。&lt;/li&gt;&lt;li&gt;MySQL 大量使用了自增 ID 作为主键。分库分表 MySQL 合并到 TiDB 时，需要解决自增 ID 冲突的问题。这个通过在 TiDB 端去掉自增 ID 建立自己的唯一主键来解决。新版 DM 也提供分表合并过程主键自动处理的功能。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Hive to TiDB &amp;amp; TiDB to Hive&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Hive to TiDB 比较好解决，这体现了 TiDB 和 MySQL 高度兼容的好处，insert 语句可以不用调整，基于 Hive to MySQL 简单改造即可。&lt;/li&gt;&lt;li&gt;TiDB to Hive 则需要基于官方 Pump + Drainer 组件，Drainer 可以消费到 Kafka、MySQL、TiDB，我们初步考虑用下图 5 中的方案通过使用 Drainer 的 Kafka 输出模式同步到 Hive。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-027ddcdac6f9751c3ba280bcbe0d41bb_r.jpg&quot; data-caption=&quot;图 5 TiDB to Hive 方案图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;831&quot; data-rawheight=&quot;302&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-027ddcdac6f9751c3ba280bcbe0d41bb&quot; data-watermark-src=&quot;v2-da5d862f10832ca37b1ba23f151d34d8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;四. 线上使用磨合&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于初期上线的业务，我们比较谨慎，基本的原则是：离线业务 -&amp;gt; 非核心业务 -&amp;gt; 核心业务。TiDB 已经发布两年多，且前期经历了大量的测试，我们也深入了解了其它公司的测试和使用情况，可以预期的是 TiDB 上线会比较稳定，但依然遇到了一些小问题。总体来看，在安全性、数据一致性等关键点上没有出现问题。其他一些性能抖动问题，参数调优的问题，也都得到了快速妥善的解决。这里给 PingCAP 的同学点个大大的赞，问题响应速度非常快，与我们内部研发的合作也非常融洽。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1  写入量大、读 QPS 高的离线业务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们上线的最大的一个业务，每天有数百 G 的写入量，前期遇到了较多的问题，我们重点说说。&lt;br&gt;&lt;br&gt;业务场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定的写入，每个事务操作 100~200 行不等，每秒 6w 的数据写入。&lt;/li&gt;&lt;li&gt;每天的写入量超过 500G，以后会逐步提量到每天 3T。&lt;/li&gt;&lt;li&gt;每 15 分钟的定时读 job，5000 QPS（高频量小）。&lt;/li&gt;&lt;li&gt;不定时的查询（低频量大）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;之前使用 MySQL 作为存储，但 MySQL 到达了容量和性能瓶颈，而业务的容量未来会 10 倍的增长。初期调研测试了 ClickHouse，满足了容量的需求，测试发现运行低频 SQL 没有问题，但高频 SQL 的大并发查询无法满足需求，只在 ClickHouse 跑全量的低频 SQL 又会 overkill，最终选择使用 TiDB。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试期间模拟写入了一天的真实数据，非常稳定，高频低频两种查询也都满足需求，定向优化后 OLAP 的 SQL 比 MySQL 性能提高四倍。&lt;/b&gt;但上线后，陆续发现了一些问题，典型的如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.1  TiKV 发生 Write Stall&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 底层有 2 个 RocksDB 作为存储。新写的数据写入 L0 层，当 RocksDB 的 L0 层数量达到一定数量，就会发生减速，更高则发生 Stall，用来自我保护。TiKV 的默认配置：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;level0-slowdown-writes-trigger = 20&lt;/li&gt;&lt;li&gt;level0-stop-writes-trigger = 36&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;遇到过的，发生 L0 文件过多可能的原因有 2 个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;写入量大，Compact 完不成。&lt;/li&gt;&lt;li&gt;Snapshot 一直创建不完，导致堆积的副本一下释放，rocksdb-raft 创建大量的 L0 文件，监控展示如图 6：&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e69159a837553ece67165e5f1d535130_r.jpg&quot; data-caption=&quot;图 6 TiKV 发生 Write Stall 监控展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;404&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e69159a837553ece67165e5f1d535130&quot; data-watermark-src=&quot;v2-256e0db1ec5838242fc538eed4517cd7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们通过以下措施，解决了 Write Stall 的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;减缓 Raft Log Compact 频率（增大 raft-log-gc-size-limit、raft-log-gc-count-limit）&lt;/li&gt;&lt;li&gt;加快 Snapshot 速度（整体性能、包括硬件性能）&lt;/li&gt;&lt;li&gt;max-sub-compactions 调整为 3&lt;/li&gt;&lt;li&gt;max-background-jobs 调整为 12&lt;/li&gt;&lt;li&gt;level 0 的 3 个 Trigger 调整为 16、32、64&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.2  Delete 大量数据，GC 跟不上&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在 TiDB 的 GC 对于每个 kv-instance 是单线程的，当业务删除数据的量非常大时，会导致 GC 速度较慢，很可能 GC 的速度跟不上写入。&lt;br&gt;目前可以通过增多 TiKV 个数来解决，长期需要靠 GC 改为多线程执行，官方对此已经实现，即将发布。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.3  Insert 响应时间越来越慢&lt;/b&gt;&lt;/p&gt;&lt;p&gt;业务上线初期，insert 的响应时间 80 线（Duration 80 By Instance）在 20ms 左右，随着运行时间增加，发现响应时间逐步增加到 200ms+。期间排查了多种可能原因，定位在由于 Region 数量快速上涨，Raftstore 里面要做的事情变多了，而它又是单线程工作，每个 Region 定期都要 heartbeat，带来了性能消耗。tikv-raft propose wait duration 指标持续增长。&lt;br&gt;解决问题的办法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;临时解决&lt;/li&gt;&lt;ul&gt;&lt;li&gt;增加 Heartbeat 的周期，从 1s 改为 2s，效果比较明显，监控展示如图 7：&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2751cc531372bb7229c9e6c080242f36_r.jpg&quot; data-caption=&quot;图 7 insert 响应时间优化前后对比图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;208&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2751cc531372bb7229c9e6c080242f36&quot; data-watermark-src=&quot;v2-d2b25490744c113349c30b801b486786&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;彻底解决&lt;/li&gt;&lt;ul&gt;&lt;li&gt;需要减少 Region 个数，Merge 掉空 Region，官方在 2.1 版本中已经实现了 Region Merge 功能，我们在升级到 2.1 后，得到了彻底解决。&lt;/li&gt;&lt;li&gt;另外，等待 Raftstore 改为多线程，能进一步优化。（官方回复相关开发已基本接近尾声，将于 2.1 的下一个版本发布。）&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.4  Truncate Table 空间无法完全回收&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DBA Truncate 一张大表后，发现 2 个现象，一是空间回收较慢，二是最终也没有完全回收。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;由于底层 RocksDB 的机制，很多数据落在 level 6 上，有可能清不掉。这个需要打开 cdynamic-level-bytes 会优化 Compaction 的策略，提高 Compact 回收空间的速度。&lt;/li&gt;&lt;li&gt;由于 Truncate 使用 delete_files_in_range 接口，发给 TiKV 去删 SST 文件，这里只删除不相交的部分，而之前判断是否相交的粒度是 Region，因此导致了大量 SST 无法及时删除掉。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;考虑 Region 独立 SST 可以解决交叉问题，但是随之带来的是磁盘占用问题和 Split 延时问题。&lt;/li&gt;&lt;li&gt;考虑使用 RocksDB 的 DeleteRange 接口，但需要等该接口稳定。&lt;/li&gt;&lt;li&gt;目前最新的 2.1 版本优化为直接使用 DeleteFilesInRange 接口删除整个表占用的空间，然后清理少量残留数据，已经解决。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.5  开启 Region Merge 功能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了解决 region 过多的问题，我们在升级 2.1 版本后，开启了 region merge 功能，但是 TiDB 的响应时间 80 线（Duration 80 By Instance）依然没有恢复到当初，保持在 50ms 左右，排查发现 KV 层返回的响应时间还很快，和最初接近，那么就定位了问题出现在 TiDB 层。研发人员和 PingCAP 定位在产生执行计划时行为和 2.0 版本不一致了，&lt;b&gt;目前已经优化。&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;4.2  在线 OLTP，对响应时间敏感的业务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了分析查询量大的离线业务场景，美团还有很多分库分表的场景，虽然业界有很多分库分表的方案，解决了单机性能、存储瓶颈，但是对于业务还是有些不友好的地方：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;业务无法友好的执行分布式事务。&lt;/li&gt;&lt;li&gt;跨库的查询，需要在中间层上组合，是比较重的方案。&lt;/li&gt;&lt;li&gt;单库如果容量不足，需要再次拆分，无论怎样做，都很痛苦。&lt;/li&gt;&lt;li&gt;业务需要关注数据分布的规则，即使用了中间层，业务心里还是没底。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此很多分库分表的业务，以及即将无法在单机承载而正在设计分库分表方案的业务，主动找到了我们，这和我们对于 TiDB 的定位是相符的。这些业务的特点是 SQL 语句小而频繁，对一致性要求高，通常部分数据有时间属性。在测试及上线后也遇到了一些问题，不过目前基本都有了解决办法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2.1  SQL  执行超时后，JDBC 报错&lt;/b&gt;&lt;/p&gt;&lt;p&gt;业务偶尔报出 privilege check fail。&lt;br&gt;是由于业务在 JDBC 设置了 QueryTimeout，SQL 运行超过这个时间，会发行一个 “kill query” 命令，而 TiDB 执行这个命令需要 Super 权限，业务是没有权限的。&lt;br&gt;其实 kill 自己的查询，并不需要额外的权限，目前已经解决了这个问题：&lt;br&gt;https://github.com/pingcap/tidb/pull/7003，不再需要 Super 权限，已在 2.0.5 上线。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2.2  执行计划偶尔不准&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的物理优化阶段需要依靠统计信息。在 2.0 版本统计信息的收集从手动执行，优化为在达到一定条件时可以自动触发&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据修改比例达到 tidb_auto_analyze_ratio&lt;/li&gt;&lt;li&gt;表一分钟没有变更（目前版本已经去掉这个条件）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但是在没有达到这些条件之前统计信息是不准的，这样就会导致物理优化出现偏差，在测试阶段（2.0 版本）就出现了这样一个案例：业务数据是有时间属性的，业务的查询有 2 个条件，比如：时间+商家 ID，但每天上午统计信息可能不准，当天的数据已经有了，但统计信息认为没有。这时优化器就会建议使用时间列的索引，但实际上商家 ID 列的索引更优化。这个问题可以通过增加 Hint 解决。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 2.1 版本对统计信息和执行计划的计算做了大量的优化，也稳定了基于 Query Feedback 更新统计信息，也用于更新直方图和 Count-Min Sketch，非常期待 2.1 的 GA。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五. 总结展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;经过前期的测试、各方的沟通协调，以及近半年对 TiDB 的使用，我们看好 TiDB 的发展，也对未来基于 TiDB 的合作充满信心。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;接下来，我们会加速推进 TiDB 在更多业务系统中的使用，同时也将 TiDB 纳入了美团新一代数据库的战略选型中。&lt;/b&gt;当前，我们已经全职投入了 3 位 DBA 同学和多位存储计算专家，从底层的存储，中间层的计算，业务层的接入，到存储方案的选型和布道，进行全方位和更深入的合作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;长期来看，结合美团不断增长的业务规模，我们将与 PingCAP 官方合作打造更强大的生态体系&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Titan&lt;/b&gt;：Titan 是 TiDB 下一步比较大的动作，也是我们非常期待的下一代存储引擎，它对大 Value 支持会更友好，将解决我们单行大小受限，单机 TiKV 最大支持存储容量的问题，大大提升大规模部署的性价比。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Cloud TiDB （based on Docker &amp;amp; K8s）&lt;/b&gt;：云计算大势所趋，PingCAP 在这块也布局比较早，今年 8 月份开源了 TiDB Operator，Cloud TiDB 不仅实现了数据库的高度自动化运维，而且基于 Docker 硬件隔离，实现了数据库比较完美的多租户架构。和官方同学沟通，目前他们的私有云方案在国内也有重要体量的 POC，这也是美团看重的一个方向。&lt;/li&gt;&lt;li&gt;&lt;b&gt;TiDB HTAP Platform&lt;/b&gt;：PingCAP 在原有 TiDB Server 计算引擎的基础上，还构建 TiSpark 计算引擎，和他们官方沟通，他们在研发了一个基于列的存储引擎，这样就形成了下层行、列两个存储引擎、上层两个计算引擎的完整混合数据库（HTAP），这个架构不仅大大的节省了核心业务数据在整个公司业务周期里的副本数量，还通过收敛技术栈，节省了大量的人力成本、技术成本、机器成本，同时还解决了困扰多年的 OLAP 的实效性。后面我们也会考虑将一些有实时、准实时的分析查询系统接入 TiDB。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c382078a73f1b6c525bcfd795399c117_r.jpg&quot; data-caption=&quot;图 8 TiDB HTAP Platform 整体架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c382078a73f1b6c525bcfd795399c117&quot; data-watermark-src=&quot;v2-c0eb01710841afbed7641f0a639677ad&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;后续的物理备份方案，跨机房多写等也是我们接下来逐步推进的场景，总之我们坚信未来 TiDB 在美团的使用场景会越来越多，发展也会越来越好。&lt;/p&gt;&lt;p&gt;TiDB 在业务层面、技术合作层面都已经在美团扬帆起航，美团点评将携手 PingCAP 开启新一代数据库深度实践、探索之旅。后续，还有美团点评架构存储团队针对 TiDB 源码研究和改进的系列文章，敬请期待！&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;赵应钢，美团点评研究员&lt;/p&gt;&lt;p&gt;李坤，美团点评数据库专家&lt;/p&gt;&lt;p&gt;朴昌俊，美团点评数据库专家&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-14-49826990</guid>
<pubDate>Wed, 14 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB at 丰巢：尝鲜分布式数据库</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-12-49418382.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49418382&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-53b245933c4c1344ffe14c3caa58a35b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;作者：丰巢技术团队&lt;/i&gt;&lt;/p&gt;&lt;p&gt;随着丰巢业务系统快速增长，其核心系统的数据量，早就跨越了亿级别，而且每年增量仍然在飞速发展。整个核心系统随着数据量的压力增长，不但系统架构复杂度急剧增长，数据架构更加复杂，传统的单节点数据库，已经日渐不能满足丰巢的需求，当单表数量上亿的时候，Oracle 还能勉强抗住，而 MySQL 到单表千万级别的时候就难以支撑，需要进行分表分库。为此，一款高性能的分布式数据库，日渐成为刚需。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;思考&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在互联网公司业务量增大之后，并行扩展是最常用、最简单、最实时的手段。例如负载均衡设备拆流量，让海量流量变成每个机器可以承受的少量流量，并且通过集群等方式支撑起来整个业务。于是当数据库扛不住的时候也进行拆分。&lt;/p&gt;&lt;p&gt;但有状态数据和无状态数据不同，当数据进行拆分的时候，会发生数据分区，而整个系统又要高可用状态下进行，于是数据的一致性变成了牺牲品，大量的核对工具在系统之间跑着保证着最终的一致性。在业务上，可能业务同学经常会遇到分过库的同学说，这个需求做不了，那个需求做不了，如果有 sql 经验的业务同学可能会有疑问不就是一条 sql 的事情么，其实这就是分库分表后遗症。&lt;/p&gt;&lt;p&gt;为此，我们需要有个数据库帮我们解决以上问题，它的特性应该是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据强一致：支持完整的 ACID；&lt;/li&gt;&lt;li&gt;不分表分库：无论多少数据我们只管插入不需要关心啥时候扩容，会不会有瓶颈；&lt;/li&gt;&lt;li&gt;数据高可用：当我们某台数据库的少部分机器磁盘或者其他挂了的时候，我们业务上可以无感知，甚至某个城市机房发生灾难的时候还可以持续提供服务，数据不丢失；&lt;/li&gt;&lt;li&gt;复杂 SQL 功能：基本上单库的 SQL，都可以在这个数据库上运行，不需要修改或者些许修改；&lt;/li&gt;&lt;li&gt;高性能：在满足高 QPS 的同时，保证比较低的延时。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;选型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;根据以上期望进行分析，我们分析了目前市面上存在的 NewSQL 分布式数据库，列表如下：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7d50aaba4268b4bcffdf1037c9df55fb_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;540&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7d50aaba4268b4bcffdf1037c9df55fb&quot; data-watermark-src=&quot;v2-d9d2d9cabfc430fe93fe923f6c3d86c3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;在综合考虑了开源协议，成熟度，可控度，性能，服务支撑等综合因素之后，我们选择了 TiDB，它主要优势如下：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。    &lt;/p&gt;&lt;ul&gt;&lt;li&gt;水平弹性扩展&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松松应对高并发、海量数据场景。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分布式事务 &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 100% 支持标准的 ACID 事务。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;金融级别的高可用性&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;相比于传统主从（M-S）复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。&lt;/p&gt;&lt;p&gt;基于如上的原因，我们选择了 TiDB，作为丰巢的核心系统的分布式数据库，来取代   Oracle 和 MySQL。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;评估&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 性能测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的基准测试，使用的工具是 sysbanch 进行测试，使用了 8 张基础数据为一千万的表，分别测试了 insert，select，oltp 和 delete 脚本得到数据如下，查询的 QPS 达到了惊人的 14 万每秒，而插入也稳定在 1 万 4 每秒。&lt;/p&gt;&lt;p&gt;核心服务器配置：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ea896dbfcc915d8b30eae37f8cd72bdd_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;218&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ea896dbfcc915d8b30eae37f8cd72bdd&quot; data-watermark-src=&quot;v2-09156297eb416aaa8ee6cdf3d36ea51f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;测试结果：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-175e029b03244dd0853c16f104c56563_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;476&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-175e029b03244dd0853c16f104c56563&quot; data-watermark-src=&quot;v2-803097652d090110d23cbb070bceb613&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;通过～&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 功能测试&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7698939b1c1a4dd75285e254111a6d9a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;363&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7698939b1c1a4dd75285e254111a6d9a&quot; data-watermark-src=&quot;v2-07bcb8e6f8393100108c878fddf734a1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;通过～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;接入&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;因为是核心系统，安全起见，我们采取了多种方案保证验证项目接入的可靠性，保证不影响业务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 项目选择&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在寻找第一个接入项目的时候，我们以下面 4 个特征，进行了选择：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-14b43de242d2761cd9c40c9bd9335c9b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;681&quot; data-rawheight=&quot;443&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-14b43de242d2761cd9c40c9bd9335c9b&quot; data-watermark-src=&quot;v2-e0772a0cd62151e113f42132dd3b2a17&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;最终，我们选择了推送服务。因为推送服务是丰巢用来发送取件通知的核心服务，量非常大，但逻辑简单，而且有备选外部推送方案，所以即便万一出现问题，而不会影响用户。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 代码修改&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;因为 TiDB 是完全兼容 MySQL 语法的，所以在这个项目的接入过程中，我们对代码的修改是很细微的。&lt;/b&gt;SQL 基本零改动，主要是外围代码，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;异步接口修改，数据异步化入库&lt;/li&gt;&lt;li&gt;同步接口修改，实现异常熔断&lt;/li&gt;&lt;li&gt;停止内嵌数据迁移代码&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以上三点，保证了整个系统在不强依赖于数据库，并且能在高并发的情况下通过异步落库保护数据库不被压垮，并且在数据库发生问题的时候，核心业务可以正常进行下去。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;效果&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 查询能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接入 TiDB 之后，原先按照时间维度来拆分的十几个分表，变成了一张大表。最明显的变化，是在大数据量下，数据查询能力有了显著的提升。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e6bda36f6bcce06417c6f8f2c7255247_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;464&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e6bda36f6bcce06417c6f8f2c7255247&quot; data-watermark-src=&quot;v2-d7e565cc555d52e9439b5cfd8ccc79bc&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;2. 监控能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 拥有很完善的监控平台，可以直观的看到容量，以及节点状态：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5ce8bed8502373190e4a9ca35461f2ef_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;220&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5ce8bed8502373190e4a9ca35461f2ef&quot; data-watermark-src=&quot;v2-3866522a4cc9ee73cea13be05dff5712&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;还能了解每个节点负载和 sql 执行的延时：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-88181e69d7396fbd0ecd51bb41aea539_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;175&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当然还能了解所在机器上的位置，CPU 内存等负载情况：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d995c9bba949f576d89a4aa9c450bbe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;334&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4d995c9bba949f576d89a4aa9c450bbe&quot; data-watermark-src=&quot;v2-e4cb9a05aab6d255d3cb3239c88b18e6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;网络状态也能清晰的监控到：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e08520002a2e483e600ed5eb18d0e69_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;342&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5e08520002a2e483e600ed5eb18d0e69&quot; data-watermark-src=&quot;v2-7923663063ef472ffbc3b4dc9a4cc89e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;所有这些能让团队能分析出来有问题的 sql，以及数据库本身的问题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 的接入过程，整体还是非常顺利的，由于之前做了很多接入的保障工作，当天切换流量到 TiDB 的过程只用了 10 分钟的时间，在此也要感谢 TiDB 对于 MySQL 语法的兼容性的支持，以及 PingCAP 提供的各种有用的工具。到目前为止，系统的稳定运行了一个多月，很好的满足了丰巢的业务需求。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的改造完成之后，丰巢推送服务对大部分消息进行了落地和查询，截止目前为止，推送服务最大的日落地量已经达到了 5 千万，而如果现在推送服务还使用的还是 MySQL 的方案，就需要上各种的分库分表方案，很多细致的业务就无法或者难以开展。&lt;/p&gt;&lt;p&gt;此次 TiDB 的改造，只是丰巢对于分布式数据技术探索的一小步，未来丰巢会将更多的分布式技术，引入到更多的业务系统，打造更加极致的产品和服务。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-12-49418382</guid>
<pubDate>Mon, 12 Nov 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
