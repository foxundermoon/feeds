<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Tue, 04 Dec 2018 15:26:17 +0800</lastBuildDate>
<item>
<title>TiDB 在小米的应用实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-03-51472404.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51472404&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-286ddf5e402ba98f9de8bfa95ce5eb57_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br&gt;张良，小米 DBA 负责人&lt;br&gt;潘友飞，小米 DBA&lt;br&gt;王必文，小米开发工程师&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;应用场景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;MIUI 是小米公司旗下基于 Android 系统深度优化、定制、开发的第三方手机操作系统，也是小米的第一个产品。MIUI 在 Android 系统基础上，针对中国用户进行了深度定制，在此之上孕育出了一系列的应用，比如主题商店、小米音乐、应用商店、小米阅读等。     &lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c4428dc7c80aea208ba650abba0f8079_r.jpg&quot; data-caption=&quot;图 1  MIUI Android 系统界面图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;595&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c4428dc7c80aea208ba650abba0f8079&quot; data-watermark-src=&quot;v2-acb05a51e9c3630558f4a6880d1ca2c1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;目前 TiDB 主要应用在：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;小米手机桌面负一屏的快递业务&lt;/li&gt;&lt;li&gt;商业广告交易平台素材抽审平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;这两个业务场景每天读写量均达到上亿级，上线之后，整个服务稳定运行；接下来我们计划逐步上线更多的业务场景，小米阅读目前正在积极的针对订单系统做迁移测试。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 特点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 结合了传统的 RDBMS 和 NoSQL 的最佳特性，兼容 MySQL 协议，支持无限的水平扩展，具备强一致性和高可用性。&lt;/p&gt;&lt;p&gt;具有如下的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL，大多数情况下无需修改代码即可从 MySQL 轻松迁移至 TiDB，即使已经分库分表的 MySQL 集群亦可通过 TiDB 提供的迁移工具进行实时迁移。&lt;/li&gt;&lt;li&gt;水平弹性扩展，通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。&lt;/li&gt;&lt;li&gt;分布式事务，TiDB 100% 支持标准的 ACID 事务。&lt;/li&gt;&lt;li&gt;真正金融级高可用，相比于传统主从（M-S）复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 的架构及原理官网有详细介绍（&lt;a href=&quot;https://pingcap.com/&quot;&gt;https://pingcap.com/&lt;/a&gt;），这里不再赘述。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2a500e631bf3062d721ce5cd2cd2c817_r.jpg&quot; data-caption=&quot;图 2  TiDB 基础架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;381&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2a500e631bf3062d721ce5cd2cd2c817&quot; data-watermark-src=&quot;v2-8169cc4855b1c15dc1d79afdb93854a4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;跟绝大数互联网公司一样，小米关系型存储数据库首选 MySQL，单机 2.6T 磁盘。由于小米手机销量的快速上升和 MIUI 负一屏用户量的快速增加，导致负一屏快递业务数据的数据量增长非常快，&lt;b&gt;每天的读写量级均分别达到上亿级别，数据快速增长导致单机出现瓶颈，比如性能明显下降、可用存储空间不断降低、大表 DDL 无法执行等，不得不面临数据库扩展的问题。&lt;/b&gt;比如，我们有一个业务场景（智能终端），需要定时从几千万级的智能终端高频的向数据库写入各种监控及采集数据，MySQL 基于 Binlog 的单线程复制模式，很容易造成从库延迟，并且堆积越来越严重。&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于 MySQL 来讲，最直接的方案就是采用分库分表的水平扩展方式，综合来看并不是最优的方案，比如对于业务来讲，对业务代码的侵入性较大；对于 DBA 来讲提升管理成本，后续需要不断的拆分扩容，即使有中间件也有一定的局限性。&lt;/b&gt;同样是上面的智能终端业务场景，从业务需求看，需要从多个业务维度进行查询，并且业务维度可能随时进行扩展，分表的方案基本不能满足业务的需求。&lt;/p&gt;&lt;p&gt;了解到 TiDB 特点之后，DBA 与业务开发沟通确认当前 MySQL 的使用方式，并与 TiDB 的兼容性做了详细对比，经过业务压测之后，根据压测的结果，决定尝试将数据存储从 MySQL 迁移到 TiDB。经过几个月的线上考验，TiDB 的表现达到预期。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;兼容性对比&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 支持包括跨行事务、JOIN、子查询在内的绝大多数 MySQL 的语法，可以直接使用 MySQL 客户端连接；对于已用 MySQL 的业务来讲，基本可以无缝切换到 TiDB。&lt;/b&gt;&lt;br&gt;二者简单对比如下几方面：&lt;/p&gt;&lt;p&gt;1. 功能支持&lt;/p&gt;&lt;p&gt;TiDB 尚不支持如下几项：&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;增加、删除主键&lt;/li&gt;&lt;li&gt;非 UTF8 字符集&lt;/li&gt;&lt;li&gt;视图（即将支持）、存储过程、触发器、部分内置函数&lt;/li&gt;&lt;li&gt;Event&lt;/li&gt;&lt;li&gt;全文索引、空间索引&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;2. 默认设置&lt;/p&gt;&lt;p&gt;字符集、排序规则、sql_mode、lower_case_table_names 几项默认值不同。&lt;/p&gt;&lt;p&gt;3. 事务&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;TiDB 使用乐观事务模型，提交后注意检查返回值。&lt;/li&gt;&lt;li&gt;TiDB 限制单个事务大小，保持事务尽可能的小。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;4. TiDB 支持绝大多数的 Online DDL。&lt;/p&gt;&lt;p&gt;5. 另，一些 MySQL 语法在 TiDB 中可以解析通过，不会产生任何作用，例如： create table 语句中 engine、partition 选项都是在解析后忽略。&lt;/p&gt;&lt;p&gt;6. 详细信息可以访问官网：https://pingcap.com/docs-cn/sql/mysql-compatibility/ 。&lt;/p&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;压测&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 目的&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过压测 TiDB 了解一下其 OLTP 性能，看是否满足业务要求。&lt;br&gt;&lt;br&gt;&lt;b&gt;2. 机器配置&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d7d319c1480a57e186b79e7bf2cd6ce_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;394&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5d7d319c1480a57e186b79e7bf2cd6ce&quot; data-watermark-src=&quot;v2-dbdd0864ecae8948d5ef342c9e5d6c78&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;3. 压测内容以及结果&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt; 标准 Select 压测&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3919bf10c952092538e4df79ee90caa2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;322&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3919bf10c952092538e4df79ee90caa2&quot; data-watermark-src=&quot;v2-1ab2200f75c089f9a9f3cade76c787b4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8d9269cdf30ac3f6bb7c846d4473a248_r.jpg&quot; data-caption=&quot;图 3  标准 Select 压测图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8d9269cdf30ac3f6bb7c846d4473a248&quot; data-watermark-src=&quot;v2-da683c683c19267c31a5e7fc3f07a732&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;标准 OLTP 压测&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c163a21feec655e19ab64dcb1b07f70a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;357&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c163a21feec655e19ab64dcb1b07f70a&quot; data-watermark-src=&quot;v2-a755b0a83bd7ddba182ba80a6ed66877&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fddec2f978f81acfee3a2d75b2d5ebcb_r.jpg&quot; data-caption=&quot;图 4  标准 OLTP  压测图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;541&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fddec2f978f81acfee3a2d75b2d5ebcb&quot; data-watermark-src=&quot;v2-847e24943021fd8f04ec9a6c907ff6a8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt; 标准 Insert 压测&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28457ad3a1997ddf3c1f2abb33d16fc4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;333&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-28457ad3a1997ddf3c1f2abb33d16fc4&quot; data-watermark-src=&quot;v2-36a16a1feb93e863164d2d83eb3c472a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-686f7602ce614f8e15fdb0ef388a009a_r.jpg&quot; data-caption=&quot;图 5  标准 Insert 压测图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-686f7602ce614f8e15fdb0ef388a009a&quot; data-watermark-src=&quot;v2-c687905215da14e1e3976f9a4196762f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;通过压测发现 TiDB 稳定性上与预期稍有差别，不过压测的 Load 会明显高于生产中的业务 Load，参考低 Threads 时 TiDB 的表现，基本可以满足业务对 DB 的性能要求，决定灰度一部分 MySQL 从库读流量体验一下实际效果。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;迁移过程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;整个迁移分为 2 大块：数据迁移、流量迁移。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 数据迁移&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据迁移分为增量数据、存量数据两部分。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于存量数据，可以使用逻辑备份、导入的方式，除了传统的逻辑导入外，官方还提供一款物理导入的工具 TiDB Lightning。&lt;/li&gt;&lt;li&gt;对于增量备份可以使用 TiDB 提供的 Syncer （新版已经更名为 DM - Data Migration）来保证数据同步。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Syncer 结构如图 6，主要依靠各种 Rule 来实现不同的过滤、合并效果，一个同步源对应一个 Syncer 进程，同步 Sharding 数据时则要多个 Syncer 进程。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-facfec2bcf6879a829017e0de8b94a38_r.jpg&quot; data-caption=&quot;图 6  Syncer 结构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;852&quot; data-rawheight=&quot;391&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-facfec2bcf6879a829017e0de8b94a38&quot; data-watermark-src=&quot;v2-fa999818be6d9fcd875987dfa5d194a8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;使用 Syncer 需要注意：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;做好同步前检查，包含 server-id、log_bin、binlog_format 是否为 ROW、binlog_row_image 是否为 FULL、同步相关用户权限、Binlog 信息等。&lt;/li&gt;&lt;li&gt;使用严格数据检查模式，数据不合法则会停止。数据迁移之前最好针对数据、表结构做检查。&lt;/li&gt;&lt;li&gt;做好监控，TiDB 提供现成的监控方案。&lt;/li&gt;&lt;li&gt;对于已经分片的表同步到同一个 TiDB 集群，要做好预先检查。确认同步场景是否可以用 route-rules 表达，检查分表的唯一键、主键在数据合并后是否冲突等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 流量迁移&lt;/b&gt;&lt;/p&gt;&lt;p&gt;流量切换到 TiDB 分为两部分：读、写流量迁移。每次切换保证灰度过程，观察周期为 1~2 周，做好回滚措施。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;读流量切换到 TiDB，这个过程中回滚比较简单，灰度无问题，则全量切换。&lt;/li&gt;&lt;li&gt;再将写入切换到 TiDB，需要考虑好数据回滚方案或者采用双写的方式（需要断掉 Syncer） 。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;集群状况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 配置&lt;/b&gt;&lt;/p&gt;&lt;p&gt;集群配置采用官方推荐的 7 节点配置，3 个 TiDB 节点，3 个 PD 节点，4 个 TiKV 节点，其中每个 TiDB 与 PD 为一组，共用一台物理机。后续随着业务增长或者新业务接入，再按需添加 TiKV 节点。&lt;br&gt;&lt;br&gt;&lt;b&gt;2. 监控&lt;/b&gt;&lt;/p&gt;&lt;p&gt;监控采用了 TiDB 的提供的监控方案，并且也接入了公司开源的 Falcon，目前整个集群运行比较稳定，监控如图 7。      &lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6288a303380a452fb7c0f8716e97d135_r.jpg&quot; data-caption=&quot;图 7  监控图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;314&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6288a303380a452fb7c0f8716e97d135&quot; data-watermark-src=&quot;v2-729e081c26da54cb02349deb61f1c839&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;遇到的问题、原因及解决办法&lt;/b&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-504342f9d0b3e7799d8dc657180e2083_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;928&quot; data-rawheight=&quot;1638&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-504342f9d0b3e7799d8dc657180e2083&quot; data-watermark-src=&quot;v2-041e4d6ecb39bebe13289f22f6f275b9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;后续和展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前 TiDB 在小米主要提供 OLTP 服务，小米手机负一屏快递业务为使用 TiDB 做了一个良好的开端，而后商业广告也有接入，2 个业务均已上线数月，TiDB 的稳定性经受住了考验，带来了很棒的体验，对于后续大体的规划如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;MIUI 生态业务中存在大量的类似场景的业务，后续将会与业务开发积极沟通，从 MySQL 迁移到 TiDB。&lt;/li&gt;&lt;li&gt;针对某些业务场景，以资源合理利用为目标，推出归档集群，利用 Syncer 实现数据归档的功能。&lt;/li&gt;&lt;li&gt;数据分析，结合 TiDB 提供的工具，将支持离线、实时数据分析支持。&lt;/li&gt;&lt;li&gt;将 TiDB 的监控融合到小米公司开源的监控系统 Falcon 中。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;致谢&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;非常感谢 TiDB 官方在迁移及业务上线期间给予我们的支持，为每一个 TiDB 人专业的精神、及时负责的响应点赞。&lt;br&gt;&lt;br&gt;&lt;br&gt;更多 TiDB 用户实践：&lt;/p&gt;&lt;a href=&quot;https://www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-60ab5bd867c2434d70c957a02a2169e1&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; data-image-size=&quot;ipico&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-03-51472404</guid>
<pubDate>Mon, 03 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 2.1 GA Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-01-51304843.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f5709477c7ad0dcb8de138272df091a1_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 11 月 30 日，TiDB 发布 2.1 GA 版。相比 2.0 版本，该版本对系统稳定性、性能、兼容性、易用性做了大量改进。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Index Join&lt;/code&gt; 选择范围，提升执行性能&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Index Join&lt;/code&gt; 外表选择，使用估算的行数较少的表作为外表&lt;/li&gt;&lt;li&gt;扩大 Join Hint &lt;code class=&quot;inline&quot;&gt;TIDB_SMJ&lt;/code&gt; 的作用范围，在没有合适索引可用的情况下也可使用 Merge Join&lt;/li&gt;&lt;li&gt;加强 Join Hint &lt;code class=&quot;inline&quot;&gt;TIDB_INLJ&lt;/code&gt; 的能力，可以指定 Join 中的内表&lt;/li&gt;&lt;li&gt;优化关联子查询，包括下推 Filter 和扩大索引选择范围，部分查询的效率有数量级的提升&lt;/li&gt;&lt;li&gt;支持在 &lt;code class=&quot;inline&quot;&gt;UPDATE&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;DELETE&lt;/code&gt; 语句中使用 Index Hint 和 Join Hint&lt;/li&gt;&lt;li&gt;支持更多函数下推：&lt;code class=&quot;inline&quot;&gt;ABS&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;CEIL&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;FLOOR&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;IS TRUE&lt;/code&gt;/&lt;code class=&quot;inline&quot;&gt;IS FALSE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;优化内建函数 &lt;code class=&quot;inline&quot;&gt;IF&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;IFNULL&lt;/code&gt; 的常量折叠算法&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;EXPLAIN&lt;/code&gt; 语句输出格式, 使用层级结构表示算子之间的上下游关系&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;SQL 执行引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;重构所有聚合函数，提升 &lt;code class=&quot;inline&quot;&gt;Stream&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;Hash&lt;/code&gt; 聚合算子的执行效率&lt;/li&gt;&lt;li&gt;实现并行 &lt;code class=&quot;inline&quot;&gt;Hash Aggregate&lt;/code&gt; 算子，部分场景下有 350% 的性能提升&lt;/li&gt;&lt;li&gt;实现并行 &lt;code class=&quot;inline&quot;&gt;Project&lt;/code&gt; 算子，部分场景有 74% 的性能提升&lt;/li&gt;&lt;li&gt;并发地读取 &lt;code class=&quot;inline&quot;&gt;Hash Join&lt;/code&gt; 的 &lt;code class=&quot;inline&quot;&gt;Inner&lt;/code&gt; 表和 &lt;code class=&quot;inline&quot;&gt;Outer&lt;/code&gt; 表的数据，提升执行性能&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;REPLACE INTO&lt;/code&gt; 语句的执行速度，性能提升 10x&lt;/li&gt;&lt;li&gt;优化时间类型的内存占用，时间类型数据的内存使用降低为原来的一半&lt;/li&gt;&lt;li&gt;优化点查的查询性能, Sysbench 点查效率提升 60%&lt;/li&gt;&lt;li&gt;TiDB 插入和更新宽表，性能提升接近 20 倍&lt;/li&gt;&lt;li&gt;支持在配置文件中设置单个查询的内存使用上限&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Hash Join&lt;/code&gt; 的执行过程，当 Join 类型为 &lt;code class=&quot;inline&quot;&gt;Inner Join&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;Semi Join&lt;/code&gt; 时，如果内表为空，不再读取外表数据，快速返回结果&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://github.com/pingcap/docs/blob/master/sql/understanding-the-query-execution-plan.md#explain-analyze-output-format&quot;&gt;EXPLAIN ANALYZE&lt;/a&gt;&lt;/code&gt; 语句，用于查看 Query 执行过程中各个算子的运行时间，返回结果行数等运行时统计信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;统计信息&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持只在一天中的某个时间段开启统计信息自动 ANALYZE 的功能&lt;/li&gt;&lt;li&gt;支持根据查询的反馈自动更新表的统计信息&lt;/li&gt;&lt;li&gt;支持通过 &lt;code class=&quot;inline&quot;&gt;ANALYZE TABLE WITH BUCKETS&lt;/code&gt; 语句配置直方图中桶的个数&lt;/li&gt;&lt;li&gt;优化等值查询和范围查询混合的情况下使用直方图估算 Row Count 的算法&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;表达式&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持内建函数：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;json_contains&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;json_contains_path&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;encode/decode&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Server&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持在单个 tidb-server 实例内部对冲突事务排队，优化事务间冲突频繁的场景下的性能&lt;/li&gt;&lt;li&gt;支持 Server Side Cursor&lt;/li&gt;&lt;li&gt;新增 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot;&gt;HTTP 管理接口&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;打散 table 的 regions 在 TiKV 集群中的分布&lt;/li&gt;&lt;li&gt;控制是否打开 &lt;code class=&quot;inline&quot;&gt;general log&lt;/code&gt;&lt;/li&gt;&lt;li&gt;在线修改日志级别&lt;/li&gt;&lt;li&gt;查询 TiDB 集群信息&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/FAQ/#3-3-11-%E5%9C%A8-tidb-%E4%B8%AD-auto-analyze-%E7%9A%84%E8%A7%A6%E5%8F%91%E7%AD%96%E7%95%A5%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84&quot;&gt;添加 auto_analyze_ratio 系统变量控制自动 Analyze 的阈值&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb-retry-limit&quot;&gt;添加 tidb_retry_limit 系统变量控制事务自动重试的次数&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb-disable-txn-auto-retry&quot;&gt;添加 tidb_disable_txn_auto_retry 系统变量控制事务是否自动重试&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/slow-query/#admin-show-slow-%E5%91%BD%E4%BB%A4&quot;&gt;支持使用 admin show slow 语句来获取慢查询语句&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb_slow_log_threshold&quot;&gt;增加环境变量 tidb_slow_log_threshold 动态设置 slow log 的阈值&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs-cn/sql/tidb-specific/#tidb_query_log_max_len&quot;&gt;增加环境变量 tidb_query_log_max_len 动态设置日志中被截断的原始 SQL 语句的长度&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持 Add Index 语句与其他 DDL 语句并行执行，避免耗时的 Add Index 操作阻塞其他操作&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;Add Index&lt;/code&gt; 的速度，在某些场景下速度大幅提升&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;select tidb_is_ddl_owner()&lt;/code&gt; 语句，方便判断 TiDB 是否为 &lt;code class=&quot;inline&quot;&gt;DDL Owner&lt;/code&gt;&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;ALTER TABLE FORCE&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;ALTER TABLE RENAME KEY TO&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;Admin Show DDL Jobs&lt;/code&gt; 输出结果中添加表名、库名等信息&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot;&gt;支持使用 ddl/owner/resign HTTP 接口释放 DDL Owner 并开启新一轮 DDL Owner 选举&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持更多 MySQL 语法&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;BIT&lt;/code&gt; 聚合函数支持 &lt;code class=&quot;inline&quot;&gt;ALL&lt;/code&gt; 参数&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;SHOW PRIVILEGES&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;CHARACTER SET&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;CREATE USER&lt;/code&gt; 语句的 &lt;code class=&quot;inline&quot;&gt;IDENTIFIED WITH&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;LOAD DATA IGNORE LINES&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;Show ProcessList&lt;/code&gt; 语句返回更准确信息&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;可用性优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引入 TiKV 版本控制机制，支持集群滚动兼容升级&lt;/li&gt;&lt;li&gt;PD 节点间 &lt;a href=&quot;https://github.com/pingcap/pd/blob/5c7b18cf3af91098f07cf46df0b59fbf8c7c5462/conf/config.toml#L22&quot;&gt;开启 Raft PreVote&lt;/a&gt;，避免网络隔离后恢复时产生的重新选举，避免网络隔离后恢复时产生的重新选举&lt;/li&gt;&lt;li&gt;开启 &lt;code class=&quot;inline&quot;&gt;raft learner&lt;/code&gt; 功能，降低调度时出现宕机导致数据不可用的风险&lt;/li&gt;&lt;li&gt;TSO 分配不再受系统时间回退影响&lt;/li&gt;&lt;li&gt;支持 &lt;code class=&quot;inline&quot;&gt;Region merge&lt;/code&gt; 功能，减少元数据带来的开销&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;调度器优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 Down Store 的处理流程，加快发生宕机后补副本的速度&lt;/li&gt;&lt;li&gt;优化热点调度器，在流量统计信息抖动时适应性更好&lt;/li&gt;&lt;li&gt;优化 Coordinator 的启动，减少重启 PD 时带来的不必要调度&lt;/li&gt;&lt;li&gt;优化 Balance Scheduler 频繁调度小 Region 的问题&lt;/li&gt;&lt;li&gt;优化 Region merge，调度时考虑 Region 中数据的行数&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/master/tools/pd-control.md#config-show--set--&quot;&gt;新增一些控制调度策略的开关&lt;/a&gt;&lt;/li&gt;&lt;li&gt;完善&lt;a href=&quot;https://github.com/pingcap/pd/tree/release-2.1/tools/pd-simulator&quot;&gt;调度模拟器&lt;/a&gt;，添加调度场景模拟&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;API 及运维工具&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843/http%3C/code%3Es://github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L40&quot;&gt;GetPrevRegion 接口&lt;/a&gt;，用于支持 TiDB reverse scan 功能&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/%3C/code%3E/github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L54&quot;&gt;BatchSplitRegion 接口&lt;/a&gt;，用于支持 TiKV 快速 Region 分裂&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843/ht%3C/code%3Etps://github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L64-L66&quot;&gt;GCSafePoint 接口&lt;/a&gt;，用于支持 TiDB 并发分布式 GC&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304843/htt%3C/code%3Eps://github.com/pingcap/kvproto/blob/8e3f33ac49297d7c93b61a955531191084a2f685/proto/pdpb.proto#L32&quot;&gt;GetAllStores 接口&lt;/a&gt;，用于支持 TiDB 并发分布式 GC&lt;/code&gt;&lt;/li&gt;&lt;li&gt;pd-ctl 新增：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#operator-show--add--remove&quot;&gt;使用统计信息进行 Region split&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#jq-%E6%A0%BC%E5%BC%8F%E5%8C%96-json-%E8%BE%93%E5%87%BA%E7%A4%BA%E4%BE%8B&quot;&gt;调用 jq 来格式化 JSON 输出&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#region-store-store_id&quot;&gt;查询指定 store 的 Region 信息&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#region-topconfver-limit&quot;&gt;查询按 version 排序的 topN 的 Region 列表&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#region-topsize-limit&quot;&gt;查询按 size 排序的 topN 的 Region 列表&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-control.md#tso&quot;&gt;更精确的 TSO 解码&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/release-2.1/tools/pd-recover.md&quot;&gt;pd-recover&lt;/a&gt; 不再需要提供 max-replica 参数&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;监控&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;增加 &lt;code class=&quot;inline&quot;&gt;Filter&lt;/code&gt;相关的监控&lt;/li&gt;&lt;li&gt;新增 etcd Raft 状态机相关监控&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;性能优化&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化处理 Region heartbeat 的性能，减少 heartbeat 带来的内存开销&lt;/li&gt;&lt;li&gt;优化 Region tree 性能&lt;/li&gt;&lt;li&gt;优化计算热点统计的性能问题&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Coprocessor&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;新增支持大量内建函数&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/rfcs/blob/master/text/2017-12-22-read-pool.md&quot;&gt;新增 Coprocessor ReadPool，提高请求处理并发度&lt;/a&gt;&lt;/li&gt;&lt;li&gt;修复时间函数解析以及时区相关问题&lt;/li&gt;&lt;li&gt;优化下推聚合计算的内存使用&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Transaction&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 MVCC 读取逻辑以及内存使用效率，提高扫描操作的性能，Count 全表性能比 2.0 版本提升 1 倍&lt;/li&gt;&lt;li&gt;折叠 MVCC 中连续的 Rollback 记录，保证记录的读取性能&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/rfcs/blob/master/text/2018-08-29-unsafe-destroy-range.md&quot;&gt;新增 UnsafeDestroyRange API 用于在 drop table/index 的情况下快速回收空间&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GC 模块独立出来，减少对正常写入的影响&lt;/li&gt;&lt;li&gt;kv_scan 命令支持设置 upper bound&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Raftstore&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 snapshot 文件写入流程避免导致 RocksDB stall&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/rfcs/pull/17&quot;&gt;增加 LocalReader 线程专门处理读请求，降低读请求的延迟&lt;/a&gt;&lt;/li&gt;&lt;li&gt;href=&quot;https://github.com/tikv/rfcs/pull/6&quot;&amp;gt;支持 BatchSplit 避免大量写入导致产生特别大的 Region&lt;/li&gt;&lt;li&gt;支持按照统计信息进行 Region Split，减少 IO 开销&lt;/li&gt;&lt;li&gt;支持按照 Key 的数量进行 Region Split，提高索引扫描的并发度&lt;/li&gt;&lt;li&gt;优化部分 Raft 消息处理流程，避免 Region Split 带来不必要的延迟&lt;/li&gt;&lt;li&gt;启用 &lt;code class=&quot;inline&quot;&gt;PreVote&lt;/code&gt; 功能，减少网络隔离对服务的影响&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;存储引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;修复 RocksDB &lt;code class=&quot;inline&quot;&gt;CompactFiles&lt;/code&gt; 的 bug，可能影响 Lightning 导入的数据&lt;/li&gt;&lt;li&gt;升级 RocksDB 到 v5.15，解决 snapshot 文件可能会被写坏的问题&lt;/li&gt;&lt;li&gt;优化 &lt;code class=&quot;inline&quot;&gt;IngestExternalFile&lt;/code&gt;，避免 flush 卡住写入的问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;tikv-ctl&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/tikv/blob/master/docs/tools/tikv-control.md#ldb-command&quot;&gt;新增 ldb 命令，方便排查 RocksDB 相关问题&lt;/a&gt;&lt;/li&gt;&lt;li&gt;compact 命令支持指定是否 compact bottommost 层的数据&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;全量数据快速导入工具 &lt;a href=&quot;https://pingcap.github.io/docs-cn/tools/lightning-overview-architecture&quot;&gt;TiDB-Lightning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;支持新版本 &lt;a href=&quot;https://pingcap.github.io/docs-cn/tools/tidb-binlog-cluster/&quot;&gt;TiDB-Binlog&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;升级兼容性说明&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;由于新版本存储引擎更新，不支持在升级后回退至 2.0.x 或更旧版本&lt;/li&gt;&lt;li&gt;新版本默认开启 &lt;code class=&quot;inline&quot;&gt;raft learner&lt;/code&gt; 功能，如果从 1.x 版本集群升级至 2.1 版本，须停机升级或者先滚动升级 TiKV，完成后再滚动升级 PD&lt;/li&gt;&lt;li&gt;从 2.0.6 之前的版本升级到 2.1.0 之前，最好确认集群中是否存在正在运行中的 DDL 操作，特别是耗时的 Add Index 操作&lt;/li&gt;&lt;li&gt;因为 2.1 版本启用了并行 DDL，对于早于 2.0.1 版本的集群，无法滚动升级到 2.1，可以选择下面两种方案：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;停机升级，直接从早于 2.0.1 的 TiDB 版本升级到 2.1&lt;/li&gt;&lt;li&gt;先滚动升级到 2.0.1 或者之后的 2.0.x 版本，再滚动升级到 2.1 版本&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-01-51304843</guid>
<pubDate>Sat, 01 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 2.1：Battle-Tested for an Unpredictable World</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-12-01-51304475.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/51304475&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-149ede427e4c2ab2ec61f20036bb4523_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;TiDB 是由 PingCAP 开发的分布式关系型数据库，今天我们很高兴地推出 TiDB 2.1 正式版，提供更丰富的功能、更好的性能以及更高的可靠性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;回顾 2.0 版本&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;今年 4 月份我们发布了 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/&quot;&gt;TiDB 2.0 版本&lt;/a&gt;，提升了稳定性、性能以及可运维性，这个版本在接下来的半年中得到了广泛的关注和使用。&lt;/p&gt;&lt;p&gt;迄今为止 TiDB 已经在 &lt;a href=&quot;https://pingcap.com/cases-cn/&quot;&gt;数百家用户&lt;/a&gt; 的生产环境中稳定运行，涉及互联网、游戏、金融、保险、制造业、银行、证券等多个行业，最大集群包含数百个节点及数百 TB 数据，业务场景包含纯 OLTP、纯 OLAP 以及混合负载。另外，既有使用 TiDB 当做关系数据库的场景，也有只用 TiKV 作为分布式 Key Value 存储的场景。&lt;/p&gt;&lt;p&gt;这几个月，在这些场景中，我们亲历了跨机房容灾需求、亲历了几十万级别的高吞吐业务、亲历了双十一的流量激增、亲历了高并发点查、高并发写入与上百行复杂 SQL 的混合负载、见到过多次的硬件/网络故障、见到过操作系统内核/编译器的 Bug。&lt;/p&gt;&lt;p&gt;简而言之，我们的世界充满了未知，而分布式关系型数据库这样一种应用广泛、功能丰富且非常关键的基础软件，最大的困难就是这些“未知”。在 2.1 版本中，我们引入了不少新的特性来抵御这些未知，适配各种复杂的场景，提升性能和稳定性，帮助我们的用户更好地支撑复杂的业务。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;更全面的 Optimizer&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2.1 版本中，我们对 TiDB 的 Cost-based Optimizer 做了改进，希望这个优化器能够处理各种复杂的 Query，尽量少的需要人工介入去处理慢 SQL。例如对 Index Join 选择索引、外表的优化，对关联子查询的优化，显著地提升了复杂 SQL 的查询效率。&lt;/p&gt;&lt;p&gt;当然，除了自动的查询优化之外，2.1 也增加了更多的手动干预机制，比如对 Join 算子的 Hint、Update/Delete 语句的 Hint。用户可以在优化器没有指定合适的计划时，手动干预结果或者是用来确保查询计划稳定。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更强大的执行引擎&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2.1 版本中，我们对部分物理算子的执行效率进行了优化，特别是对 Hash Aggregation 和 Projection 这两个算子进行了并行化改造，另外重构了聚合算子的运行框架，支持向量化计算。&lt;/p&gt;&lt;p&gt;得益于这些优化，在 TPC-H 这种 OLAP 的测试集上，2.1 比 2.0 版本有了显著的性能提升，让 2.1 版本更好的面对 HTAP 应用场景。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft 新特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2.1 版本中，我们引入了 Raft PreVote、Raft Learner、Raft Region Merge 三个新特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PreVote 是在 Raft Group Member 发起投票之前，预先检查是否能被其他成员所支持，以避免集群中被网络隔离的节点重新接入集群中的时候引发性能抖动，提升集群稳定性。2.1 版本已经支持 PreVote 功能，并默认打开。&lt;/li&gt;&lt;li&gt;Learner 是只同步数据不参与投票的 Raft Group Member。在新加副本的时候，首先增加 Learner 副本，以避免添加副本过程中，部分 TiKV 节点故障引发丢失多数副本的情况发生，以提升集群的安全性。2.1 版本已经支持 Learner 功能，并默认打开。&lt;/li&gt;&lt;li&gt;Region Merge 用于将多个过小的 Region 合并为一个大的 Region，降低集群的管理成本，对于长期运行的集群以及数据规模较大的集群的性能、稳定性有帮助。2.1 版本已经支持 Region Merge 功能，尚未默认打开。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些新特性的引入，有助于提升存储集群尤其是大规模集群的稳定性和性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;自动更新统计信息&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息的及时性对查询计划的正确性非常重要。在 2.1 版本中，我们提供了基于 Query Feedback 的动态增量更新机制。&lt;/p&gt;&lt;p&gt;在制定查询计划时，会根据现有的统计信息估算出需要处理的数据量；在执行查询计划时，会统计出真实处理的数据量。TiDB 会根据这两个值之间的差距来更新统计信息，包括直方图和 CM-Sketch。在我们的测试中，对于一个完全没有统计信息的表，经过十轮左右的更新，可以达到统计信息基本稳定的状态。这对于维持正确的查询计划非常重要。&lt;/p&gt;&lt;p&gt;除了动态增量更新之外，我们对自动全量 Analyze 也提供了更多支持，可以通过 &lt;a href=&quot;https://www.pingcap.com/docs-cn/sql/statistics/#%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0&quot;&gt;系统变量&lt;/a&gt; 指定做自动 Analyze 的时间段。&lt;/p&gt;&lt;p&gt;&lt;b&gt;并行 DDL&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 所有的 DDL 操作都是 Online 进行，不过在 2.0 以及之前的版本中，所有的 DDL 操作都是串行执行，即使 DDL 所操作的表之间没有关联。比如在对 A 表 Add Index 时候，想创建一个 B 表，需要等待 Add Index 操作结束。这在一些场景下对用户使用造成了困扰。&lt;br&gt;在 2.1 版本中，我们对 DDL 流程进行拆分，将 Add Index 操作和其他的 DDL 操作的处理分开。由于在 TiDB 的 DDL 操作中，只有 Add Index 操作需要去回填数据，耗时较长，其他的 DDL 操作正常情况下都可以在秒级别完成，所以经过这个拆分，可以保证大多数 DDL 操作能够不需要等待，直接执行。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Explain 和 Explain Analyze&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Explain 对于理解查询计划至关重要，2.1 之前的版本，TiDB 追随 MySQL 的 Explain 输出格式来展示查询计划。但是当 SQL 比较复杂时，MySQL 的格式并不利于展示算子之间的层级关系，不利于用户定位问题。&lt;/p&gt;&lt;p&gt;2.1 版本中，我们使用缩进来展示算子之间的层级关系，对每个算子的详细信息也做了优化，希望整个查询计划一目了然，帮助用户尽快定位问题。&lt;a href=&quot;https://www.pingcap.com/docs/sql/understanding-the-query-execution-plan/&quot;&gt;这篇文档&lt;/a&gt; 可以帮助用户了解 TiDB 的查询计划。&lt;/p&gt;&lt;p&gt;用户除了通过 Explain 语句查看查询计划之外，在 2.1 版本中还可以通过 Explain Analyze 语句查看语句的运行时信息，包括每个算子运行时的处理时间以及处理的数据量。这样可以通过实际的运行结果，拿到更加精确的信息。&lt;/p&gt;&lt;p&gt;&lt;b&gt;热点调度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;热点是分布式系统最大的敌人之一，并且用户的业务场景复杂多变，让热点问题捉摸不定，也是最狡猾的敌人。2.1 版本中，我们一方面增强热点检测能力，尽可能详细地统计系统负载，更快的发现热点；另一方面优化热点调度策略，用尽可能小的代价，尽快地打散热点。同时我们也提供了手动分裂 Region 的接口，让用户在特殊场景下将单点瓶颈手动分裂开，再由 PD 进行负载均衡。&lt;/p&gt;&lt;p&gt;&lt;b&gt;高效的 GC 机制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2.1 版本对 GC（垃圾回收） 模块进行优化。一方面减少对线上的写入的影响，另一方面加快了空间回收速度。在内部测试场景中，删除一个 1TB 的表，新的 GC 机制能够在 10 秒内回收 99% 左右的空间。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;更好的性能&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;OLTP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们针对 OLTP 场景中，点查占多数的特点进行了针对性的优化。当通过 Unique Key 或者 Primary Key 进行数据访问时，在优化器和执行引擎中都做了改进，使得语句的执行效率更高，通过 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/benchmark/sysbench-v3.md&quot;&gt;2.1 和 2.0 版本的 Sysbench 对比&lt;/a&gt; 可以看到，点查性能提升 50%。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-135377cc39aac37746c4852e8761f9a8_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;937&quot; data-rawheight=&quot;579&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-135377cc39aac37746c4852e8761f9a8&quot; data-watermark-src=&quot;v2-15ef32935b3deb5c82daa52ef0bca23f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;OLAP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;发布 2.0 的时候，我们同时发布了在 TPC-H Scale 50 的场景中 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/benchmark/tpch.md&quot;&gt;2.0 和 1.0 的对比结果&lt;/a&gt;。其中大多数 Query 都有数量级的提升，部分 Query 在 1.0 中跑不出结果，在 2.0 中可以顺利运行。不过对于 Query17 和 Query18，运行时间依然很长。&lt;/p&gt;&lt;p&gt;我们在相同的场景下，对 2.1 和 2.0 进行了 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/benchmark/tpch-v2.md&quot;&gt;对比测试&lt;/a&gt;。从下图可以看到（纵坐标是 Query 的响应时间，越低越好），之前的两个慢 Query 的运行时间大幅缩短，其他的 Query 也有一定程度的提升。这些提升一方面得益于查询优化器以及执行引擎的改进，另一方面 得益于 TiKV 对连续数据扫描的性能优化。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61efde2ac32bc3c281332b498558a5d9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;581&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-61efde2ac32bc3c281332b498558a5d9&quot; data-watermark-src=&quot;v2-9dab87e5d7d6e756217b14e7c7db7918&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;完善的生态工具&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了让用户更方便的使用 TiDB，我们提供了三个工具：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs/tools/lightning/overview-architecture/&quot;&gt;TiDB Lightning&lt;/a&gt; 用于将全量数据导入到 TiDB 中，这个工具可以提升全量数据导入速度，目前内部测试场景中，一小时可以导入 100GB 数据。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs/tools/tidb-binlog-cluster/&quot;&gt;TiDB Binlog&lt;/a&gt; 用于将 TiDB 中的数据更新实时同步到下游系统中，可以用于做主从集群同步或者是将 TiDB 中的数据同步回 MySQL。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/docs/tools/data-migration-overview/&quot;&gt;TiDB DM&lt;/a&gt;（Data-Migration）用于将 MySQL/MariaDB 中的数据通过 Binlog 实时同步到 TiDB 集群中，并且提供 Binlog 数据转换功能，可以将 Binlog 中的表/库名称进行修改，或者是对数据内容本身做修改和裁剪。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上述三个工具可以将 TiDB 和周边的系统打通，既能将数据同步进 TiDB，又可以将数据同步出来。所以无论是迁移、回退还是做数据热备，都有完整的解决方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Open Source Community&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们相信战胜“未知”最好的武器就是社区的力量，基础软件需要坚定地走开源路线。为了让社区更深入的了解 TiDB 的技术细节并且更好地参与到项目中来，我们今年已经完成超过 20 篇源码阅读文章，项目的设计文档（&lt;a href=&quot;https://github.com/pingcap/tidb/wiki/Design-Documents&quot;&gt;TiDB&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/tikv/rfcs&quot;&gt;TiKV&lt;/a&gt;）已经在 GitHub 上面公开出来，项目的开发过程也尽量通过 GitHub Issue/Project 向社区展示。一些 Feature 设计方案的讨论也会通过在线视频会议的方式方便社区参与进来，&lt;a href=&quot;https://github.com/pingcap/community/blob/master/proposals.md&quot;&gt;这里&lt;/a&gt; 可以看到会议安排。&lt;/p&gt;&lt;p&gt;从 TiDB 2.0 版发布到现在的半年多时间，TiDB 开源社区新增了 87 位 Contributor，其中 &lt;a href=&quot;https://github.com/spongedu&quot;&gt;杜川&lt;/a&gt; 成为了 TiDB Committer，他已经贡献了 &lt;a href=&quot;https://github.com/pingcap/tidb/commits?author=spongedu&quot;&gt;76 次 PR&lt;/a&gt;，还有一些活跃的 Contributor 有希望成为下一批 Committer。&lt;/p&gt;&lt;p&gt;在这里我们对社区贡献者表示由衷的感谢，希望更多志同道合的人能加入进来，也希望大家在 TiDB 这个开源社区能够有所收获！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-12-01-51304475</guid>
<pubDate>Sat, 01 Dec 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>捕获和增强原生系统的可观测性来发现错误</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-23-50671185.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/50671185&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3c69c2bd32515795a24a4c954c0e428d_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘&lt;/p&gt;&lt;p&gt;在对 TiDB 进行 Chaos 实践的时候，我一直在思考如何更好的发现 TiDB 整个系统的故障。最开始，我们参考的就是 Chaos Engineering 里面的方式，观察系统的稳定状态，注入一个错误，然后看 metrics 上面有啥异常，这样等实际环境中出现类似的 metrics，我们就知道发现了什么故障。&lt;/p&gt;&lt;p&gt;但这套机制其实依赖于如何去注入错误，虽然现在我们已经有了很多种错误注入的方式，但总有一些实际的情况我们没有料到。所以后来我们又考虑了另外的一种方式，也就是直接对 metrics 历史进行学习，如果某一段时间 metrics 出现了不正常的波动，那么我们就能报警。但这个对我们现阶段来说难度还是有点大，只使用了几种策略，对 QPS，Latency 这些进行了学习，并不能很好的定位到具体出了什么样的问题。&lt;/p&gt;&lt;p&gt;所以我一直在思考如何更好的去发现系统的故障。最近，刚好看到了OSDI 2018 一篇 Paper， &lt;a href=&quot;https://www.usenix.org/system/files/osdi18-huang.pdf&quot;&gt;Capturing and Enhancing In Situ System Observability for Failure Detection&lt;/a&gt;，眼睛一亮，觉得这种方式也是可以来实践的。&lt;/p&gt;&lt;p&gt;大家都知道，在生产环境中，故障是无处不在，随时可能发生的，譬如硬件问题，软件自身的 bug，或者运维使用了一个错误的配置这些。虽然多数时候，我们的系统都做了容错保护，但我们还是需要能尽快的发现故障，才好进行故障转移。&lt;/p&gt;&lt;p&gt;但现实世界并没有那么美好，很多时候，故障并不是很明显的，譬如整个进程挂掉，机器坏掉这些，它们处于一种时好时坏的状态，我们通常称为『Gray Failure』，譬如磁盘变慢了，网络时不时丢包。这些故障都非常隐蔽，很难被发现。如果单纯的依赖外部的工具，其实很难检测出来。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b3291c8c8e60ecbc9c96aad2b353d60_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1090&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8b3291c8c8e60ecbc9c96aad2b353d60&quot; data-watermark-src=&quot;v2-068dd0bd73f4851f887d506a77a0019e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上面是作者举得一个 Zookeeper 的例子，client 已经完全不能跟 Leader 进行交互了，但是 Leader 却仍然能够给 Follower 发送心跳，同时也能响应外面 Monitor 发过来的探活命令。&lt;br&gt; 如果从外面的 Monitor 看来，这个 Zookeeper 集群还是正常的，但其实它已经有故障了。而这个故障其实 client 是知道的，所以故障检测的原理很简单，从发起请求的这一端来观察，如果发现有问题，那就是有故障了。而这也是这篇论文的中心思想。&lt;/p&gt;&lt;p&gt;在论文里面，作者认为，任何严重的 Gray Failure 都是能够被观察到的，如果发起请求的这边遇到了错误，自然下一件事情就是将这个错误给汇报出去，这样我们就知道某个地方出现了故障。于是作者开发了 &lt;a href=&quot;https://github.com/ryanphuang/panorama&quot;&gt;Panorama&lt;/a&gt; 这套系统，来对故障进行检测。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;整体架构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;先来说说 Panorama 一些专业术语。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4f53fe8c77b8a65ddfcfd80caca665fa_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;634&quot; data-rawheight=&quot;329&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4f53fe8c77b8a65ddfcfd80caca665fa&quot; data-watermark-src=&quot;v2-87ba341924b4bfd8985d1e250208885b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Panorama 整体结构如下：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-be3c0f34afb5db8ec6b663f3c9994e06_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1148&quot; data-rawheight=&quot;696&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-be3c0f34afb5db8ec6b663f3c9994e06&quot; data-watermark-src=&quot;v2-7f7ad761ff2cc070637b9ded88f1bc04&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Panorama 通过一些方式，譬如静态分析代码进行代码注入等，将 Observer 跟要观察的 Subject 进行绑定，Observer 会将 Subject 的一些信息记录并且汇报给本地的一个 Local Observation Store（LOS）。本地一个决策引擎就会分析 LOS 里面的数据来判断这个组件的状态。如果多个 LOS 里面都有对某个 Subject 的 observation，那么 LOS 会相互交换，用来让中央的 verdict 更好的去判断这个 component 的状态。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;故障判定&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;而用来判断一个 component 是不是有故障也比较容易，采用的是一种大多数 bounded-look-back 算法。对于一个 subject，它可能会有很多 observations，首先我们会对这些 observations 按照 observer 进行分组，对每组单独进行分析。在每个组里面，Observations 会按照时间从后往前检查，并且按照 context 进行聚合。如果一个被观察的 observation 的 status 跟记录前面相同 context 的 observation status 状态不一样，就继续 loop-back，直到遇到一个新的 status。对于一个 context，如果最后的状态是 unhealthy 或者 healthy 的状态没有达到多数，就会被认为是 unhealthy 的。&lt;/p&gt;&lt;p&gt;通过这种方式，我们在每组里面得到了每个 context 的状态，然后又会在多个组里面进行决策，也就是最常用的大多数原则，哪个状态最多，那么这个 context 对应的状态就是哪一个。这里我们需要额外处理下 PENDING 这个状态，如果当前状态是 HEALTHY 而之前老的状态是 PENDING，那么 PENDING 就会变成 HEALTHY，而如果一直是 PENDING 状态并超过了某个阈值，就会退化成 UNHEALTHY。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Observability&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这里再来说说 Observability 的模式。对于分布式系统来说，不同 component 之间的交互并不是同步的，我们会面临如下几种情况：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fb41105f1ecc32a94800ea06a1c8aa53_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;992&quot; data-rawheight=&quot;282&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fb41105f1ecc32a94800ea06a1c8aa53&quot; data-watermark-src=&quot;v2-e471aea1424c2115bf962e335f755348&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如果两个组件 C1 和 C2 是同步交互，那么当 C1 给 C2 发送请求，我们就完全能在 C1 这一端知道这次请求成功还是失败了，但是对于非同步的情况，我们可能面临一个问题，就是 C1 给 C2 发了请求，但其实这个请求是放到了异步消息队列里面，但 C1 觉得是成功了，可是后面的异步队列却失败了。所以 Panorama 需要有机制能正确处理上面多种情况。&lt;/p&gt;&lt;p&gt;为了能更好的从 component 上面得到有用的 observations，Panorama 会用一个离线工具对代码进行静态分析，发现一些关键的地方，注入钩子，这样就能去汇报 observations 了。&lt;/p&gt;&lt;p&gt;通常运行时错误是非常有用能证明有故障的证据，但是，并不是所有的错误都需要汇报，Panorama 仅仅会关系跨 component 边界产生的错误，因为这也是通过发起请求端能观察到的。Panorama 对于这种跨域的函数调用称为 observation boundaries。对于 Panorama 来说，第一件事情就是定位 observation boundaries。通常有两种 boundaries，进程间交互和线程间交互。进程间交互通常就是 socket I/O，RPC，而线程间则是在一个进程里面跨越线程的调用。这些 Panorama 都需要分析出来。&lt;/p&gt;&lt;p&gt;当定位了 observation boundaries 之后，下一件事情就是确定 observer 和 subject 的标识。譬如对于进程间交互的 boundaries，observer 的标识就可能是这个进程在系统里面的唯一标识，而对于 subject，我们可以用 method 名字，或者是函数的一个参数，类里面的一个字段来标识。&lt;/p&gt;&lt;p&gt;然后我们需要去确定 observation points，也就是观测点。通常这些点就是代码处理异常的地方，另外可能就是一些正常处理返回结果但会对外报错的地方。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3155f69432096b54c29da20ebf74c276_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;720&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3155f69432096b54c29da20ebf74c276&quot; data-watermark-src=&quot;v2-9a7ca500a7eef87bb3f07c69caf9e79f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上面就是一个简单分析代码得到 observation points 的例子，但这个仍然是同步的，对于 indirection 的，还需要额外处理。&lt;/p&gt;&lt;p&gt;对于异步请求，我们知道，通过发出去之后，会异步的处理结果，所以这里分为了两步，叫做 ob-origin 和 ob-sink。如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-60616ccca52710a6a69b13c602821e09_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;746&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-60616ccca52710a6a69b13c602821e09&quot; data-watermark-src=&quot;v2-225b009ea1fc63f50a6b03ca46844f98&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 ob-origin，代码分析的时候会先给这个 observation 设置成 PENDING 状态，只有对应的 ob-sink 调用并且返回了正确的结果，才会设置成 HEALTHY。因为 ob-origin 和 ob-sink 是异步的，所以代码分析的时候会加上一个特殊的字段，包含 subject 的标识和 context，这样就能让 ob-origin 和 ob-sink 对应起来。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面大概介绍了 Panorama 的架构以及一些关键的知识点是如何实现的，简单来说，就是在一些关键代码路径上面注入 hook，然后通过 hook 对外将相关的状态给汇报出去，在外面会有其他的分析程序对拿到的数据进行分析从而判定系统是否在正常工作。它其实跟加 metrics 很像，但 metrics 只能看出哪里出现了问题，对于想更细致定位具体的某一个问题以及它的上下文环境，倒不是特别的方便。这点来说 Panorama 的价值还是挺大的。&lt;/p&gt;&lt;p&gt;Panorama 的代码已经开源，总的来说还是挺简单的，但我没找到核心的代码分析，注入 hook 这些，有点遗憾。但理解了大概原理，其实先强制在代码写死也未尝不可。另一个比较可行的办法就是进行在代码里面把日志添加详细，这样就不用代码注入了，而是在外面写一个程序来分析日志，其实 Panorama 代码里面提供了日志分析的功能，为 Zookeeper 来设计的，但作者自己也说到，分析日志的效果比不上直接在代码里面进行注入。&lt;/p&gt;&lt;p&gt;那对我们来说，有啥可以参考的呢？首先当然是这一套故障检查的理念，既然 Panorama 已经做出来并且能发现故障量，自然我们也可以在 TiDB 里面实施。因为我们已经有在 Go 和 Rust 代码里面使用 fail 来进行错误注入的经验，所以早起手写监控代码也未尝不可，但也可以直接完善日志，提供一个程序来分析日志就成。如果你对这块感兴趣，想把 Panorama 相关的东西应用到 TiDB 中来，欢迎联系我 &lt;a href=&quot;mailto:tl@pingcap.com&quot;&gt;tl@pingcap.com&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://www.jianshu.com/p/de53ff95d697&quot;&gt;捕获和增强原生系统的可观测性来发现错误&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-23-50671185</guid>
<pubDate>Fri, 23 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>拿奖秘诀泄露，TiDB Hackathon 等你来挑战！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-16-50103243.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/50103243&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-507a9d1aeff2b774624b5be2cf38c312_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;i&gt;TiDB Hackathon 2018 开启报名已有半月有余，作为本场 Hackathon &lt;b&gt;唯一的“小可爱”——我，TiDB Robot&lt;/b&gt;，这段时间受到了小伙伴们的问题轰炸，包括但不限于怎么组队选题、怎么和队友合作、住哪儿、吃啥……还有求划重点拿大奖的。所以今天我总结了一些常见 QA，&lt;b&gt;分为报名篇 / 选题篇 / 实操篇 / 吃住篇&lt;/b&gt;，顺便也划了一下重点，希望对大家有所帮助～&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;报名篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：对参赛者本身有什么门槛吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：没有门槛，不限年龄，不限职业，唯一的要求是&lt;b&gt;来现场参赛（北京）&lt;/b&gt;。Hackathon 注重现场的团队配合和竞技氛围，不接受线上参与哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：如何组建一支“梦之队”？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：Hackathon 精髓之一是团队协作，&lt;b&gt;队员配合和角色分配&lt;/b&gt;很重要。谁来选题谁来设计，是否需要前端等等都是组队时要考虑的因素。还有一个容易被忽视的重要角色是&lt;b&gt;演讲人&lt;/b&gt;，两天一夜的比赛最后的决定性时刻就在展示的几分钟，如何条理清晰的把做的东西讲清楚，以及这个项目解决了什么实质性的问题很关键。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：一个人也可以成队报名吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：当然可以，我们非常欢迎技能值满点的小伙伴以个人身份参赛（传说中的“一个人活成一支队伍”），也欢迎暂时没有选题或队友的个人参赛者报名，主办方会协调大家进行赛前组队。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;选题篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：对选题毫无思路怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：本场 Hackathon 主题为 &lt;b&gt;TiDB Ecosystem。&lt;/b&gt;如果想参赛但不知从何入手，可以&lt;b&gt;勾搭我（微信号：tidbai）&lt;/b&gt;获取我们的选题参考方向哦～希望大家可以举一反三，think out of the box，做出令人眼前一亮的作品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：已有选题的队伍可以提前写代码了吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：&lt;b&gt;不可以&lt;/b&gt;。为了公平起见，参赛作品的所有代码必须在 Hackathon 现场完成，前期准备仅限于资料搜集、架构设计、环境配置与测试。我们不就是为了在有限的时间里做最有挑战的事情，对吗？&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0f0b9fbaf639866ad88b6d5e46c00085_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;370&quot; data-rawheight=&quot;366&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0f0b9fbaf639866ad88b6d5e46c00085&quot; data-watermark-src=&quot;v2-ba2d9f4a5a6f5e5243169f6ed2a2148f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;实操篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：当天如何与队友合作呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：指定团队协作平台—— &lt;b&gt;GitHub&lt;/b&gt;。GitHub 上的提交记录，也方便于评审团审核参赛作品的完整度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：还不会使用 GitHub 怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：五分钟学会使用 GitHub——&lt;/p&gt;&lt;p&gt;    - What is GitHub：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=w3jLJU7DT5E&quot;&gt;https://www.youtube.com/watch?v=w3jLJU7DT5E&lt;/a&gt;&lt;/p&gt;&lt;p&gt;    - GitHub Tutorial For Beginners：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0fKg7e37bQE&quot;&gt;https://www.youtube.com/watch?v=0fKg7e37bQE&lt;/a&gt;&lt;/p&gt;&lt;p&gt;    - 知乎 GitHub 话题助攻&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/20070065&quot;&gt;https://www.zhihu.com/question/20070065&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：TiDB 的代码对于新手来说好复杂啊，哪里可以找到更多的参考资料？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：&lt;b&gt;官方文档&lt;/b&gt;（github.com/pingcap/docs-cn）中有详细的安装部署及运用指导，另外，&lt;b&gt;官方微信公众号&lt;/b&gt;中有宝藏哦。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;推荐阅读：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27275483&quot;&gt;三篇文章了解 TiDB 技术内幕系列&lt;/a&gt;&lt;/u&gt; |   &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46524530&quot;&gt;TiKV 是如何存储数据的&lt;/a&gt;&lt;/u&gt;  | &lt;u&gt;&lt;a href=&quot;https://pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;我们定期举办的 Infra Meetup 常常有 TiDB 相关议题，大家可以在微信公众号（ID: pingcap2015）菜单栏“社区活动-&amp;gt;往期 Meetup”中翻阅视频&amp;amp;文字回顾。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外悄悄的说，我们&lt;b&gt;官网&lt;/b&gt;的搜索很强大，大家可以搜索关键词找到相关资料。除此之外，也可以求助导师团（&lt;a href=&quot;https://mp.weixin.qq.com/s/C5FbZ7HEG3Sr6l_oqCxNng&quot;&gt;七龙珠导师团介绍在此，大家现场“照图抓人”即可&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：如何更好的展示成果？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：Hackathon 不仅是一场代码技术的比拼，临场发挥和演讲技巧也很重要，最后需要在短短几分钟内让大家明白你做了什么以及这个项目的价值。&lt;/p&gt;&lt;p&gt;我们见过花了大量时间介绍项目背景而正题只进行到一半就草草结束的团队，也见过测试时完美运行的项目在演示时却频频报错、选手满头大汗的场景。所以我们建议：&lt;b&gt;演讲时逻辑清晰，开门见山，在有限的时间里阐述项目的重点，并预留出一部分时间进行程序演示，&lt;/b&gt;而现场跑 demo 是一门&lt;b&gt;玄学&lt;/b&gt;，如果不想冒险可以预先录制一个 Demo 视频。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：奖金好诱人，好想拿奖！求划重点！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：和有趣的人一起做有趣的事很重要，顺便拿个大奖当然就更好啦～本次比赛的评判标准是实用性、完成度和创新性。&lt;b&gt;其中，权重最大的是实用性，我们希望 Hackathon 中产出的项目可以长久的在社区运行下去，因此解决实际问题和提高效率是比较重要的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;吃住篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：主办方提供餐饮和住宿吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：我们提供参赛者和志愿者比赛期间的餐饮（正餐包括 12 月 1 日午餐、晚餐，12 月 2 日早餐、午餐），参赛选手可留在比赛场地过夜，如需在场地附近租住宾馆需要自己解决哟～&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：比赛两天都需要呆在活动场地吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：如果没有特殊需求请不要离开场地，需要回自己住处过夜的小伙伴需要提前告知工作人员，并于第二天早晨 8 点前返回场地。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;最后也是最最重要的建议：&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;合理规划项目时间，选定主题之后不要轻易改动，要有团队精神，&lt;b&gt;不能轻易抛弃队友。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;一定、一定要&lt;b&gt;慎用 rm-rf/ &lt;/b&gt; （这是往年 Hackathon 真实发生过的“惨案”……）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;赛程重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;奖项设置&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;一等奖（1 支队伍）：¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;除此之外还设有最佳创意奖和最佳贡献奖。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名时间&lt;/b&gt;：即日起至 11 月 23 日 17:00&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名审核&lt;/b&gt;：5 个工作日内反馈审核结果&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名链接&lt;/b&gt;：点击【&lt;a href=&quot;http://nc9hsk15y2xczuor.mikecrm.com/3AarNns&quot;&gt;这里&lt;/a&gt;】报名&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-16-50103243</guid>
<pubDate>Fri, 16 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在美团点评的深度实践之旅</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-14-49826990.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49826990&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ef8c60fcae0adc633941847ade639a5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;一. 背景和现状&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在美团，基于 MySQL 构建的传统关系型数据库服务已经难于支撑公司业务的爆发式增长，促使我们去探索更合理的数据存储方案和实践新的运维方式。随着近一两年来分布式数据库大放异彩，美团 DBA 团队联合架构存储团队，于 2018 年初启动了分布式数据库项目。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0420b47ac623a455b3f47c455151dd80_r.jpg&quot; data-caption=&quot;图 1 美团点评产品展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;733&quot; data-rawheight=&quot;481&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0420b47ac623a455b3f47c455151dd80&quot; data-watermark-src=&quot;v2-7d98566cf142d5882069e5f7d874d85c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;立项之初，我们进行了大量解决方案的对比，深入了解了业界多种 scale-out、scale-up 方案，考虑到技术架构的前瞻性、发展潜力、社区活跃度、以及服务本身与 MySQL 的兼容性，最终敲定了基于 TiDB 数据库进行二次开发的整体方案，并与 PingCAP 官方和开源社区进行深入合作的开发模式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;美团业务线众多，我们根据业务特点及重要程度逐步推进上线，到截稿为止，已经上线 10 个集群，近 200 个物理节点，大部分是 OLTP 类型的应用，除了上线初期遇到了一些小问题，目前均已稳定运行。初期上线的集群，已经分别服务于配送、出行、闪付、酒旅等业务。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 架构分层清晰，服务平稳流畅，但在美团当前的数据量规模和已有稳定的存储体系的基础上，推广新的存储服务体系，需要对周边工具和系统进行一系列改造和适配，从初期探索到整合落地需要走很远的路。下面从几个方面分别介绍：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一是从 0 到 1 的突破，重点考虑做哪些事情；&lt;/li&gt;&lt;li&gt;二是如何规划实施不同业务场景的接入和已有业务的迁移；&lt;/li&gt;&lt;li&gt;三是上线后遇到的一些典型问题介绍；&lt;/li&gt;&lt;li&gt;四是后续规划和对未来的展望。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;二. 前期调研测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1  对 TiDB 的定位&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们对于 TiDB 的定位，前期在于重点解决 MySQL 的单机性能和容量无法线性和灵活扩展的问题，与 MySQL 形成互补。业界分布式方案很多，我们为何选择了 TiDB 呢？考虑到公司业务规模的快速增长，以及公司内关系数据库以 MySQL 为主的现状，因此我们在调研阶段，对以下技术特性进行了重点考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;协议兼容 MySQL&lt;/b&gt;：这个是必要项。&lt;/li&gt;&lt;li&gt;&lt;b&gt;可在线扩展&lt;/b&gt;：数据通常要有分片，分片要支持分裂和自动迁移，并且迁移过程要尽量对业务无感知。&lt;/li&gt;&lt;li&gt;&lt;b&gt;强一致的分布式事务&lt;/b&gt;：事务可以跨分片、跨节点执行，并且强一致。&lt;/li&gt;&lt;li&gt;&lt;b&gt;支持二级索引&lt;/b&gt;：为兼容 MySQL 的业务，这个是必须的。&lt;/li&gt;&lt;li&gt;&lt;b&gt;性能&lt;/b&gt;：MySQL 的业务特性，高并发的 OLTP 性能必须满足。&lt;/li&gt;&lt;li&gt;&lt;b&gt;跨机房服务&lt;/b&gt;：需要保证任何一个机房宕机，服务能自动切换。&lt;/li&gt;&lt;li&gt;&lt;b&gt;跨机房双写&lt;/b&gt;：支持跨机房双写是数据库领域一大难题，是我们对分布式数据库的一个重要期待，也是美团下一阶段重要的需求。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;业界的一些传统方案虽然支持分片，但无法自动分裂、迁移，不支持分布式事务，还有一些在传统 MySQL 上开发一致性协议的方案，但它无法实现线性扩展，最终我们选择了与我们的需求最为接近的 TiDB。与 MySQL 语法和特性高度兼容，具有灵活的在线扩容缩容特性，支持 ACID 的强一致性事务，可以跨机房部署实现跨机房容灾，支持多节点写入，对业务又能像单机 MySQL 一样使用。&lt;br&gt;&lt;br&gt;&lt;b&gt;2.2  测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对官方声称的以上优点，我们进行了大量的研究、测试和验证。&lt;/p&gt;&lt;p&gt;首先，我们需要知道扩容、Region 分裂转移的细节、Schema 到 kv 的映射、分布式事务的实现原理。而 TiDB 的方案，参考了较多的 Google 论文，我们进行了阅读，这有助于我们理解 TiDB 的存储结构、事务算法、安全性等，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Spanner: Google’s Globally-Distributed Database&lt;/li&gt;&lt;li&gt;Large-scale Incremental Processing Using Distributed Transactions and Notifications&lt;/li&gt;&lt;li&gt;In Search of an Understandable Consensus Algorithm&lt;/li&gt;&lt;li&gt;Online, Asynchronous Schema Change in F1&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们也进行了常规的性能和功能测试，用来与 MySQL 的指标进行对比，其中一个比较特别的测试，是证明 3 副本跨机房部署，确实能保证每个机房分布一个副本，从而保证任何一个机房宕机不会导致丢失超过半数副本。&lt;/b&gt;从以下几个点进行测试：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Raft 扩容时是否支持 learner 节点，从而保证单机房宕机不会丢失 2/3 的副本。&lt;/li&gt;&lt;li&gt;TiKV 上的标签优先级是否可靠，保证当机房的机器不平均时，能否保证每个机房的副本数依然是绝对平均的。&lt;/li&gt;&lt;li&gt;实际测试，单机房宕机，TiDB 在高并发下，QPS、响应时间、报错数量，以及最终数据是否有丢失。&lt;/li&gt;&lt;li&gt;手动 Balance 一个 Region 到其他机房，是否会自动回来。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从测试结果来看，一切都符合预期。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三. 存储生态建设&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;美团的产品线丰富，业务体量大，业务对在线存储的服务质量要求也非常高。因此，从早期做好服务体系的规划非常重要。下面从业务接入层、监控报警、服务部署，来分别介绍一下我们所做的工作。&lt;br&gt;&lt;br&gt;&lt;b&gt;3.1  业务接入层&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当前 MySQL 的业务接入方式主要有两种，DNS 接入和 Zebra 客户端接入。在前期调研阶段，我们选择了 DNS + 负载均衡组件的接入方式，TiDB-Server 节点宕机，15s 可以被负载均衡识别到，简单有效。业务架构如图 2：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fd9faed3064e8efeb78f8224f74bdfb3_r.jpg&quot; data-caption=&quot;图 2 业务架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;347&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fd9faed3064e8efeb78f8224f74bdfb3&quot; data-watermark-src=&quot;v2-9270cf0e10e6e142bd0dea62eb54aa26&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;后面我们会逐渐过渡到当前大量使用的 Zebra 接入方式来访问 TiDB，从而保持与访问 MySQL 的方式一致，一方面减少业务改造的成本，另一方面尽量实现从 MySQL 到 TiDB 的透明迁移。&lt;br&gt;&lt;b&gt;3.2  监控报警&lt;/b&gt;&lt;/p&gt;&lt;p&gt;美团目前使用 Mt-Falcon 平台负责监控报警，通过在 Mt-Falcon 上配置不同的插件，可以实现对多种组件的自定义监控。另外也会结合 Puppet 识别不同用户的权限、文件的下发。这样，只要我们编写好插件脚本、需要的文件，装机和权限控制就可以完成了。监控架构如图 3：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d329d5862cd00f9d6f10e0ecf7b9073c_r.jpg&quot; data-caption=&quot;图 3 监控架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;804&quot; data-rawheight=&quot;483&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d329d5862cd00f9d6f10e0ecf7b9073c&quot; data-watermark-src=&quot;v2-f7fb49c3f75488a38be205b05835e2ae&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;而 TiDB 有丰富的监控指标，使用流行的 Prometheus + Grafana，一套集群有 700+ 的 Metric。从官方的架构图可以看出，每个组件会推送自己的 Metric 给 PushGateWay，Prometheus 会直接到 PushGateWay 去抓数据。&lt;/p&gt;&lt;p&gt;由于我们需要组件收敛，原生的 TiDB 每个集群一套 Prometheus 的方式不利于监控的汇总、分析、配置，而报警已经在 Mt-Falcon 上实现的比较好了，在 AlertManager 上再造一个也没有必要。因此我们需要想办法把监控和报警汇总到 Mt-Falcon 上面，有如下几种方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;方案一：修改源代码，将 Metric 直接推送到 Falcon，由于 Metric 散落在代码的不同位置，而且 TiDB 代码迭代太快，把精力消耗在不停调整监控埋点上不太合适。&lt;/li&gt;&lt;li&gt;方案二：在 PushGateWay 是汇总后的，可以直接抓取，但 PushGateWay 是个单点，不好维护。&lt;/li&gt;&lt;li&gt;方案三：通过各个组件（TiDB、PD、TiKV）的本地 API 直接抓取，优点是组件宕机不会影响其他组件，实现也比较简单。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们最终选择了方案三。该方案的难点是需要把 Prometheus 的数据格式转化为 Mt-Falcon 可识别的格式，因为 Prometheus 支持 Counter、Gauge、Histogram、Summary 四种数据类型，而 Mt-Falcon 只支持基本的 Counter 和 Gauge，同时 Mt-Falcon 的计算表达式比较少，因此需要在监控脚本中进行转换和计算。&lt;br&gt;&lt;br&gt;&lt;b&gt;3.3  批量部署&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 使用 Ansible 实现自动化部署。迭代快，是 TiDB 的一个特点，有问题快速解决，但也造成 Ansible 工程、TiDB 版本更新过快，我们对 Ansible 的改动，也只会增加新的代码，不会改动已有的代码。因此线上可能同时需要部署、维护多个版本的集群。如果每个集群一个 Ansible 目录，造成空间的浪费。我们采用的维护方式是，在中控机中，每个版本一个 Ansible 目录，每个版本中通过不同 inventory 文件来维护。这里需要跟 PingCAP 提出的是，Ansible 只考虑了单集群部署，大量部署会有些麻烦，像一些依赖的配置文件，都不能根据集群单独配置（咨询官方得知，PingCAP 目前正在基于 Cloud TiDB 打造一站式 HTAP 平台，会提供批量部署、多租户等功能，能比较好的解决这个问题）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.4  自动化运维平台&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着线上集群数量的增加，打造运维平台提上了日程，而美团对 TiDB 和 MySQL 的使用方式基本相同，因此 MySQL 平台上具有的大部分组件，TiDB 平台也需要建设。典型的底层组件和方案：SQL 审核模块、DTS、数据备份方案等。自动化运维平台展示如图 4：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb534e712cfff40c4dd8a4d086bb851e_r.jpg&quot; data-caption=&quot;图 4 自动化运维平台展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;531&quot; data-rawheight=&quot;481&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bb534e712cfff40c4dd8a4d086bb851e&quot; data-watermark-src=&quot;v2-1d7fc5cce8af85f15bcd16c544b8f7cb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;3.5  上下游异构数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是在线存储体系中的一环，它同时也需要融入到公司现有的数据流中，因此需要一些工具来做衔接。PingCAP 官方标配了相关的组件。&lt;/p&gt;&lt;p&gt;公司目前 MySQL 和 Hive 结合的比较重，而 TiDB 要代替 MySQL 的部分功能，需要解决 2 个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;MySQL to TiDB&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MySQL 到 TiDB 的迁移，需要解决数据迁移以及增量的实时同步，也就是 DTS，Mydumper + Loader 解决存量数据的同步，官方提供了 DM 工具可以很好的解决增量同步问题。&lt;/li&gt;&lt;li&gt;MySQL 大量使用了自增 ID 作为主键。分库分表 MySQL 合并到 TiDB 时，需要解决自增 ID 冲突的问题。这个通过在 TiDB 端去掉自增 ID 建立自己的唯一主键来解决。新版 DM 也提供分表合并过程主键自动处理的功能。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Hive to TiDB &amp;amp; TiDB to Hive&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Hive to TiDB 比较好解决，这体现了 TiDB 和 MySQL 高度兼容的好处，insert 语句可以不用调整，基于 Hive to MySQL 简单改造即可。&lt;/li&gt;&lt;li&gt;TiDB to Hive 则需要基于官方 Pump + Drainer 组件，Drainer 可以消费到 Kafka、MySQL、TiDB，我们初步考虑用下图 5 中的方案通过使用 Drainer 的 Kafka 输出模式同步到 Hive。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-027ddcdac6f9751c3ba280bcbe0d41bb_r.jpg&quot; data-caption=&quot;图 5 TiDB to Hive 方案图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;831&quot; data-rawheight=&quot;302&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-027ddcdac6f9751c3ba280bcbe0d41bb&quot; data-watermark-src=&quot;v2-da5d862f10832ca37b1ba23f151d34d8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;四. 线上使用磨合&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于初期上线的业务，我们比较谨慎，基本的原则是：离线业务 -&amp;gt; 非核心业务 -&amp;gt; 核心业务。TiDB 已经发布两年多，且前期经历了大量的测试，我们也深入了解了其它公司的测试和使用情况，可以预期的是 TiDB 上线会比较稳定，但依然遇到了一些小问题。总体来看，在安全性、数据一致性等关键点上没有出现问题。其他一些性能抖动问题，参数调优的问题，也都得到了快速妥善的解决。这里给 PingCAP 的同学点个大大的赞，问题响应速度非常快，与我们内部研发的合作也非常融洽。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1  写入量大、读 QPS 高的离线业务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们上线的最大的一个业务，每天有数百 G 的写入量，前期遇到了较多的问题，我们重点说说。&lt;br&gt;&lt;br&gt;业务场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定的写入，每个事务操作 100~200 行不等，每秒 6w 的数据写入。&lt;/li&gt;&lt;li&gt;每天的写入量超过 500G，以后会逐步提量到每天 3T。&lt;/li&gt;&lt;li&gt;每 15 分钟的定时读 job，5000 QPS（高频量小）。&lt;/li&gt;&lt;li&gt;不定时的查询（低频量大）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;之前使用 MySQL 作为存储，但 MySQL 到达了容量和性能瓶颈，而业务的容量未来会 10 倍的增长。初期调研测试了 ClickHouse，满足了容量的需求，测试发现运行低频 SQL 没有问题，但高频 SQL 的大并发查询无法满足需求，只在 ClickHouse 跑全量的低频 SQL 又会 overkill，最终选择使用 TiDB。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试期间模拟写入了一天的真实数据，非常稳定，高频低频两种查询也都满足需求，定向优化后 OLAP 的 SQL 比 MySQL 性能提高四倍。&lt;/b&gt;但上线后，陆续发现了一些问题，典型的如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.1  TiKV 发生 Write Stall&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 底层有 2 个 RocksDB 作为存储。新写的数据写入 L0 层，当 RocksDB 的 L0 层数量达到一定数量，就会发生减速，更高则发生 Stall，用来自我保护。TiKV 的默认配置：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;level0-slowdown-writes-trigger = 20&lt;/li&gt;&lt;li&gt;level0-stop-writes-trigger = 36&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;遇到过的，发生 L0 文件过多可能的原因有 2 个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;写入量大，Compact 完不成。&lt;/li&gt;&lt;li&gt;Snapshot 一直创建不完，导致堆积的副本一下释放，rocksdb-raft 创建大量的 L0 文件，监控展示如图 6：&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e69159a837553ece67165e5f1d535130_r.jpg&quot; data-caption=&quot;图 6 TiKV 发生 Write Stall 监控展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;404&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e69159a837553ece67165e5f1d535130&quot; data-watermark-src=&quot;v2-256e0db1ec5838242fc538eed4517cd7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们通过以下措施，解决了 Write Stall 的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;减缓 Raft Log Compact 频率（增大 raft-log-gc-size-limit、raft-log-gc-count-limit）&lt;/li&gt;&lt;li&gt;加快 Snapshot 速度（整体性能、包括硬件性能）&lt;/li&gt;&lt;li&gt;max-sub-compactions 调整为 3&lt;/li&gt;&lt;li&gt;max-background-jobs 调整为 12&lt;/li&gt;&lt;li&gt;level 0 的 3 个 Trigger 调整为 16、32、64&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.2  Delete 大量数据，GC 跟不上&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在 TiDB 的 GC 对于每个 kv-instance 是单线程的，当业务删除数据的量非常大时，会导致 GC 速度较慢，很可能 GC 的速度跟不上写入。&lt;br&gt;目前可以通过增多 TiKV 个数来解决，长期需要靠 GC 改为多线程执行，官方对此已经实现，即将发布。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.3  Insert 响应时间越来越慢&lt;/b&gt;&lt;/p&gt;&lt;p&gt;业务上线初期，insert 的响应时间 80 线（Duration 80 By Instance）在 20ms 左右，随着运行时间增加，发现响应时间逐步增加到 200ms+。期间排查了多种可能原因，定位在由于 Region 数量快速上涨，Raftstore 里面要做的事情变多了，而它又是单线程工作，每个 Region 定期都要 heartbeat，带来了性能消耗。tikv-raft propose wait duration 指标持续增长。&lt;br&gt;解决问题的办法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;临时解决&lt;/li&gt;&lt;ul&gt;&lt;li&gt;增加 Heartbeat 的周期，从 1s 改为 2s，效果比较明显，监控展示如图 7：&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2751cc531372bb7229c9e6c080242f36_r.jpg&quot; data-caption=&quot;图 7 insert 响应时间优化前后对比图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;208&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2751cc531372bb7229c9e6c080242f36&quot; data-watermark-src=&quot;v2-d2b25490744c113349c30b801b486786&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;彻底解决&lt;/li&gt;&lt;ul&gt;&lt;li&gt;需要减少 Region 个数，Merge 掉空 Region，官方在 2.1 版本中已经实现了 Region Merge 功能，我们在升级到 2.1 后，得到了彻底解决。&lt;/li&gt;&lt;li&gt;另外，等待 Raftstore 改为多线程，能进一步优化。（官方回复相关开发已基本接近尾声，将于 2.1 的下一个版本发布。）&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.4  Truncate Table 空间无法完全回收&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DBA Truncate 一张大表后，发现 2 个现象，一是空间回收较慢，二是最终也没有完全回收。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;由于底层 RocksDB 的机制，很多数据落在 level 6 上，有可能清不掉。这个需要打开 cdynamic-level-bytes 会优化 Compaction 的策略，提高 Compact 回收空间的速度。&lt;/li&gt;&lt;li&gt;由于 Truncate 使用 delete_files_in_range 接口，发给 TiKV 去删 SST 文件，这里只删除不相交的部分，而之前判断是否相交的粒度是 Region，因此导致了大量 SST 无法及时删除掉。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;考虑 Region 独立 SST 可以解决交叉问题，但是随之带来的是磁盘占用问题和 Split 延时问题。&lt;/li&gt;&lt;li&gt;考虑使用 RocksDB 的 DeleteRange 接口，但需要等该接口稳定。&lt;/li&gt;&lt;li&gt;目前最新的 2.1 版本优化为直接使用 DeleteFilesInRange 接口删除整个表占用的空间，然后清理少量残留数据，已经解决。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.5  开启 Region Merge 功能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了解决 region 过多的问题，我们在升级 2.1 版本后，开启了 region merge 功能，但是 TiDB 的响应时间 80 线（Duration 80 By Instance）依然没有恢复到当初，保持在 50ms 左右，排查发现 KV 层返回的响应时间还很快，和最初接近，那么就定位了问题出现在 TiDB 层。研发人员和 PingCAP 定位在产生执行计划时行为和 2.0 版本不一致了，&lt;b&gt;目前已经优化。&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;4.2  在线 OLTP，对响应时间敏感的业务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了分析查询量大的离线业务场景，美团还有很多分库分表的场景，虽然业界有很多分库分表的方案，解决了单机性能、存储瓶颈，但是对于业务还是有些不友好的地方：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;业务无法友好的执行分布式事务。&lt;/li&gt;&lt;li&gt;跨库的查询，需要在中间层上组合，是比较重的方案。&lt;/li&gt;&lt;li&gt;单库如果容量不足，需要再次拆分，无论怎样做，都很痛苦。&lt;/li&gt;&lt;li&gt;业务需要关注数据分布的规则，即使用了中间层，业务心里还是没底。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此很多分库分表的业务，以及即将无法在单机承载而正在设计分库分表方案的业务，主动找到了我们，这和我们对于 TiDB 的定位是相符的。这些业务的特点是 SQL 语句小而频繁，对一致性要求高，通常部分数据有时间属性。在测试及上线后也遇到了一些问题，不过目前基本都有了解决办法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2.1  SQL  执行超时后，JDBC 报错&lt;/b&gt;&lt;/p&gt;&lt;p&gt;业务偶尔报出 privilege check fail。&lt;br&gt;是由于业务在 JDBC 设置了 QueryTimeout，SQL 运行超过这个时间，会发行一个 “kill query” 命令，而 TiDB 执行这个命令需要 Super 权限，业务是没有权限的。&lt;br&gt;其实 kill 自己的查询，并不需要额外的权限，目前已经解决了这个问题：&lt;br&gt;https://github.com/pingcap/tidb/pull/7003，不再需要 Super 权限，已在 2.0.5 上线。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2.2  执行计划偶尔不准&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的物理优化阶段需要依靠统计信息。在 2.0 版本统计信息的收集从手动执行，优化为在达到一定条件时可以自动触发&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据修改比例达到 tidb_auto_analyze_ratio&lt;/li&gt;&lt;li&gt;表一分钟没有变更（目前版本已经去掉这个条件）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但是在没有达到这些条件之前统计信息是不准的，这样就会导致物理优化出现偏差，在测试阶段（2.0 版本）就出现了这样一个案例：业务数据是有时间属性的，业务的查询有 2 个条件，比如：时间+商家 ID，但每天上午统计信息可能不准，当天的数据已经有了，但统计信息认为没有。这时优化器就会建议使用时间列的索引，但实际上商家 ID 列的索引更优化。这个问题可以通过增加 Hint 解决。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 2.1 版本对统计信息和执行计划的计算做了大量的优化，也稳定了基于 Query Feedback 更新统计信息，也用于更新直方图和 Count-Min Sketch，非常期待 2.1 的 GA。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五. 总结展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;经过前期的测试、各方的沟通协调，以及近半年对 TiDB 的使用，我们看好 TiDB 的发展，也对未来基于 TiDB 的合作充满信心。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;接下来，我们会加速推进 TiDB 在更多业务系统中的使用，同时也将 TiDB 纳入了美团新一代数据库的战略选型中。&lt;/b&gt;当前，我们已经全职投入了 3 位 DBA 同学和多位存储计算专家，从底层的存储，中间层的计算，业务层的接入，到存储方案的选型和布道，进行全方位和更深入的合作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;长期来看，结合美团不断增长的业务规模，我们将与 PingCAP 官方合作打造更强大的生态体系&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Titan&lt;/b&gt;：Titan 是 TiDB 下一步比较大的动作，也是我们非常期待的下一代存储引擎，它对大 Value 支持会更友好，将解决我们单行大小受限，单机 TiKV 最大支持存储容量的问题，大大提升大规模部署的性价比。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Cloud TiDB （based on Docker &amp;amp; K8s）&lt;/b&gt;：云计算大势所趋，PingCAP 在这块也布局比较早，今年 8 月份开源了 TiDB Operator，Cloud TiDB 不仅实现了数据库的高度自动化运维，而且基于 Docker 硬件隔离，实现了数据库比较完美的多租户架构。和官方同学沟通，目前他们的私有云方案在国内也有重要体量的 POC，这也是美团看重的一个方向。&lt;/li&gt;&lt;li&gt;&lt;b&gt;TiDB HTAP Platform&lt;/b&gt;：PingCAP 在原有 TiDB Server 计算引擎的基础上，还构建 TiSpark 计算引擎，和他们官方沟通，他们在研发了一个基于列的存储引擎，这样就形成了下层行、列两个存储引擎、上层两个计算引擎的完整混合数据库（HTAP），这个架构不仅大大的节省了核心业务数据在整个公司业务周期里的副本数量，还通过收敛技术栈，节省了大量的人力成本、技术成本、机器成本，同时还解决了困扰多年的 OLAP 的实效性。后面我们也会考虑将一些有实时、准实时的分析查询系统接入 TiDB。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c382078a73f1b6c525bcfd795399c117_r.jpg&quot; data-caption=&quot;图 8 TiDB HTAP Platform 整体架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c382078a73f1b6c525bcfd795399c117&quot; data-watermark-src=&quot;v2-c0eb01710841afbed7641f0a639677ad&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;后续的物理备份方案，跨机房多写等也是我们接下来逐步推进的场景，总之我们坚信未来 TiDB 在美团的使用场景会越来越多，发展也会越来越好。&lt;/p&gt;&lt;p&gt;TiDB 在业务层面、技术合作层面都已经在美团扬帆起航，美团点评将携手 PingCAP 开启新一代数据库深度实践、探索之旅。后续，还有美团点评架构存储团队针对 TiDB 源码研究和改进的系列文章，敬请期待！&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;赵应钢，美团点评研究员&lt;/p&gt;&lt;p&gt;李坤，美团点评数据库专家&lt;/p&gt;&lt;p&gt;朴昌俊，美团点评数据库专家&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-14-49826990</guid>
<pubDate>Wed, 14 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB at 丰巢：尝鲜分布式数据库</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-12-49418382.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49418382&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-53b245933c4c1344ffe14c3caa58a35b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;作者：丰巢技术团队&lt;/i&gt;&lt;/p&gt;&lt;p&gt;随着丰巢业务系统快速增长，其核心系统的数据量，早就跨越了亿级别，而且每年增量仍然在飞速发展。整个核心系统随着数据量的压力增长，不但系统架构复杂度急剧增长，数据架构更加复杂，传统的单节点数据库，已经日渐不能满足丰巢的需求，当单表数量上亿的时候，Oracle 还能勉强抗住，而 MySQL 到单表千万级别的时候就难以支撑，需要进行分表分库。为此，一款高性能的分布式数据库，日渐成为刚需。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;思考&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在互联网公司业务量增大之后，并行扩展是最常用、最简单、最实时的手段。例如负载均衡设备拆流量，让海量流量变成每个机器可以承受的少量流量，并且通过集群等方式支撑起来整个业务。于是当数据库扛不住的时候也进行拆分。&lt;/p&gt;&lt;p&gt;但有状态数据和无状态数据不同，当数据进行拆分的时候，会发生数据分区，而整个系统又要高可用状态下进行，于是数据的一致性变成了牺牲品，大量的核对工具在系统之间跑着保证着最终的一致性。在业务上，可能业务同学经常会遇到分过库的同学说，这个需求做不了，那个需求做不了，如果有 sql 经验的业务同学可能会有疑问不就是一条 sql 的事情么，其实这就是分库分表后遗症。&lt;/p&gt;&lt;p&gt;为此，我们需要有个数据库帮我们解决以上问题，它的特性应该是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据强一致：支持完整的 ACID；&lt;/li&gt;&lt;li&gt;不分表分库：无论多少数据我们只管插入不需要关心啥时候扩容，会不会有瓶颈；&lt;/li&gt;&lt;li&gt;数据高可用：当我们某台数据库的少部分机器磁盘或者其他挂了的时候，我们业务上可以无感知，甚至某个城市机房发生灾难的时候还可以持续提供服务，数据不丢失；&lt;/li&gt;&lt;li&gt;复杂 SQL 功能：基本上单库的 SQL，都可以在这个数据库上运行，不需要修改或者些许修改；&lt;/li&gt;&lt;li&gt;高性能：在满足高 QPS 的同时，保证比较低的延时。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;选型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;根据以上期望进行分析，我们分析了目前市面上存在的 NewSQL 分布式数据库，列表如下：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7d50aaba4268b4bcffdf1037c9df55fb_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;540&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7d50aaba4268b4bcffdf1037c9df55fb&quot; data-watermark-src=&quot;v2-d9d2d9cabfc430fe93fe923f6c3d86c3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;在综合考虑了开源协议，成熟度，可控度，性能，服务支撑等综合因素之后，我们选择了 TiDB，它主要优势如下：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。    &lt;/p&gt;&lt;ul&gt;&lt;li&gt;水平弹性扩展&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松松应对高并发、海量数据场景。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分布式事务 &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 100% 支持标准的 ACID 事务。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;金融级别的高可用性&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;相比于传统主从（M-S）复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。&lt;/p&gt;&lt;p&gt;基于如上的原因，我们选择了 TiDB，作为丰巢的核心系统的分布式数据库，来取代   Oracle 和 MySQL。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;评估&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 性能测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的基准测试，使用的工具是 sysbanch 进行测试，使用了 8 张基础数据为一千万的表，分别测试了 insert，select，oltp 和 delete 脚本得到数据如下，查询的 QPS 达到了惊人的 14 万每秒，而插入也稳定在 1 万 4 每秒。&lt;/p&gt;&lt;p&gt;核心服务器配置：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ea896dbfcc915d8b30eae37f8cd72bdd_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;218&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ea896dbfcc915d8b30eae37f8cd72bdd&quot; data-watermark-src=&quot;v2-09156297eb416aaa8ee6cdf3d36ea51f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;测试结果：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-175e029b03244dd0853c16f104c56563_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;476&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-175e029b03244dd0853c16f104c56563&quot; data-watermark-src=&quot;v2-803097652d090110d23cbb070bceb613&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;通过～&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 功能测试&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7698939b1c1a4dd75285e254111a6d9a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;363&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7698939b1c1a4dd75285e254111a6d9a&quot; data-watermark-src=&quot;v2-07bcb8e6f8393100108c878fddf734a1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;通过～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;接入&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;因为是核心系统，安全起见，我们采取了多种方案保证验证项目接入的可靠性，保证不影响业务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 项目选择&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在寻找第一个接入项目的时候，我们以下面 4 个特征，进行了选择：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-14b43de242d2761cd9c40c9bd9335c9b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;681&quot; data-rawheight=&quot;443&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-14b43de242d2761cd9c40c9bd9335c9b&quot; data-watermark-src=&quot;v2-e0772a0cd62151e113f42132dd3b2a17&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;最终，我们选择了推送服务。因为推送服务是丰巢用来发送取件通知的核心服务，量非常大，但逻辑简单，而且有备选外部推送方案，所以即便万一出现问题，而不会影响用户。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 代码修改&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;因为 TiDB 是完全兼容 MySQL 语法的，所以在这个项目的接入过程中，我们对代码的修改是很细微的。&lt;/b&gt;SQL 基本零改动，主要是外围代码，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;异步接口修改，数据异步化入库&lt;/li&gt;&lt;li&gt;同步接口修改，实现异常熔断&lt;/li&gt;&lt;li&gt;停止内嵌数据迁移代码&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以上三点，保证了整个系统在不强依赖于数据库，并且能在高并发的情况下通过异步落库保护数据库不被压垮，并且在数据库发生问题的时候，核心业务可以正常进行下去。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;效果&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 查询能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接入 TiDB 之后，原先按照时间维度来拆分的十几个分表，变成了一张大表。最明显的变化，是在大数据量下，数据查询能力有了显著的提升。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e6bda36f6bcce06417c6f8f2c7255247_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;464&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e6bda36f6bcce06417c6f8f2c7255247&quot; data-watermark-src=&quot;v2-d7e565cc555d52e9439b5cfd8ccc79bc&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;2. 监控能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 拥有很完善的监控平台，可以直观的看到容量，以及节点状态：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5ce8bed8502373190e4a9ca35461f2ef_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;220&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5ce8bed8502373190e4a9ca35461f2ef&quot; data-watermark-src=&quot;v2-3866522a4cc9ee73cea13be05dff5712&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;还能了解每个节点负载和 sql 执行的延时：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-88181e69d7396fbd0ecd51bb41aea539_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;175&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当然还能了解所在机器上的位置，CPU 内存等负载情况：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d995c9bba949f576d89a4aa9c450bbe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;334&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4d995c9bba949f576d89a4aa9c450bbe&quot; data-watermark-src=&quot;v2-e4cb9a05aab6d255d3cb3239c88b18e6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;网络状态也能清晰的监控到：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e08520002a2e483e600ed5eb18d0e69_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;342&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5e08520002a2e483e600ed5eb18d0e69&quot; data-watermark-src=&quot;v2-7923663063ef472ffbc3b4dc9a4cc89e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;所有这些能让团队能分析出来有问题的 sql，以及数据库本身的问题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 的接入过程，整体还是非常顺利的，由于之前做了很多接入的保障工作，当天切换流量到 TiDB 的过程只用了 10 分钟的时间，在此也要感谢 TiDB 对于 MySQL 语法的兼容性的支持，以及 PingCAP 提供的各种有用的工具。到目前为止，系统的稳定运行了一个多月，很好的满足了丰巢的业务需求。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的改造完成之后，丰巢推送服务对大部分消息进行了落地和查询，截止目前为止，推送服务最大的日落地量已经达到了 5 千万，而如果现在推送服务还使用的还是 MySQL 的方案，就需要上各种的分库分表方案，很多细致的业务就无法或者难以开展。&lt;/p&gt;&lt;p&gt;此次 TiDB 的改造，只是丰巢对于分布式数据技术探索的一小步，未来丰巢会将更多的分布式技术，引入到更多的业务系统，打造更加极致的产品和服务。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-12-49418382</guid>
<pubDate>Mon, 12 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 开源社区指南（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-09-49032099.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49032099&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cd7d9bab60939208425651627bac56f5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/ed548ab735221a534cfc14702e4c8638&quot; data-hash=&quot;ed548ab735221a534cfc14702e4c8638&quot; data-hovercard=&quot;p$b$ed548ab735221a534cfc14702e4c8638&quot;&gt;@申砾&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;本系列文章旨在帮助社区开发者了解 TiDB 项目的全貌，更好的参与 TiDB 项目开发。大致会分两个角度进行描述：&lt;br&gt;1. 从社区参与者的角度描述如何更好的参与 TiDB 项目开发；&lt;br&gt;2. 从 PingCAP 内部团队的角度展示 TiDB 的开发流程，包括版本规划、开发流程、Roadmap 制定等。&lt;br&gt;希望通过一内一外两条线的描述，读者能在技术之外对 TiDB 有更全面的了解。本篇将聚焦在社区参与者的角度进行描述，也就是“外线”。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;了解 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;参与一个开源项目第一步总是了解它，特别是对 TiDB 这样一个大型的项目，了解的难度比较高，这里列出一些相关资料，帮助 newcomers 从架构设计到工程实现细节都能有所了解：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs#tidb-introduction&quot;&gt;Overview&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/blog/2016-10-17-how-we-build-tidb/&quot;&gt;How we build TiDB&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://tikv.github.io/deep-dive-tikv/book/&quot;&gt;Deep Dive TiKV (Work-In-Process)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，最高效地熟悉 TiDB 的方式还是使用它，在某些场景下遇到了问题或者是想要新的 feature，去跟踪代码，找到相关的代码逻辑，在这个过程中很容易对相关模块有了解，不少 Contributor 就是这样完成了第一次贡献。&lt;/p&gt;&lt;p&gt;我们还有一系列的 Infra Meetup，大约两周一次，如果方便到现场的同学可以听到这些高质量的 Talk。除了北京之外，其他的城市（上海、广州、成都、杭州）也开始组织 Meetup，方便更多的同学到现场来面基。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;发现可以参与的事情&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对 TiDB 有基本的了解之后，就可以选一个入手点。在 TiDB repo 中我们给一些简单的 issue 标记了 &lt;a href=&quot;https://github.com/pingcap/tidb/issues?q=is%3Aissue+is%3Aopen+label%3A%22for+new+contributors%22&quot;&gt;for-new-contributors &lt;/a&gt;标签，这些 issue 都是我们评估过容易上手的事情，可以以此为切入点。另外我们也会定期举行一些活动，把框架搭好，教程写好，新 Contributor 按照固定的模式即可完成某一特性开发。&lt;/p&gt;&lt;p&gt;当然除了那些标记为 for-new-contributors 的 issue 之外，也可以考虑其他的 issue，标记为 &lt;a href=&quot;https://github.com/pingcap/tidb/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22&quot;&gt;help-wanted &lt;/a&gt;标签的 issue 可以优先考虑。除此之外的 issue 可能会比较难解决，需要对 TiDB 有较深入的了解或者是对完成时间有较高的要求，不适合第一次参与的同学。&lt;/p&gt;&lt;p&gt;当然除了现有的 issue 之外，也欢迎将自己发现的问题或者是想要的特性提为新的 issue，然后自投自抢 :) 。&lt;/p&gt;&lt;p&gt;当你已经对 TiDB 有了深入的了解，那么可以尝试从 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/ROADMAP.md&quot;&gt;Roadmap &lt;/a&gt;上找到感兴趣的事项，和我们讨论一下如何参与。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;讨论方案&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;找到一个感兴趣的点之后，可以在 issue 中进行讨论，如果是一个小的 bug-fix 或者是小的功能点，可以简单讨论之后开工。即使再简单的问题，也建议先进行讨论，以免出现解决方案有问题或者是对问题的理解出了偏差，做了无用功。&lt;/p&gt;&lt;p&gt;但是如果要做的事情比较大，可以先写一个详细的设计文档，提交到 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/docs/design&quot;&gt;docs/design &lt;/a&gt;目录下面，这个目录下有设计模板以及一些已有的设计方案供你参考。一篇好的设计方案要写清楚以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;背景知识&lt;/li&gt;&lt;li&gt;解决什么问题&lt;/li&gt;&lt;li&gt;方案详细设计&lt;/li&gt;&lt;li&gt;对方案的解释说明，证明正确性和可行性&lt;/li&gt;&lt;li&gt;和现有系统的兼容性&lt;/li&gt;&lt;li&gt;方案的具体实现&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;用一句话来总结就是写清楚“你做了什么，为什么要做这个，怎么做的，为什么要这样做”。如果对自己的方案不太确定，可以先写一个 Google Doc，share 给我们简单评估一下，再提交 PR。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;提交 PR&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;按照方案完成代码编写后，就可以提交 PR。当然如果开发尚未完成，在某些情况下也可以先提交 PR，比如希望先让社区看一下大致的解决方案，这个时候请将 PR 标记为 WIP。&lt;br&gt;对于 PR 我们有一些要求：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;需要能通过 &lt;code class=&quot;inline&quot;&gt;make dev&lt;/code&gt; 的测试，跑过基本的单元测试；&lt;/li&gt;&lt;li&gt;必须有测试，除非只是改动文档或者是依赖包，其他情况需要有充足的理由说明没有测试的原因；&lt;/li&gt;&lt;li&gt;代码以及注释的质量需要足够高， &lt;a href=&quot;https://github.com/pingcap/community/blob/master/CONTRIBUTING.md#code-style&quot;&gt;这里 &lt;/a&gt;有一些关于编码风格和 commit message 的 guide；&lt;/li&gt;&lt;li&gt;请尽可能详细的填写 PR 的描述，并打上合适的 label。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;对于 PR 的描述，我们提供了一个模板，希望大家能够认真填写，一个好的描述能够加速 PR 的 review 过程。通过这个模板能够向 reviewers 以及社区讲明白：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;这个PR 解决什么问题：相关的问题描述或者是 issue 链接；&lt;/li&gt;&lt;li&gt;如何解决：具体的解决方法，reviewers 会根据这里的描述去看代码变动，所以请将这一段写的尽可能详细且有帮助；&lt;/li&gt;&lt;li&gt;测试的情况；&lt;/li&gt;&lt;li&gt;其他相关信息（如果需要）：benchmark 结果、兼容性问题、是否需要更新文档。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后再说几句测试，正确性是数据库安身立命之本，怎么强调测试都不为过。PR 中的测试不但需要充足，覆盖到所做的变动，还需要足够清晰，通过代码或者注释来表达测试的目的，帮助 reviewer 以及今后可能变动/破坏相关逻辑的人能够容易的理解这段测试。一段完善且清晰的测试也有利于让 reviewer 相信这个 Patch 是正确的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;PR review&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PR review 的过程就是 reviewer 不断地提出 comment，PR 作者持续解决 comment 的过程。&lt;br&gt;&lt;b&gt;每个 PR 在合并之前都需要至少得到两个 Committer/Maintainer 的 LGTM，一些重要的 PR 需要得到三个，比如对于 DDL 模块的修改，默认都需要得到三个 LGTM。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;Tips：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提了PR 之后，可以 at 一下相关的同学来 review&lt;/li&gt;&lt;li&gt;Address comment 之后可以 at 一下之前提过 comment 的同学，标准做法是 comment 一下 “ &lt;b&gt;PTAL @xxx&lt;/b&gt; ”，这样我们内部的 Slack 中可以得到通知，相关的同学会受到提醒，让整个流程更紧凑高效。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;与项目维护者之间的交流&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;目前标准的交流渠道是 GitHub issue&lt;/b&gt; ，请大家优先使用这个渠道，我们有专门的同学来维护这个渠道，其他渠道不能保证得到研发同学的及时回复。这也是开源项目的标准做法。&lt;br&gt;无论是遇到 bug、讨论具体某一功能如何做、提一些建议、产品使用中的疑惑，都可以来提 issue。在开发过程中遇到了问题，也可以在相关的 issue 中进行讨论，包括方案的设计、具体实现过程中遇到的问题等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后请大家注意一点，除了 pingcap/docs-cn 这个 repo 之外，请大家使用英文。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;更进一步&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当你完成上面这些步骤的之后，恭喜你已经跨过第一个门槛，正式进入了 TiDB 开源社区，开始参与 TiDB 项目开发，成为 &lt;b&gt;TiDB Contributor&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;如果想更进一步，深入了解 TiDB 的内部机制，掌握一个分布式数据库的核心模块，并能做出改进，那么可以了解更多的模块，提更多的 PR，进一步向 Committer 发展（ &lt;a href=&quot;https://github.com/pingcap/community/blob/master/become-a-committer.md&quot;&gt;这里 &lt;/a&gt;解释了什么是 Committer）。目前 TiDB 社区的 Committer 还非常少，我们希望今后能出现更多的 Committer 甚至是 Maintainer。&lt;/p&gt;&lt;p&gt;从 Contributor 到 Committer 的门槛比较高，比如今年的新晋 Committer 杜川同学，在成为 Committer 的道路上给 tidb/tikv 项目提交了大约 80 个 PR，并且对一些模块有非常深入的了解。当然，成为 Committer 之后，会有一定的权利，比如对一些 PR 点 LGTM 的权利，参加 PingCAP 内部的技术事项、开发规划讨论的权利，参加定期举办的 TechDay/DevCon 的权利。目前社区中还有几位贡献者正走在从 Contributor 到 Committer 的道路上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-09-49032099</guid>
<pubDate>Fri, 09 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 助力卡思数据视频大数据业务创新</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-06-48674946.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/48674946&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-632a19539faeb998a4f082d80f81c175_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;卡思数据是国内领先的视频全网数据开放平台，依托领先的数据挖掘与分析能力，为视频内容创作者在节目创作和用户运营方面提供数据支持，为广告主的广告投放提供数据参考和效果监测，为内容投资提供全面客观的价值评估。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07b63db2487756269fd6da9db5d051ce_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1594&quot; data-rawheight=&quot;753&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-07b63db2487756269fd6da9db5d051ce&quot; data-watermark-src=&quot;v2-69ee6da76a96003dff0ae2094e22aaef&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt; 图 1 卡思数据产品展示图&lt;/p&gt;&lt;h2&gt;&lt;b&gt;业务发展遇到的痛点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;卡思数据首先通过分布式爬虫系统进行数据抓取，每天新增数据量在 50G - 80G 之间，并且入库时间要求比较短，因此对数据库写入性能要求很高，由于数据增长比较快，对数据库的扩展性也有很高的要求。数据抓取完成后，对数据进行清洗和计算，因为数据量比较大，单表 5 亿 + 条数据，所以对数据库的查询性能要求很高。&lt;/p&gt;&lt;p&gt;起初卡思数据采用的是多个 MySQL 实例和一个 MongoDB 集群，如图 2。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;MySQL 存储业务相关数据，直接面向用户，对事务的要求很高，但在海量数据存储方面偏弱，由于单行较大，单表数据超过千万或 10G 性能就会急剧下降。&lt;/li&gt;&lt;li&gt;MongoDB 存储最小单元的数据，MongoDB 有更好的写入性能，保证了每天数据爬取存储速度；对海量数据存储上，MongoDB 内建的分片特性，可以很好的适应大数据量的需求。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-146fd37a7dbce48dd44ca485ffaaf630_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;777&quot; data-rawheight=&quot;330&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-146fd37a7dbce48dd44ca485ffaaf630&quot; data-watermark-src=&quot;v2-db7288bb62cc10adb9d3df1ba44def5c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 2 起初卡思数据架构图 &lt;/p&gt;&lt;p&gt;但是随着业务发展，暴露出一些问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;MySQL 在大数据量的场景下，查询性能难以满足要求，并且扩展能力偏弱，如果采用分库分表方式，需要对业务代码进行全面改造，成本非常高。&lt;/li&gt;&lt;li&gt;MongoDB 对复杂事务的不支持，前台业务需要用到数据元及连表查询，当前架构支持的不太友好。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;架构优化&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 需求&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对我们遇到的问题，我们急需这样一款数据库：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;兼容 MySQL 协议，数据迁移成本和代码改造成本低&lt;/li&gt;&lt;li&gt;插入性能强&lt;/li&gt;&lt;li&gt;大数据量下的实时查询性能强，无需分库分表&lt;/li&gt;&lt;li&gt;水平扩展能力强&lt;/li&gt;&lt;li&gt;稳定性强，产品最好有成熟的案例&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 方案调研&lt;/b&gt;&lt;/p&gt;&lt;p&gt;未选择 TiDB 之前我们调研了几个数据库，Greenplum、HybirdDB for MySQL（PetaData）以及 PolarDB。Greenplum 由于插入性能比较差，并且跟 MySQL 协议有一些不兼容，首先被排除。&lt;/p&gt;&lt;p&gt;HybirdDB for MySQL 是阿里云推出的 HTAP 关系型数据库，我们在试用一段时间发现一些问题：&lt;/p&gt;&lt;p&gt;一是复杂语句导致计算引擎拥堵，阻塞所有业务，经常出现查询超时的情况。&lt;/p&gt;&lt;p&gt;二是连表查询性能低下，网络 I/O 出现瓶颈。举一个常见的关联查询，cd_video 表，2200 万数据，cd_program_video 表，节目和视频的关联表，4700 万数据，在关联字段上都建有索引，如下 SQL：&lt;/p&gt;&lt;p&gt;select &lt;a href=&quot;http://v.id&quot;&gt;v.id&lt;/a&gt;,v.url,v.extra_id,v.title fromcd_video v join cd_program_video pv on &lt;a href=&quot;http://v.id&quot;&gt;v.id&lt;/a&gt; = pv.video_id where program_id =xxx；&lt;/p&gt;&lt;p&gt;当相同查询并发超过一定数量时，就会频繁报数据库计算资源不可用的错误。&lt;/p&gt;&lt;p&gt;三是 DDL 操作比较慢，该字段等操作基本需要几分钟，下发至节点后易出现死锁。&lt;/p&gt;&lt;p&gt;PolarDB 是阿里云新推出新一代关系型数据库，主要思想是计算和存储分离架构，使用共享存储技术。由于写入还是单点写入，插入性能有上限，未来我们的数据采集规模还会进一步提升，这有可能成为一个瓶颈。另外由于只有一个只读实例，在对大表进行并发查询时性能表现一般。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 选择 TiDB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在经历了痛苦的传统解决方案的折磨以及大量调研及对比后，卡思数据最终选择了 TiDB 作为数据仓库及业务数据库。&lt;/p&gt;&lt;p&gt;TiDB 结合了传统的 RDBMS 和 NoSQL 的最佳特性，高度兼容 MySQL，具备强一致性和高可用性，100% 支持标准的 ACID 事务。由于是 Cloud Native 数据库，可通过并行计算发挥机器性能，在大数量的查询下性能表现良好，并且支持无限的水平扩展，可以很方便的通过加机器解决性能和容量问题。另外提供了非常完善的运维工具，大大减轻数据库的运维工作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;上线 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;卡思数据目前配置了两个 32C64G 的 TiDB、三个 4C16G 的 PD、四个 32C128G 的 TiKV。数据量大约 60 亿条、4TB 左右，每天新增数据量大约 5000 万，单节点 QPS 峰值为 3000 左右。&lt;/p&gt;&lt;p&gt;由于数据迁移不能影响线上业务，卡思数据在保持继续使用原数据架构的前提下，使用 Mydumper、Loader 进行数据迁移，并在首轮数据迁移完成后使用 Syncer 进行增量同步。&lt;/p&gt;&lt;p&gt;卡思数据部署了数据库监控系统（Prometheus/Grafana）来实时监控服务状态，可以非常清晰的查看服务器问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;由于 TiDB 对 MySQL 的高度兼容性，在数据迁移完成后，几乎没有对代码做任何修改，平滑实现了无侵入升级。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前卡思数据的架构如图 3：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fac44545432ecf26d884a7440c333c9f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;794&quot; data-rawheight=&quot;606&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fac44545432ecf26d884a7440c333c9f&quot; data-watermark-src=&quot;v2-75128212ab54ea15dc91b47a7cce596d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 3 目前卡思数据架构图&lt;/p&gt;&lt;p&gt;查询性能，单表最小 1000 万，最大 8 亿，有比较复杂的连表查询，整体响应延时非常稳定，监控展示如图 4、图 5。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-54d64dec60af44a379f55b6ff9b4ab84_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;279&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-54d64dec60af44a379f55b6ff9b4ab84&quot; data-watermark-src=&quot;v2-5c0d79b3b7dfa1bd50565bca3bc4dbe0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 4 Duration 监控展示图&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0ac9b8d8cd9b6de67cac4a3540531b85_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;244&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0ac9b8d8cd9b6de67cac4a3540531b85&quot; data-watermark-src=&quot;v2-a700f65ed736c50ffbc6ad1db8695976&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt; 图 5 QPS 监控展示图&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前的卡思数据已全部迁移至 TiDB，但对 TiDB 的使用还局限在数据存储上，可以说只实现了 OLTP。卡思数据准备深入了解 OLAP，将目前一些需要实时返回的复杂查询、数据分析下推至 TiDB。既减少计算服务的复杂性，又可增加数据的准确性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;感谢 PingCAP&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;非常感谢 PingCAP 小伙伴们在数据库上线过程中的大力支持，每次遇到困难都能及时、细心的给予指导，非常的专业和热心。相信 PingCAP 会越来越好，相信 TiDB 会越来越完善，引领 NewSQL 的发展。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者：刘广信，火星文化技术经理&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-06-48674946</guid>
<pubDate>Tue, 06 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP University · TiDB DBA 官方培训认证计划正式启动</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-31-48098540.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/48098540&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5ac8300d301ef25f49a6b0a7c71d25c4_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;伴随着产品的成熟，TiDB 在越来越多样化的应用场景中落地。在落地过程中，大家遇到问题会寻求官方的答疑和支持，但由于咨询量很大，我们有时无法及时响应。因此，为了赋能社区，提升社区用户满意度，避免因测试用户过多官方无法及时响应的问题，同时打造活跃的 TiDB 技术社区，培养熟悉分布式系统、能独立运维 TiDB 的一流 NewSQL 人才，我们宣布正式成立 &lt;b&gt;PingCAP University。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP University 是 PingCAP 官方设立的对企业和个人进行 TiDB 全线产品培训并认证的部门，其培训讲师团队由来自 PingCAP 官方的资深解决方案架构师、顶尖核心技术研发工程师和高级资深 TiDB DBA 组成，拥有丰富且专业的 TiDB 实践经验和培训经验。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PingCAP University 也在今天正式启动 TiDB DBA 官方培训认证计划。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;通过该培训认证计划，大家可以：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;深度理解 TiDB 架构、原理及最佳实践，具备独立部署、运维和调优 TiDB 的能力&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;提升分布式计算和存储领域的技术前沿视野&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;获得来自 PingCAP 官方的专业技术能力认可，提升个人技术竞争力&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-858843cb89a7ec10d45813c33fc89c29_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;577&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-858843cb89a7ec10d45813c33fc89c29&quot; data-watermark-src=&quot;v2-3e1a2a03a88a23033b9da7cb77327d76&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;培训特色&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;理论与实践结合，强调动手能力（实践超过 50%），提供累计 4 个半天实战&lt;/li&gt;&lt;li&gt;课程滚动更新，包含大量前沿技术解读及实践分享&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB DBA 官方培训认证总览&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;初级 TiDB DBA&lt;/b&gt;：PCTA（PingCAP Certified TiDB Associate）培训及认证&lt;/li&gt;&lt;li&gt;&lt;b&gt;高级 TiDB DBA&lt;/b&gt;：PCTP（PingCAP Certified TiDB Professional） 培训及认证&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-092ade55e28a33bfb8fc788fd4eb1575_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1032&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-092ade55e28a33bfb8fc788fd4eb1575&quot; data-watermark-src=&quot;v2-ebfab4252b3e30025bc0343616c46173&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;培训及考试安排&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PCTA：线上培训及考试&lt;/li&gt;&lt;li&gt;PCTP：线下小班集中培训及考试，时间地点由 PingCAP 统一安排&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;垂询及报名方式&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;点击 &lt;a href=&quot;http://pingcaptidb.mikecrm.com/KXCarRw&quot;&gt;这里&lt;/a&gt; 直接填写报名信息&lt;/li&gt;&lt;li&gt;或联系您的客户总监&lt;/li&gt;&lt;li&gt;或发送邮件至 university-cn@pingcap.com 交流&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;P.S. 2018 年 11 月 30 日前报名还有&lt;b&gt;【官方技术支持服务礼包】&lt;/b&gt;赠送～&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-31-48098540</guid>
<pubDate>Wed, 31 Oct 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
