<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Tue, 23 Oct 2018 23:39:06 +0800</lastBuildDate>
<item>
<title>一致性模型</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-23-47445841.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47445841&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c8b584a8186554d98b4bb5442eeeafcd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘（siddontang）&lt;/p&gt;&lt;p&gt;有时候，在跟一些同学讨论 TiKV 事务模型的时候，我都提到了 Linearizability，也提到了 Snapshot Isolation，以及需要手动 lock 来保证 Serializable Snapshot Isolation，很多时候，当我嘴里面蹦出来这些名词的时候，有些同学就一脸懵逼了。所以我觉得有必要仔细来解释一下，顺带让我自己将所有的 isolation 以及 consistency 这些情况都归纳总结一遍，让自己也理解透彻一点。&lt;/p&gt;&lt;p&gt;幸运的是，业内已经有很多人做了这个事情，譬如在 &lt;a href=&quot;http://www.vldb.org/pvldb/vol7/p181-bailis.pdf&quot;&gt;Highly Available Transactions: Virtues and Limitations&lt;/a&gt; 这篇论文里面，作者就总结了不同模型是否能满足 Highly Available Transactions(HATs)。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-38087fea60b99e9c2e34a151c1cd6a08_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;258&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-38087fea60b99e9c2e34a151c1cd6a08&quot; data-watermark-src=&quot;v2-7ee2fd316c00de39dcf3b26620cce6a0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;图中，红色圆圈里面的模型属于 Unavailable，蓝色的属于 Sticky Available，其余的就是  Highly Available。这里解释下相关的含义：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Unavailable：当出现网络隔离等问题的时候，为了保证数据的一致性，不提供服务。熟悉 CAP 理论的同学应该清楚，这就是典型的 CP 系统了。&lt;/li&gt;&lt;li&gt;Sticky Available：即使一些节点出现问题，在一些还没出现故障的节点，仍然保证可用，但需要保证 client 的操作是一致的。&lt;/li&gt;&lt;li&gt;Highly Available：就是网络全挂掉，在没有出现问题的节点上面，仍然可用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Unavailable 比较容易理解，这里在讨论下 Sticky 和 Highly，对于 Highly Available 来说，如果一个 server 挂掉了，client 可以去连接任意的其他 server，如果这时候仍然能获取到结果，那么就是 Highly Available 的。但对于 Sticky 来说，还需要保证 client 操作的一致性，譬如 client 现在 server 1 上面进行了很多操作，这时候 server 1 挂掉了，client 切换到 server 2，但在 server 2 上面看不到 client 之前的操作结果，那么这个系统就不是 Sticky 的。所有能在 Highly Available 系统上面保证的事情一定也能在 Sticky Available 系统上面保证，但反过来就不一定了。&lt;/p&gt;&lt;p&gt;Jepsen 在&lt;a href=&quot;https://jepsen.io/consistency&quot;&gt;官网&lt;/a&gt;上面有一个简化但更好看一点的图&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb3847f8b9e69b1154cfdf6591af0202_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bb3847f8b9e69b1154cfdf6591af0202&quot; data-watermark-src=&quot;v2-706a307a3c684b7713aa678335b0baa9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;下面，我会按照 Jepsen 里面的图，对不同的 model 进行解释一下。至于为啥选择 Jepsen 里面的例子，一个是因为 Jepsen 现在是一款主流的测试不同分布式系统一致性的工具，它的测试用例就是测试的是上图提到的模型，我们自然也会关心这些模型。另外一个就是这个模型已经覆盖了大多数场景了，理解了这些，大部分都能游刃有余处理了。&lt;/p&gt;&lt;p&gt;如果大家仔细观察，可以发现，从根节点 Strict Serializable，其实是有两个分支的，一个对应的就是数据库里面的 Isolation（ACID 里面的 I），另一个其实对应的是分布式系统的 Consistency（CAP 里面的 C），在 HATs 里面，叫做 Session Guarantees。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Isolation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;要对 Isolation 有个快速的理解，其实只需要看 &lt;a href=&quot;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf&quot;&gt;A Critique of ANSI SQL Isolation Levels&lt;/a&gt; 这篇论文就足够了，里面详细的介绍了数据库实现中遇到的各种各样的 isolation 问题，以及不同的 isolation level 到底能不能解决。&lt;/p&gt;&lt;p&gt;在论文里面，作者详细的列举了多种异常现象，这里大概介绍一下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P0 - Dirty Write&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Dirty Write 就是一个事务，覆盖了另一个之前还未提交事务写入的值。假设现在我们有两个事务，一个事务写入 x = y = 1，而另一个事务写入 x = y = 2，那么最终的结果，我们是希望看到 x 和 y 要不全等于 1，要不全等于 2。但在 Dirty Write 情况下面，可能会出现如下情况：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f9420db92296f248e521212a86bd33d1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;310&quot; data-rawheight=&quot;177&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f9420db92296f248e521212a86bd33d1&quot; data-watermark-src=&quot;v2-55a99d7a4bcd04bb2d166e9ac33009a3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;可以看到，最终的值是 x = 2 而 y = 1，已经破坏了数据的一致性了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P1 - Dirty Read&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Dirty Read 出现在一个事务读取到了另一个还未提交事务的修改数据。假设现在我们有一个两个账户，x 和 y，各自有 50 块钱，x 需要给 y 转 40 元钱，那么无论怎样，x + y = 100 这个约束是不能打破的，但在 Dirty Read 下面，可能出现：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a2b718ff1efaf2a194275bfb7ff1bced_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;343&quot; data-rawheight=&quot;172&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a2b718ff1efaf2a194275bfb7ff1bced&quot; data-watermark-src=&quot;v2-e6146413f66d4fe5679ec476ea9633be&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在事务 T2，读取到的 x + y = 60，已经打破了约束条件了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P2 - Fuzzy Read&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Fuzzy Read 也叫做 Non-Repeatable Read，也就是一个还在执行的事务读取到了另一个事务的更新操作，仍然是上面的转账例子：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d827daeddda6b1707d9d721f95a9f1db_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;341&quot; data-rawheight=&quot;166&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d827daeddda6b1707d9d721f95a9f1db&quot; data-watermark-src=&quot;v2-909c1d04a9fe89a09272b083bf22b579&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在 T1 还在运行的过程中，T2 已经完成了转账，但 T1 这时候能读到最新的值，也就是 x + y = 140 了，破坏了约束条件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P3 - Phantom&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Phantom 通常发生在一个事务首先进行了一次按照某个条件的 read 操作，譬如 SQL 里面的 &lt;code class=&quot;inline&quot;&gt;SELECT WHERE P&lt;/code&gt;，然后在这个事务还没结束的时候，另外的事务写入了一个新的满足这个条件的数据，这时候这个新写入的数据就是 Phantom 的了。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2f8f49d023908e37d376c59fe70b83fe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;555&quot; data-rawheight=&quot;163&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2f8f49d023908e37d376c59fe70b83fe&quot; data-watermark-src=&quot;v2-c68b450aacc22072b667197b5fca85ab&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;假设现在 T1 按照某个条件读取到了所有雇员 a，b，c，这时候 count 是 3，然后 T2 插入了一个新的雇员 d，同时更新了 count 为 4，但这时候 T1 在读取 count 的时候会得到 4，已经跟之前读取到的 a，b，c 冲突了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P4 - Lost Update&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们有时候也会遇到一种 Lost Update 的问题，如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0ec0ae1e2ab8faf39d3a2ac241805d5a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;275&quot; data-rawheight=&quot;132&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0ec0ae1e2ab8faf39d3a2ac241805d5a&quot; data-watermark-src=&quot;v2-22e2ce89eb33e3b91d492ffa7559d430&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在上面的例子中，我们没有任何 dirty write，因为 T2 在 T1 更新之前已经提交成功，也没有任何 dirty read，因为我们在 write 之后没有任何 read 操作，但是，当整个事务结束之后，T2 的更新其实丢失了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P4C - Cursor Lost Update&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Cursor Lost Update 是上面 Lost Update 的一个变种，跟 SQL 的 cursor 相关。在下面的例子中，RC(x) 表明在 cursor 下面 read x，而 WC(x) 则表明在 cursor 下面写入 x。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-41b6ac72eef6631f1a1b519b1bae22ec_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;317&quot; data-rawheight=&quot;134&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-41b6ac72eef6631f1a1b519b1bae22ec&quot; data-watermark-src=&quot;v2-f043051e2c5dcb038d9ca5dac74724c2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如果我们允许 T2 在  T1 RC 和 WC 之间写入数据，那么 T2 的更新也会丢失。&lt;/p&gt;&lt;p&gt;&lt;b&gt;A5A - Read Skew&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Read Skew 发生在两个或者多个有完整性约束的数据上面，还是传统的转账例子，需要保证 x + y = 100，那么 T1 就会看到不一致的数据了。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bee88aafb7485a0ee2b236dfbf1fc7fe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;342&quot; data-rawheight=&quot;168&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bee88aafb7485a0ee2b236dfbf1fc7fe&quot; data-watermark-src=&quot;v2-1d53742a9442a787055a5570a211b7d7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;A5B - Write Skew&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Write Skew 跟 Read Skew 比较类似，假设 x + y &amp;lt;= 100，T1 和 T2 在执行的时候都发现满足约束，然后 T1 更新了 y，而 T2 更新了 x，然后最终结果打破了约束，如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27784693015ffe46fde0048b629336fc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;339&quot; data-rawheight=&quot;163&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-27784693015ffe46fde0048b629336fc&quot; data-watermark-src=&quot;v2-cbbd6978ff401beb981159d476f26e1b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;Isolation Levels&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面我们介绍了不同的异常情况，下面的表格说明了，在不同的隔离级别下面，那些异常情况可能发生：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98b3731ffae0c53321617da70017601a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;630&quot; data-rawheight=&quot;271&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-98b3731ffae0c53321617da70017601a&quot; data-watermark-src=&quot;v2-e879cb84c711e5d3f411752013581b54&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;NP - Not Possible，在该隔离级别下面不可能发生&lt;/li&gt;&lt;li&gt;SP - Sometimes Possible，在该隔离级别下面有时候可能发生&lt;/li&gt;&lt;li&gt;P - Possible，在该隔离级别下面会发生&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;鉴于网上已经对不同的 Isolation Level，尤其是 MySQL 的解释的太多了，这里就简单的解释一下。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Read Uncommitted - 能读到另外事务未提交的修改。&lt;/li&gt;&lt;li&gt;Read Committed - 能读到另外事务已经提交的修改。&lt;/li&gt;&lt;li&gt;Cursor Stability - 使用 cursor 在事务里面引用特定的数据，当一个事务用 cursor 来读取某个数据的时候，这个数据不可能被其他事务更改，除非 cursor 被释放，或者事务提交。&lt;/li&gt;&lt;li&gt;Monotonic Atomic View - 这个级别是 read committed 的增强，提供了一个原子性的约束，当一个在 T1 里面的 write 被另外事务 T2 观察到的时候，T1 里面所有的修改都会被 T2 给观察到。&lt;/li&gt;&lt;li&gt;Repeatable Read - 可重复读，也就是对于某一个数据，即使另外的事务有修改，也会读取到一样的值。&lt;/li&gt;&lt;li&gt;Snapshot - 每个事务都会在各自独立，一致的 snapshot 上面对数据库进行操作。所有修改只有在提交的时候才会对外可见。如果 T1 修改了某个数据，在提交之前另外的事务 T2 修改并提交了，那么 T1 会回滚。&lt;/li&gt;&lt;li&gt;Serializable - 事务按照一定顺序执行。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外需要注意，上面提到的 isolation level 都不保证实时约束，如果一个进程 A 完成了一次写入 w，然后另外的进程 B 开始了一次读取 r，r 并不能保证观察到 w 的结果。另外，在不同事务之间，这些 isolation level 也不保证不同进程的顺序。一个进程可能在一次事务里面看到一次写入 w，但可能在后面的事务上面没看到同样的 w。事实上，一个进程甚至可能看不到在这个进程上面之前的写入，如果这些写入都是发生在不同的事务里面。有时候，他们还可能会对事务进行排序，譬如将 write-only 的事务放到所有的 read 事务的后面。&lt;/p&gt;&lt;p&gt;要解决这些问题，我们需要引入顺序约束，这也就是下面 Session Guarantee 要干的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Session Guarantee&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 HATs 论文里面，相关的概念叫做 Session Guarantee，主要是用来保证在一个 session 里面的实时性约束以及客户端的操作顺序。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Writes Follow Reads&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果某个进程读到了一次写入 w1 写入的值 v，然后进行了一次新的写入 w2，那么 w2 写入的值将会在 w1 之后可见。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Monotonic Reads&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个进程开始了一次读取 r1，然后在开始另一次读取 r2，那么 r2 不可能看到 r1 之前数据。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Monotonic Writes&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个进程先进行了一次写入 w1，然后在进行了一次写入 w2，那么所有其他的进程都会观察到 w1 在 w2 之前发生。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Read Your Writes&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个进程先进行了一次写入 w，然后后面执行了一次读取 r，那么 r 一定会看到 w 的改动。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PRAM&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PRAM 就是 Pipeline Random Access Memory，对于单个进程的写操作都被观察到是顺序的，但不同的进程写会观察到不同的顺序。譬如下面这个操作是满足 PRAM 的，但不满足后面说的 Causal。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff2541b159c86357affa7d99ea5ada82_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;310&quot; data-rawheight=&quot;165&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ff2541b159c86357affa7d99ea5ada82&quot; data-watermark-src=&quot;v2-803e3938c3a11c087360711b85e30659&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;Causal&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Causal 确定了有因果关系的操作在所有进程间的一致顺序。譬如下面这个：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-83163b55feb11508651baa8e834f7369_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;358&quot; data-rawheight=&quot;162&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-83163b55feb11508651baa8e834f7369&quot; data-watermark-src=&quot;v2-dc8e7b39dd320e689f93f8656748865c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 和 P4 来说，无论是先读到 2，还是先读到 1， 都是没问题的，因为 P1 和 P2 里面的 write 操作并没有因果性，是并行的。但是下面这个：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6b1daeebfd990cecb82687b46d80418c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;360&quot; data-rawheight=&quot;165&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6b1daeebfd990cecb82687b46d80418c&quot; data-watermark-src=&quot;v2-a579e40eaa5a6c55bbc68c02a3a2c596&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;就不满足 Cansal 的一致性要求了，因为对于 P2 来说，在 Write 2 之前，进行了一次 Read 1 的操作，已经确定了 Write 1 会在 Write 2 之前发生，也就是确定了因果关系，所以 P3 打破了这个关系。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sequential&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Sequential 会保证操作按照一定顺序发生，并且这个顺序会在不同的进程上面都是一致的。一个进程会比另外的进程超前，或者落后，譬如这个进程可能读到了已经是陈旧的数据，但是，如果一个进程 A 从进程 B 读到了某个状态，那么它就不可能在读到 B 之前的状态了。&lt;/p&gt;&lt;p&gt;譬如下面的操作就是满足 Sequential 的：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e254f620c178957e286dedc8b39521c6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;357&quot; data-rawheight=&quot;161&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e254f620c178957e286dedc8b39521c6&quot; data-watermark-src=&quot;v2-a54247f317d5539b43f6f1d43bfe7bc7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 来说，它仍然能读到之前的 stale 状态 1。但下面的就不对了：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0894ed397fa0d0bcbfc5e8ad9a47dfbf_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;358&quot; data-rawheight=&quot;164&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0894ed397fa0d0bcbfc5e8ad9a47dfbf&quot; data-watermark-src=&quot;v2-443516e6968a62e0a43cf08e7d87e6a4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 来说，它已经读到了最新的状态 2，就不可能在读到之前的状态 1 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Linearizable&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Linearizability 要求所有的操作都是按照一定的顺序原子的发生，而这个顺序可以认为就是跟操作发生的时间一致的。也就是说，如果一个操作 A 在 B 开始之前就结束了，那么 B 只可能在 A 之后才能产生作用。&lt;/p&gt;&lt;p&gt;譬如下面的操作：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f66bc3e9f6504131cf24a2a940cd94f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;302&quot; data-rawheight=&quot;161&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3f66bc3e9f6504131cf24a2a940cd94f&quot; data-watermark-src=&quot;v2-f876bd93b74fe1b9d004ffd3a171c148&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 和 P4 来说，因为之前已经有新的写入，所以他们只能读到 2，不可能读到 1。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Strict Serializable&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;终于来到了 Strict Serializable，大家可以看到，它结合了 serializable 以及 linearizable，也就是说，它会让所有操作按照实时的顺序依次操作，也就是所有的进程会观察到完全一致的顺序，这也是最强的一致性模型了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;好了，最后再来聊聊 &lt;a href=&quot;https://github.com/tikv/tikv&quot;&gt;TiKV&lt;/a&gt;，TiKV 是一个支持分布式事务的 key-value database。对于某个事务，TiKV 会通过 PD 这个服务在事务开始的时候分配一个 start timestamp，以及事务提交的时候分配一个 commit timestamp。因为我们的授时是通过 PD 这个单点服务进行的，所以时间是一定能保证单调递增的，也就是说，我们所有的操作都能跟保证实时有序，也就是满足 Linearizable。&lt;/p&gt;&lt;p&gt;TiKV 采用的是常用的 MVCC 模型，也就是每个 key-value 实际存储的时候，会在 key 上面带一个 timestamp，我们就可以用 timestamp 来生成整个数据库的 snapshot 了，所以 TiKV 是 snapshot isolation 的。既然是 snapshot isolation，那么就会遇到 write skew 问题，所以 TiKV 额外提供了 serializable snapshot isolation，用户需要显示的对要操作的数据进行 lock 操作。&lt;/p&gt;&lt;p&gt;但现在 TiKV 并不支持对 range 加 lock，所以不能完全的防止 phantom，譬如假设最多允许 8 个任务，现在已经有 7 个任务了，我们还可以添加一个任务，但这时候另外一个事务也做了同样的事情，但添加的是不同的任务，这时候就会变成 9 个任务，另外的事务在 scan 的时候就会发现打破了约束。这个也就是 A Critique of ANSI SQL Isolation Levels 里面提到的 sometimes possible。&lt;/p&gt;&lt;p&gt;所以，TiKV 是 snapshot isolation + linearizable。虽然 TiKV 也可以支持 Read Committed，但通常不建议在生产环境中使用，因为 TiKV 的 Read Committed 跟传统的还不太一样，可能会出现能读到一个事务提交到某个节点的数据，但这时候在另外的节点还读不到这个事务提交的数据，毕竟在分布式系统下面，不同节点的事务提交也是有网络延迟的，不可能同时执行。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在分布式系统里面，一致性是非常重要的一个概念，理解了它，在自己设计分布式系统的时候，就能充分的考虑到底系统应该提供怎样的一致性模型。譬如对于 TP 数据库来说，就需要有一个比较 strong 的一致性模型，而对于一些不重要的系统，譬如 cache 这些，就可以使用一些比较 weak 的模型。对 TiKV 来说，我们在 Percolator 基础上面，也一直在致力于分布式事务的优化，如果你对这方面感兴趣，欢迎联系我 tl@pingcap.com。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;原文链接：&lt;a href=&quot;https://www.jianshu.com/p/3673e612cce2&quot;&gt;一致性模型&lt;/a&gt;&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;延展阅读 &lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;i&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486947&amp;amp;idx=1&amp;amp;sn=28f3fe47d380e0ee991c207251fdd415&amp;amp;chksm=eb162a89dc61a39f47bb4d3f90be9789f4b7f0a23ada7979ee65d21efcb43edd9f5e8254ff2b&amp;amp;scene=21#wechat_redirect&quot;&gt;线性一致性和 Raft&lt;/a&gt;&lt;/i&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;i&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486842&amp;amp;idx=1&amp;amp;sn=2e21e65010f497693f26cfc344e418fe&amp;amp;chksm=eb162a10dc61a30650269d414de2cfe4eeff08e0d5e9b50834c3353c70850c83b796fd2be364&amp;amp;scene=21#wechat_redirect&quot;&gt;TiKV 是如何存取数据的（上）&lt;/a&gt;&lt;/i&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;i&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486872&amp;amp;idx=1&amp;amp;sn=1f8d7e88cd92878142a444c2aea8e764&amp;amp;chksm=eb162af2dc61a3e4a6675f86f91e8bd97886b6fd8006662df2f8e58f5190514a192a259beb25&amp;amp;scene=21#wechat_redirect&quot;&gt;TiKV 是如何存储数据的（下）&lt;/a&gt;&lt;/i&gt;&lt;/u&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-23-47445841</guid>
<pubDate>Tue, 23 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>线性一致性和 Raft</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-22-47117804.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47117804&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-85e813810e9221590c5a48b11d906dc2_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：沈泰宁&lt;/p&gt;&lt;p&gt;在讨论分布式系统时，共识算法（Consensus algorithm）和一致性（Consistency）通常是讨论热点，两者的联系很微妙，很容易搞混。一些常见的误解：使用了 Raft [0] 或者 paxos 的系统都是线性一致的（Linearizability [1]，即强一致），其实不然，共识算法只能提供基础，要实现线性一致还需要在算法之上做出更多的努力。以 TiKV 为例，它的共识算法是 Raft，在 Raft 的保证下，TiKV 提供了满足线性一致性的服务。&lt;/p&gt;&lt;p&gt;本篇文章会讨论一下线性一致性和 Raft，以及 TiKV 针对前者的一些优化。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;线性一致性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;什么是一致性，简单的来说就是评判一个并发系统正确与否的标准。线性一致性是其中一种，CAP [2] 中的 C 一般就指它。什么是线性一致性，或者说怎样才能达到线性一致？在回答这个问题之前先了解一些背景知识。&lt;/p&gt;&lt;p&gt;&lt;b&gt;背景知识&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了回答上面的问题，我们需要一种表示方法描述分布式系统的行为。分布式系统可以抽象成几个部分:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Client&lt;/li&gt;&lt;li&gt;Server&lt;/li&gt;&lt;li&gt;Events&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Invocation&lt;/li&gt;&lt;li&gt;Response&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Operations&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Read&lt;/li&gt;&lt;li&gt;Write&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;一个分布式系统通常有两种角色，Client 和 Server。Client 通过发起请求来获取 Server 的服务。一次完整请求由两个事件组成，Invocation（以下简称 Inv）和 Response（以下简称 Resp）。一个请求中包含一个 Operation，有两种类型 Read 和 Write，最终会在 Server 上执行。&lt;/p&gt;&lt;p&gt;说了一堆不明所以的概念，现在来看如何用这些表示分布式系统的行为。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c6efe0b1804c98ae04cd2ba866aea6f9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;232&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c6efe0b1804c98ae04cd2ba866aea6f9&quot; data-watermark-src=&quot;v2-2dbf1014330a7675f4198926546c6826&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图展示了 Client A 的一个请求从发起到结束的过程。变量 x 的初始值是 1，“x R() A” 是一个事件 Inv 意思是 A 发起了读请求，相应的 “x OK(1) A” 就是事件 Resp，意思是 A 读到了 x 且值为 1，Server 执行读操作（Operation）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如何达到线性一致&lt;/b&gt;&lt;/p&gt;&lt;p&gt;背景知识介绍完了，怎样才能达到线性一致？这就要求 Server 在执行 Operations 时需要满足以下三点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;瞬间完成（或者原子性）&lt;/li&gt;&lt;li&gt;发生在 Inv 和 Resp 两个事件之间&lt;/li&gt;&lt;li&gt;反映出“最新”的值&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下面我举一个例子，用以解释上面三点。&lt;/p&gt;&lt;p&gt;&lt;b&gt;例：&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6465b3ad4bd77c4926e2786c020b5c46_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;799&quot; data-rawheight=&quot;440&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6465b3ad4bd77c4926e2786c020b5c46&quot; data-watermark-src=&quot;v2-83bbf021252b353fec99845780381d71&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;先下结论，上图表示的行为满足线性一致。&lt;/p&gt;&lt;p&gt;对于同一个对象 x，其初始值为 1，客户端 ABCD 并发地进行了请求，按照真实时间（real-time）顺序，各个事件的发生顺序如上图所示。对于任意一次请求都需要一段时间才能完成，例如 A，“x R() A” 到 “x Ok(1) A” 之间的那条线段就代表那次请求花费的时间，而请求中的读操作在 Server 上的执行时间是很短的，相对于整个请求可以认为瞬间，读操作表示为点，并且在该线段上。线性一致性中没有规定读操作发生的时刻，也就说该点可以在线段上的任意位置，可以在中点，也可以在最后，当然在最开始也无妨。&lt;/p&gt;&lt;p&gt;第一点和第二点解释的差不多了，下面说第三点。&lt;/p&gt;&lt;p&gt;反映出“最新”的值？我觉得三点中最难理解就是它了。先不急于对“最新”下定义，来看看上图中 x 所有可能的值，显然只有 1 和 2。四个次请求中只有 B 进行了写请求，改变了 x 的值，我们从 B 着手分析，明确 x 在各个时刻的值。由于不能确定 B 的 W（写操作）在哪个时刻发生，能确定的只有一个区间，因此可以引入&lt;b&gt;上下限&lt;/b&gt;的概念。对于 x=1，它的上下限为&lt;b&gt;开始到事件“x W(2) B”&lt;/b&gt;，在这个范围内所有的读操作必定读到 1。对于 x=2，它的上下限为 &lt;b&gt;事件“x Ok() B”&lt;/b&gt; 到结束，在这个范围内所有的读操作必定读到 2。那么“x W(2) B”到“x Ok() B”这段范围，x 的值是什么？&lt;b&gt;1 或者 2&lt;/b&gt;。由此可以将 x 分为三个阶段，各阶段”最新”的值如下图所示:&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-14f1c87da0956711e7d1325446ea2619_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;996&quot; data-rawheight=&quot;614&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-14f1c87da0956711e7d1325446ea2619&quot; data-watermark-src=&quot;v2-196f91a809357196ccf0e3ef5881865f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;清楚了 x 的变化后理解例子中 A C D 的读到结果就很容易了。&lt;/p&gt;&lt;p&gt;最后返回的 D 读到了 1，看起来是 “stale read”，其实并不是，它仍满足线性一致性。D 请求横跨了三个阶段，而读可能发生在任意时刻，所以 1 或 2 都行。同理，A 读到的值也可以是 2。C 就不太一样了，C 只有读到了 2 才能满足线性一致。因为 “x R() C” 发生在 “x Ok() B” 之后（happen before [3]），可以推出 R 发生在 W 之后，那么 R 一定得读到 W 完成之后的结果：2。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一句话概括：在分布式系统上实现寄存器语义。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;实现线性一致&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如开头所说，一个分布式系统正确实现了共识算法并不意味着能线性一致。共识算法只能保证多个节点对某个对象的状态是一致的，以 Raft 为例，它只能保证不同节点对 Raft Log（以下简称 Log）能达成一致。那么 Log 后面的状态机（state machine）的一致性呢？并没有做详细规定，用户可以自由实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Raft 是一个强 Leader 的共识算法，只有 Leader 能处理客户端的请求，集群的数据（Log）的流向是从 Leader 流向 Follower。其他的细节在这就不赘述了，网上有很多资料 [4]。&lt;/p&gt;&lt;p&gt;In Practice&lt;/p&gt;&lt;p&gt;以 TiKV 为例，TiKV 内部可分成多个模块，Raft 模块，RocksDB 模块，两者通过 Log 进行交互，整体架构如下图所示，consensus 就是 Raft 模块，state machine 就是 RocksDB 模块。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-18b6d578da3ad19604d89bfc0dbe7641_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;627&quot; data-rawheight=&quot;389&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-18b6d578da3ad19604d89bfc0dbe7641&quot; data-watermark-src=&quot;v2-fcadf6608de8a0d1478f67e3838f0943&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Client 将请求发送到 Leader 后，Leader 将请求作为一个 Proposal 通过 Raft 复制到自身以及 Follower 的 Log 中，然后将其 commit。TiKV 将 commit 的 Log 应用到 RocksDB 上，由于 Input（即 Log）都一样，可推出各个 TiKV 的状态机（即 RocksDB）的状态能达成一致。但实际多个 TiKV 不能保证同时将某一个 Log 应用到 RocksDB 上，也就是说各个节点不能&lt;b&gt;实时&lt;/b&gt;一致，加之 Leader 会在不同节点之间切换，所以 Leader 的状态机也不总有最新的状态。Leader 处理请求时稍有不慎，没有在最新的状态上进行，这会导致整个系统违反线性一致性。&lt;b&gt;好在有一个很简单的解决方法：依次应用 Log，将应用后的结果返回给 Client。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这方法不仅简单还通用，读写请求都可以这样实现。这个方法依据 commit index 对所有请求都做了排序，使得每个请求都能反映出状态机在执行完前一请求后的状态，可以认为 commit 决定了 R/W 事件发生的顺序。Log 是严格全序的（total order），那么自然所有 R/W 也是全序的，将这些 R/W 操作一个一个应用到状态机，所得的结果必定符合线性一致性。这个方法的缺点很明显，性能差，因为所有请求在 Log 那边就被序列化了，无法并发的操作状态机。&lt;br&gt;这样的读简称 LogRead。由于读请求不改变状态机，这个实现就显得有些“重“，不仅有 RPC 开销，还有写 Log 开销。优化的方法大致有两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;ReadIndex&lt;/li&gt;&lt;li&gt;LeaseRead&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;ReadIndex&lt;/b&gt;&lt;/p&gt;&lt;p&gt;相比于 LogRead，ReadIndex 跳过了 Log，节省了磁盘开销，它能大幅提升读的吞吐，减小延时（但不显著）。Leader 执行 ReadIndex 大致的流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;记录当前的 commit index，称为 ReadIndex&lt;/li&gt;&lt;li&gt;向 Follower 发起一次心跳，如果大多数节点回复了，那就能确定现在仍然是 Leader&lt;/li&gt;&lt;li&gt;等待状态机&lt;b&gt;至少&lt;/b&gt;应用到 ReadIndex 记录的 Log&lt;/li&gt;&lt;li&gt;执行读请求，将结果返回给 Client&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;第 3 点中的“至少”是关键要求，它表明状态机应用到 ReadIndex 之后的状态都能使这个请求满足线性一致，不管过了多久，也不管 Leader 有没有飘走。为什么在 ReadIndex 只有就满足了线性一致性呢？之前 LogRead 的读发生点是 commit index，这个点能使 LogRead 满足线性一致，那显然发生这个点之后的 ReadIndex 也能满足。&lt;/p&gt;&lt;p&gt;&lt;b&gt;LeaseRead&lt;/b&gt;&lt;/p&gt;&lt;p&gt;LeaseRead 与 ReadIndex 类似，但更进一步，不仅省去了 Log，还省去了网络交互。它可以大幅提升读的吞吐也能显著降低延时。基本的思路是 Leader 取一个比 Election Timeout 小的租期，在租期不会发生选举，确保 Leader 不会变，所以可以跳过 ReadIndex 的第二步，也就降低了延时。 LeaseRead 的正确性和时间挂钩，因此时间的实现至关重要，如果漂移严重，这套机制就会有问题。&lt;/p&gt;&lt;p&gt;Wait Free&lt;/p&gt;&lt;p&gt;到此为止 Lease 省去了 ReadIndex 的第二步，实际能再进一步，省去第 3 步。这样的 LeaseRead 在收到请求后会立刻进行读请求，不取 commit index 也不等状态机。由于 Raft 的强 Leader 特性，在租期内的 Client 收到的 Resp 由 Leader 的状态机产生，所以只要状态机满足线性一致，那么在 Lease 内，不管何时发生读都能满足线性一致性。有一点需要注意，只有在 Leader 的状态机应用了当前 term 的第一个 Log 后才能进行 LeaseRead。因为新选举产生的 Leader，它虽然有全部 committed Log，但它的状态机可能落后于之前的 Leader，状态机应用到当前 term 的 Log 就保证了新 Leader 的状态机一定新于旧 Leader，之后肯定不会出现 stale read。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文粗略地聊了聊线性一致性，以及 TiKV 内部的一些优化。最后留四个问题以便更好地理解本文：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;对于线性一致中的例子，如果 A 读到了 2，那么 x 的各个阶段是怎样的呢？&lt;/li&gt;&lt;li&gt;对于下图，它符合线性一致吗？（温馨提示：请使用游标卡尺。;-P）&lt;/li&gt;&lt;/ol&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-58c02cee775ff40a6f89e29afb3e7fe5_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;739&quot; data-rawheight=&quot;432&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-58c02cee775ff40a6f89e29afb3e7fe5&quot; data-watermark-src=&quot;v2-165658e7cfbec5e0b5c61f0df93c982a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;3. Leader 的状态机在什么时候没有最新状态？要线性一致性，Raft 该如何解决这问题？&lt;/p&gt;&lt;p&gt;4. FollowerRead 可以由 ReadIndex 实现，那么能由 LeaseRead 实现吗？&lt;/p&gt;&lt;p&gt;如有疑问或想交流，欢迎联系我：&lt;b&gt;shentaining@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;[0].Ongaro, Diego. Consensus: Bridging theory and practice. Diss. Stanford University, 2014.&lt;br&gt;[1].Herlihy, Maurice P., and Jeannette M. Wing. “Linearizability: A correctness condition for concurrent objects.” ACM Transactions on Programming Languages and Systems (TOPLAS) 12.3 (1990): 463-492.&lt;br&gt;[2].Gilbert, Seth, and Nancy Lynch. “Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services.” Acm Sigact News 33.2 (2002): 51-59.&lt;br&gt;[3].Lamport, Leslie. “Time, clocks, and the ordering of events in a distributed system.” Communications of the ACM 21.7 (1978): 558-565.&lt;br&gt;[4].&lt;a href=&quot;https://raft.github.io/&quot;&gt;https://raft.github.io/&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-22-47117804</guid>
<pubDate>Mon, 22 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>成都 Meetup 预告 |  PingCAP 成都分舵第一次干货分享趴</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-18-47050511.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47050511&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6c06b1218c416abf3c2b2c8b3b3a32fd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;i&gt;&lt;b&gt;Hit!!! &lt;/b&gt;&lt;/i&gt;社区小伙伴期待已久的「西南第一分舵」——&lt;i&gt;&lt;b&gt;成都 Office&lt;/b&gt;&lt;/i&gt;正式成立了！&lt;br&gt;我们将在本周日举办一场 Infra Meetup，欢迎新老朋友过来面基～不管你是想聊一聊技术干货还是想加入分舵，都可以点击文末链接直接报名来现场交流！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;PingCAP Infra Meetup No.77&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;🚀 时间：2018-10-21  周日  13:00 - 16:00&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;🛸 地点：成都武侯区吉泰路银泰城 17 栋 优客工场&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;🚇 交通：&lt;/b&gt;地铁 1 号线天府三街站 B 口出，步行从吉泰路上的银泰城正门进入。银泰城车库入口在天府四街。&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;报名通道&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://www.huodongxing.com/event/8462453900500&quot;&gt;报名：【成都】PingCAP Infra Meetup No.77&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;日程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;13:00 - 13:30  &lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;现场签到&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;13:30 - 14:30 &lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Speaker&lt;/b&gt;&lt;br&gt;&lt;b&gt;申砾&lt;/b&gt;，我司技术副总裁&lt;/li&gt;&lt;li&gt;&lt;b&gt;Talk&lt;/b&gt;&lt;br&gt;Deep Dive into TiDB SQL Layer&lt;/li&gt;&lt;li&gt;&lt;b&gt;Content&lt;/b&gt;&lt;br&gt;本次分享主要涉及 TiDB 和 TiDB SQL 层的架构，带大家深入了解 TiDB SQL 层的优化器和执行引擎。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;14:30 - 14:45 &lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;茶歇&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;14:45 - 15:30 &lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Speaker&lt;/b&gt;&lt;br&gt;李银龙，马上消费金融 NewSQL 负责人，原腾讯云运维工程师，原猪八戒 DBA 团队构建者。「马上消费金融股份有限公司是一家经中国银保监会批准，持有消费金融牌照的科技驱动的金融机构，是注册资本金第一大的内资消费金融公司。」&lt;/li&gt;&lt;li&gt;&lt;b&gt;Talk&lt;/b&gt;&lt;br&gt;马上消费金融 TiDB 实践分享&lt;/li&gt;&lt;li&gt;&lt;b&gt;Content&lt;/b&gt;&lt;br&gt;本次我们将分享在消费金融行业爆发式增长背景下，马上消费金融面对的传统 MySQL 关系型数据库瓶颈与 NewSQL 技术探索实践。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;15:30 - 16:00 &lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;社区圆桌讨论&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;入舵指南&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;成都分舵地址&lt;/b&gt;：天府大道中段 666 号希顿国际中心 C 座&lt;/li&gt;&lt;li&gt;&lt;b&gt;勾搭通道&lt;/b&gt;：hire@pingcap.com&lt;/li&gt;&lt;li&gt;&lt;b&gt;职位信息：&lt;/b&gt;Infrastructure Engineer（包括分布式存储-TiKV、分布式计算-TiDB、分布式调度-PD、商业工具-Tools、SRE、Cloud 等方向）在成都分舵已全面开放，了解更多职位信息：&lt;a href=&quot;https://pingcap.com/recruit-cn/join/&quot;&gt;虚位以待 | PingCAP&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;🧐 报名通道：&lt;a href=&quot;http://www.huodongxing.com/event/8462453900500&quot;&gt;【成都】PingCAP Infra Meetup No.77&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-18-47050511</guid>
<pubDate>Thu, 18 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 是如何存储数据的（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-11-46524530.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46524530&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ef0379b7d20b5347e99e16cc5f6bed9e_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;u&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486842&amp;amp;idx=1&amp;amp;sn=2e21e65010f497693f26cfc344e418fe&amp;amp;chksm=eb162a10dc61a30650269d414de2cfe4eeff08e0d5e9b50834c3353c70850c83b796fd2be364&amp;amp;scene=21#wechat_redirect&quot;&gt;上篇文章&lt;/a&gt;&lt;/u&gt;中，我们介绍了与 TiKV 处理读写请求相关的基础知识，下面将开始详细的介绍 TiKV 的读写流程。Enjoy~&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;作者：唐刘 siddontang&lt;/p&gt;&lt;h2&gt;&lt;b&gt;RawKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiKV 提供两套 API，一套叫做 RawKV，另一套叫做 TxnKV。TxnKV 对应的就是上面提到的 Percolator，而 RawKV 则不会对事务做任何保证，而且比 TxnKV 简单很多，这里我们先讨论 RawKV。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Write&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-08650031b484425439a68ed74eca75c3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;675&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-08650031b484425439a68ed74eca75c3&quot; data-watermark-src=&quot;v2-1fd4a870d321c5da5c89ad8b1e17ccd3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;当进行写入，譬如 Write a = 1，会进行如下步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Client 找 PD 问 a 所在的 Region&lt;/li&gt;&lt;li&gt;PD 告诉 Region 相关信息，主要是 Leader 所在的 TiKV&lt;/li&gt;&lt;li&gt;Client 将命令发送给 Leader 所在的 TiKV&lt;/li&gt;&lt;li&gt;Leader 接受请求之后执行 Raft 流程&lt;/li&gt;&lt;li&gt;Leader 将 a = 1 Apply 到 KV RocksDB 然后给 Client 返回写入成功&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;Read&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-633b8d2972993810a83683ae9a9fbf7f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;660&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-633b8d2972993810a83683ae9a9fbf7f&quot; data-watermark-src=&quot;v2-2f6356ecb30b884ce25ceec89af1c519&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;对于 Read 来说，也是一样的操作，唯一不同在于 Leader 可以直接提供 Read，不需要走 Raft。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TxnKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Write&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d4e569db6e896428f6d61f59dd10b934_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;649&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d4e569db6e896428f6d61f59dd10b934&quot; data-watermark-src=&quot;v2-8b72f207ab9b77f534c6393acb27b488&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;对于 TxnKV 来说，情况就要复杂的多，不过大部分流程已经在 Percolator 章节进行说明了。这里需要注意的是，因为我们要快速的 seek 到最新的 commit，所以在 RocksDB 里面，我们会先将 TS 使用 bigendian 生成 8 字节的 bytes，然后将这个 bytes 逐位取反，在跟原始的 key 组合存储到 RocksDB 里面，这样就能保证最新的提交存放到前面，seek 的时候就能直接定位了，当然 seek 的时候，也同样会将对应的 TS 按照相同的方式编码处理。&lt;/p&gt;&lt;p&gt;譬如，假设一个 key 现在有两次提交，commitTS 分别为 10 和 12，startTS 则是 9 和 11，那么在 RocksDB 里面，key 的存放顺序则是：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Write CF：

a_12 -&amp;gt; 11
a_10 -&amp;gt; 9

Data CF:

a_11 -&amp;gt; data_11
a_9 -&amp;gt; data_9&lt;/code&gt;&lt;p&gt;另外，还需要注意的是，对于 value 比较小的情况，TiKV 会直接将 value 存放到 Write CF 里面，这样 Read 的时候只要走 Write CF 就行了。在写入的时候，流程如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;PreWrite：

Lock CF: W a -&amp;gt; Lock + Data

Commit:
Lock CF: R a -&amp;gt; Lock + 10 + Data
Lock CF: D a

Write CF: W a_11 -&amp;gt; 10 + Data&lt;/code&gt;&lt;p&gt;对于 TiKV 来说，在 Commit 阶段无论怎样都会读取 Lock 来判断事务冲突，所以我们可以从 Lock 拿到数据，然后再写入到 Write CF 里面。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Read&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-59ca441db4424772565202a0b7b3e5bb_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;659&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-59ca441db4424772565202a0b7b3e5bb&quot; data-watermark-src=&quot;v2-e3239f73c2c07d91376dd4fd8a766bc1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Read 的流程之前的 Percolator 已经有说明了，这里就不详细解释了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;SQL Key Mapping&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们在 TiKV 上面构建了一个分布式数据库 TiDB，它是一个关系型数据库，所以大家需要关注的是一个关系型的 table 是如何映射到 key-value 上面的。假设我们有如下的表结构：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t1 {
	id BIGINT PRIMARY KEY,
	name VARCHAR(1024),
	age BIGINT,
	content BLOB,
	UNIQUE(name),
	INDEX(age),
}&lt;/code&gt;&lt;p&gt;上面我们创建了一张表 t1，里面有四个字段，id 是主键，name 是唯一索引，age 是一个索引。那么这个表里面的数据是如何对应到 TiKV 的呢？&lt;/p&gt;&lt;p&gt;在 TiDB 里面，任何一张表都有一个唯一的 ID，譬如这里是 11，任何的索引也有唯一的 ID，上面 name 就是 12，age 就是 13。我们使用前缀 t 和 i 来区分表里面的 data 和 index。对于上面表 t1 来说，假设现在它有两行数据，分别是 (1, “a”, 10, “hello”) 和 (2, “b”, 12, “world”)，在 TiKV 里面，每一行数据会有不同的 key-value 对应。如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;PK
t_11_1 -&amp;gt; (1, “a”, 10, “hello”)
t_11_2 -&amp;gt; (2, “b”, 12, “world”)

Unique Name
i_12_a -&amp;gt; 1
i_12_b -&amp;gt; 2

Index Age
i_13_10_1 -&amp;gt; nil
i_13_12_2 -&amp;gt; nil&lt;/code&gt;&lt;p&gt;因为 PK 具有唯一性，所以我们可以用 t + Table ID + PK 来唯一表示一行数据，value 就是这行数据。对于 Unique 来说，也是具有唯一性的，所以我们用 i + Index ID + name 来表示，而 value 则是对应的 PK。如果两个 name 相同，就会破坏唯一性约束。当我们使用 Unique 来查询的时候，会先找到对应的 PK，然后再通过 PK 找到对应的数据。&lt;/p&gt;&lt;p&gt;对于普通的 Index 来说，不需要唯一性约束，所以我们使用 i + Index ID + age + PK，而 value 为空。因为 PK 一定是唯一的，所以两行数据即使 age 一样，也不会冲突。当我们使用 Index 来查询的时候，会先 seek 到第一个大于等于 i + Index ID + age 这个 key 的数据，然后看前缀是否匹配，如果匹配，则解码出对应的 PK，再从 PK 拿到实际的数据。&lt;/p&gt;&lt;p&gt;TiDB 在操作 TiKV 的时候需要保证操作 keys 的一致性，所以需要使用 TxnKV 模式。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面简单的介绍了下 TiKV 读写数据的流程，还有很多东西并没有覆盖到，譬如错误处理，Percolator 的性能优化这些，如果你对这些感兴趣，可以参与到 TiKV 的开发，欢迎联系我 tl@pingcap.com。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-11-46524530</guid>
<pubDate>Thu, 11 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 是如何存取数据的（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-10-46372968.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46372968&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-427f9cc9aaef7836737e7c751e2324ec_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：唐刘 &lt;/blockquote&gt;&lt;p&gt;本文会详细的介绍 TiKV 是如何处理读写请求的，通过该文档，同学们会知道 TiKV 是如何将一个写请求包含的数据更改存储到系统，并且能读出对应的数据的。&lt;/p&gt;&lt;p&gt;本文分为上下两篇，在上篇中，我们将介绍一些基础知识，便于大家去理解后面的流程。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基础知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6489ef5e81f554b62f7b3b592ca977b3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6489ef5e81f554b62f7b3b592ca977b3&quot; data-watermark-src=&quot;v2-6199c4b5150737aa28f158a06fa8bb09&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;TiKV 使用 Raft 一致性算法来保证数据的安全，默认提供的是三个副本支持，这三个副本形成了一个 Raft Group。&lt;/p&gt;&lt;p&gt;当 Client 需要写入某个数据的时候，Client 会将操作发送给 Raft Leader，这个在 TiKV 里面我们叫做 Propose，Leader 会将操作编码成一个 entry，写入到自己的 Raft Log 里面，这个我们叫做 Append。&lt;/p&gt;&lt;p&gt;Leader 也会通过 Raft 算法将 entry 复制到其他的 Follower 上面，这个我们叫做 Replicate。Follower 收到这个 entry 之后也会同样进行 Append 操作，顺带告诉 Leader Append 成功。&lt;br&gt;当 Leader 发现这个 entry 已经被大多数节点 Append，就认为这个 entry 已经是 Committed 的了，然后就可以将 entry 里面的操作解码出来，执行并且应用到状态机里面，这个我们叫做 Apply。&lt;/p&gt;&lt;p&gt;在 TiKV 里面，我们提供了 Lease Read，对于 Read 请求，会直接发给 Leader，如果 Leader 确定自己的 lease 没有过期，那么就会直接提供 Read 服务，这样就不用走一次 Raft 了。如果 Leader 发现 lease 过期了，就会强制走一次 Raft 进行续租，然后再提供 Read 服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Multi Raft&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-02fcecc350e76cac6d8a35bdc3febfb3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;443&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-02fcecc350e76cac6d8a35bdc3febfb3&quot; data-watermark-src=&quot;v2-cdfe9eadb97a3d203cc670f488af3cff&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;因为一个 Raft Group 处理的数据量有限，所以我们会将数据切分成多个 Raft Group，我们叫做 Region。切分的方式是按照 range 进行切分，也就是我们会将数据的 key 按照字节序进行排序，也就是一个无限的 sorted map，然后将其切分成一段一段（连续）的 key range，每个 key range 当成一个 Region。&lt;/p&gt;&lt;p&gt;两个相邻的 Region 之间不允许出现空洞，也就是前面一个 Region 的 end key 就是后一个 Region 的 start key。Region 的 range 使用的是前闭后开的模式  [start, end)，对于 key start 来说，它就属于这个 Region，但对于 end 来说，它其实属于下一个 Region。&lt;br&gt;TiKV 的 Region 会有最大 size 的限制，当超过这个阈值之后，就会分裂成两个 Region，譬如 [a, b) -&amp;gt; [a, ab) + [ab, b)，当然，如果 Region 里面没有数据，或者只有很少的数据，也会跟相邻的 Region 进行合并，变成一个更大的 Region，譬如 [a, ab) + [ab, b) -&amp;gt; [a, b)。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Percolator&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于同一个 Region 来说，通过 Raft 一致性协议，我们能保证里面的 key 操作的一致性，但如果我们要同时操作多个数据，而这些数据落在不同的 Region 上面，为了保证操作的一致性，我们就需要分布式事务。&lt;/p&gt;&lt;p&gt;譬如我们需要同时将 a = 1，b = 2 修改成功，而 a 和 b 属于不同的 Region，那么当操作结束之后，一定只能出现 a 和 b 要么都修改成功，要么都没有修改成功，不能出现 a 修改了，但 b 没有修改，或者 b 修改了，a 没有修改这样的情况。&lt;/p&gt;&lt;p&gt;最通常的分布式事务的做法就是使用 two-phase commit，也就是俗称的 2PC，但传统的 2PC 需要有一个协调者，而我们也需要有机制来保证协调者的高可用。这里，TiKV 参考了 Google 的 Percolator，对 2PC 进行了优化，来提供分布式事务支持。&lt;/p&gt;&lt;p&gt;Percolator 的原理是比较复杂的，需要关注几点：&lt;/p&gt;&lt;p&gt;首先，Percolator 需要一个服务 timestamp oracle (TSO) 来分配全局的 timestamp，这个 timestamp 是按照时间单调递增的，而且全局唯一。任何事务在开始的时候会先拿一个 start timestamp (startTS)，然后在事务提交的时候会拿一个 commit timestamp (commitTS)。&lt;/p&gt;&lt;p&gt;Percolator 提供三个 column family (CF)，Lock，Data 和 Write，当写入一个 key-value 的时候，会将这个 key 的 lock 放到 Lock CF 里面，会将实际的 value 放到 Data CF 里面，如果这次写入 commit 成功，则会将对应的 commit 信息放到入 Write CF 里面。&lt;/p&gt;&lt;p&gt;Key 在 Data CF 和 Write CF 里面存放的时候，会把对应的时间戳给加到 Key 的后面。在 Data CF 里面，添加的是 startTS，而在 Write CF 里面，则是 commitCF。&lt;/p&gt;&lt;p&gt;假设我们需要写入 a = 1，首先从 TSO 上面拿到一个 startTS，譬如 10，然后我们进入 Percolator 的 PreWrite 阶段，在 Lock 和 Data CF 上面写入数据，如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Lock CF: W a = lock
Data CF: W a_10 = value&lt;/code&gt;&lt;p&gt;后面我们会用 W 表示 Write，R 表示 Read， D 表示 Delete，S 表示 Seek。&lt;/p&gt;&lt;p&gt;当 PreWrite 成功之后，就会进入 Commit 阶段，会从 TSO 拿一个 commitTS，譬如 11，然后写入：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Lock CF: D a
Write CF: W a_11 = 10&lt;/code&gt;&lt;p&gt;当 Commit 成功之后，对于一个 key-value 来说，它就会在 Data CF 和 Write CF 里面都有记录，在 Data CF 里面会记录实际的数据， Write CF 里面则会记录对应的 startTS。&lt;br&gt;当我们要读取数据的时候，也会先从 TSO 拿到一个 startTS，譬如 12，然后进行读：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Lock CF: R a
Write CF: S a_12 -&amp;gt; a_11 = 10
Data CF: R a_10&lt;/code&gt;&lt;p&gt;在 Read 流程里面，首先我们看 Lock CF 里面是否有 lock，如果有，那么读取就失败了。如果没有，我们就会在 Write CF 里面 seek 最新的一个提交版本，这里我们会找到 11，然后拿到对应的 startTS，这里就是 10，然后将 key 和 startTS 组合在 Data CF 里面读取对应的数据。&lt;br&gt;上面只是简单的介绍了下 Percolator 的读写流程，实际会比这个复杂的多。&lt;/p&gt;&lt;p&gt;&lt;b&gt;RocksDB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 会将数据存储到 RocksDB，RocksDB 是一个 key-value 存储系统，所以对于 TiKV 来说，任何的数据都最终会转换成一个或者多个 key-value 存放到 RocksDB 里面。&lt;/p&gt;&lt;p&gt;每个 TiKV 包含两个 RocksDB 实例，一个用于存储 Raft Log，我们后面称为 Raft RocksDB，而另一个则是存放用户实际的数据，我们称为 KV RocksDB。&lt;/p&gt;&lt;p&gt;一个 TiKV 会有多个 Regions，我们在 Raft RocksDB 里面会使用 Region 的 ID 作为 key 的前缀，然后再带上 Raft Log ID 来唯一标识一条 Raft Log。譬如，假设现在有两个 Region，ID 分别为 1，2，那么 Raft Log 在 RocksDB 里面类似如下存放：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;1_1 -&amp;gt; Log {a = 1}
1_2 -&amp;gt; Log {a = 2}
…
1_N -&amp;gt; Log {a = N}
2_1 -&amp;gt; Log {b = 2}
2_2 -&amp;gt; Log {b = 3}
…
2_N -&amp;gt; Log {b = N}&lt;/code&gt;&lt;p&gt;因为我们是按照 range 对 key 进行的切分，那么在 KV RocksDB 里面，我们直接使用 key 来进行保存，类似如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;a -&amp;gt; N
b -&amp;gt; N&lt;/code&gt;&lt;p&gt;里面存放了两个 key，a 和 b，但并没有使用任何前缀进行区分。&lt;/p&gt;&lt;p&gt;RocksDB 支持 Column Family，所以能直接跟 Percolator 里面的 CF 对应，在 TiKV 里面，我们在 RocksDB 使用 Default CF 直接对应 Percolator 的 Data CF，另外使用了相同名字的 Lock 和 Write。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 会将自己所有的 Region 信息汇报给 PD，这样 PD 就有了整个集群的 Region 信息，当然就有了一张 Region 的路由表，如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18bf04cad2aa6a7995a78e9518a0d0e1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;484&quot; data-rawheight=&quot;418&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-18bf04cad2aa6a7995a78e9518a0d0e1&quot; data-watermark-src=&quot;v2-fd49907324671035b34aa6b19a1b3f78&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;当 Client 需要操作某一个 key 的数据的时候，它首先会向 PD 问一下这个 key 属于哪一个 Region，譬如对于 key a 来说，PD 知道它属于 Region 1，就会给 Client 返回 Region 1 的相关信息，包括有多少个副本，现在 Leader 是哪一个副本，这个 Leader 副本在哪一个 TiKV 上面。&lt;/p&gt;&lt;p&gt;Client 会将相关的 Region 信息缓存到本地，加速后续的操作，但有可能 Region 的 Raft Leader 变更，或者 Region 出现了分裂，合并，Client 会知道缓存失效，然后重新去 PD 获取最新的信息。&lt;/p&gt;&lt;p&gt;PD 同时也提供全局的授时服务，在 Percolator 事务模型里面，我们知道事务开始以及提交都需要有一个时间戳，这个就是 PD 统一分配的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;基础知识就介绍到这里，下篇我们将详细的介绍 TiKV 的读写流程～ &lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-10-46372968</guid>
<pubDate>Wed, 10 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>雷神 Thor —— TiDB 自动化运维平台</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-08-46185503.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46185503&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-557ce943fab1b90541ff2d490292bc16_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：瞿锴，同程艺龙资深 DBA &lt;/blockquote&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;背景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;随着互联网的飞速发展，业务量可能在短短的时间内爆发式地增长，对应的数据量可能快速地从几百 GB 涨到几百个 TB，传统的单机数据库提供的服务，在系统的可扩展性、性价比方面已经不再适用。为了应对大数据量下业务服务访问的性能问题，MySQL 数据库常用的分库、分表方案会随着 MySQL Sharding（分片）的增多，业务访问数据库逻辑会越来越复杂。而且对于某些有多维度查询需求的表，需要引入额外的存储或牺牲性能来满足查询需求，这样会使业务逻辑越来越重，不利于产品的快速迭代。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 的架构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 作为 PingCAP 旗下开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。&lt;/p&gt;&lt;p&gt;TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。&lt;/p&gt;&lt;p&gt;TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。&lt;/p&gt;&lt;p&gt;PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。&lt;/p&gt;&lt;p&gt;上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-dfe437d191248134116e53aea0296e98_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;473&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-dfe437d191248134116e53aea0296e98&quot; data-watermark-src=&quot;v2-6fa8417f9ee498b4632ae6108b2e867e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;由此可见，分布式系统本身的复杂性导致手工部署和运维的成本是比较高的，并且容易出错。传统的自动化部署运维工具如 Puppet / Chef / SaltStack / Ansible 等，由于缺乏状态管理，在节点出现问题时不能及时自动完成故障转移，需要运维人员人工干预。有些则需要写大量的 DSL 甚至与 Shell 脚本一起混合使用，可移植性较差，维护成本比较高。&lt;/p&gt;&lt;p&gt;针对 TiDB 这种复杂的分布式数据库，我们考虑通过对 TiDB 容器化管理，实现以下几个目的：&lt;/p&gt;&lt;p&gt;一、屏蔽底层物理资源&lt;/p&gt;&lt;p&gt;二、提升资源利用率（CPU、内存）&lt;/p&gt;&lt;p&gt;三、提升运维效率&lt;/p&gt;&lt;p&gt;四、精细化管理&lt;/p&gt;&lt;p&gt;因此结合上述需要，我们开发了雷神系统来统一管理和维护 TiDB，其整体架构如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-992b9ecce8d568b33541b73fa9ad11b2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1018&quot; data-rawheight=&quot;511&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-992b9ecce8d568b33541b73fa9ad11b2&quot; data-watermark-src=&quot;v2-dee14b705d51f32695209dbacb771bd1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;从架构图中可以看出此方案是 TiDB 的私有云架构。最下层是容器云，中间一层是开发的容器编排工具，最上面一层针对 TiDB 特性和实际使用中遇到的问题点，进行了针对性开发从而实现了 TiDB 集群实例的统一化管理。下面将逐个介绍各个模块的功能。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;容器调度&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前主流的的容器编排系统 Kuberbetes 曾是我们容器调度的首选解决方案。但 TiDB 作为数据库服务需要将数据库存储到本地磁盘，而 Kuberbetes 对 Local Storage 不支持（目前新的版本已经开始支持）。针对 TiDB 的特性和业务需求，我们决定自己实现一套容器编排系统，具体解决以下问题： &lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持 LocalStorage，解决数据存储问题&lt;/li&gt;&lt;li&gt;基于 cpuset-cpus 实现 CPU 资源的随机均衡分配&lt;/li&gt;&lt;li&gt;定制化，支持 label，实现特定服务运行在特定宿主机上；宿主机资源限制&lt;/li&gt;&lt;li&gt;容器的主动发现和通知，以便将之前未管理的宿主机接入统一管理&lt;/li&gt;&lt;li&gt;容器的全生命周期的管理&lt;/li&gt;&lt;li&gt;容器异常的修复和通知&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;雷神 Thor 采用了模块化设计，分为控制模块和代理模块，其整体架构如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-28a86e4adc0a0f145c9550a05b5f48ec_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;585&quot; data-rawheight=&quot;623&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-28a86e4adc0a0f145c9550a05b5f48ec&quot; data-watermark-src=&quot;v2-f2782c72ef3ce96e42140b41f3696c4f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;说明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;控制模块包含了 Allocator，Label，Discover，Manage，Customize。Allocator 主要负责宿主机资源的分配；Label 主要用于标签定制；Customize 主要负责定制化需求； Discover 主要负责容器的发现和异常检测；Manage 主要负责整体的调度和分发。&lt;/li&gt;&lt;li&gt;代理模块主要负责资源检查和信息收集、接受控制端的命令。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;集群管理&lt;/b&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-08f65ecac29c104de00d9d3275bb34b4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;530&quot; data-rawheight=&quot;436&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-08f65ecac29c104de00d9d3275bb34b4&quot; data-watermark-src=&quot;v2-572a148e311363b3c8a4f47828df8e6d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;集群管理是整套系统的核心模块之一，包含了 TiDB 集群的日常维护操作，实现了 TiDB 初始化、平滑升级、弹性容量管理、监控的整合、集群的维护、节点的维护等功能。虽然 PingCAP 提供了基于 Ansible 的自动部署方案，但是依然需要填写大量的内容和检查相关机器设定来完成部署。通过此系统只需要将需求按照如何格式提交，即可完成整套集群的部署，部署时间从之前 2 个小时，缩减为 2 分钟左右。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据库管理&lt;/b&gt;&lt;br&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-babcc4bebbf0727ef16051ceeea49e47_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;801&quot; data-rawheight=&quot;431&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-babcc4bebbf0727ef16051ceeea49e47&quot; data-watermark-src=&quot;v2-7688be0215c1f39d4339c06c3e8f2eb7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;数据库管理是日常运维很核心的一块，此模块通过任务完成统计信息更新、过载保护、慢查询分析和 SQL 预警。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.统计信息更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 虽然会自动更新统计信息，但需要达到固定的变更百分比，因 TiDB 是作为分片库的合并库，数据量高达几十亿，若依赖自身的统计信息维护，将出现因统计信息不准确而触发的慢查询，故针对此种情况，设计和开发统计信息自动更新，除常规设定外，还可设定例外，避免因统计信息更新时影响业务的正常使用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 过载保护&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过对 SQL 的执行时间和内存的使用情况分析，针对不同的集群可以定制不同的过载保护策略，也可以使用统一的过载保护策略；当触发策略时，会将相关信息通过微信的方式通知相关人员。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 慢查询分析和 SQL 预警&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过 ELK 构建慢查询分析系统，通过 mysql-sniffer、flume、kafka、spark、hadoop 构建 SQL 预警，通过对趋势的分析和预判，为后续自动化容量管理做数据的积累。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据同步&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们尝试将 TiDB 作为所有数据的集合库提供复杂查询，分片集群则提供简单查询，同时由于 TiDB 高度兼容 MySQL 的连接协议为满足复杂的业务查询需求，我们基于 PingCAP 的数据同步工具 Syncer 进行了代码重构，开发了 hamal 同步工具，可以自定义库名和表名，同时新增了同步状态监控，如 TPS、延迟等，如果出现异常，会通过微信告警。从 MySQL 将数据实时同步到 TiDB 来确保数据的一致。该实时同步查询系统架构如下所示：&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8ad16b7b9d86910c4a9b6b7bdf9cde86_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;650&quot; data-rawheight=&quot;469&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8ad16b7b9d86910c4a9b6b7bdf9cde86&quot; data-watermark-src=&quot;v2-30a07f231b88e76c42df5f5bf582f3cb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;Hamal 是伪装成 mysql 从，从 mysql 主上通过主从复制协议来解析成对应的 sql 语句，并经过过滤、改写等步骤，将最终语句在目标库执行的工具。Hamal 主要包含以下特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;position 以及 gtid 模式支持&lt;/li&gt;&lt;li&gt;自动切换主从支持（需要提前配置好主从服务列表）&lt;/li&gt;&lt;li&gt;多目标库支持（多 tidb-server）&lt;/li&gt;&lt;li&gt;binlog 心跳支持&lt;/li&gt;&lt;li&gt;库、表级别过滤，重写支持（用于分片合库）&lt;/li&gt;&lt;li&gt;库表级别额外索引支持&lt;/li&gt;&lt;li&gt;拆解字段支持（额外输出选择某几个字段的小表）&lt;/li&gt;&lt;li&gt;字段过滤支持&lt;/li&gt;&lt;li&gt;智能更新表结构&lt;/li&gt;&lt;li&gt;多线程合并小事务后执行，多种分发策略&lt;/li&gt;&lt;li&gt;纯文本执行模式支持&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Hamal 的内部实现如下：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73520b9115d50bf2cce7e93b3c229993_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;827&quot; data-rawheight=&quot;419&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-73520b9115d50bf2cce7e93b3c229993&quot; data-watermark-src=&quot;v2-1b352156ecac7dcaa98007b8a141d7c7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt; &lt;br&gt;从架构图中可以看出，通过设定不同的 generators，hamal 支持同步到不同目的库或者其他存储方式。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;监控和告警中心&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;监控对于系统的重要性不言而喻。能否有效的告警直接影响着监控的质量，因此监控的核心是监控数据的采集和有效的告警。监控数据主要有三种系统本身的运行状态，例如 CPU、内存、磁盘、网络的使用情况；各种应用的运行状况，例如数据库、容器等，处理网络上发送过来的数据。通过监控项设定和监控例外，可以灵活的定制监控信息的收集。合理、灵活的监控规则可以帮助更快、更精确的定位异常，通过告警策略和告警例外满足不同的告警需求。监控和告警中心的架构图如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4dab4417616d0f38524d33cf8caed068_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;473&quot; data-rawheight=&quot;422&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4dab4417616d0f38524d33cf8caed068&quot; data-watermark-src=&quot;v2-376f9db0cb3f9d9cc931ff24a7e97049&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其中，监控数据的采集一部分依赖于现有监控系统中的数据，如 zabbix 之类；一部分通过 TiDB 的 API 获取，一部分是开源的收集器，因此导致原始数据存储在不同类型的数据库，通过开发的同步工具，将上述数据同步独立部署的 TiDB 集群，以便后续的数据分析。可视化的实现主要基于 grafana 来完成。告警模块是基于实际的需求，进行开发和实现的，未采用现有的一些开源方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在对 TiDB 的使用过程中，我们按照 1 库 1 集群的方式进行服务部署，这种部署方式可以有效避免不同库的压力不均导致相互影响的问题，同时性能监控精准到库级别，而使用了雷神系统后，能够有效的在单台服务器上对各种服务资源进行快速部署，提升资源利用率的同时避免资源争用带来的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;系统上线一年以来，已完成公司所有 TiDB 集群从物理机部署到容器化的平稳迁移；管理了数百台机器和数十套 TiDB Cluster，接入应用数百个，承载着几十 T 的数据量，峰值 TPS 数十万；上线前部署一个 TiDB 集群需要花费将近 2 个小时，雷神系统上线后只需要 2 分钟即可部署完成。有效的提升了 DBA 的运维效率和整个 TiDB 服务的可用性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;未来我们将继续深入，从审计和 SQL 分析方面着手，为业务提供更多的效率提升和稳定性保障。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/0cHC8yPzNgKgFUmIWEsJ5g?scene=25#wechat_redirect&quot;&gt;雷神Thor—TIDB自动化运维平台&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-08-46185503</guid>
<pubDate>Mon, 08 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十九）tikv-client（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-27-45475314.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45475314&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fa485b637a9f12bf5a48586d49285dfd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：周昱行&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43926052&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了数据读写过程中 tikv-client 需要解决的几个具体问题，本文将继续介绍 tikv-client 里的两个主要的模块——负责处理分布式计算的 copIterator 和执行二阶段提交的 twoPhaseCommitter。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;copIterator&lt;/b&gt;&lt;/h2&gt;&lt;h2&gt;&lt;b&gt;1.copIterator 是什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在介绍 copIterator 的概念之前，我们需要简单回顾一下前面 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;TiDB 源码阅读系列文章（六）&lt;/a&gt;中讲过的 distsql 和 coprocessor 的概念以及它们和 SQL 语句的关系。&lt;/p&gt;&lt;p&gt;tikv-server 通过 coprocessor 接口，支持部分 SQL 层的计算能力，大部分只涉及单表数据的常用的算子都可以下推到 tikv-server 上计算，计算下推以后，从存储引擎读取的数据虽然是一样的多，但是通过网络返回的数据会少很多，可以大幅节省序列化和网络传输的开销。&lt;/p&gt;&lt;p&gt;distsql 是位于 SQL 层和 coprocessor 之间的一层抽象，它把下层的 coprocessor 请求封装起来对上层提供一个简单的 &lt;code class=&quot;inline&quot;&gt;Select&lt;/code&gt; 方法。执行一个单表的计算任务。最上层的 SQL 语句可能会包含 &lt;code class=&quot;inline&quot;&gt;JOIN&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;SUBQUERY&lt;/code&gt; 等复杂算子，涉及很多的表，而 distsql 只涉及到单个表的数据。一个 distsql 请求会涉及到多个 region，我们要对涉及到的每一个 region 执行一次 coprocessor 请求。&lt;/p&gt;&lt;p&gt;所以它们的关系是这样的，一个 SQL 语句包含多个 distsql 请求，一个 distsql 请求包含多个 coprocessor 请求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;copIterator 的任务就是实现 distsql 请求，执行所有涉及到的 coprocessor 请求，并依次返回结果。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. 构造 coprocessor task&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一个 distsql 请求需要处理的数据是一个单表上的 index scan 或 table scan，在 Request 包含了转换好的 KeyRange list。接下来，通过 region cache 提供的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/region_cache.go#L138&quot;&gt;LocateKey&lt;/a&gt; 方法，我们可以找到有哪些 region 包含了一个 key range 范围内的数据。&lt;/p&gt;&lt;p&gt;找到所有 KeyRange 包含的所有的 region 以后，我们需要按照 region 的 range 把 key range list 进行切分，让每个 coprocessor task 里的 key range list 不会超过 region 的范围。&lt;/p&gt;&lt;p&gt;构造出了所有 coprocessor task 之后，下一步就是执行这些 task 了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. copIterator 的执行模式&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了更容易理解 copIterator 的执行模式，我们先从最简单的实现方式开始， 逐步推导到现在的设计。&lt;/p&gt;&lt;p&gt;copIterator 是 &lt;code class=&quot;inline&quot;&gt;kv.Response&lt;/code&gt; 接口的实现，需要实现对应 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L516&quot;&gt;Next&lt;/a&gt; 方法，在上层调用 Next  的时候，返回一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L390:6&quot;&gt;coprocessor response&lt;/a&gt;，上层通过多次调用 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法，获取多个 coprocessor response，直到所有结果获取完。&lt;/p&gt;&lt;p&gt;最简单的实现方式，是在 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法里，执行一个 coprocessor task，返回这个 task 的执行结果。&lt;/p&gt;&lt;p&gt;这个执行方式的一个很大的问题，大量时间耗费在等待 coprocessor 请求返回结果，我们需要改进一下。&lt;/p&gt;&lt;p&gt;coprocessor 请求如果是由 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 触发的，每次调用 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 就必须等待一个 &lt;code class=&quot;inline&quot;&gt;RPC  round trip&lt;/code&gt; 的延迟。我们可以改造成请求在 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 被调用之前触发，这样就能在 Next 被调用的时候，更早拿到结果返回，省掉了阻塞等待的过程。&lt;/p&gt;&lt;p&gt;在 copIterator 创建的时候，我们启动一个后台 worker goroutine 来依次执行所有的 coprocessor task，并把执行结果发送到一个 response channel，这样前台 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法只需要从这个 channel 里  receive 一个 coprocessor response 就可以了。如果这个 task 已经执行完成，&lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法可以直接获取到结果，立即返回。&lt;/p&gt;&lt;p&gt;当所有 coprocessor task 被 work 执行完成的时候，worker 把这个 response channel 关闭，&lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法在 receive channel 的时候发现 channel 已经关闭，就可以返回 &lt;code class=&quot;inline&quot;&gt;nil response&lt;/code&gt;，表示所有结果都处理完成了。&lt;/p&gt;&lt;p&gt;以上的执行方案还是存在一个问题，就是 coprocessor task 只有一个 worker 在执行，没有并行，性能还是不理想。&lt;/p&gt;&lt;p&gt;为了增大并行度，我们可以构造多个 worker 来执行 task，把所有的 task 发送到一个 task channel，多个 worker 从这一个 channel 读取 task，执行完成后，把结果发到 response channel，通过设置 worker 的数量控制并发度。&lt;/p&gt;&lt;p&gt;这样改造以后，就可以充分的并行执行了，但是这样带来一个新的问题，task 是有序的，但是由于多个 worker 并行执行，返回的 response 顺序是乱序的。对于不要求结果有序的 distsql 请求，这个执行模式是可行的，我们使用这个模式来执行。对于要求结果有序的 distsql 请求，就不能满足要求了，我们需要另一种执行模式。&lt;/p&gt;&lt;p&gt;当 worker 执行完一个 task 之后，当前的做法是把 response 发送到一个全局的 channel 里，如果我们给每一个 task 创建一个 channel，把 response 发送到这个 task 自己的 response channel 里，Next 的时候，就可以按照 task 的顺序获取 response，保证结果的有序。&lt;/p&gt;&lt;p&gt;以上就是 copIterator 最终的执行模式。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. copIterator 实现细节&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;理解执行模式之后，我们从源码的角度，分析一遍完整的执行流程。&lt;/p&gt;&lt;p&gt;&lt;b&gt;前台执行流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;前台的执行的第一步是 CopClient 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L82&quot;&gt;Send&lt;/a&gt; 方法。先根据 distsql 请求里的 &lt;code class=&quot;inline&quot;&gt;KeyRanges&lt;/code&gt; &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L238&quot;&gt;构造 coprocessor task&lt;/a&gt;，用构造好的 task 创建 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L88&quot;&gt;copIterator&lt;/a&gt;，然后调用 copIterator 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L438&quot;&gt;open&lt;/a&gt; 方法，启动多个后台 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L452&quot;&gt;worker goroutine&lt;/a&gt;，然后启动一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L454&quot;&gt;sender&lt;/a&gt; 用来把 task 丢进 task channel，最后 copIterator 做为 &lt;code class=&quot;inline&quot;&gt;kv.Reponse&lt;/code&gt; 返回。&lt;/p&gt;&lt;p&gt;前台执行的第二步是多次调用 &lt;code class=&quot;inline&quot;&gt;kv.Response&lt;/code&gt; 的 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法，直到获取所有的 response。&lt;/p&gt;&lt;p&gt;copIterator 在 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 里会根据结果是否有序，选择相应的执行模式，无序的请求会从 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L526&quot;&gt;全局 channel 里获取结果&lt;/a&gt;，有序的请求会在每一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L537&quot;&gt;task 的 response channel&lt;/a&gt; 里获取结果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;后台执行流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L417&quot;&gt;从 task channel 获取到一个 task&lt;/a&gt; 之后，worker 会执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L424&quot;&gt;handleTask&lt;/a&gt; 来发送 RPC 请求，并处理请求的异常，当 region 分裂的时候，我们需要重新构造 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L572&quot;&gt;新的 task&lt;/a&gt;，并重新发送。对于有序的 distsql 请求，分裂后的多个 task 的执行结果需要发送到旧的 task 的 response channel 里，所以一个 task 的 response channel 可能会返回多个 response，发送完成后需要 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L428&quot;&gt;关闭 task 的 response channel&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;twoPhaseCommitter&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 2PC 简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2PC 是实现分布式事务的一种方式，保证跨越多个网络节点的事务的原子性，不会出现事务只提交一半的问题。&lt;/p&gt;&lt;p&gt;在 TiDB，使用的 2PC 模型是 Google percolator 模型，简单的理解，percolator 模型和传统的 2PC 的区别主要在于消除了事务管理器的单点，把事务状态信息保存在每个 key 上，大幅提高了分布式事务的线性 scale 能力，虽然仍然存在一个 timestamp oracle 的单点，但是因为逻辑非常简单，而且可以 batch 执行，所以并不会成为系统的瓶颈。&lt;/p&gt;&lt;p&gt;关于 percolator 模型的细节，可以参考这篇文章的介绍 &lt;a href=&quot;https://pingcap.com/blog-cn/percolator-and-txn/&quot;&gt;https://pingcap.com/blog-cn/percolator-and-txn/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. 构造 twoPhaseCommitter&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当一个事务准备提交的时候，会创建一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L62&quot;&gt;twoPhaseCommiter&lt;/a&gt;，用来执行分布式的事务。&lt;/p&gt;&lt;p&gt;构造的时候，需要做以下几件事情&lt;/p&gt;&lt;ul&gt;&lt;li&gt; href=&quot;https&lt;code class=&quot;inline&quot;&gt;://github.&lt;/code&gt;com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L91&quot;&amp;gt;从 memBuffer 和 lockedKeys 里收集所有的 key 和 mutation&lt;br&gt;&lt;code class=&quot;inline&quot;&gt;memBuffer&lt;/code&gt; 里的 key 是有序排列的，我们从头遍历 &lt;code class=&quot;inline&quot;&gt;memBuffer&lt;/code&gt; 可以顺序的收集到事务里需要修改的 key，value 长度为 0 的 entry 表示 &lt;code class=&quot;inline&quot;&gt;DELETE&lt;/code&gt; 操作，value 长度大于 0 表示 &lt;code class=&quot;inline&quot;&gt;PUT&lt;/code&gt; 操作，&lt;code class=&quot;inline&quot;&gt;memBuffer&lt;/code&gt; 里的第一个 key 做为事务的 primary key。&lt;code class=&quot;inline&quot;&gt;lockKeys&lt;/code&gt; 里保存的是不需要修改，但需要加读锁的 key，也会做为 mutation 的 &lt;code class=&quot;inline&quot;&gt;LOCK&lt;/code&gt; 操作，写到 TiKV 上。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L132&quot;&gt;计算事务的大小是否超过限制&lt;/a&gt;&lt;br&gt;在收集 mutation 的时候，会统计整个事务的大小，如果超过了最大事务限制，会返回报错。&lt;br&gt;太大的事务可能会让 TiKV 集群压力过大，执行失败并导致集群不可用，所以要对事务的大小做出硬性的限制。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L164&quot;&gt;计算事务的 TTL 时间&lt;/a&gt;&lt;br&gt;如果一个事务的 key 通过 &lt;code class=&quot;inline&quot;&gt;prewrite&lt;/code&gt; 加锁后，事务没有执行完，tidb-server 就挂掉了，这时候集群内其他 tidb-server 是无法读取这个 key 的，如果没有 TTL，就会死锁。设置了 TTL 之后，读请求就可以在 TTL 超时之后执行清锁，然后读取到数据。&lt;br&gt;我们计算一个事务的超时时间需要考虑正常执行一个事务需要花费的时间，如果太短会出现大的事务无法正常执行完的问题，如果太长，会有异常退出导致某个 key 长时间无法访问的问题。所以使用了这样一个算法，TTL 和事务的大小的平方根成正比，并控制在一个最小值和一个最大值之间。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;3. execute&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 twoPhaseCommiter 创建好以后，下一步就是执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L562&quot;&gt;execute&lt;/a&gt; 函数。&lt;/p&gt;&lt;p&gt;在 &lt;code class=&quot;inline&quot;&gt;execute&lt;/code&gt; 函数里，需要在 &lt;code class=&quot;inline&quot;&gt;defer&lt;/code&gt; 函数里执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L572&quot;&gt;cleanupKeys&lt;/a&gt;，在事务没有成功执行的时候，清理掉多余的锁，如果不做这一步操作，残留的锁会让读请求阻塞，直到 TTL 过期才会被清理。第一步会执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L585&quot;&gt;prewriteKeys&lt;/a&gt;，如果成功，会从 PD 获取一个 &lt;code class=&quot;inline&quot;&gt;commitTS&lt;/code&gt; 用来执行 &lt;code class=&quot;inline&quot;&gt;commit&lt;/code&gt; 操作。取到了 &lt;code class=&quot;inline&quot;&gt;commitTS&lt;/code&gt; 之后，还需要做以下验证:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;commitTS&lt;/code&gt; 比 &lt;code class=&quot;inline&quot;&gt;startTS&lt;/code&gt; 大&lt;/li&gt;&lt;li&gt;schema 没有过期&lt;/li&gt;&lt;li&gt;事务的执行时间没有过长&lt;/li&gt;&lt;li&gt;如果没有通过检查，事务会失败报错。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过检查之后，执行最后一步 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L620&quot;&gt;commitKeys&lt;/a&gt;，如果没有错误，事务就提交完成了。&lt;/p&gt;&lt;p&gt;当 &lt;code class=&quot;inline&quot;&gt;commitKeys&lt;/code&gt; 请求遇到了网络超时，那么这个事务是否已经提交是不确定的，这时候不能执行 &lt;code class=&quot;inline&quot;&gt;cleanupKeys&lt;/code&gt; 操作，否则就破坏了事务的一致性。我们对这种情况返回一个特殊的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L625&quot;&gt;undetermined error&lt;/a&gt;，让上层来处理。上层会在遇到这种 error 的时候，把连接断开，而不是返回给用一个执行失败的错误。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L533&quot;&gt;prewriteKeys&lt;/a&gt;,  &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L537&quot;&gt;commitKeys&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L541&quot;&gt;cleanupKeys&lt;/a&gt; 有很多相同的逻辑，需要把 keys 根据 region 分成 batch，然后对每个 batch 执行一次 RPC。&lt;/p&gt;&lt;p&gt;当 RPC 返回 region 过期的错误时，我们需要把这个 region 上的 keys 重新分成 batch，发送 RPC 请求。&lt;/p&gt;&lt;p&gt;这部分逻辑我们把它抽出来，放在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L191&quot;&gt;doActionOnKeys&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L239&quot;&gt;doActionOnBatches&lt;/a&gt; 里，并实现 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L319&quot;&gt;prewriteSinlgeBatch&lt;/a&gt;，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L421&quot;&gt;commitSingleBatch&lt;/a&gt;，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L497&quot;&gt;cleanupSingleBatch&lt;/a&gt; 函数，用来执行单个 batch 的 RPC 请求。&lt;/p&gt;&lt;p&gt;虽大部分逻辑是相同的，但是不同的请求在执行顺序上有一些不同，在 &lt;code class=&quot;inline&quot;&gt;doActionOnKeys&lt;/code&gt; 里需要特殊的判断和处理。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;prewrite&lt;/code&gt; 分成的多个 batch 需要同步并行的执行。&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;commit&lt;/code&gt; 分成的多个 batch 需要先执行第一个 batch，成功后再异步并行执行其他的 batch。&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;cleanup&lt;/code&gt; 分成的多个 batch 需要异步并行执行。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L239:29&quot;&gt;doActionOnBatches&lt;/a&gt; 会开启多个 goroutines 并行的执行多个 batch，如果遇到了 error，会把其他正在执行的 &lt;code class=&quot;inline&quot;&gt;context cancel&lt;/code&gt; 掉，然后返回第一个遇到的 error。&lt;/p&gt;&lt;p&gt;执行 &lt;code class=&quot;inline&quot;&gt;prewriteSingleBatch&lt;/code&gt; 的时候，有可能会遇到 region 分裂错误，这时候 batch 里的 key 就不再是一个 region 上的 key 了，我们会在这里递归的调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L352&quot;&gt;prewriteKeys&lt;/a&gt;，重新走一遍拆分 batch 然后执行 &lt;code class=&quot;inline&quot;&gt;doActionOnBatch&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;prewriteSingleBatch&lt;/code&gt; 的流程。这部分逻辑在 &lt;code class=&quot;inline&quot;&gt;commitSingleBatch&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;cleanupSingleBatch&lt;/code&gt; 里也都有。&lt;/p&gt;&lt;p&gt;twoPhaseCommitter 包含的逻辑只是事务模型的一小部分，主要的逻辑在 tikv-server 端，超出了这篇文章的范围，就不在这里详细讨论了。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;更多 TiDB 源码阅读系列文章详见：&lt;a href=&quot;http://pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot;&gt;Blog-cns&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-27-45475314</guid>
<pubDate>Thu, 27 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 集群版本的安全迁移</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-22-45144603.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45144603&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3bc0f0e99ad335bf0ff6992419402210_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：陈书宁&lt;/p&gt;&lt;h2&gt;&lt;b&gt;问题描述&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 TiDB 的产品迭代中，不免会碰到一些兼容性问题出现。通常协议上的兼容性 protobuf 已经能帮我们处理的很好，在进行功能开发，性能优化时，通常会保证版本是向后兼容的，但并不保证向前兼容性，因此，当集群中同时有新旧版本节点存在时，旧版本不能兼容新版本的特性，就有可能造成该节点崩溃，影响集群可用性，甚至丢失数据。目前在有不兼容的版本升级时，会要求进行离线升级，但这会影响到服务，我们需要一个适合的机制来进行不停服务的升级。因此我们需要在进行滚动升级时，让这些不能保证整个集群的向后兼容性的功能不被启用。只有在保证集群中所有节点都已经升级完成后，我们才安全的启用这些功能。&lt;/p&gt;&lt;p&gt;常见的当我们对引入新的 &lt;code class=&quot;inline&quot;&gt;RaftCommand&lt;/code&gt; 的时候，旧版本的 TiKV 并不能识别新的添加的 &lt;code class=&quot;inline&quot;&gt;RaftCommand&lt;/code&gt;，对于不能认知的 &lt;code class=&quot;inline&quot;&gt;RaftCommand&lt;/code&gt; TiKV 有不同的处理，可能会报错退出或忽略。比如为了支持 Raft Learner, 在 raftpb 里对添加新的 ConfChange 类型。 当 PD 在进行 Region 调度时，会先发送 &lt;code class=&quot;inline&quot;&gt;AddLearner&lt;/code&gt; 到 TiKV 上，接受到这个命令的肯定是这个 Region 的 Leader，在进行一系列检查后，会将该命令 Proposal, 而 Follwer 如果是旧版本的话，在 Apply 这条 Command 就会出错。而在滚动升级时，很有可能存在 Leader 是新版本，Follwer 是老版本的情况。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;引入版本检查机制&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的版本定义是遵循 Semver 的版本规则的。版本格式一般由主版本号（Major），次版本号（Minor），修订号（Patch），版本号递增规则如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;主版本号：当进行了不兼容的 API 修改。&lt;/li&gt;&lt;li&gt;次版本号：当做了向下兼容的功能性新增。&lt;/li&gt;&lt;li&gt;修订号：当做了向下兼容的问题修正。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;先行版本号（PreRelase）及版本编译信息可以加到“主版本号.次版本号.修订号”的后面，作为延伸。比如 TiDB 目前的版本是 2.1.0-beta，先行版号为 beta 版。&lt;/p&gt;&lt;p&gt;在此之前，集群并没有版本的概念，虽然每个组件都有各自的版本信息，但各个节点的各自组件的版本都可以任意的。没有一个管理机制可以管理或查看所有组件的版本信息。为了解决滚动升级过程中存在多个版本的兼容性问题，这里引入集群版本的概念，并由 TiDB 集群的中心节点 PD 来进行管理和检查。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;具体实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1.升级集群&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 PD 中，会设置一个 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 的键值对，对应当前运行集群中 TiKV 节点中最旧的版本。也就是必须要兼容这个版本， 因此不能打开集群中其他新版本的节点的一些不兼容的特性。&lt;/p&gt;&lt;p&gt;在集群启动的时候，每个 TiKV 都需要向 PD 注册，注册时会带上版本信息。当当前 TiKV 的版本低于集群版本的时候，该 TiKV 会注册失败。因为此时集群的版本已经是更高的版本了，而加入旧版本的节点需要对旧版本进行兼容，为了防止已有的特性降级，直接拒绝不兼容的版本加入，目前默认主版本号和此版本号一样则为兼容的版本。&lt;/p&gt;&lt;p&gt;如果 TiKV 的版本高于或等于当前的 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 时， TiKV 能够注册成功并成功启动。每次注册都会触发 PD 的一次检查，会检测当前集群中正常运行的 TiKV 的最低版本，并与当前的 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 进行比对，如果最低版本比 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 更加新，则将 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 更新。因此每次滚动升级的时候，能够自动更新集群的版本。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 版本特性的开启&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 很多功能是需要 PD 的参与，目前这些新功能的开启也是通过 PD 进行控制的。在 PD 中，会将每个版本新特性记录下来，在 TiKV 2.0 中，对应有 Raft Leaner， Region Merge。 TiKV 2.1 中有 Batch Split，Joint Consensus 等。这些特性都需要 PD 的参与与控制。比如说 Add Leaner，Region Merge，Joint Consensus 需要 PD 下发调度给 TiKV，Batch Split 则是 TiKV 主动发起并请求 PD 分配新的 Region ID。因此这些功能都是能通过 PD 进行控制的。PD 会通过比对当前的集群版本，选择开启当前集群版本所支持的新特性。从而保证版本的兼容性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 集群回滚&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当升级完成后，如果遇到问题需要进行集群进行回滚时， 需要手动修改集群版本后。PD 提供了 pdctl 可以通过命令手动修改集群的 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt;，这时旧版本的 TiKV 就能注册并启动，从而进行回滚。&lt;/p&gt;&lt;p&gt;PD 对 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 是通过 etcd 进行了持久化，在每次 PD 启动的时候，leader 都会从 etcd kv 中加载出 &lt;code class=&quot;inline&quot;&gt;clustrer_version&lt;/code&gt;，然后提供服务。从而保证在 PD leader 切换后 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 的一致性。另外 PD 本身的版本可能会小于当前 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt;。因此在滚动升级的时候，需要先升级 PD，如果只升级了 TiKV，虽然 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt;已经更新到新的版本的，但 PD 并不能开启新的功能，因为对它来说是不支持的。如果出现这种情况，PD 的日志中会有报警。在升级的时候，最好按 PD，TiKV，TiDB 的顺序逐一对各个组件。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;后续计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面提到的新功能特性一般都是需要 PD 参与的。而有些特性不需要PD的参与，因此需要保证这种特性在 TiKV 之间是可以兼容的，实现的时候可以采用类是 &lt;code class=&quot;inline&quot;&gt;http2 &amp;lt;-&amp;gt; http&lt;/code&gt; 的方式，对请求进行降级装发，保留两套接口等。另为 TiDB 目前是自身保证可以无缝兼容，但与 TiKV 可能存在兼容性问题，往后同样考虑让TiDB 也在 PD上进行注册。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-22-45144603</guid>
<pubDate>Sat, 22 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在爱奇艺的应用及实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-21-45078083.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45078083&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d6f3202173d72ff80b810466ed58c39_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;爱奇艺，中国高品质视频娱乐服务提供者，2010 年 4 月 22 日正式上线，推崇品质、青春、时尚的品牌内涵如今已深入人心，网罗了全球广大的年轻用户群体，积极推动产品、技术、内容、营销等全方位创新。企业愿景为做一家以科技创新为驱动的伟大娱乐公司。我们在前沿技术领域也保持一定的关注度。&lt;br&gt;&lt;br&gt;随着公司业务的快速发展，原来普遍使用的 MySQL 集群遇到了很多瓶颈，比如单机 MySQL 实例支撑的数据量有限，只能通过不停删除较旧的数据来维持数据库的运转。同时单表的数据行数不断增大导致查询速度变慢。急需一种可扩展、高可用同时又兼容 MySQL 访问方式的数据库来支撑业务的高速发展。&lt;br&gt;&lt;br&gt;我司从 2017 年年中开始调研 TiDB，并且在数据库云部门内部系统中使用了 TiDB 集群。从今年 TiDB 推出 2.0 之后，TiDB 愈发成熟，稳定性与查询效率都有很大提升。今年陆续接入了边控中心、视频转码、用户登录信息等几个业务，这几个业务背景和接入方式如下详述。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;项目介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 边控中心&lt;/b&gt;&lt;/p&gt;&lt;p&gt;边控中心存储的是机器的安全统计信息，包括根据 DC、IP、PORT 等不同维度统计的流量信息。上层业务会不定期做统计查询，其业务页面如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-15d28d946b829179d42b8620b349debc_r.jpg&quot; data-caption=&quot;图 1 边控中心上层业务页面（一）&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;452&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-15d28d946b829179d42b8620b349debc&quot; data-watermark-src=&quot;v2-7b9ea19dfc7d3397f0bab3d27e03cb93&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2c4de3f6fcc83f7ea9a62dc54d638216_r.jpg&quot; data-caption=&quot;图 2 边控中心上层业务页面（二）&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;450&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2c4de3f6fcc83f7ea9a62dc54d638216&quot; data-watermark-src=&quot;v2-e5e6c3b09be14fc25b72696dfb9ad41d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;在选型过程中，也考虑过时序型数据库 Apache Druid（http://druid.io），但是 Druid 聚合查询不够灵活，最终放弃 Druid 选择了 TiDB 数据库。TiDB 几乎完全兼容 MySQL 的访问协议，可以使用现有的 MySQL 连接池组件访问 TiDB，业务迁移成本低，开发效率高。&lt;/p&gt;&lt;p&gt;边控中心是爱奇艺第一个在线业务使用 TiDB 的项目，所以我们制定了详细的上线计划。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一，部署单独的 TiDB 集群。然后，为了数据安全，部署了 TokuDB 集群，用作 TiDB 集群的备份数据库。&lt;/li&gt;&lt;li&gt;第二，我们通过 TiDB-Binlog 将 TiDB 集群的数据变更实时同步到 TokuDB 集群中，作为 TiDB 的灾备方案。&lt;/li&gt;&lt;li&gt;第三，前端部署了自研的负载均衡中间件，以最大化利用多个 TiDB 节点的计算能力，同时保证 TiDB 节点的高可用。&lt;/li&gt;&lt;li&gt;第四，部署 Prometheus 和 Grafana 监控 TiDB 集群健康状况，同时 Grafana 接入了公司的告警平台，会及时将告警信息通过短信、邮件等方式通知到运维值班同事。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;边控中心上线过程中，也遇到了一些问题，都比较顺利的解决了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最常见的问题是连接超时。经过仔细排查发现是统计信息严重过时导致执行计划无法选择最优解造成的，这个问题其实是关系型数据库普遍存在的问题，普遍的解决思路是手工进行统计信息收集，或者通过 hint 的方式来固定执行计划，这两种方式对使用者都有一定的要求，而最新版本的 TiDB 完善了统计信息收集策略，比如增加了自动分析功能，目前这个问题已经解决。&lt;/li&gt;&lt;li&gt;还遇到了加索引时间较长的问题。这一方面是由于 DDL 执行信息更新不及时，造成查询 DDL 进度时看到的是滞后的信息。另一方面是由于有时会存在 size 过大的 Region，导致加索引时间变长。这个问题反馈给 PingCAP 官方后得到比较积极的响应，大 Region 已经通过增加 Batch split 等功能在新版的 TiDB 中修复了。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;边控中心上线以后，在不中断业务的情况下成功做过版本升级，修改 TiKV 节点内部参数等操作，基本对业务没有影响。在升级 TiKV 节点过程中会有少量报错，如“region is unvailable[try again later]、tikv server timeout”等。这是由于缓存信息滞后性造成的，在分布式系统中是不可避免的，只要业务端有重试机制就不会造成影响。&lt;/p&gt;&lt;p&gt;边控中心上线以后，数据量一直在稳定增长，但查询性能保持稳定，响应时间基本保持不变，能做到这点殊为不易，我个人的理解，这个主要依赖 TiDB 底层自动分片的策略，TiDB 会根据表数据量，按照等长大小的策略（默认 96M）自动分裂出一个分片，然后通过一系列复杂的调度算法打散到各个分布式存储节点上，对一个特定的查询，不管原表数据量多大，都能通过很快定位到某一个具体分片进行数据查询，保证了查询响应时间的稳定。&lt;/p&gt;&lt;p&gt;边控中心数据量增长情况如下：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bd4d272c646f0101976b275af7fce2f1_r.jpg&quot; data-caption=&quot;图 3 边控中心数据量增长情况&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;300&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bd4d272c646f0101976b275af7fce2f1&quot; data-watermark-src=&quot;v2-0d25d4f2f5e63ae12c69de8980bbdc2b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;TiDB 底层自动分片策略：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9ef0617a97f8882565939b6e988fa9db_r.jpg&quot; data-caption=&quot;图 4 TiDB 底层自动分片策略&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;390&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9ef0617a97f8882565939b6e988fa9db&quot; data-watermark-src=&quot;v2-6f6ed608bed0599e79e20f89185e27e2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;2. 视频转码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;视频转码业务是很早就接入 TiDB 集群的一个业务。视频转码数据库中主要存储的是转码生产过程中的历史数据，这些数据在生产完成后还需要进一步分析处理，使用 MySQL 集群时因为容量问题只好保留最近几个月的数据，较早的数据都会删掉，失去了做分析处理的机会。&lt;/p&gt;&lt;p&gt;针对业务痛点，在 2017 年年底部署了 TiDB 独立集群，并全量+增量导入数据，保证原有 MySQL 集群和新建 TiDB 集群的数据一致性。在全量同步数据过程中，起初采用 Mydumper+Loader 方式。Loader 是 PingCAP 开发的全量导入工具，但是导入过程总遇到导入过慢的问题，为解决这个问题，PingCAP 研发了 TiDB-Lightning 作为全量同步工具。TiDB-Lightning 会直接将导出的数据直接转化为 sst 格式的文件导入到 TiKV 节点中，极大的提高了效率，1T 数据量在 5-6 个小时内就能完成，在稳定运行一段时间后将流量迁移到了 TiDB 集群，并且扩充了业务功能，迄今稳定运行。&lt;/p&gt;&lt;p&gt;TiDB-Lightning 实现架构图：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-27e095315c85adac271ea24948063dad_r.jpg&quot; data-caption=&quot;图 5 TiDB-Lightning 实现架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-27e095315c85adac271ea24948063dad&quot; data-watermark-src=&quot;v2-1e7d216f79633015a2d4b15ba598ff00&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;3. 用户登录信息&lt;/b&gt;&lt;/p&gt;&lt;p&gt;用户登录信息项目的数据量一直在稳定增长，MySQL 主备集群在不久的将来不能满足存储容量的需求。另外，由于单表数据量巨大，不得不在业务上进行分表处理，业务数据访问层代码变得复杂和缺乏扩展性。在迁移到 TiDB 后，直接去掉了分库分表，简化了业务的使用方式。另外，在 MySQL 中存在双散表并进行双写。在 TiDB 中进一步合并成了一种表，利用 TiDB 的索引支持多种快速查询，进一步简化了业务代码。&lt;/p&gt;&lt;p&gt;在部署增量同步的过程中使用了官方的 Syncer 工具。Syncer 支持通过通配符的方式将多源多表数据汇聚到一个表当中，是个实用的功能，大大简化了我们的增量同步工作。目前的 Syncer 工具还不支持在 Grafana 中展示实时延迟信息，这对同步延迟敏感的业务是个缺点，据官方的消息称已经在改进中，同时 PingCAP 他们重构了整个 Syncer，能自动处理分表主键冲突，多源同时 DDL 自动过滤等功能，总之通过这套工具，可以快速部署 TiDB “实时”同步多个 MySQL，数据迁移体验超赞。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d1610958e01bbddab6a46d66d3d36e11_r.jpg&quot; data-caption=&quot;图 6 Syncer 架构&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;531&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d1610958e01bbddab6a46d66d3d36e11&quot; data-watermark-src=&quot;v2-236621aba796853905372a8aa18c0655&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;在我们公司业务对数据库高可用有两个需求：一个是机房宕机了，服务仍然可用。另一个是，多机房的业务，提供本机房的只读从库，提升响应速度。针对这些不同的需求，TiDB 集群采用了多机房部署的方式，保证其中任一个机房不可用时仍然正常对外提供服务（如下图）。对每个 TiKV 节点设置 label 后，TiDB 集群在每个机房都有一份数据的副本，PD 集群会自动调度到合适的副本进行读操作，也可以满足第二个要求。为了满足迁移过程中的高可用性，会在流量迁移完成后部署 TiDB 到 MySQL 的实时同步。Drainer 支持指定同步开始的时间戳，有力支持了反向同步功能。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f4cc9896480eb2192e3ed6cf8c798d72_r.jpg&quot; data-caption=&quot;图 7  TiDB 集群多机房部署形式&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;848&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f4cc9896480eb2192e3ed6cf8c798d72&quot; data-watermark-src=&quot;v2-fa9e101a090eec110df644e9b64743f7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;在整个运维过程中，PingCAP 的小伙伴们提供了及时的帮助，帮助我们定位问题并提出建议，保证了业务的有序运行。在此表示由衷的感谢！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;适用范围&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在实践过程中感受到 TiDB 解决的痛点主要是横向扩展和高可用。单机数据库支撑的数据量有限，如果采用分库分表 + proxy 的方式，无论 proxy 是在客户端还是服务端都增加了运维的成本。同时 proxy 的查询效率在很多场景下不能满足要求。另外，proxy 对事务的支持都比较弱，不能满足数据强一致性的要求。&lt;b&gt;TiDB 可以直接替代 proxy+MySQL 的架构，服务高可用性、数据高可用性、横向扩展性都由 TiDB 集群完成，完美解决了数据量增量情况下出现的很多问题。而且，TiDB 在数据量越大的情况下性能表现得比 MySQL 越惊艳。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一些改进建议&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;统计信息的收集期望更加的智能化，选择更好的时机自动完成而且不影响线上业务。&lt;/li&gt;&lt;li&gt;OLTP 和 OLAP 混合场景下相互间的隔离和尽量互不影响还有许多工作值得推进。&lt;/li&gt;&lt;li&gt;一些外围工具还需要提供高可用特性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;未来计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我司仍有其它业务在接入 TiDB 服务，目前正在评估测试中。一些业务场景是 OLTP+OLAP 混合的场景，TiSpark 正好可以大展身手。目前在测试集群发现 TiSpark 查询时对 OLTP 业务的影响还是比较大的，必须限制 TiSpark 对 TiDB 集群造成的压力。还部署了单独 TiDB 集群做 OLAP 场景的测试，对内部参数做了针对性的优化。未来计划会继续加大对 TiDB 的投入，贡献一些 PR 到社区，其中很大的一部分工作是增强 TiDB-Binlog 的功能，和现有的一些数据同步组件整合起来，支持 TiDB 到 Kudu、HBase 等的同步。&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;作者：朱博帅，爱奇艺资深数据库架构师&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-21-45078083</guid>
<pubDate>Fri, 21 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP 完成 C 轮 5000 万美元融资</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-12-44322174.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/44322174&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-11fb7be39efa3b3e40af9addc6780530_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;近日，新型分布式关系型数据库公司 PingCAP 宣布完成 5000 万美元 C 轮融资，这是目前为止新型分布式关系型数据库领域的最大笔融资。本轮融资由复星、晨兴资本领投，华创资本、云启资本、经纬中国等多家投资机构跟投，将主要用于技术研发和全球化生态系统建设。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-11fb7be39efa3b3e40af9addc6780530_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2210&quot; data-rawheight=&quot;1266&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-11fb7be39efa3b3e40af9addc6780530&quot; data-watermark-src=&quot;v2-09412e37d5508a38e75aabc1e07680a6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;PingCAP 成立于 2015 年，是面向全球的开源的新型分布式关系型数据库公司，其核心产品 TiDB 项目是基础软件领域的重大创新，实现了水平弹性伸缩、分布式事务、强一致性的多副本数据安全、实时 OLAP 等重要特性，是大数据时代理想的数据库集群和云数据库解决方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;真正落地的 HTAP 融合型通用数据库&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;TiDB 作为一款定位于 HTAP（Hybrid Transactional/Analytical Processing）的融合型通用数据库产品，很早就开始尝试融合 OLTP 和 OLAP 的边界。互联网背景出身的 PingCAP 创始团队的每名成员，都经历过数据指数级增长的时期，具备处理海量数据的经验，这让 TiDB 在满足 OLTP 分布式性能的基础上融合了有场景意义的 OLAP 性能。目前 TiDB 已演进为一套技术栈，既能解决用户业务快速增长过程中海量数据存储、超大规模并发访问问题，又能支持复杂的实时查询分析，极大的提高了用户生产力。&lt;/p&gt;&lt;p&gt;尤其面对风险控制要求更高的金融行业，TiDB 表现出了架构的先进性和高效的性能，水平扩展能力、交易处理能力、功能指标特性均在应用中具备较大的优势，被成功应用在金融核心交易场景中。PingCAP 目前已经成为一家在互联网领域和传统金融领域均有大规模落地的新型分布式数据库公司。&lt;/p&gt;&lt;p&gt;截止目前 TiDB 已有准生产测试（POC）用户 1400 余家，其中 300 余家企业已经将其应用在实际生产环境中，涉及互联网、游戏、银行、证券、保险、第三方支付、政府、电信、航空、制造业、新零售、快消等多个领域。此外，还与国内外多家主流的大型公有云厂商深度集成，提供公有云数据库服务。&lt;/p&gt;&lt;p&gt;复星新技术与新经济产业集团副总裁丛永罡说：“在 PingCAP 持续 3 年的产品打磨和不断实践验证后，TiDB 成为早期将 HTAP 这个概念从实验室带到现实的产品之一。其 TiDB 开源项目获得业内高度认可，并已将国内大多数互联网独角兽企业揽为用户，这具有里程碑式的意义，也是业内高度认可的体现。”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;进一步构建全球化生态体系&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;作为一款基础设施领域的明星级开源项目，TiDB 项目目前在 GitHub 上拥有 15000+ 的 Star，集合了 200 多位 Contributor，入选 CNCF Cloud Native Landscape， 2018 Big Data &amp;amp; AI Landscape。此外， Databricks、Mobike、SpeedyCloud、韩国三星研究院等机构人员也已参与到 TiDB 项目的合作开发中，全球顶级云计算技术基金会 CNCF 也于 8 月 28 日正式接纳 TiDB 项目核心组件之一 TiKV 为基金会项目，TiDB 在全球技术社区的影响力开始爆发。&lt;/p&gt;&lt;p&gt;回顾 PingCAP 的发展历史，用 3 年时间逐步打造产品和布局，以稳健的产品表现及高速的公司发展获得业界瞩目。PingCAP 联合创始人、CEO 刘奇表示，作为一家技术驱动为核心的公司，PingCAP 从创立的第一天起，就专注于解决大数据和云计算时代的海量存储和计算问题，我们将持续保持技术驱动的内核和开源的生命力，不断强化技术和产品优势，为行业带来更多期待。&lt;/p&gt;&lt;p&gt;晨兴资本副总裁刘凯表示：“一直以来，数据库领域都是产品研发能力和商业运营能力的最高级竞技场，PingCAP 持续深耕互联网领域客户，取得了骄人业绩，已成为规模互联网企业和金融企业的主流选择，我们很高兴能够和公司一起成长，共同打造开源软件生态。”&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://pingcap.com/&quot;&gt;PingCAP&lt;/a&gt; 此前曾在 2015 年获得经纬中国的天使轮融资，2016 年获得云启资本领投 A 轮融资，2017 年获得华创资本领投 B 轮融资。2018 年获得复星、晨兴资本领投的 C 轮融资，成为目前为止新型分布式关系型数据库领域的最大笔融资。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-12-44322174</guid>
<pubDate>Wed, 12 Sep 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
