<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 08 Aug 2018 13:44:01 +0800</lastBuildDate>
<item>
<title>TiDB 源码阅读（十五） Sort Merge Join</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-08-41535500.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41535500&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e445e0a331d683cab8f11fda36478022_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/5202d0b6a9c623e0674ff36891c8ab52&quot; data-hash=&quot;5202d0b6a9c623e0674ff36891c8ab52&quot; data-hovercard=&quot;p$b$5202d0b6a9c623e0674ff36891c8ab52&quot;&gt;@姚维&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是 Sort Merge Join&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在开始阅读源码之前, 我们来看看什么是 Sort Merge Join (SMJ)，定义可以看 &lt;a href=&quot;https://en.wikipedia.org/wiki/Sort-merge_join&quot;&gt;wikipedia&lt;/a&gt;。简单说来就是将 Join 的两个表，首先根据连接属性进行排序，然后进行一次扫描归并, 进而就可以得出最后的结果。这个算法最大的消耗在于对内外表数据进行排序，而当连接列为索引列时，我们可以利用索引的有序性避免排序带来的消耗, 所以通常在查询优化器中，连接列为索引列的情况下可以考虑选择使用 SMJ。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Sort Merge Join 实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;执行过程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的实现代码在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/merge_join.go&quot;&gt;tidb/executor/merge_join.go&lt;/a&gt; 中 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.NextChunk&lt;/code&gt; 是这个算子的入口。下面以 &lt;code class=&quot;inline&quot;&gt;SELECT * FROM A JOIN B ON A.a = B.a&lt;/code&gt; 为例，对 SMJ 执行过程进行简述，假设此时外表为 A，内表为 B，join-keys 为 a，A，B 表的 a 列上都有索引：&lt;/p&gt;&lt;p&gt;1.顺序读取外表 A 直到 join-keys 中出现另外的值，把相同 keys 的行放入数组 a1，同样的规则读取内表 B，把相同 keys 的行放入数组 a2。如果外表数据或者内表数据读取结束，退出。&lt;/p&gt;&lt;p&gt;2. 从 a1 中读取当前第一行数据，设为 v1。从 a2 中读取当前第一行数据，设为 v2。&lt;/p&gt;&lt;p&gt;3. 根据 join-keys 比较 v1，v2，结果分为几种情况：&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0, 表示 v1 大于 v2，把当前 a2 的数据丢弃，从内表读取下一批数据，读取方法同 1。重复 2。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0, 表示 v1 小于 v2，说明外表的 v1 没有内表的值与之相同，把外表数据输出给 resultGenerator（不同的连接类型会有不同的结果输出，例如外连接会把不匹配的外表数据输出）。&lt;/li&gt;&lt;li&gt;cmpResult == 0, 表示 v1 等于 v2。那么遍历 a1 里面的数据，跟 a2 的数据，输出给 resultGenerator 作一次连接。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;4. 回到步骤 1。&lt;/p&gt;&lt;p&gt;下面的图展示了 SMJ 的过程：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b72f20067fcc79e607e567fbc8711bad_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;942&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b72f20067fcc79e607e567fbc8711bad&quot; data-watermark-src=&quot;v2-08f69ef7725298bf5d409e0fc691037f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;读取内表 / 外表数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们分别通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取内表和外表的数据。这两个函数实现的功能类似，这里只详述函数 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 的实现。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子读取数据，是通过迭代器 &lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 完成，&lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 可以顺序读取数据。&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子维护两个 readerIterator：&lt;code class=&quot;inline&quot;&gt;outerIter&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;innerIter&lt;/code&gt;，它们在 &lt;code class=&quot;inline&quot;&gt;buildMergeJoin&lt;/code&gt; 函数中被构造。&lt;/p&gt;&lt;p&gt;真正读取数据的操作是在 &lt;code class=&quot;inline&quot;&gt;readerIterator.nextSelectedRow&lt;/code&gt; 中完成, 这里会通过 &lt;code class=&quot;inline&quot;&gt;ri.reader.NextChunk&lt;/code&gt; 每次读取一个 Chunk 的数据，关于 Chunk 的相关内容，可以查看我们之前的文章 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;TiDB 源码阅读系列文章（十）Chunk 和执行框架简介&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;这里值得注意的是，我们通过 &lt;code class=&quot;inline&quot;&gt;expression.VectorizedFilter&lt;/code&gt; 对外表数据进行过滤，返回一个 curSelected 布尔数组，用于外表的每一行数据是否是满足 filter 过滤条件。以 &lt;code class=&quot;inline&quot;&gt;select * from t1 left outer join t2 on t1.a=100;&lt;/code&gt; 为例, 这里的 filter 是 &lt;code class=&quot;inline&quot;&gt;t1.a=100&lt;/code&gt;, 对于没有通过这个过滤条件的行，我们通过 &lt;code class=&quot;inline&quot;&gt;ri.joinResultGenerator.emitToChunk&lt;/code&gt; 函数发送给 resultGenerator, 这个 resultGenerator 是一个 interface，具体是否输出这行数据，会由 join 的类型决定，比如外连接则会输出，内连接则会忽略。具体关于 resultGenerator, 可以参考之前的文章：&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-9/&quot;&gt;TiDB 源码阅读系列文章（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;rowsWithSameKey&lt;/code&gt; 通过 &lt;code class=&quot;inline&quot;&gt;nextSelectedRow&lt;/code&gt; 不断读取下一行数据，并通过对每行数据的 join-keys 进行判断是不是属于同一个 join-keys，如果是，会把相同 join-keys 的行分别放入到 &lt;code class=&quot;inline&quot;&gt;innerChunkRows&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;outerIter4Row&lt;/code&gt; 数组中。然后对其分别建立迭代器 innerIter4Row 和 outerIter4Row。在 SMJ 中的执行过程中，会利用这两个迭代器来获取数据进行真正的比较得出 join result。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Merge-Join&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实现 Merge-Join 逻辑的代码在函数 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.joinToChunk&lt;/code&gt;, 对内外表迭代器的当前数据根据各自的 join-keys 作对比，有如下几个结果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0，代表外表当前数据大于内表数据，那么通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 直接读取下一个内表数据，然后重新比较即可。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0，代表外表当前数据小于内表数据，这个时候就分几种情况了，如果是外连接，那么需要输出外表数据 + NULL，如果是内连接，那么这个外表数据就被忽略，对于这个不同逻辑的处理，统一由 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator&lt;/code&gt; 来控制，我们只需要把外表数据通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 调用它即可。然后通过 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取下一个外表数据，重新比较。&lt;/li&gt;&lt;li&gt;cmpResult == 0，代表外表当前数据等于内表当前数据，这个时候就把外表数据跟内表当前数据做一次连接，通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 生成结果。之后外表跟内表分别获取下一个数据，重新开始比较。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;重复上面的过程，直到外表或者内表数据被遍历完，退出 Merge-Join 的过程。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们上面的分析代码基于 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/source-code&quot;&gt;Source-code&lt;/a&gt; 分支，可能大家已经发现了一些问题，比如我们会一次性读取内外表的 Join group（相同的 key）。这里如果相同的 key 比较多，是有内存 OOM 的风险的。针对这个问题，我们在最新的 master 分支做了几个事情来优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;外表其实不需要把相同的 keys 一次性都读取上来， 它只需要按次迭代外表数据，再跟内表逐一对比作连接即可。这里至少可以减少外表发生 OOM 的问题，可以大大减少 OOM 的概率。&lt;/li&gt;&lt;li&gt;对于内表，我们对 OOM 也不是没有办法，我们用 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 这个内存追踪器来记录当前内表已经使用的中间结果的内存大小，如果它超过我们设置的阈值，我们会采取输出日志或者终止 SQL 继续运行的方法来规避 OOM 的发生。关于 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 我们不在此展开，可以留意我们后续的源码分析文章。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续我们还会在 Merge-Join 方面做一些优化， 比如我们可以做多路归并，中间结果存外存等等，敬请期待。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-08-41535500</guid>
<pubDate>Wed, 08 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>30 分钟成为 TiKV Contributor</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-02-41103417.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41103417&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3e6973721ffe23e838d18d1d6cebc858_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;作者：吴雪莲&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;背景知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;SQL 语句发送到 TiDB 后经过 parser 生成 AST（抽象语法树），再经过 Query Optimizer 生成执行计划，执行计划切分成很多子任务，这些子任务以表达式的方式最后下推到底层的各个 TiKV 来执行。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d54ea1017d24caf90ab9d7f987f40fae_r.jpg&quot; data-caption=&quot;图 1&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;860&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d54ea1017d24caf90ab9d7f987f40fae&quot; data-watermark-src=&quot;v2-d826905412f823c66e227f7c2ec3f603&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;如图 1，当 TiDB 收到来自客户端的查询请求&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;select count(*) from t where a + b &amp;gt; 5&lt;/code&gt;&lt;/p&gt;&lt;p&gt;时，执行顺序如下：&lt;/p&gt;&lt;p&gt;1.TiDB 对 SQL 进行解析，组织成对应的表达式，下推给 TiKV&lt;/p&gt;&lt;p&gt;2. TiKV 收到请求后，循环以下过程&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;获取下一行完整数据，并按列解析&lt;/li&gt;&lt;li&gt;使用参数中的 where 表达式对数据进行过滤&lt;/li&gt;&lt;li&gt;若上一条件符合，进行聚合计算&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;3. TiKV 向 TiDB 返回聚合计算结果&lt;/p&gt;&lt;p&gt;4. TiDB 对所有涉及的结果进行二次聚合，返回给客户端&lt;/p&gt;&lt;p&gt;这里的 where 条件便是以表达式树的形式下推给 TiKV。在此之前 TiDB 只会向 TiKV 下推一小部分简单的表达式，比如取出某一个列的某个数据类型的值，简单数据类型的比较操作，算术运算等。为了充分利用分布式集群的资源，进一步提升 SQL 在整个集群的执行速度，我们需要将更多种类的表达式下推到 TiKV 来运行，其中的一大类就是 MySQL built-in 函数。&lt;br&gt;目前，由于 TiKV 的 built-in 函数尚未全部实现，对于无法下推的表达式，TiDB 只能自行解决。这无疑将成为提升 TiDB 速度的最大绊脚石。好消息是，TiKV 在实现 built-in 函数时，可以直接参考 TiDB 的对应函数逻辑（顺便可以帮 TiDB 找找 Bug），为我们减少了不少工作量。&lt;/p&gt;&lt;p&gt;Built-in 函数无疑是 TiDB 和 TiKV 成长道路上不可替代的一步，如此艰巨又庞大的任务，我们需要广大社区朋友们的支持与鼓励。亲爱的朋友们，想玩 Rust 吗？想给 TiKV 提 PR 吗？想帮助 TiDB 跑得更快吗？动动您的小手指，拿 PR 来砸我们吧。您的 PR 一旦被采用，将会有小惊喜哦。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;手把手教你实现 built-in 函数&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Step 1：准备下推函数&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiKV 的 &lt;a href=&quot;https://github.com/pingcap/tikv/issues/3275&quot;&gt;https://github.com/pingcap/tikv/issues/3275&lt;/a&gt; issue 中，找到未实现的函数签名列表，选一个您想要实现的函数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 2：获取 TiDB 中可参考的逻辑实现&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下查找相关 builtinXXXSig 对象，这里 XXX 为您要实现的函数签名，本例中以 &lt;a href=&quot;https://github.com/pingcap/tikv/pull/3277&quot;&gt;MultiplyIntUnsigned&lt;/a&gt; 为例，可以在 TiDB 中找到其对应的函数签名（&lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;）及 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;实现&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 3：确定函数定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1.built-in 函数所在的文件名要求与 TiDB 的名称对应，如 TiDB 中，&lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下的下推文件统一以 builtin_XXX 命名，对应到 TiKV 这边，就是 &lt;code class=&quot;inline&quot;&gt;builtin_XXX.rs&lt;/code&gt;。若同名对应的文件不存在，则需要自行在同级目录下新建。对于本例，当前函数存放于 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;builtin_arithmetic.go&lt;/a&gt; 文件里，对应到 TiKV 便是存放在 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;2. 函数名称：函数签名转为 Rust 的函数名称规范，这里 &lt;code class=&quot;inline&quot;&gt;MultiplyIntUnsigned&lt;/code&gt; 将会被定义为 &lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;3. 函数返回值，可以参考 TiDB 中实现的 &lt;code class=&quot;inline&quot;&gt;Eval&lt;/code&gt; 函数，对应关系如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4fb256c456c3220224e6055ca6ab6bf6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1158&quot; data-rawheight=&quot;838&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4fb256c456c3220224e6055ca6ab6bf6&quot; data-watermark-src=&quot;v2-6781bac667ad6b94c4a8b7ec58af83eb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;  对象实现了 evalInt 方法，故当前函数（&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;）的返回类型应该为 &lt;code class=&quot;inline&quot;&gt;Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;4. 函数的参数, 所有 builtin-in 的参数都与 Expression 的 &lt;code class=&quot;inline&quot;&gt;eval&lt;/code&gt; 函数一致，即：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;环境配置量 (ctx:&amp;amp;StatementContext)&lt;/li&gt;&lt;li&gt;该行数据每列具体值 (row:&amp;amp;[Datum])&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上，&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt; 的下推函数定义为：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 4：实现函数逻辑&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一块相对简单，直接对照 TiDB 的相关逻辑实现即可。这里，我们可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt; 的具体实现如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;func (s *builtinArithmeticMultiplyIntUnsignedSig) evalInt(row types.Row) (val int64, isNull bool, err error) {
  a, isNull, err := s.args[0].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedA := uint64(a)
  b, isNull, err := s.args[1].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedB := uint64(b)
  result := unsignedA * unsignedB
  if unsignedA != 0 &amp;amp;&amp;amp; result/unsignedA != unsignedB {
     return 0, true, types.ErrOverflow.GenByArgs(&quot;BIGINT UNSIGNED&quot;, fmt.Sprintf(&quot;(%s * %s)&quot;, s.args[0].String(), s.args[1].String()))
  }
  return int64(result), false, nil
}&lt;/code&gt;&lt;p&gt;参考以上代码，翻译到 TiKV 即可，如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt; {
       let lhs = try_opt!(self.children[0].eval_int(ctx, row));
       let rhs = try_opt!(self.children[1].eval_int(ctx, row));
       let res = (lhs as u64).checked_mul(rhs as u64).map(|t| t as i64);
       // TODO: output expression in error when column&#39;s name pushed down.
       res.ok_or_else(|| Error::overflow(&quot;BIGINT UNSIGNED&quot;, &amp;amp;format!(&quot;({} * {})&quot;, lhs, rhs)))
           .map(Some)
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 5：添加参数检查&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在收到下推请求时，首先会对所有的表达式进行检查，表达式的参数个数检查就在这一步进行。&lt;/p&gt;&lt;p&gt;TiDB 中对每个 built-in 函数的参数个数有严格的限制，这一部分检查可参考 TiDB 同目录下 builtin.go 相关代码。&lt;/p&gt;&lt;p&gt;在 TiKV 同级目录的 scalar_function.rs 文件里，找到 ScalarFunc 的 check_args 函数，按照现有的模式，加入参数个数的检查即可。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 6：添加下推支持&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在对一行数据执行具体的 expression 时，会调用 eval 函数，eval 函数又会根据具体的返回类型，执行具体的子函数。这一部分工作在 scalar_function.rs 中以宏（dispatch_call）的形式完成。&lt;/p&gt;&lt;p&gt;对于 MultiplyIntUnsigned, 我们最终返回的数据类型为 Int，所以可以在 dispatch_call 中找到 INT_CALLS，然后照着加入 MultiplyIntUnsigned =&amp;gt; multiply_int_unsigned , 表示当解析到函数签名 MultiplyIntUnsigned 时，调用上述已实现的函数 multiply_int_unsigned。&lt;/p&gt;&lt;p&gt;至此 MultiplyIntUnsigned 下推逻辑已完全实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 7：添加测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在函数 multiply_int_unsigned 所在文件 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 底部的 test 模块中加入对该函数签名的单元测试，要求覆盖到上述添加的所有代码，这一部分也可以参考 TiDB 中相关的测试代码。本例在 TiKV 中实现的测试代码如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;#[test]
   fn test_multiply_int_unsigned() {
       let cases = vec![
           (Datum::I64(1), Datum::I64(2), Datum::U64(2)),
           (
               Datum::I64(i64::MIN),
               Datum::I64(1),
               Datum::U64(i64::MIN as u64),
           ),
           (
               Datum::I64(i64::MAX),
               Datum::I64(1),
               Datum::U64(i64::MAX as u64),
           ),
           (Datum::U64(u64::MAX), Datum::I64(1), Datum::U64(u64::MAX)),
       ];

       let mut ctx = EvalContext::default();
       for (left, right, exp) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap();
           assert_eq!(got, exp);
       }

       // test overflow
       let cases = vec![
           (Datum::I64(-1), Datum::I64(2)),
           (Datum::I64(i64::MAX), Datum::I64(i64::MAX)),
           (Datum::I64(i64::MIN), Datum::I64(i64::MIN)),
       ];

       for (left, right) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap_err();
           assert!(check_overflow(got).is_ok());
       }
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 8：运行测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;运行 make expression，确保所有的 test case 都能跑过。&lt;/p&gt;&lt;p&gt;完成以上几个步骤之后，就可以给 TiKV 项目提 PR 啦。想要了解提 PR 的基础知识，尝试移步 &lt;a href=&quot;https://pingcap.com/blog-how-to-contribute-zh&quot;&gt;此文&lt;/a&gt;，看看是否有帮助。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;欢迎大家踊跃贡献代码，加入 TiDB community ！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://github.com/pingcap.com&quot;&gt;http://github.com/pingcap.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-02-41103417</guid>
<pubDate>Thu, 02 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>社区 | 如何优雅降落到 TiDB 星球？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-25-40529913.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40529913&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74fe289237a86bdb2092bfb84524db33_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;提到「开源项目 TiDB」人们总是习惯性反应：它在 GitHub 上 Star 数已经超过 17000，并拥有 260+ 位全球各地的 Contributors 。但数据总归是冷冰冰的，不能生动的展现 TiDB 社区的魅力。所以今天推送一篇 &lt;b&gt;TiDB contributor&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;杜川&lt;/b&gt;同学加入 TiDB 社区前后的「心路历程」，他从亲历者的角度告诉你——&lt;/i&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;PingCAPer 够 nice 么？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;积极参与 TiDB 社区对自己的能力提升有何帮助？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;如何在 TiDB 星球上找到最适合自己的落点？（ 或者在大树上找到自己最擅长的“小树杈”hhhhhh）&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;&lt;b&gt;以及…利用好碎片时间，你也可以一年给 TiDB 提&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;70&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;个 PR！&lt;/b&gt;&lt;/i&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;🚀&lt;/b&gt; 作者：杜川，TiDB contributor&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;最近这一年多断断续续一直在往 TiDB 中提交一些修改，前两天看了一些 GitHub  提交记录，发现竟然已经累计了 70 来个 PR 了。考虑到最近这一年基本处于疯狂加班的节奏，另外忙里偷闲还基本上刷完了之前列的十几本书的读书清单，我觉得这也算一个不大不小的成就吧，值得 mark 一下。&lt;/p&gt;&lt;p&gt;话说回来，虽然我 17 年年中才开始给 TiDB 提交 PR，其实在之前一年多以前，大概在 2016 年 4 月份左右, 就听说过 TiDB 这个项目了。当时我的主要工作也是车一个 SQL 执行引擎，所以对分布式数据库业界的相关新闻还是比较关注的。&lt;/p&gt;&lt;p&gt;虽然数据库是一个轮子高发领域，各种轮子五花八门，但是在国内，数据库，特别是分布式数据库这块的轮子，基本还是几个大厂在车，要么不开源，要么开源了社区也不甚活跃。像 TiDB 这样要从头车一个分布式数据库，并且还是完全开源的方式来搞，确实让我印象深刻。后来组里一个小哥离职投奔 PingCAP，我借着面基的名义陆陆续续参加了 TiDB 几次线下 Meetup，也由此认识了很多 TiDB 社区的小伙伴。&lt;/p&gt;&lt;p&gt;16 年底从北京回到成都以后，工作重心发生了一些变化，从之前的纯做 infra，转变为更多地要面对业务层面的需求。不过做了几年 infra，自己本身对数据库内核还是很感兴趣的，所以工作之余，开始研究 TiDB 的实现，并且搭了一套 TiDB，在开发环境里代替 MySQL。我们都知道，MySQL 经过多年的发展，其 SQL 语法是比较复杂的。TiDB 虽然全面兼容 MySQL 的语法和协议，但是因为没有复用 MySQL 代码，肯定不可能做到 100% 兼容，落实到一些具体的语句上，肯定会和 MySQL 有一些区别。因为之前我也一直在做 OLAP 系统的 SQL 引擎的开发工作，对这一块比较熟悉，在遇到这方面问题后，感觉解决起来也并不很麻烦，因此慢慢开始在这个方面给 TiDB 提一些 PR。到后面熟悉了以后，有时间的话也会到 TiDB 的 issue list 上捞相关的 issue 解决，主要集中于 SQL Parser, 表达式计算和 MySQL 兼容性等方面。最近抽空在做的是和聚合函数相关的一些 Feature。&lt;/p&gt;&lt;p&gt;因为平时工作还是比较忙，加班也是家常便饭，因此给 TiDB 提交 PR，回复 Review 意见的时间段基本都集中在周末，晚上老婆睡觉以后，或者午休间隙。这样有一个问题是时间段比较离散，很难有长时间的连贯思考的时间。因此现阶段一方面我在提 PR 的时候会选择一些相对较小，独立一些的 Feature。&lt;b&gt;另一方面，我尽量把开发放在时间相对充裕的周末，把晚上和其他零碎时间用来查看和回复 Review 意见，Update 代码和跑回归测试。这样算下来，平均提交一个 PR，算上开发，测试，和社区小伙伴沟通，大概要消耗 3 到 5 个工时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不过这个时间投入我觉得倒是非常划算，一是因为我本身对数据库就非常感兴趣，把参与 TiDB 社区开发当成了一种兴趣，可以看做是工作之余的一种放松，二是我一直在从事数据库相关的工作，包括之前 OLAP SQL 引擎的运行时优化相关工作，和现在云数据库相关的工作，其实和在社区所做的事情都是密切相关的。比如一个 MySQL Builtin 函数, 在各种极端输入下的表现是怎样的，或是 SQL_MODE 的各种组合对这个 Builtin 函数的行为有什么样的影响，这些问题在平时工作中，我可能很难考虑得非常周全；但是要在社区中提一个 PR 实现这个 Builtin 函数，我就非得把这些问题考虑清楚，并经受社区小伙伴各种 Case 的轰炸考验。等这个 PR 顺利被 Commit，这些细节我也烂熟于心了。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-13d78a931d43996617464c58e89c8b85_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2006&quot; data-rawheight=&quot;1034&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-13d78a931d43996617464c58e89c8b85&quot; data-watermark-src=&quot;v2-2370357a5b7bf01a8e24495f78b5f21b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;说到社区，我觉得 TiDB 做得相当不错。一方面 PingCAPers 都很活跃，在 GitHub 上提的 Issue 一般很快就能得到回复, 有什么疑问通过 GitHub, 微信群甚至知乎提问等很快都能得到反馈；另一方面更重要的是在 Review PR 的时候社区小伙伴能保持比较严谨的态度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就我的经历而言，我在开发过程中没有注意到的一些 Corner Case 和细节错误，基本都能在 Review PR 过程被翻出来，这不仅需要 Reviewer 理清楚 PR 对应 Feature 的相关细节，构造出可能有问题的场景，还需要 Reviewer 理解 PR 作者的开发思路。其中需要花费的精力，常常不低于开发这个 Feature 本身。此外，还有一个我觉得很赞的方面是 TiDB 花了很多心思来构建从 UT，FT 到集成测试的一系列测试框架，让我在参与开发工程中比较容易对自己开发的 Feature 进行各个方位的测试，节省了很多来回捣腾的麻烦。&lt;/p&gt;&lt;p&gt;总的来说，参与 TiDB 社区是一件非常有意思的事情，给我带来很多收获，我也会继续关注 TiDB 项目的进展。短时间来看，我的计划主要还是抽空完成手头聚合函数相关的一些 Feature，包括对 MySQL 聚合函数 STDDEV，VARIANCE 等的支持，以及在 TiKV Coprocessor 侧的对应改动。之后，我打算看看能不能够结合我之前在 OLAP SQL 引擎的运行时优化方面的经验，提升 TiDB 在 OLAP 领域的能力。不过这个是一个比较大的目标了，到时候还要和社区的小伙伴多多讨论。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;TiDB 社区大事件&lt;/b&gt;&lt;/i&gt; &lt;/p&gt;&lt;p&gt;&lt;i&gt;TiDB TechDay2018 即将于 7 月 28 日在深圳举办，目前报名已满，我们周六见哦！点击&lt;u&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486395&amp;amp;idx=1&amp;amp;sn=bfa0227d14a27e02dcd0e26939125c24&amp;amp;chksm=eb162cd1dc61a5c7d6da2bc2e3dc8e6413e28c1085a69cb0518adb1dc27cd38c8bdc64ec1fbb&amp;amp;scene=21#wechat_redirect&quot;&gt;【这里】&lt;/a&gt;&lt;/u&gt;查看活动详情。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;P.S 欢迎踊跃勾搭 &lt;b&gt;TiDB Robot （微信号：tidbai）&lt;/b&gt;加入 TiDB 星球～&lt;/i&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-84bfe17ec8227fa695e364a4815dfe35_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;3515&quot; data-rawheight=&quot;1758&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-84bfe17ec8227fa695e364a4815dfe35&quot; data-watermark-src=&quot;v2-15585058505faf294ec8f410cce97ab5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-25-40529913</guid>
<pubDate>Wed, 25 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十四）统计信息（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-19-40079139.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40079139&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c34786efbf579d9eef6f636c5afda076_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：谢海滨&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价，本篇将会结合原理介绍 TiDB 的源码实现。&lt;/p&gt;&lt;p&gt;文内会先介绍直方图和 Count-Min(CM) Sketch 的数据结构，然后介绍 TiDB 是如何实现统计信息的查询、收集以及更新的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据结构定义&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;直方图的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L40&quot;&gt;histograms.go&lt;/a&gt; 中找到，值得注意的是，对于桶的上下界，我们使用了在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;《TiDB 源码阅读系列文章（十）Chunk 和执行框架简介》&lt;/a&gt; 中介绍到 Chunk 来存储，相比于用 Datum 的方式，可以减少内存分配开销。&lt;/p&gt;&lt;p&gt;CM Sketch 的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L31&quot;&gt;cmsketch.go&lt;/a&gt; 中找到，比较简单，包含了 CM Sketch 的核心——二维数组 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt;，并存储了其深度与宽度，以及总共插入的值的数量，当然这些都可以直接从 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt; 中得到。&lt;/p&gt;&lt;p&gt;除此之外，对列和索引的统计信息，分别使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L699&quot;&gt;Column&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L773&quot;&gt;Index&lt;/a&gt; 来记录，主要包含了直方图，CM Sketch 等。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息创建&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在执行 analyze 语句时，TiDB 会收集直方图和 CM Sketch 的信息。在执行 analyze 命令时，会先将需要 analyze 的列和索引在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/master/plan/planbuilder.go#L609&quot;&gt;builder.go&lt;/a&gt; 中切分成不同的任务，然后在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/executor/analyze.go#L114&quot;&gt;analyze.go&lt;/a&gt; 中将任务下推至 TiKV 上执行。由于在 TiDB 中也包含了 TiKV 部分的实现，因此在这里还是会以 TiDB 的代码来介绍。在这个部分中，我们会着重介绍直方图的创建。&lt;/p&gt;&lt;p&gt;&lt;b&gt;列直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在统计信息（上）中提到，在建立列直方图的时候，会先进行抽样，然后再建立直方图。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/sample.go#L113&quot;&gt;collect&lt;/a&gt; 函数中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。由于其原理和代码都比较简单，在这里不再介绍。&lt;/p&gt;&lt;p&gt;采样完成后，在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L97&quot;&gt;BuildColumn&lt;/a&gt; 中，我们实现了列直方图的创建。首先将样本排序，确定每个桶的高度，然后顺序遍历每个值 V：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如果 V 等于上一个值，那么把 V 放在与上一个值同一个桶里，无论桶是不是已经满，这样可以保证每个值只存在于一个桶中。&lt;/li&gt;&lt;li&gt;如果不等于上一个值，那么判断当前桶是否已经满，就直接放入当前桶，并用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L146&quot;&gt;updateLastBucket&lt;/a&gt; 更改桶的上界和深度。&lt;/li&gt;&lt;li&gt;否则的话，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L151&quot;&gt;AppendBucket&lt;/a&gt; 放入一个新的桶。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;索引直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在建立索引列直方图的时候，我们使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L24&quot;&gt;SortedBuilder&lt;/a&gt; 来维护建立直方图的中间状态。由于不能事先知道有多少行的数据，也就不能确定每一个桶的深度，不过由于索引列的数据是已经有序的，因次我们在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L38&quot;&gt;NewSortedBuilder&lt;/a&gt; 中将每个桶的初始深度设为 1。对于每一个数据，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L50&quot;&gt;Iterate&lt;/a&gt; 会使用建立列直方图时类似的方法插入数据。如果在某一时刻，所需桶的个数超过了当前桶深度，那么用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L74&quot;&gt;mergeBucket&lt;/a&gt; 将之前的每两个桶合并为 1 个，并将桶深扩大一倍，然后继续插入。&lt;/p&gt;&lt;p&gt;在收集了每一个 Region 上分别建立的直方图后，还需要用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L609&quot;&gt;MergeHistogram&lt;/a&gt; 把每个 Region 上的直方图进行合并。在这个函数中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了保证每个值只在一个桶中，我们处理了处理一下交界处桶的问题，即如果交界处两个桶的上界和下界 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L623&quot;&gt;相等&lt;/a&gt;，那么需要先合并这两个桶；&lt;/li&gt;&lt;li&gt;在真正合并前，我们分别将两个直方图的平均桶深 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L642&quot;&gt;调整&lt;/a&gt; 至大致相等；&lt;/li&gt;&lt;li&gt;如果直方图合并之后桶的个数超过了限制，那么把两两相邻的桶 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L653&quot;&gt;合二为一&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息维护&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了 TiDB 是如何更新直方图和 CM Sketch 的。对于 CM Sketch 其更新比较简单，在这里不再介绍。这个部分主要介绍一下 TiDB 是如何收集反馈信息和维护直方图的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;反馈信息的收集&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，为了不去假设所有桶贡献的误差都是均匀的，需要收集每一个桶的反馈信息，因此需要先把查询的范围按照直方图桶的边界切分成不相交的部分。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L511&quot;&gt;SplitRange&lt;/a&gt; 中，我们按照直方图去切分查询的范围。由于目前直方图中的一个桶会包含上下界，为了方便，这里只按照上界去划分，即这里将第 i 个桶的范围看做 &lt;code class=&quot;inline&quot;&gt;(i-1 桶的上界，i 桶的上界]&lt;/code&gt;。特别的，对于最后一个桶，将其的上界视为无穷大。比方说一个直方图包含 ３ 个桶，范围分别是: [2，5]，[8，8]，[10，13]，查询的范围是 (3，20]，那么最终切分得到的查询范围就是 (3，5]，(5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;将查询范围切分好后，会被存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，以便在每个 Region 的结果返回时，调用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L165&quot;&gt;Update&lt;/a&gt; 函数来更新每个范围所包含的 key 数目。注意到这个函数需要两个参数：每个 Region 上扫描的 start key 以及 Region 上每一个扫描范围输出的 key 数目 output counts，那么要如何更新 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 中每个范围包含的 key 的数目呢？&lt;/p&gt;&lt;p&gt;继续以划分好的 (3，5]，(5，8]，(8，20] 为例，假设这个请求需要发送到两个 region 上，region1 的范围是 [0，6)，region2 的范围是 [6，30)，由于 coprocessor 在发请求的时候还会根据 Region 的范围切分 range，因此 region1 的请求范围是 (3，5]，(5，6)，region2 的请求范围是 [6，8]，(8，20]。为了将对应的 key 数目更新到 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，需要知道每一个 output count 对应的查询范围。注意到 coprocessor 返回的 output counts 其对应的 Range 都是连续的，并且同一个值只会对应一个 range，那么我们只需要知道第一个 output count 所对应的 range，即只需要知道这次扫描的 start key 就可以了。举个例子，对于 region1 来说，start key 是 3，那么 output counts 对应的 range 就是 (3，5]，(5，8]，对 region2 来说，start key 是 6，output countshangyipians 对应的 range 就是 (5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;&lt;b&gt;直方图的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在收集了 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 后，我们就可以去使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L536&quot;&gt;UpdateHistogram&lt;/a&gt; 来更新直方图了。其大体上可以分为分裂与合并。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L503&quot;&gt;splitBuckets&lt;/a&gt; 中，我们实现了直方图的分裂：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先，由于桶与桶之间的反馈信息不相关，为了方便，先将 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L504&quot;&gt;buildBucketFeedback&lt;/a&gt; 拆分了每一个桶的反馈信息，并存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L213&quot;&gt;BucketFeedback&lt;/a&gt; 中。&lt;/li&gt;&lt;li&gt;接着，使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L507&quot;&gt;getSplitCount&lt;/a&gt; 来根据可用的桶的个数和反馈信息的总数来决定分裂的数目。&lt;/li&gt;&lt;li&gt;对于每一个桶，将可以分裂的桶按照反馈信息数目的比例均分，然后用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;splitBucket&lt;/a&gt; 来分裂出需要的桶的数目：&lt;/li&gt;&lt;li&gt;首先，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;getBoundaries&lt;/a&gt; 会每隔几个点取一个作为边界，得到新的桶。&lt;/li&gt;&lt;li&gt;然后，对于每一个桶，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L32%201&quot;&gt;refineBucketCount&lt;/a&gt; 用与新生成的桶重合部分最多的反馈信息更新桶的深度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，在分裂的时候，如果一个桶过小，那么这个桶不会被分裂；如果一个分裂后生成的桶过小，那么它也不会被生成。&lt;/p&gt;&lt;p&gt;在桶的分裂完成后，我们会使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L467&quot;&gt;mergeBuckets&lt;/a&gt; 来合并桶，对于那些超过：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在分裂的时候，会记录每一个桶是不是新生成的，这样，对于原先就存在的桶，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L476&quot;&gt;getBucketScore&lt;/a&gt; 计算合并的之后产生的误差，令第一个桶占合并后桶的比例为 r，那么令合并后产生的误差为 abs（合并前第一个桶的高度 - r * 两个桶的高度和）/ 合并前第一个桶的高度。&lt;/li&gt;&lt;li&gt;接着，对每一桶的合并的误差进行排序。&lt;/li&gt;&lt;li&gt;最后，按照合并的误差从下到大的顺序，合并需要的桶。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在查询语句中，我们常常会使用一些过滤条件，而统计信息估算的主要作用就是估计经过这些过滤条件后的数据条数，以便优化器选择最优的执行计划。&lt;/p&gt;&lt;p&gt;由于在单列上的查询比较简单，这里不再赘述，代码基本是按照 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中的原理实现，感兴趣可以参考 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L408&quot;&gt;histogram.go/lessRowCount&lt;/a&gt;  以及 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L69&quot;&gt;cmsketch.go/queryValue&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L148&quot;&gt;Selectivity&lt;/a&gt; 是统计信息模块对优化器提供的最重要的接口，处理了多列查询的情况。Selectivity 的一个最重要的任务就是将所有的查询条件分成尽量少的组，使得每一组中的条件都可以用某一列或者某一索引上的统计信息进行估计，这样我们就可以做尽量少的独立性假设。&lt;/p&gt;&lt;p&gt;需要注意的是，我们将单列的统计信息分为 3 类：&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L42&quot;&gt;indexType&lt;/a&gt; 即索引列，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L43&quot;&gt;pkType&lt;/a&gt; 即 Int 类型的主键，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L44&quot;&gt;colType&lt;/a&gt; 即普通的列类型，如果一个条件可以同时被多种类型的统计信息覆盖，那么我们优先会选择 pkType 或者 indexType。&lt;/p&gt;&lt;p&gt;在 Selectivity 中，有如下几个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L230&quot;&gt;getMaskAndRange&lt;/a&gt; 为每一列和每一个索引计算了可以覆盖的过滤条件，用一个 int64 来当做一个 bitset，并把将该列可以覆盖的过滤条件的位置置为 1。&lt;/li&gt;&lt;li&gt;接下来在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L258&quot;&gt;getUsableSetsByGreedy&lt;/a&gt; 中，选择尽量少的 bitset，来覆盖尽量多的过滤条件。每一次在还没有使用的 bitset 中，选择一个可以覆盖最多尚未覆盖的过滤条件。并且如果可以覆盖同样多的过滤条件，我们会优先选择 pkType 或者 indexType。&lt;/li&gt;&lt;li&gt;用统计信息（上）提到的方法对每一个列和每一个索引上的统计信息进行估计，并用独立性假设将它们组合起来当做最终的结果。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;统计信息的收集和维护是数据库的核心功能，对于基于代价的查询优化器，统计信息的准确性直接影响了查询效率。在分布式数据库中，收集统计信息和单机差别不大，但是维护统计信息有比较大的挑战，比如怎样在多节点更新的情况下，准确及时的维护统计信息。&lt;/p&gt;&lt;p&gt;对于直方图的动态更新，业界一般有两种方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于每一次增删，都去更新对应的桶深。在一个桶的桶深过高的时候分裂桶，一般是把桶的宽度等分，不过这样很难准确的确定分界点，引起误差。&lt;/li&gt;&lt;li&gt;使用查询得到的真实数去反馈调整直方图，假定所有桶贡献的误差都是均匀的，用连续值假设去调整所有涉及到的桶。然而误差均匀的假设常常会引起问题，比如当当新插入的值大于直方图的最大值时，就会把新插入的值引起的误差分摊到直方图中，从而引起误差。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 TiDB 的统计信息还是以单列的统计信息为主，为了减少独立性假设的使用，在将来 TiDB 会探索多列统计信息的收集和维护，为优化器提供更准确的统计信息。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39649659&quot;&gt;（十三）索引范围计算简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;（十二）统计信息（上）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-19-40079139</guid>
<pubDate>Thu, 19 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>邀请函 | TiDB TechDay2018 我们在深圳等你</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-17-39909349.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39909349&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9c5c16735754d909c3d8e9f011d55d3c_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;7 月 28 日，第二届 TiDB TechDay 即将落地深圳。&lt;/b&gt;我们准备了干货 Talk、美食和你们心心念念的 T 恤、贴纸……想和你一起聊聊技术，吃吃喝喝，谈谈情面面基&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;自由软件之父 Richard Matthew Stallman 曾说过：“如果你想为这世界做些什么，仅有理想是不够的，你需要找条通往目标的道路并走完。”&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 选择的开源之路，让我们在正确的道路上可以快速奔跑，同时收获了一个充满能量又有趣的社区。&lt;/b&gt;目前 TiDB/TiKV 已经汇聚了 &lt;b&gt;260&lt;/b&gt; 位来自全球各地的 Contributors，并在 GitHub 上获得了 &lt;b&gt;17000+&lt;/b&gt; Stars，这是我们遥远征途上的一个小小的成就，感谢社区帮助我们一起走得更远。&lt;/p&gt;&lt;p&gt;去年七月，我们在上海举办了首场 TiDB TechDay，用一整天的时间为社区小伙伴抽丝剥茧的讲解 TiDB 技术细节。今年我们除了 TiDB 技术分享之外，还带来了精彩的用户实践和社区小伙伴的贡献心得。希望这一天，能满足你对 TiDB 更深层细节的所有好奇。&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家加入这一场社区狂欢，和我们一起感受开源的魅力！&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-053f8cff20688c7ffd8efe58269f1851_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1028&quot; data-rawheight=&quot;1626&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-053f8cff20688c7ffd8efe58269f1851&quot; data-watermark-src=&quot;v2-ddcc1d914a44963e876074df60a70a79&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2018-07-28 周六&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：深圳市 · 南山区 · 南海大道 1079 号花园城数码大厦 A 座 2 楼 201 优客工场&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href=&quot;http://www.huodongxing.com/event/6449101295200&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-f59f2b532f746892c5b17729eed83b3b&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; data-image-size=&quot;180x120&quot;&gt;TiDB TechDay2018 · 深圳&lt;/a&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;TiDB TechDay2018 日 程 &lt;/b&gt;&lt;br&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;9:00 - 9:45  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;现场签到&lt;/p&gt;&lt;p&gt;&lt;b&gt;9:45 - 10:00  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;开场&lt;/p&gt;&lt;p&gt;&lt;b&gt;10:00 - 11:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.1: What&#39;s new and What&#39;s next&lt;br&gt;申砾 | PingCAP Engineering VP&lt;/p&gt;&lt;p&gt;&lt;b&gt;11:00 - 11:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 1：TiDB 在转转的千亿级大规模实践&lt;br&gt;孙玄 | 转转 首席架构师&lt;/p&gt;&lt;p&gt;&lt;b&gt;11:30 - 12:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 社区及开源大生态&lt;br&gt;黄东旭 | PingCAP 联合创始人兼 CTO &lt;/p&gt;&lt;p&gt;&lt;b&gt;12:30 - 13:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;午餐&lt;/p&gt;&lt;p&gt;&lt;b&gt;13:30 - 14:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 2：平安产险 TiDB 应用实践&lt;br&gt;丁永 | 平安产险 大数据平台产品团队负责人&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:00 - 14:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 3：TiDB contributor 之路&lt;br&gt;杨文 | TiDB contributor&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:30 - 14:40 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;Break&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:40 - 15:40&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Chaos Practice in TiDB&lt;br&gt;唐刘 | PingCAP 首席架构师&lt;/p&gt;&lt;p&gt;&lt;b&gt;15:40 - 16:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;领取 T 恤、贴纸等周边&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://www.huodongxing.com/event/6449101295200&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-f59f2b532f746892c5b17729eed83b3b&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; data-image-size=&quot;180x120&quot;&gt;TiDB TechDay2018 · 深圳&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-17-39909349</guid>
<pubDate>Tue, 17 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十三）索引范围计算简介</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-13-39649659.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39649659&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b7f88291dd3855ebcc79e627554a10c3_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：崔一丁&lt;/blockquote&gt;&lt;h2&gt;简述&lt;/h2&gt;&lt;p&gt;在数据库中处理查询请求时，如果可以尽早的将无关数据过滤掉，那么后续的算子就可以少做无用功，提升整个 SQL 的执行效率。过滤数据最常用的手段是使用索引，TiDB 的优化器也会尽量采用索引过滤的方式处理请求，利用索引有序的特点来提升查询效率。比如当查询条件为 &lt;code class=&quot;inline&quot;&gt;a = 1&lt;/code&gt; 时，如果 a 这一列上有索引，我们就可以利用索引很快的把满足 &lt;code class=&quot;inline&quot;&gt;a = 1&lt;/code&gt; 的数据拿出来，而不需要逐行检查 a 的值是否为 1。当然是否会选择索引过滤也取决于代价估算。&lt;/p&gt;&lt;p&gt;索引分为单列索引和多列索引（组合索引），筛选条件也往往不会是简单的一个等值条件，可能是非常复杂的条件组合。TiDB 是如何分析这些复杂条件，来得到这些条件在对应的索引上的逻辑区间范围（range），就是本文要介绍的内容。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 TiDB 如何构建索引，如何存储索引数据，希望读者能够有基本的了解（参考阅读：&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-2/&quot;&gt;三篇文章了解 TiDB 技术内幕 - 说计算&lt;/a&gt; ）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里是一个例子，展示这里所说的索引范围计算是做什么的，建表语句和查询语句如下：&lt;br&gt;CREATE TABLE t (a int primary key, b int, c int);&lt;br&gt;select * from t where ((a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2) or (a &amp;gt; 8 and a &amp;lt; 10 and c &amp;gt; 3)) and d = 5;&lt;br&gt;计算索引逻辑区间范围的流程如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6721b3933dec315f3de020d2a6df28d7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;677&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6721b3933dec315f3de020d2a6df28d7&quot; data-watermark-src=&quot;v2-fe49c70702f4c93c2fc2fd8104f7cc19&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;从上图可以看出，整个流程分为从 Filter 中抽取可用索引的表达式以及利用选出的表达式构造数据范围两个步骤，接下来分别描述。&lt;/p&gt;&lt;h2&gt;抽取表达式&lt;/h2&gt;&lt;p&gt;这个步骤是从 Filter 中将能够用上索引的表达式选出来。由于单列索引和多列索引在处理逻辑上有很大的不同，所以会分单列索引和多列索引两中情况进行讲解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;单列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;单列索引的情况相对来说比较简单。很多满足 Column op Constant 形式的简单表达式都可以用来计算 range，单个表达式的判断逻辑在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/checker.go&quot;&gt;checker.go&lt;/a&gt; 的 conditionChecker 中。而对于包含了 AND 或者 OR 的复杂情况，我们可以按照下述规则进行处理：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;AND 表达式无关的 filter 并不会影响其可以计算 range 的子项。所以直接舍去无关的表示即可。以流程图中的一个子表达式 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2&lt;/code&gt; 为例，我们只要将 &lt;code class=&quot;inline&quot;&gt;b &amp;gt; 2&lt;/code&gt; 扔掉，保留 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 5&lt;/code&gt; 即可。&lt;/li&gt;&lt;li&gt;OR 表达式中，每个子项都要可以用来计算 range，如果有不可以计算 range 的子项，那么这整个表达式都不可用来计算 range。以 &lt;code class=&quot;inline&quot;&gt;a = 1 or b = 2&lt;/code&gt;为例，&lt;code class=&quot;inline&quot;&gt;b = 2&lt;/code&gt; 这一子项不可以用来计算 a 的 range，所以这个表达式整体上无法计算 a 的 range。而如果是 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 or ( a &amp;lt; 2 and b = 1)&lt;/code&gt;，根据 1 中的规则，第二个子项会留下 &lt;code class=&quot;inline&quot;&gt;a &amp;lt; 2&lt;/code&gt; 的部分，可以用来计算 a 的 range，因此整个表达式会返回 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 2&lt;/code&gt; 来供接下来计算 range 的部分处理。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这里补充说明一点，TiDB 的主键在实现方式上限定了只有整数类型的单列主键会把主键值当做 RowID，然后编码成 RowKey，和这行数据存储在一起。其他类型的单列主键会作为普通的 unique key 看待，当查询的列包含索引上没有的列时，需要一次查索引 + 一次扫表。所以我们将这种整数类型作为主键的索引处理逻辑单独抽取出来，其入口函数为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L329&quot;&gt;DetachCondsForTableRange&lt;/a&gt; 。其中对 AND 表达式和 OR 表达式的处理入口分别为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L28&quot;&gt;detachColumnCNFConditions&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L61&quot;&gt;detachColumnDNFConditions&lt;/a&gt;。这两个函数也用来处理其他类型的主键或者索引的的 range 计算。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;多列索引的情况较单列索引而言会复杂一些，因为在处理 OR 表达式中列与列之间的关系需要考虑更多情况。TiDB 中为了简化 ranger 的逻辑，目前只考虑下列情况：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;AND 表达式中，只有当之前的列均为点查的情况下，才会考虑下一个列。&lt;br&gt;e.g. 对于索引 (a, b, c)，有条件 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and b = 1&lt;/code&gt;，那么会被选中的只有 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1&lt;/code&gt;。对于条件 &lt;code class=&quot;inline&quot;&gt;a in (1, 2, 3) and b &amp;gt; 1&lt;/code&gt;，两个条件均会被选到用来计算 range。&lt;br&gt;由于非点查的部分只会涉及到一个列，所以可以直接复用 &lt;code class=&quot;inline&quot;&gt;detachColumnCNFConditions&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;OR 表达式中，每个子项会视为 AND 表达式分开考虑。与单列索引的情况一样，如果其中一个子项无法用来计算索引，那么该 OR 表达式便完全无法计算索引。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;多列索引处理的入口函数为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L270&quot;&gt;DetachCondAndBuildRangeForIndex&lt;/a&gt;，AND 表达式和 OR 表达式的处理入口分别为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L142&quot;&gt;detachCNFCondAndBuildRangeForIndex&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L214&quot;&gt;detachDNFCondAndBuildRangeForIndex&lt;/a&gt;。（由于多列索引对 range 的处理相对单列索引而言会复杂一些，所以没有拆分为 DetachCondition 和 BuildRange 两部分，而是由 DetachCondAndBuildRangeForIndex 处理。）&lt;/p&gt;&lt;p&gt;由于逻辑进行到了简化，因此目前 TiDB 的 ranger 存在无法正确处理的情况。比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;a = 1 and (b = 1 or b = 2) and c &amp;gt; 1&lt;/code&gt;。对于这个式子，当 (a, b ,c) 为索引时，如上述所言，由于 &lt;code class=&quot;inline&quot;&gt;(b = 1 or b = 2)&lt;/code&gt; 形式上是 OR 表达式的情况，而非点查。所以会在 b 列停止，不会考虑 &lt;code class=&quot;inline&quot;&gt;c &amp;gt; 1&lt;/code&gt; 的情况。所以目前为了兼容 TiDB 的逻辑，遇到这种情况尽量改写为 &lt;code class=&quot;inline&quot;&gt;a = 1 and b in (1, 2) and c &amp;gt; 1&lt;/code&gt; 的形式。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d2c052d9158e790bde962cd16d0e8c07_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1155&quot; data-rawheight=&quot;286&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d2c052d9158e790bde962cd16d0e8c07&quot; data-watermark-src=&quot;v2-fe43cc0ef0d02aefe44bd3d95026677b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;类似的如 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1) or (a = 2 and b = 2)) and c = 1&lt;/code&gt; 形式的式子，前段 OR 表达式实际上为点查的行为，但是由于是 OR 连接起来的式子，所以在 TiDB 的逻辑中作为范围查询处理，因此 &lt;code class=&quot;inline&quot;&gt;c = 1&lt;/code&gt; 不会作为索引的计算条件处理。而这时改写为 &lt;code class=&quot;inline&quot;&gt;(a, b) in ((1, 1)&lt;/code&gt;,  &lt;code class=&quot;inline&quot;&gt;(2, 2)) and c = 1&lt;/code&gt; 的形式也不会使 &lt;code class=&quot;inline&quot;&gt;c = 1&lt;/code&gt; 选入索引计算的条件，原因是多列 in 的函数会被 TiDB 改写为 OR 连接的形式，所以 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1) or (a = 2 and b = 2))&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;(a, b) in ((1, 1),  (2, 2))&lt;/code&gt; 在 TiDB 中是完全一致的行为。针对这种情况，目前的办法只有将这些条件都放入 OR 的子项中，针对这里用到的例子，那就是要改写为 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1 and c = 1) or (a = 2 and b = 2 and c = 1))&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-50e759f5b37e8f6e5b2a1fbf430bfc3a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1155&quot; data-rawheight=&quot;294&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-50e759f5b37e8f6e5b2a1fbf430bfc3a&quot; data-watermark-src=&quot;v2-54cef9f6e4aac480b9e3a8b5f5021aa1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;计算逻辑区间&lt;/h2&gt;&lt;p&gt;这一步骤中，利用上一步抽取出来的表达式估算出数据的逻辑区间范围，后续会根据这个逻辑区间以及数据编码方式构造物理区间进行数据访问。我们仍然分为单列索引和多列索引两个情况来介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;单列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这种情况下，输入的表达式为 Column op Constant 形式的简单表达式由 OR 以及 AND 连接而成。我们对每一个具体的操作符，都设计了一段对应的计算 range 的逻辑，当遇到 AND 或者 OR 时，会对两个区间求交或者求并。在 point.go 中有一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L146&quot;&gt;builder&lt;/a&gt; 的结构体用来处理上述逻辑。&lt;/p&gt;&lt;p&gt;在这个阶段我们记录 range 时用 rangePoint 的结构来存储 range。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// Point is the end point of range interval.
type point struct {
	value types.Datum
	excl  bool // exclude
	start bool
}&lt;/code&gt;&lt;p&gt;每个 point 代表区间的一个端点，其中的 excl 表示端点为开区间的端点还是闭区间的端点。start 表示这个端点是左端点还是右端点。&lt;/p&gt;&lt;p&gt;builder 中每个 buildFromXXX 的方法都是计算一个具体函数的 range 的方法。比如 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L299&quot;&gt;buildFromIn&lt;/a&gt; 便是处理 &lt;a href=&quot;https://dev.mysql.com/doc/refman/5.7/en/comparison-operators.html#function_in&quot;&gt;in 函数&lt;/a&gt; 的方法。可以看到它首先对 in 函数的值列表的每个值都构造了一个 rangPoint 的单点区间，然后对这些区间放在一个 slice 中做排序以及去重。最终将去重后的结果输出。&lt;/p&gt;&lt;p&gt;在 pointer.go 中还包含其他各类的函数的处理，具体可以翻阅源代码。&lt;/p&gt;&lt;p&gt;除了对具体函数的处理外，pointer.go 中还有区间交和区间并的操作。&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L484&quot;&gt;intersection&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L488&quot;&gt;union&lt;/a&gt; 分别代表区间交和区间并。两个函数的逻辑均通过 merge 方法进行处理，通过传入一个 flag 来区分。merge 函数做了如下两个假设：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;a, b 两个区间均已经做过去重&lt;/li&gt;&lt;li&gt;单个区间序列内部不会有重叠的部分&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;merge 函数使用 inRangeCount 来记录当前位置被 a, b 两个区间序列覆盖的情况。区间求并的情况时，只要 a, b 两个区间序列中有一个区间序列覆盖便可以作为解输出，被两个区间同时覆盖的端点必然是属于一个更大的区间的内部不需要输出。所以当 inRangeCount 为 1 时，即为需要输出的区间端点。&lt;/p&gt;&lt;p&gt;当区间求交时，需要两个序列都覆盖到才是可以输出的端点，所以当 inRangeCount 为 2 时，即为需要输出的区间端点。&lt;/p&gt;&lt;p&gt;在得到最后的区间端点序列后，由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/ranger.go#L174&quot;&gt;points2TableRanges&lt;/a&gt; 转化为对外暴露的 range 结构，由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/ranger.go#L224&quot;&gt;BuildTableRange&lt;/a&gt; 输出到 plan package。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// NewRange represents a range generated in physical plan building phase.
type NewRange struct {
	LowVal  []types.Datum
	HighVal []types.Datum

	LowExclude  bool // Low value is exclusive.
	HighExclude bool // High value is exclusive.
}&lt;/code&gt;&lt;p&gt;在现在的 TiDB 中，单列索引和多列索引使用了相同的 range 结构，所以这里的端点值为 slice 的形式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于多列索引，当其为 AND 表达式时，根据前述我们可以知道，其形式必为索引前缀列上的等值条件再加上关于前缀之后一个列的复杂条件组成。所以我们只需要按顺序处理点查的等值条件部分，将点查的区间依次 append 到 NewRange 中的 LowVal 和 HighVal 两个 Slice 中即可（&lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L133&quot;&gt;appendPoints2Ranges&lt;/a&gt;）。处理到最后一列时，将之前的 NewRange 按最后非点查列所计算得到的区间个数拷贝一下，再依次 append 即可。具体代码可见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L282&quot;&gt;buildCNFIndexRange&lt;/a&gt;。&lt;br&gt;对于 OR 表达式的情况，由于此时 range 已经无法转回 point 的结构。所以这里重新实现了一下区间并的操作。实现的形式便是比较常见的将区间按左端点排序，在依次扫过区间的同时，记录当前所有重叠过的区间的最右右端点来进行做区间并的算法。区间并的具体的实现可见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L357&quot;&gt;unionRanges&lt;/a&gt; 方法。&lt;/p&gt;&lt;h2&gt;Future Plan&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;目前 TiDB 对单列索引的处理在逻辑上已经非常完备，在实际表现上可能由于没有对部分函数实现计算 range 的逻辑而有遗漏。这部分会根据情况进行优化。&lt;/li&gt;&lt;li&gt;如上文提到的，目前 TiDB 为了简化 ranger 的逻辑，对多列索引做了一些假设。未来会尝试去掉或者弱化这些假设，或者在前期对 SQL 进行更充分的改写使得 SQL 不会触发这些假设，来提供更加强大的功能，免于手动 rewrite 的麻烦。&lt;/li&gt;&lt;li&gt;目前 TiDB 对简单式子的形式的检查限定在了 Column op Constant 的形式。所以诸如 &lt;code class=&quot;inline&quot;&gt;from_unixtime(timestamp_col) op datetime_constant&lt;/code&gt; 形式的条件是无法计算索引的，也需要手动 rewrite 为 &lt;code class=&quot;inline&quot;&gt;timestamp_col op timestamp_constant&lt;/code&gt; 才可以使用到索引。这部分也会考虑进行改进以提升用户体验。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;（十二）统计信息（上）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-13-39649659</guid>
<pubDate>Fri, 13 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十二）统计信息（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-06-39139693.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b2c9a7be595f1991e8381638b7c7ebfc_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者： 谢海滨&lt;/blockquote&gt;&lt;p&gt;在 TiDB 里，SQL 优化的过程可以分为逻辑优化和物理优化两个部分，在物理优化阶段需要为逻辑查询计划中的算子估算运行代价，并选择其中代价最低的一条查询路径作为最终的查询计划。这里非常关键的一点是如何估算查询代价，本文所介绍的统计信息是这个估算过程的核心模块。&lt;/p&gt;&lt;p&gt;这部分内容非常复杂，所以会分成两篇文章来介绍。本篇文章介绍统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价。上篇侧重于介绍原理，下篇会结合原理介绍 TiDB 的源码实现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息是什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了得到查询路径的执行代价，最简单的办法就是实际执行这个查询计划，不过这样子做就失去了优化器的意义。不过，优化器并不需要知道准确的代价，只需要一个估算值，以便能够区分开代价差别较大的执行计划。因此，数据库常常会维护一些实际数据的概括信息，用以快速的估计代价，这便是统计信息。&lt;/p&gt;&lt;p&gt;在 TiDB 中，我们维护的统计信息包括表的总行数，列的等深直方图，Count-Min Sketch，Null 值的个数，平均长度，不同值的数目等等。下面会简单介绍一下直方图和 Count-Min Sketch。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 直方图简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;直方图是一种对数据分布情况进行描述的工具，它会按照数据的值大小进行分桶，并用一些简单的数据来描述每个桶，比如落在桶里的值的个数。大多数数据库都会选择用直方图来进行区间查询的估算。根据分桶策略的不同，常见的直方图可以分为等深直方图和等宽直方图。&lt;br&gt;在 TiDB 中，我们选择了等深直方图，于 1984 年在 &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=602294&quot;&gt;Accurate estimation of the number of tuples satisfying a condition&lt;/a&gt; 文献中提出。相比于等宽直方图，等深直方图在最坏情况下也可以很好的保证误差。所谓的等深直方图，就是落入每个桶里的值数量尽量相等。举个例子，比方说对于给定的集合 {1.6, 1.9, 1.9, 2.0, 2.4, 2.6, 2.7, 2.7, 2.8, 2.9, 3.4, 3.5}，并且生成 4 个桶，那么最终的等深直方图就会如下图所示，包含四个桶 [1.6, 1.9]，[2.0, 2.6]，[2.7, 2.8]，[2.9, 3.5]，其桶深均为 3。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bf267d665f4b4b453b7a83f1828122ae_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;590&quot; data-rawheight=&quot;442&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bf267d665f4b4b453b7a83f1828122ae&quot; data-watermark-src=&quot;v2-63eda8d9641b1da20ccfb5755e3089b0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;2. Count-Min Sketch 简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Count-Min Sketch 是一种可以处理等值查询，Join 大小估计等的数据结构，并且可以提供很强的准确性保证。自 2003 年在文献 &lt;a href=&quot;http://dimacs.rutgers.edu/~graham/pubs/papers/cm-full.pdf&quot;&gt;An improved data stream summary: The count-min sketch and its applications&lt;/a&gt; 中提出以来，由于其创建和使用的简单性获得了广泛的使用。&lt;br&gt;Count-Min Sketch 维护了一个 d*w 的计数数组，对于每一个值，用 d 个独立的 hash 函数映射到每一行的一列中，并对应修改这 d 个位置的计数值。如下图所示：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5604bbc47256be098b8aef1079a4a89_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;379&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a5604bbc47256be098b8aef1079a4a89&quot; data-watermark-src=&quot;v2-e8f042d7cf6b686ef605e28bfb63279e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;这样在查询一个值出现了多少次的时候，依旧用 d 个 hash 函数找到每一行中被映射到的位置，取这 d 个值的最小值作为估计值。&lt;/p&gt;&lt;p&gt;直方图和 CM-Sketch 是常用的两种数据概要手段，想了解更多相关技术，可以参考 《Synopses for Massive Data: Samples,Histograms, Wavelets, Sketches》。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息创建&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过上面的描述，我们知道统计信息主要需要创建和维护的是直方图和 Count-Min Sketch。&lt;br&gt;通过执行 analyze 语句，TiDB 会收集上述所需要的信息。在执行 analyze 语句的时候，TiDB 会将 analyze 请求下推到每一个 Region 上，然后将每一个 Region 的结果合并起来。对于 Count-Min Sketch，其创建和合并都比较简单，在这里略去不讲。以下主要介绍列和索引的直方图的创建。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 列直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在创建直方图的时候，需要数据是有序的，而排序的代价往往很高，因此我们在 TiDB 中实现了抽样算法，对抽样之后的数据进行排序，建立直方图，即会在每一个 Region 上进行抽样，随后在合并结果的时候再进行抽样。&lt;/p&gt;&lt;p&gt;在 sample.go 中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。令样本集合的容量为 S，在任一时刻 n，数据流中的元素都以 S/n 的概率被选取到样本集合中去。如果样本集合大小超出 S，则从中随机去除一个样本。举个例子，假如样本池大小为 S = 100 ，从头开始扫描全表，当读到的记录个数 n &amp;lt; 100 时，会把每一条记录都加入采样池，这样保证了在记录总数小于采样池大小时，所有记录都会被选中。而当扫描到的第 n = 101 条时，用概率 P = S/n = 100⁄101 决定是否把这个新的记录加入采样池，如果加入了采样池，采样池的总数会超过 S 的限制，这时需要随机选择一个旧的采样丢掉，保证采样池大小不会超过限制。&lt;/p&gt;&lt;p&gt;采样完成后，将所有的数据排序，由于知道采样过后总的行数和直方图的桶数，因此就可以知道每个桶的深度。这样就可以顺序遍历每个值 V：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如果 V 等于上一个值，那么把 V 放在与上一个值同一个桶里，无论桶是不是已经满，这样可以保证每个值只存在于一个桶中。&lt;/li&gt;&lt;li&gt;如果不等于，那么判断当前桶是否已经满，如果不是的话，就直接放入当前桶，否则的话，就放入下一个桶。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 索引直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在建立索引列直方图的时候，由于不能事先知道有多少行的数据，也就不能确定每一个桶的深度，不过由于索引列的数据是已经有序的，因次可以采用如下算法：在确定了桶的个数之后，将每个桶的初始深度设为 1，用前面列直方图的创建方法插入数据，这样如果到某一时刻所需桶的个数超过了当前桶深度，那么将桶深扩大一倍，将之前的每两个桶合并为 1 个，然后继续插入。&lt;/p&gt;&lt;p&gt;在收集了每一个 Region 上分别建立的直方图后，还需要把每个 Region 上的直方图进行合并。对于两个相邻 Region 上的直方图，由于索引是有序的，因此前一个的上界不会大于后一个的下界。不过为了保证每个值只在一个桶里，我们还需要先处理一下交界处桶的问题，即如果交界处两个桶的上界和下界相等，那么需要先合并这两个桶。如果直方图合并之后桶的个数超过了限制，那么只需要把两两相邻的桶合二为一。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息维护&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 2.0 版本中，TiDB 引入了动态更新机制（2.0 版本默认没有打开， 2.1-beta 版本中已经默认打开），可以根据查询的结果去动态调整统计信息。对于直方图，需要调整桶高和桶的边界；对于 CM Sketch，需要调整计数数组，使得估计值和查询的结果相等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 桶高的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在范围查询的时候，涉及的桶都有可能对最终的结果贡献一些误差。因此，一种更新的方法便是假定所有桶贡献的误差都是均匀的，即如果最终估计的结果为 E，实际的结果为 R，某一个桶的估计结果为 b = 桶高 h * 覆盖比例 r，那么就可以将这个桶的桶高调整为 (b / r) * (R / E) = h * (R / E)。不过如果可以知道落在每一个桶范围中的实际结果，便可以不去假定所有桶贡献的误差都是均匀的。&lt;/p&gt;&lt;p&gt;为了知道落在每一个桶范围中的实际结果，需要先把查询的范围按照直方图桶的边界切分成不相交的部分，这样在 TiKV 在执行查询的时候，可以统计出每一个范围中实际含有的行数目。这样我们便可以按照类似于前述的方法调整每一个桶，不过这个时候不需要假定每个桶贡献的误差都是均匀的，因为我们可以准确知道每一个桶贡献的误差。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 桶边界的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在用直方图估计的时候，对于那些只被查询范围覆盖了一部分的桶，主要的误差来自连续平均分布假设。这样桶边界更新的主要目便是使得查询的边界能尽量的落在与桶的边界不远的地方。桶边界的更新主要方法包括分裂和合并。&lt;br&gt;对于分裂，需要解决的问题是哪些桶需要分裂，分裂成几个，分裂的边界在哪里：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪些桶需要分裂，分裂成几个：如果决定了每一次更新最多分裂 10 个桶，那么如果一个桶上落入了 10% 的查询点，那个这个桶就可以分裂一次，如果落入了 20% 的查询点，那么这个桶就可以分裂两次，以此类推。&lt;/li&gt;&lt;li&gt;分裂的边界：由于目标是使得查询的边界能尽量的落在与桶的边界不远的地方，那么如果这个桶要分裂 N 次，就需要选择不超过 N 个查询点，使得剩下的查询点与这 N 个查询点的最近距离之和最小。不过这种方法比较复杂，我们也可以采用比较简单的方法，即假定每个不同的查询点之间的距离都是相等的，这样只需要每隔几个点取一个作为边界就可以。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;分裂完成后，我们还要去合并桶。首先分裂得来的桶是不能合并的；除此之外，考虑连续的两个桶，如果第一个桶占合并后桶的比例为 r，那么令合并后产生的误差为 abs(合并前第一个桶的高度 - r * 两个桶的高度和) / 合并前第一个桶的高度，就只需要去合并误差最小的那些连续的桶。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Count-Min Sketch 的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;CM Sketch 的更新比较简单，对于某一个等值查询的反馈结果 x，其估计值是 y，那么我们只需要将这个值涉及到的所有点加上 c = x-y。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在查询语句中，我们常常会使用一些过滤条件，而统计信息估算的主要作用就是估计经过这些过滤条件后的数据条数，以便优化器选择最优的执行计划。在这篇 &lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/master/sql/understanding-the-query-execution-plan.md#explain-%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F&quot;&gt;文档&lt;/a&gt; 中，介绍到 explain 输出结果中会包含的一列 count，即预计当前 operator 会输出的数据条数，便是基于统计信息以及 operator 的执行逻辑估算而来。&lt;br&gt;在这个部分中，我们会先从最简单的单一列上的过滤条件开始，然后考虑如何处理多列的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 范围查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于某一列上的范围查询，TiDB 选择了常用的等深直方图来进行估算。&lt;/p&gt;&lt;p&gt;在前面介绍等深直方图时，我们得到了一个包含四个桶 [1.6, 1.9]，[2.0, 2.6]，[2.7, 2.8]，[2.9, 3.5]，其桶深均为 3 的直方图。假设我们得到了这样一个直方图，并且想知道落在区间 [1.7, 2.8] 范围内的有多少值。把这个区间对应到直方图上，可以看到有两个桶是被完全覆盖的，即桶 [2.0, 2.6] 和桶 [2.7，2.8]，因此区间 [2.0, 2.8] 内一共有 6 个值；但是第一个桶只被覆盖了一部分，那么问题就变成了已经知道区间 [1.6, 1.9] 范围内有 3 个值，怎样估算 [1.7, 1.9] 内有多少个值呢？一个常用的方法是假设这个范围的值是连续且均匀的，那么我们就可以按照查范围占桶的比例去估算，也就是 (1.9 - 1.7) / (1.9 - 1.6) * 3 = 2。&lt;/p&gt;&lt;p&gt;不过这里还有一个问题是估算的时候要去算比例，这对于数值类型很简单，对于其他类型，比方说字符串类型怎么办呢？一个方法是把字符串映射成数字，然后计算比例，具体可以参见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/statistics/scalar.go&quot;&gt;statistics/scalar.go&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 等值查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于类似查询等于某个值的这样的等值查询，直方图就捉襟见肘了。一般常用的估计方法是假设每个值出现的次数都相等，这样就可以用（总行数/不同值的数量）来估计。不过在 TiDB 中，我们选择了 Count-Min Sketch 的来进行等值查询的估算。&lt;/p&gt;&lt;p&gt;由于 Count-Min Sketch 估计的结果总是不小于实际值，因此在 TiDB 中，我们选择了文献 &lt;a href=&quot;http://webdocs.cs.ualberta.ca/~drafiei/papers/cmm.pdf&quot;&gt;New estimation algorithms for streaming data: Count-min can do more&lt;/a&gt; 中提出了一种 Count-Mean-Min Sketch，其与 Count-Min Sketch 在更新的时候是一样的，区别在与查询的时候：对于每一行 i，若 hash 函数映射到了值 j，那么用 &lt;code class=&quot;inline&quot;&gt;(N - CM[i, j]) / (w-1)&lt;/code&gt;（N 是总共的插入的值数量）作为其他值产生的噪音，因此用 &lt;code class=&quot;inline&quot;&gt;CM[i,j] - (N - CM[i, j]) / (w-1)&lt;/code&gt; 这一行的估计值，然后用所有行的估计值的中位数作为最后的估计值。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 多列查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面两个小节介绍了 TiDB 是如何对单列上的查询条件进行估计的，不过实际的查询语句中往往包含多个列上的多个查询条件，因此我们需要考虑如何处理多列的情况。在 TiDB 中，selectivity.go 中的 &lt;code class=&quot;inline&quot;&gt;Selectivity&lt;/code&gt; 函数实现了这个功能，它是统计信息模块对优化器提供的最重要的接口。&lt;/p&gt;&lt;p&gt;在处理多列之间的查询条件的时候，一个常见的做法是认为不同列之间是相互独立的，因此我们只需要把不同列之间的过滤率乘起来。不过，对于索引上的可以用来构造索引扫描的范围的过滤条件，即对于一个 &lt;code class=&quot;inline&quot;&gt;(a, b, c)&lt;/code&gt; 这样的索引，类似 &lt;code class=&quot;inline&quot;&gt;(a = 1 and b = 1 and c &amp;lt; 5)&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;(a = 1 and b = 1)&lt;/code&gt; 这样的条件，将索引中的值编码后，就可以用前面提到的方法进行估算，这样就不需要假定列之间是相互独立的。&lt;/p&gt;&lt;p&gt;因此，&lt;code class=&quot;inline&quot;&gt;Selectivity&lt;/code&gt; 的一个最重要的任务就是将所有的查询条件分成尽量少的组，使得每一组中的条件都可以用某一列或者某一索引上的统计信息进行估计，这样我们就可以做尽量少的独立性假设。&lt;/p&gt;&lt;p&gt;在 &lt;code class=&quot;inline&quot;&gt;Selectivity&lt;/code&gt; 中，首先计算了每一列和每一个索引可以覆盖的过滤条件，并用一个 &lt;code class=&quot;inline&quot;&gt;int64&lt;/code&gt; 来当做一个 bitset，将该列可以覆盖的过滤条件的位置置为 1。接下来的任务就是选择尽量少的 bitset，来覆盖尽量多的过滤条件，在这一步中，我们使用了贪心算法，即每一次在还没有使用的 bitset 中，选择一个可以覆盖最多尚未覆盖的过滤条件。最后一步便是用前面提到的方法对每一个列和每一个索引上的统计信息进行估计，并用独立性假设将它们组合起来当做最终的结果。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-06-39139693</guid>
<pubDate>Fri, 06 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在特来电的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-01-38760049.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38760049&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a456a06b62972dd2a47920e3097ca383_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;背景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;特来电新能源有限公司是创业板第一股特锐德（300001）的全资子公司，主要从事新能源汽车充电网的建设、运营及互联网的增值服务。特来电颠覆了传统充电桩的模式，世界首创了电动汽车群智能充电系统，获得 336 项技术专利，以“无桩充电、无电插头、群管群控、模块结构、主动防护、柔性充电”的特点引领世界新能源汽车充电的发展，系统的鉴定结论为：“产品世界首创、技术水平国际领先。主动柔性充电对电池寿命可以延长 30% 左右，电池充电的安全性可以提升 100 倍以上。”&lt;/p&gt;&lt;p&gt;特来电采用互联网思维，依靠国际领先的汽车群智能充电技术和系统，创新电动汽车充电商业模式，建设全国最大的汽车充电网，通过大系统卖电、大平台卖车、大共享租车、大数据修车、大支付金融、大客户电商，打造让客户满意、政府放心的中国最大汽车充电网生态公司，引领充电网、车联网、互联网“三网融合”的新能源互联网。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么研究 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;特来电大数据平台通过开源与自研相结合的方式，目前已经上线多套集群满足不同的业务需求。目前在大数据存储和计算方面主要使用了 HBase、Elasticsearch、Druid、Spark、Flink。大数据技术可谓是百花齐放、百家争鸣，不同的技术都有针对性的场景。结合实际情况，选择合适的技术不是一件容易的事情。&lt;/p&gt;&lt;p&gt;随着接入大数据平台的核心业务的增加，我们在 OLAP 上主要遇到以下痛点问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;随着基于大数据分析计算的深入应用，使用 SQL 进行分析的需求越来越旺盛，但目前已经上线的大数据集群（ HBase、Elasticsearch、Druid、Spark、Flink）对 SQL 的支持度都比较弱。&lt;/li&gt;&lt;li&gt;目前进入大数据集群的数据主要以宽表方式进行，导致在数据归集和后期基础数据放生变化时应用成本较高。&lt;/li&gt;&lt;li&gt;数据仓库业务有些还是基于复杂的 T+1 模式的 ETL 过程，延时较高，不能实时的反映业务变化。&lt;/li&gt;&lt;li&gt;由于每个大数据集群主要针对特定的场景，数据重复存储的情况较多，这就造成了存储成本的增加，同时也会导致数据的不一致性。&lt;/li&gt;&lt;li&gt;目前进入 HDFS / Druid / ES 的数据，在历史数据更新时，成本较高，灵活性降低。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大数据技术发展迅速，我们也一直希望采用新的技术可以解决我们以上问题，我们关注到目前 NewSQL 技术已经有落地产品，并且不少企业在使用，所以决定在我们平台内尝试引入 NewSQL 技术解决我们的痛点问题。&lt;/p&gt;&lt;p&gt;我们先了解一下 NewSQL。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e825ad65efc06df04addcfca0bf8b9c2_r.jpg&quot; data-caption=&quot;图 1 数据库发展史&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;514&quot; data-rawheight=&quot;301&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e825ad65efc06df04addcfca0bf8b9c2&quot; data-watermark-src=&quot;v2-e75d9e8c5df1bce001a63c594d263f0d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如图 1 所示，数据库的发展经历了 RDBMS、NoSQL 以及现在的 NewSQL，每种不同的技术都有对应的产品，每种数据库的技术背后，都有典型的理论支撑。2003 年 Google GFS 开创了分布式文件系统、2006 年的 BigTable 论文催生了 Hadoop 生态，在 2012 年的 Spanner 和 2013 年的 F1 论文发表后，被业界认为指明了未来关系型数据库的发展。&lt;/p&gt;&lt;p&gt;随着大数据技术的发展，实际上 SQL 和 NoSQL 的界限逐渐模糊，比如现在 HBase  之上有 Phoenix，HiveSQL，SparkSQL 等，也有一些观点认为 NewSQL = SQL + NoSQL。不同的技术都有各自的最佳适应场景，Spanner 和 F1 被认为是第一个 NewSQL 在生产环境提供服务的分布式系统技术，基于该理念的开源产品主要为 CockroachDB、TiDB。结合社区活跃度以及相关案例、技术支持，我们决定 NewSQL  技术上引入 TiDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 是 PingCAP 公司受 Google Spanner / F1 论文启发而设计的开源分布式 HTAP 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ccc03f62389ab498786b59f7fba5bab_r.jpg&quot; data-caption=&quot;图 2 TiDB 架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;827&quot; data-rawheight=&quot;393&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7ccc03f62389ab498786b59f7fba5bab&quot; data-watermark-src=&quot;v2-87924f905d12c2cfb2bd7050e1dd7fbd&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;TiDB 具有以下核心特性：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL —— 无需修改代码即可从 MySQL 轻松迁移至 TiDB&lt;/li&gt;&lt;li&gt;水平弹性扩展 —— 轻松应对高并发、海量数据场景&lt;/li&gt;&lt;li&gt;分布式事务 —— TiDB 100% 支持标准的 ACID 事务&lt;/li&gt;&lt;li&gt;高可用 —— 基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证&lt;/li&gt;&lt;li&gt;一站式 HTAP 解决方案 —— 一份存储同时处理 OLTP &amp;amp; OLAP，无需传统繁琐的 ETL 过程&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中涉及到的分布式存储和分布式计算，大家可以参考 TiDB 的官方网站，在这里就不再进行论述。&lt;/p&gt;&lt;p&gt;在处理大型复杂的计算时，PingCAP 结合上图说的 TiKV 以及目前大数据生态的 Spark，提供了另外一个开源产品 TiSpark。不得不说这是一个巧妙的设计，充分利用了现在企业已有的 Spark 集群的资源，不需要另外再新建集群。TiSpark 架构以及核心原理简单描述如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-92c0f11228150c5cf56dfdaf5b21ea1f_r.jpg&quot; data-caption=&quot;图 3 TiSpark 架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;617&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-92c0f11228150c5cf56dfdaf5b21ea1f&quot; data-watermark-src=&quot;v2-a7609fdaf0319081318d88b6e9eb21e5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;TiSpark 深度整合了 Spark Catalyst 引擎， 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查。&lt;/p&gt;&lt;p&gt;通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。&lt;/p&gt;&lt;p&gt;从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。&lt;/p&gt;&lt;p&gt;除此之外，用户借助 TiSpark 项目可以在 TiDB 上使用 Spark 生态圈提供的多种工具进行数据处理。例如使用 TiSpark 进行数据分析和 ETL；使用 TiKV 作为机器学习的数据源；借助调度系统产生定时报表等等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;目前的应用情况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由于很多用户已经部署了生产系统，我们没有在测试上再次投入比较大的精力，经过了简单的性能测试以后，搭建了我们的第一个 TiDB 集群，尝试在我们的业务上进行使用。目前主要用于我们的离线计算，以及部分即系查询场景，后续根据使用情况，逐渐调整我们的集群规模以及增加我们的线上应用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 目前的集群配置&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8f32b0c3aaa1ae9b0fd7d66d1c3af88_r.jpg&quot; data-caption=&quot;图 4 集群配置清单&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;580&quot; data-rawheight=&quot;287&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f8f32b0c3aaa1ae9b0fd7d66d1c3af88&quot; data-watermark-src=&quot;v2-b54aeaeb7444ec84d3049a7031a7cb99&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;2. 规划的应用架构&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-48cc92e111dd0a45da7c85a7a5094f68_r.jpg&quot; data-caption=&quot;图 5 引入 TiDB 以后的应用架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-48cc92e111dd0a45da7c85a7a5094f68&quot; data-watermark-src=&quot;v2-a0e2c64fa8a49061b569454d00c54751&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;基于 TiDB 我们规划了完整的数据流处理逻辑，从数据接入到数据展现，由于 TiDB 高度兼容 MySQL，因此在数据源接入和 UI 展现就有很多成熟的工具可以使用，比如 Flume、Grafana、Saiku 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 应用简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;a. 充电功率的分时统计&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每个用户使用特来电的充电桩进行充电时，车辆的 BMS 数据、充电桩数据、环境温度等数据是实时的保存到大数据库中。我们基于采集的用户充电数据，需要按照一定的时间展示全国的充电功率 比如展示过去一天，全国的充电功率变化曲线，每隔 15 分钟或者 30 分钟进行一次汇总。随着我们业务规模的增加，此场景的计算也逐步进行了更新换代。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-341fe1d2cb79d61df04446a1d898fdf8_r.jpg&quot; data-caption=&quot;图 6 充电功率的分时统计&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;653&quot; data-rawheight=&quot;236&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-341fe1d2cb79d61df04446a1d898fdf8&quot; data-watermark-src=&quot;v2-b311c213bc9f7d70206bece78b84f843&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;目前我们单表数据量接近 20 亿，每天的增量接近 800 万左右。使用 TiDB 后，在进行离线计算分析时，我们的业务逻辑转成了直接在我们的离线计算平台通过 SQL 的方式进行定义和维护，极大的提高了维护效率，同时计算速度也得到了大幅提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;b. 充电过程分析&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面我们讲了，我们已经有了充电过程中的宝贵的海量数据，如何让数据发挥价值，我们基于充电数据进行充电过程的分析就是其中的一个方式，比如分析不同的车型在不同的环境（环境温度、电池特性）下，充电的最大电压和电流的变化情况，以及我们充电桩的需求功率满足度等。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fbce582daa6f5a7cf0083489eeef5ad8_r.jpg&quot; data-caption=&quot;图 7 充电过程分析&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;287&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fbce582daa6f5a7cf0083489eeef5ad8&quot; data-watermark-src=&quot;v2-ce51b393bb4f074ab6d845fbfb635310&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;针对海量的历史数据计算我们使用了 TiSpark 进行计算，直接使用了我们现有的 Spark 集群，在使用 Spark 进行计算时，一开始由于不熟悉 TiSpark，分配的资源比较少，耗时多一些。后来和 TiDB 技术人员交流了解到最佳实践，提升配置和调整部分参数后，性能提升不少。这个场景中我们充分利用了 TiDB 和 TiSpark 进行协同工作，满足了我们的业务需求。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结及问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 最佳应用场景&lt;/b&gt;&lt;/p&gt;&lt;p&gt;结合我们的线上验证，我们认为使用 TiDB，主要有以下几个优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SQL 支持度相对于现有的集群支持度较好，灵活性和功能性大大增强。&lt;/li&gt;&lt;li&gt;可以进行表之间的 join 运算，降低了构造宽边的复杂度以及因此带来的维护成本。&lt;/li&gt;&lt;li&gt;历史数据方便修改。&lt;/li&gt;&lt;li&gt;高度兼容 MySQL 生态下对应的成熟软件较多（开发工具、展现、数据接入）。&lt;/li&gt;&lt;li&gt;基于索引的 SQL 性能在离线计算上基本可以满足我们需求，在即席查询上最适合海量数据下进行多维度的精确查询，类似与 “万里挑一” 的场景。&lt;/li&gt;&lt;li&gt;使用 TiSpark 进行复杂的离线计算，充分利用了现有的集群，数据存储做到了一份，同时也降低了运维成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 目前的定位&lt;/b&gt;&lt;/p&gt;&lt;p&gt;结合我们的实际现状，现阶段我们主要用于进行离线计算和部分即席查询的场景，后期随着应用的深入，我们逐步考虑增加更多的应用以及部分 OLTP 场景。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;作者介绍：潘博存，特来电大数据技术研发部架构师，具有 10 多年平台软件设计开发经验，现专注于大数据领域快速读写方向。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-01-38760049</guid>
<pubDate>Sun, 01 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十一）Index Lookup Join</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-06-27-38572730.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1bc90f4fea487a82ecb0a73acbf3b306_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt; 作者：徐怀宇&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;什么是 Index Lookup Join&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Nested Loop Join&lt;/b&gt;&lt;br&gt;在介绍 Index Lookup Join 之前，我们首先看一下什么是 &lt;b&gt;Nested Loop Join（NLJ）&lt;/b&gt;。 NLJ 的具体定义可以参考 &lt;a href=&quot;https://en.wikipedia.org/wiki/Nested_loop_join&quot;&gt;Wikipedia&lt;/a&gt;。NLJ 是最为简单暴力的 Join 算法，其执行过程简述如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;遍历 Outer 表，取一条数据 r；&lt;/li&gt;&lt;li&gt;遍历 Inner 表，对于 Inner 表中的每条数据，与 r 进行 join 操作并输出 join 结果；&lt;/li&gt;&lt;li&gt;重复步骤 1，2 直至遍历完 Outer 表中的所有数据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;NLJ 算法实现非常简单并且 join 结果的顺序与 Outer 表的数据顺序一致。&lt;br&gt;但是存在性能上的问题：执行过程中，对于每一条 OuterRow，我们都需要对 Inner 表进行一次&lt;b&gt;全表扫&lt;/b&gt;操作，这将消耗大量时间。&lt;br&gt;为了减少对于 Inner 表的全表扫次数，我们可以将上述步骤 1 优化为每次从 Outer 表中读取一个 batch 的数据，优化后的算法即 &lt;b&gt;Block Nested-Loop Join（BNJ）&lt;/b&gt;，BNJ 的具体定义可以参考 &lt;a href=&quot;https://en.wikipedia.org/wiki/Block_nested_loop&quot;&gt;Wikipedia&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Index Lookup Join&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于 BNJ 算法，我们注意到，对于 Outer 表中每个 batch，我们并没有必要对 Inner 表都进行一次全表扫操作，很多时候可以通过索引减少数据读取的代价。&lt;b&gt;Index Lookup Join（ILJ）&lt;/b&gt; 在 BNJ 基础上进行了改进，其执行过程简述如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;从 Outer 表中取一批数据，设为 B；&lt;/li&gt;&lt;li&gt;通过 Join Key 以及 B 中的数据构造 Inner 表取值范围，只读取对应取值范围的数据，设为 S；&lt;/li&gt;&lt;li&gt;对 B 中的每一行数据，与 S 中的每一条数据执行 Join 操作并输出结果；&lt;/li&gt;&lt;li&gt;重复步骤 1，2，3，直至遍历完 Outer 表中的所有数据。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB Index Lookup Join 的实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的 ILJ 算子是一个多线程的实现，主要的线程有： Main Thead，Outer Worker，和 Inner Worker：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Outer Worker 一个：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;按 batch 遍历 Outer 表，并封装对应的 task&lt;/li&gt;&lt;li&gt;将 task 发送给 Inner Worker 和 Main Thread&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Inner Worker N 个：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;读取 Outer Worker 构建的 task&lt;/li&gt;&lt;li&gt;根据 task 中的 Outer 表数据，构建 Inner 表的扫描范围，并构造相应的物理执行算子读取该范围内的 Inner 表数据&lt;/li&gt;&lt;li&gt;对读取的 Inner 表数据创建对应的哈希表并存入 task&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Main Thread 一个：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;启动 Outer Worker 及 Inner Workers&lt;/li&gt;&lt;li&gt;读取 Outer Worker 构建的 task，并对每行 Outer 数据在对应的哈希表中 probe&lt;/li&gt;&lt;li&gt;对 probe 到的数据进行 join 并返回执行结果&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;这个算子有如下特点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Join 结果的顺序与 Outer 表的数据顺序一致，这样对上一层算子可以提供顺序保证；&lt;/li&gt;&lt;li&gt;对于 Outer 表中的每个 batch，只在 Inner 表中扫描部分数据，提升单个 batch 的处理效率；&lt;/li&gt;&lt;li&gt;Outer 表的读数据操作，Inner 表的读数据操作，及 Join 操作并行执行，整体上是一个并行+Pipeline 的方式，尽可能提升执行效率。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;执行阶段详述&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 中 ILJ 的执行阶段可划分为如下图所示的 5 步：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bce13c946db6b2f593524843dca98df0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;635&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bce13c946db6b2f593524843dca98df0&quot; data-watermark-src=&quot;v2-4fa27fd9a02423446cc8231976e9f80f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;1. 启动 Outer Worker 及 Inner Workers&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这部分工作由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L130&quot;&gt;startWorkers&lt;/a&gt; 函数完成。该函数会 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L138&quot;&gt;启动一个 Outer Worker&lt;/a&gt; 和&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L141&quot;&gt;多个 Inner Worker&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L141&quot;&gt;多个 Inner Worker&lt;/a&gt;。Inner Woker 的数量可以通过 &lt;code class=&quot;inline&quot;&gt;tidb_index_lookup_concurrency&lt;/code&gt; 这个系统变量进行设置，默认为 4。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 读取 Outer 表数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这部分工作由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L314&quot;&gt;buildTask&lt;/a&gt; 函数完成。此处主要注意两点：&lt;/p&gt;&lt;p&gt;第一点，对于每次读取的 batch 大小，如果将其设置为固定值，则可能会出现如下问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;若设置的 batch 值&lt;b&gt;较大&lt;/b&gt;，但 Outer 表数据量&lt;b&gt;较小&lt;/b&gt;时。各个 Inner Worker 所需处理的任务量可能会不均匀，出现数据倾斜的情况，导致并发整体性能相对单线程提升有限。&lt;/li&gt;&lt;li&gt;若设置的 batch 值&lt;b&gt;较小&lt;/b&gt;，但 Outer 表数据量&lt;b&gt;较大&lt;/b&gt;时。Inner Worker 处理任务时间短，需要频繁从管道中取任务，CPU 不能被持续高效利用，由此带来大量的线程切换开销。此外, 当 batch 值较小时，同一批 inner 表数据能会被反复读取多次，带来更大的网络开销，对整体性能产生极大影响。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，我们通过指数递增的方式动态控制 batch 的大小（由函数 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L348&quot;&gt;increaseBatchSize&lt;/a&gt; 完成），以避免上述问题，batch size 的最大值由 session 变量 &lt;code class=&quot;inline&quot;&gt;tidb_index_join_batch_size&lt;/code&gt; 控制，默认是 25000。读取到的 batch 存储在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/expression/chunk_executor.go#L225&quot;&gt;lookUpJoinTask.outerResult&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;第二点，如果 Outer 表的过滤条件不为空，我们需要对 outerResult 中的数据进行过滤（由函数 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/expression/chunk_executor.go#L225&quot;&gt;VectorizedFilter&lt;/a&gt; 完成）。outerResult 是 Chunk 类型（&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;Chunk 的介绍请参考 TiDB 源码阅读系列文章（十）&lt;/a&gt;），如果对满足过滤条件的行进行提取并重新构建对象进行存储，会带来不必要的时间和内存开销。&lt;code class=&quot;inline&quot;&gt;VectorizedFilter&lt;/code&gt; 函数通过一个长度与 outerResult 实际数据行数相等的 bool slice 记录 outerResult 中的每一行是否满足过滤条件以避免上述开销。 该 bool slice 存储在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L81&quot;&gt;lookUpJoinTask.outerMatch&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Outer Worker 将 task 发送给 Inner Worker 和 Main Thread&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Inner Worker 需要根据 Outer 表每个 batch 的数据，构建 Inner 表的数据扫描范围并读取数据，因此 Outer Worker 需要将 task &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L304&quot;&gt;发送给 Inner Worker&lt;/a&gt;。&lt;br&gt;如前文所述，ILJ 多线程并发执行，且 Join 结果的顺序与 Outer 表的数据顺序一致。 为了实现这一点，Outer Worker 通过管道将 task &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L299&quot;&gt;发送给 Main Thread&lt;/a&gt;，Main Thread 从管道中按序读取 task 并执行 Join 操作，这样便可以实现在多线程并发执行的情况下的保序需求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Inner Worker 读取 inner 表数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这部分工作由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L376&quot;&gt;handleTask&lt;/a&gt; 这个函数完成。handleTask 有如下几个步骤:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L393&quot;&gt;constructDatumLookupKeys&lt;/a&gt; 函数计算 Outer 表对应的 Join Keys 的值，我们可以根据 Join Keys 的值从 Inner 表中仅查询所需要的数据即可，而不用对 Inner 表中的所有数据进行遍历。为了避免对同一个 batch 中相同的 Join Keys 重复查询 Inner 表中的数据，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L447&quot;&gt;sortAndDedupDatumLookUpKeys&lt;/a&gt; 会在查询前对前面计算出的 Join Keys 的值进行去重。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L480&quot;&gt;fetchInnerResult&lt;/a&gt; 函数利用去重后的 Join Keys 构造对 Inner 表进行查询的执行器，并读取数据存储于 &lt;code class=&quot;inline&quot;&gt;task.innerResult&lt;/code&gt; 中。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L502&quot;&gt;buildLookUpMap&lt;/a&gt; 函数对读取的 Inner 数据按照对应的 Join Keys 构建哈希表，存储于 &lt;code class=&quot;inline&quot;&gt;task.lookupMap&lt;/code&gt; 中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上述步骤完成后，Inner Worker 向 &lt;code class=&quot;inline&quot;&gt;task.doneCh&lt;/code&gt; 中发送数据，以唤醒 Main Thread 进行接下来的工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. Main Thread 执行 Join 操作&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这部分工作由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L209&quot;&gt;prepareJoinResult&lt;/a&gt; 函数完成。prepareJoinResult 有如下几个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L216&quot;&gt;getFinishedTask&lt;/a&gt; 从 resultCh 中读取 task，并等待 task.doneCh 发送来的数据，若该 task 没有完成，则阻塞住；&lt;/li&gt;&lt;li&gt;接下来的步骤与 Hash Join类似（参考 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;TiDB 源码阅读系列文章（九）&lt;/a&gt;），&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L273&quot;&gt;lookUpMatchedInners&lt;/a&gt; 取一行 OuterRow 对应的 Join Key，从 task.lookupMap 中 probe 对应的 Inner 表的数据；&lt;/li&gt;&lt;li&gt;主线程对该 OuterRow，与取出的对应的 InnerRows 执行 Join 操作，写满存储结果的 chk 后返回。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;示例&lt;/b&gt;&lt;/h2&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE `t` (
`a` int(11) DEFAULT NULL,
`pk` int(11) NOT NULL AUTO_INCREMENT,
PRIMARY KEY (`pk`)
);

CREATE TABLE `s` (
`a` int(11) DEFAULT NULL,
KEY `idx_s_a` (`a`)
);
​
insert into t(`a`) value(1),(1),(1),(4),(4),(5);
insert into s value(1),(2),(3),(4);
​
select /*+ TIDB_INLJ(t) */ * from t left join s on t.a = s.a;&lt;/code&gt;&lt;p&gt;&lt;br&gt;在上例中， &lt;code class=&quot;inline&quot;&gt;t&lt;/code&gt; 为 Outer 表，&lt;code class=&quot;inline&quot;&gt;s&lt;/code&gt; 为 Inner 表。 &lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/master/sql/tidb-specific.md#tidb_inljt1-t2&quot;&gt;/** TIDN_INLJ */&lt;/a&gt; 可以让优化器尽可能选择 Index Lookup Join 算法。&lt;/p&gt;&lt;p&gt;设 Outer 表读数据 batch 的初始大小为 2 行，Inner Worker 数量为 2。&lt;/p&gt;&lt;p&gt;查询语句的一种可能的执行流程如下图所示，其中由上往下箭头表示时间线：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-351d7c688bdf43506185bd617b99ffae_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;521&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-351d7c688bdf43506185bd617b99ffae&quot; data-watermark-src=&quot;v2-2cea494c8abd250e517b7fddae0a0446&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延展阅读&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-06-27-38572730</guid>
<pubDate>Wed, 27 Jun 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>SuRF: 一个优化的 Fast Succinct Tries</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-06-22-38385054.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38385054&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e1b5f6d9e6e925d3093d622e3ccdeb17_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：唐刘&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在前一篇文章中，我简单介绍了 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/38194127&quot;&gt;Succinct Data Structure&lt;/a&gt;，这里我们继续介绍 SuRF。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Fast Succinct Tries&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;SuRF 的核心数据结构就是 Fast Succinct Tries（FST），一种空间节省，支持 point 和 range query 的静态 trie。在很多时候，对于一棵树来说，上层的 trie 节点较少，但访问频繁，也就是我们俗称的 hot，而下层的节点则相对的 cold 一点。因此，SuRF 使用了两种数据结构来分别处理 hot 和 cold 节点。在 upper 层上面使用了 LOUDS-Dedense，而在 lower 层上面使用 LOUDS-Sparse。&lt;/p&gt;&lt;p&gt;对于一个 trie 来说，SuRF 会将其编码成：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8e6a70a350de2199f8292dbbd699d34f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;336&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8e6a70a350de2199f8292dbbd699d34f&quot; data-watermark-src=&quot;v2-ddcacf7aecd4f2ccbbc1218bcab37b86&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;对于一次查询来说，首先会在 LOUDS-Dense 上面查找，如果找到了，就直接返回，找不到，就会进入到 LOUDS-Sparse 进行查找。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;LOUDS-Dense&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;LOUDS-Dense 对于每个 Node 都使用了三个 256 bit 大小的 bitmap。第一个 bitmap 叫做 D-labels，如果表示这个 node 是否有 label i，如果有，那么第 i bit 位就是 1。譬如上面的例子，Dense 的 label 在 level 1 有 f，s 和 t，那么在第 102（f），115（s） 和 116 （t）bit 位就会设置为 1。大家其实可以看到，具体哪一个 bit 位，就是 ASCII 码的值。&lt;br&gt;第二个 bitmap 是 D-HasChild，如果一个 node 下面还有子节点，那么就将该 label 对应的 bit 在 D-HasChild 里面设置为 1。继续上面的例子，f 和 t 都有子节点，而 s 没有，所以 102 和 116 bit 都会设置为 1。&lt;/p&gt;&lt;p&gt;第三个 bitmap 是 D-IsPrefixKey，这个解释其实有点绕，主要是用来表示一个 prefix 是否也是一个合法的 key。还是上面的例子，我们可以看到，f 这个 node 是有子节点的，所以它是一个 prefix，但同时，f 也是一个 key。在上图中， SuRF 使用了 ‘$’ 这个符号（实际对应的值是 0xFF）来表示这样的情况。&lt;/p&gt;&lt;p&gt;最后一个字节序列就是 D-Values，存储的是固定大小的 value。Value 就是按照 每层 level 的顺序存放的。&lt;/p&gt;&lt;p&gt;如果要进行遍历 LOUDS-Dense，我们可以使用之前提到的 rank 和 select 操作。对于 bit 序列 &lt;code class=&quot;inline&quot;&gt;bs&lt;/code&gt; 来说，我们用 &lt;code class=&quot;inline&quot;&gt;rank1/select1(bs, pos)&lt;/code&gt; 来表示在 &lt;code class=&quot;inline&quot;&gt;bs&lt;/code&gt; 上面 pos 的 rank 和 select 操作。譬如，假设 pos 是 D-Labels 上面的当前 bit pos，如果 &lt;code class=&quot;inline&quot;&gt;D-HasChild[pos] = 1&lt;/code&gt;，那么第一个子节点的 pos 则是 &lt;code class=&quot;inline&quot;&gt;D-ChildNodePos(pos) = 256 x rank1(D-HasChild, pos)&lt;/code&gt;，而父节点则是 &lt;code class=&quot;inline&quot;&gt;ParentNodePos(pos) = 256 x select1(D-HasChild, pos / 256)&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;LOUDS-Sparse&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不同于 LOUDS-Dense，LOUDS-Sparse 使用了 bytes 或者 bits 序列来编码。第一个 bytes 序列，S-Labels，按照 level order 的方式记录了所有 node 的 label。譬如上图的 &lt;code class=&quot;inline&quot;&gt;rst&lt;/code&gt; 这样的 bytes 顺序，Sparse 仍然使用了 0xFF（也就是上图的 &lt;code class=&quot;inline&quot;&gt;$&lt;/code&gt; 符号）来表示一个 prefix key。因为这样的 0xFF 只会出现在第一个子节点上面，所以是能跟实际的 0xFF label 进行区分的。&lt;br&gt;第二个 bit 序列就是 S-HasChild, 这个跟 D-HasChild 差不多，就不解释了。&lt;/p&gt;&lt;p&gt;第三个 bit 序列 S-LOUDS 用来表示，如果一个 label 是第一个节点，那么对应的 S-LOUDS 就设置为 1，否则为 0。譬如上图第三层，r，p 和 i 都是第一个节点，那么对应的 S-LOUDS 就设置为 1 了。&lt;/p&gt;&lt;p&gt;最后一个 bytes 序列是 S-Values，跟 D-Values 类似，不再解释了。&lt;/p&gt;&lt;p&gt;如果要便利 Sparse，也是通过 rank 和 select 进行，譬如找到第一个子节点 &lt;code class=&quot;inline&quot;&gt;S-ChildNodePos(pos) = select1(S-LOUDS, ranks(S-HasChild, pos) + 1)&lt;/code&gt;，而找到父节点则是 &lt;code class=&quot;inline&quot;&gt;S-ParentNodePos(pos) = select1(S-HasChild, rank1(S-LOUDS, pos) - 1)&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Optimization&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于 SuRF 来说，为了提高查询的速度，一个重要的优化手段就是提高 rank 和 select 执行的效率，在 SuRF 里面，引入了 LookUp Table（LUT）。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a07fb76d8e444f2c7d17b37492b5f7c6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;242&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a07fb76d8e444f2c7d17b37492b5f7c6&quot; data-watermark-src=&quot;v2-8036fccdff18afcfca8931b23c3129f6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;对于 rank 来说，会将 bit vector 切分成 B bits 大小的块，每块都使用 32 bits 的字段来预先保存了计算好的到这个 block 的 rank 值。譬如，在上面的例子，第三个就是 7，保存的就是前两个 block 总的 rank 数量。&lt;/p&gt;&lt;p&gt;而对于一个 pos 来说，它的 &lt;code class=&quot;inline&quot;&gt;rank1(pos) = LUT[i / B] + popcount[i / B * B, i]&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;popcount&lt;/code&gt; 是一个 CPU 指令，用来快速的计算某一段区间的 1 的个数。假设我们现在要得到 pos 12 的 rank 值，先通过 &lt;code class=&quot;inline&quot;&gt;LUT[12 / 5] = LUT[2] = 7&lt;/code&gt;，然后得到 range &lt;code class=&quot;inline&quot;&gt;[12 / 5 * 5, 12] = [10, 12]&lt;/code&gt;，使用 &lt;code class=&quot;inline&quot;&gt;popcount&lt;/code&gt; 得到 2，那么 12 的 rank 就是 9。&lt;br&gt;对于 select 来说，也是使用的 LUT 方法，预先记录算好的值。具体到上面，假设将采样的周期设置为 3，那么第三个 LUT 就保存的是 3 x 2，也就是第 6 的 1 的 pos 值，也就是 8。对于一个 pos 来说，&lt;code class=&quot;inline&quot;&gt;select1(i) = LUT[i / S] + (selecting (i - i / S * S)th set bit starting from LUT[i / S] + 1) + 1&lt;/code&gt;。譬如，如果我们要得到 &lt;code class=&quot;inline&quot;&gt;select1(8)&lt;/code&gt;，首先得到 &lt;code class=&quot;inline&quot;&gt;LUT[8 / 3] = LUT[2] = 8&lt;/code&gt;，然后需要从 position &lt;code class=&quot;inline&quot;&gt;LUT[8 / 3] + 1 = 9&lt;/code&gt; 这个位置，得到第 &lt;code class=&quot;inline&quot;&gt;(8 - 8 / 3 * 3) = 2&lt;/code&gt; 个位置的 bit，也就是 1，所以 &lt;code class=&quot;inline&quot;&gt;select1(8)&lt;/code&gt; 就是 10。&lt;/p&gt;&lt;p&gt;当然，SuRF 还有其它很多优化手段，譬如使用 SIMD 来提速 label 的查找，使用 prefetchj 技术等，这里就不说明了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Succinct Range Filter&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于通常的 SuRF 来说，它因为对这个 trie 都进行了编码，所以它是完全精确的，虽然它是一种省空间的数据结构，但很多时候，我们仍然需要能保证在内存里面存储所有的 SuRF 数据，所以我们就需要对 SuRF 进行裁剪，不存储所有的信息，也就是说，我们需要在查询的 False Positive Rate（FPR）和空间上面做一个权衡。&lt;/p&gt;&lt;p&gt;在 SuRF 里面，有几种方式，Basic，Hash，Real 以及 Mixed。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d99c188249d1164000c0c7b3dadf4f0e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;379&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d99c188249d1164000c0c7b3dadf4f0e&quot; data-watermark-src=&quot;v2-d309450eabe0749b86f8173b32218c2b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;Basic 比较简单，就是直接将最后面的叶子层全部砍掉，这样其实是最省空间的，但 FPR 会比较高。Hash 的方式，则是在最底层，保存了这个 key n bits 位的 hash 值，这样能显著减少 point get 的 FPR，但对于 range 操作则没有任何帮助。&lt;/p&gt;&lt;p&gt;为了解决 Hash range 查询的问题，也可以使用 Real 方式，在最后面继续保存 n bits 位的 key 数据。Real 虽然能处理 point get 和 range，但它的 FPR 其实是比 Hash 要高的。所以我们可以使用 Mixed 方式，将 Hash 和 Real 混合在一起使用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Example&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;SuRF 的代码已经开源，大家可以自己从 &lt;a href=&quot;https://github.com/efficient/SuRF&quot;&gt;Github&lt;/a&gt; 获取到，使用起来也非常的简单，下面是一个非常简单的例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;vector&amp;lt;string&amp;gt; words = {
 &quot;f&quot;,
 &quot;farther&quot;,
 &quot;fas&quot;
 &quot;trying&quot;
};

SuRF s(words, true, 16, kNone, 0, 0);

cout &amp;lt;&amp;lt; &quot;Find abc &quot; &amp;lt;&amp;lt; s.lookupKey(&quot;abc&quot;) &amp;lt;&amp;lt; endl;
cout &amp;lt;&amp;lt; &quot;Find trying &quot; &amp;lt;&amp;lt; s.lookupKey(&quot;trying&quot;) &amp;lt;&amp;lt; endl; &lt;/code&gt;&lt;p&gt;上面我创建了一个 SuRF，传入了一批 words，使用了 Full Trie 的模式，然后做了两次点查。&lt;br&gt;具体代码，大家可以自己去研究下，代码质量还是很不错的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Epilogue&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;SuRF 的研究就暂时到这里结束了，对于 Succinct Data Structure，我个人还是觉得很有意思，可以探究的东西挺多的，毕竟如果能把查询索引全放在内存，不走磁盘，性能还是非常不错的。但我个人毕竟水平有限，仅仅限于了解，所以特别希望能跟业界的大牛多多交流。如果你也对这块很感兴趣，欢迎联系我 &lt;a href=&quot;mailto:tl@pingcap.com&quot;&gt;tl@pingcap.com&lt;/a&gt;。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-06-22-38385054</guid>
<pubDate>Fri, 22 Jun 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
