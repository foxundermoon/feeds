<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sun, 18 Nov 2018 16:50:48 +0800</lastBuildDate>
<item>
<title>拿奖秘诀泄露，TiDB Hackathon 等你来挑战！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-16-50103243.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/50103243&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-507a9d1aeff2b774624b5be2cf38c312_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;i&gt;TiDB Hackathon 2018 开启报名已有半月有余，作为本场 Hackathon &lt;b&gt;唯一的“小可爱”——我，TiDB Robot&lt;/b&gt;，这段时间受到了小伙伴们的问题轰炸，包括但不限于怎么组队选题、怎么和队友合作、住哪儿、吃啥……还有求划重点拿大奖的。所以今天我总结了一些常见 QA，&lt;b&gt;分为报名篇 / 选题篇 / 实操篇 / 吃住篇&lt;/b&gt;，顺便也划了一下重点，希望对大家有所帮助～&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;报名篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：对参赛者本身有什么门槛吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：没有门槛，不限年龄，不限职业，唯一的要求是&lt;b&gt;来现场参赛（北京）&lt;/b&gt;。Hackathon 注重现场的团队配合和竞技氛围，不接受线上参与哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：如何组建一支“梦之队”？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：Hackathon 精髓之一是团队协作，&lt;b&gt;队员配合和角色分配&lt;/b&gt;很重要。谁来选题谁来设计，是否需要前端等等都是组队时要考虑的因素。还有一个容易被忽视的重要角色是&lt;b&gt;演讲人&lt;/b&gt;，两天一夜的比赛最后的决定性时刻就在展示的几分钟，如何条理清晰的把做的东西讲清楚，以及这个项目解决了什么实质性的问题很关键。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：一个人也可以成队报名吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：当然可以，我们非常欢迎技能值满点的小伙伴以个人身份参赛（传说中的“一个人活成一支队伍”），也欢迎暂时没有选题或队友的个人参赛者报名，主办方会协调大家进行赛前组队。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;选题篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：对选题毫无思路怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：本场 Hackathon 主题为 &lt;b&gt;TiDB Ecosystem。&lt;/b&gt;如果想参赛但不知从何入手，可以&lt;b&gt;勾搭我（微信号：tidbai）&lt;/b&gt;获取我们的选题参考方向哦～希望大家可以举一反三，think out of the box，做出令人眼前一亮的作品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：已有选题的队伍可以提前写代码了吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：&lt;b&gt;不可以&lt;/b&gt;。为了公平起见，参赛作品的所有代码必须在 Hackathon 现场完成，前期准备仅限于资料搜集、架构设计、环境配置与测试。我们不就是为了在有限的时间里做最有挑战的事情，对吗？&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0f0b9fbaf639866ad88b6d5e46c00085_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;370&quot; data-rawheight=&quot;366&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0f0b9fbaf639866ad88b6d5e46c00085&quot; data-watermark-src=&quot;v2-ba2d9f4a5a6f5e5243169f6ed2a2148f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;实操篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：当天如何与队友合作呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：指定团队协作平台—— &lt;b&gt;GitHub&lt;/b&gt;。GitHub 上的提交记录，也方便于评审团审核参赛作品的完整度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：还不会使用 GitHub 怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：五分钟学会使用 GitHub——&lt;/p&gt;&lt;p&gt;    - What is GitHub：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=w3jLJU7DT5E&quot;&gt;https://www.youtube.com/watch?v=w3jLJU7DT5E&lt;/a&gt;&lt;/p&gt;&lt;p&gt;    - GitHub Tutorial For Beginners：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0fKg7e37bQE&quot;&gt;https://www.youtube.com/watch?v=0fKg7e37bQE&lt;/a&gt;&lt;/p&gt;&lt;p&gt;    - 知乎 GitHub 话题助攻&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/20070065&quot;&gt;https://www.zhihu.com/question/20070065&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：TiDB 的代码对于新手来说好复杂啊，哪里可以找到更多的参考资料？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：&lt;b&gt;官方文档&lt;/b&gt;（github.com/pingcap/docs-cn）中有详细的安装部署及运用指导，另外，&lt;b&gt;官方微信公众号&lt;/b&gt;中有宝藏哦。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;推荐阅读：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27275483&quot;&gt;三篇文章了解 TiDB 技术内幕系列&lt;/a&gt;&lt;/u&gt; |   &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46524530&quot;&gt;TiKV 是如何存储数据的&lt;/a&gt;&lt;/u&gt;  | &lt;u&gt;&lt;a href=&quot;https://pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;我们定期举办的 Infra Meetup 常常有 TiDB 相关议题，大家可以在微信公众号（ID: pingcap2015）菜单栏“社区活动-&amp;gt;往期 Meetup”中翻阅视频&amp;amp;文字回顾。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外悄悄的说，我们&lt;b&gt;官网&lt;/b&gt;的搜索很强大，大家可以搜索关键词找到相关资料。除此之外，也可以求助导师团（&lt;a href=&quot;https://mp.weixin.qq.com/s/C5FbZ7HEG3Sr6l_oqCxNng&quot;&gt;七龙珠导师团介绍在此，大家现场“照图抓人”即可&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：如何更好的展示成果？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：Hackathon 不仅是一场代码技术的比拼，临场发挥和演讲技巧也很重要，最后需要在短短几分钟内让大家明白你做了什么以及这个项目的价值。&lt;/p&gt;&lt;p&gt;我们见过花了大量时间介绍项目背景而正题只进行到一半就草草结束的团队，也见过测试时完美运行的项目在演示时却频频报错、选手满头大汗的场景。所以我们建议：&lt;b&gt;演讲时逻辑清晰，开门见山，在有限的时间里阐述项目的重点，并预留出一部分时间进行程序演示，&lt;/b&gt;而现场跑 demo 是一门&lt;b&gt;玄学&lt;/b&gt;，如果不想冒险可以预先录制一个 Demo 视频。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：奖金好诱人，好想拿奖！求划重点！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：和有趣的人一起做有趣的事很重要，顺便拿个大奖当然就更好啦～本次比赛的评判标准是实用性、完成度和创新性。&lt;b&gt;其中，权重最大的是实用性，我们希望 Hackathon 中产出的项目可以长久的在社区运行下去，因此解决实际问题和提高效率是比较重要的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;吃住篇&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：主办方提供餐饮和住宿吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：我们提供参赛者和志愿者比赛期间的餐饮（正餐包括 12 月 1 日午餐、晚餐，12 月 2 日早餐、午餐），参赛选手可留在比赛场地过夜，如需在场地附近租住宾馆需要自己解决哟～&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：比赛两天都需要呆在活动场地吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：如果没有特殊需求请不要离开场地，需要回自己住处过夜的小伙伴需要提前告知工作人员，并于第二天早晨 8 点前返回场地。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;最后也是最最重要的建议：&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;合理规划项目时间，选定主题之后不要轻易改动，要有团队精神，&lt;b&gt;不能轻易抛弃队友。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;一定、一定要&lt;b&gt;慎用 rm-rf/ &lt;/b&gt; （这是往年 Hackathon 真实发生过的“惨案”……）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;赛程重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;奖项设置&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;一等奖（1 支队伍）：¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;除此之外还设有最佳创意奖和最佳贡献奖。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名时间&lt;/b&gt;：即日起至 11 月 23 日 17:00&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名审核&lt;/b&gt;：5 个工作日内反馈审核结果&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名链接&lt;/b&gt;：点击【&lt;a href=&quot;http://nc9hsk15y2xczuor.mikecrm.com/3AarNns&quot;&gt;这里&lt;/a&gt;】报名&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-16-50103243</guid>
<pubDate>Fri, 16 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在美团点评的深度实践之旅（9000 字长文 / 真实实践经验）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-14-49826990.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49826990&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ef8c60fcae0adc633941847ade639a5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;一. 背景和现状&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在美团，基于 MySQL 构建的传统关系型数据库服务已经难于支撑公司业务的爆发式增长，促使我们去探索更合理的数据存储方案和实践新的运维方式。随着近一两年来分布式数据库大放异彩，美团 DBA 团队联合架构存储团队，于 2018 年初启动了分布式数据库项目。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0420b47ac623a455b3f47c455151dd80_r.jpg&quot; data-caption=&quot;图 1 美团点评产品展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;733&quot; data-rawheight=&quot;481&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0420b47ac623a455b3f47c455151dd80&quot; data-watermark-src=&quot;v2-7d98566cf142d5882069e5f7d874d85c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;立项之初，我们进行了大量解决方案的对比，深入了解了业界多种 scale-out、scale-up 方案，考虑到技术架构的前瞻性、发展潜力、社区活跃度、以及服务本身与 MySQL 的兼容性，最终敲定了基于 TiDB 数据库进行二次开发的整体方案，并与 PingCAP 官方和开源社区进行深入合作的开发模式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;美团业务线众多，我们根据业务特点及重要程度逐步推进上线，到截稿为止，已经上线 10 个集群，近 200 个物理节点，大部分是 OLTP 类型的应用，除了上线初期遇到了一些小问题，目前均已稳定运行。初期上线的集群，已经分别服务于配送、出行、闪付、酒旅等业务。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 架构分层清晰，服务平稳流畅，但在美团当前的数据量规模和已有稳定的存储体系的基础上，推广新的存储服务体系，需要对周边工具和系统进行一系列改造和适配，从初期探索到整合落地需要走很远的路。下面从几个方面分别介绍：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一是从 0 到 1 的突破，重点考虑做哪些事情；&lt;/li&gt;&lt;li&gt;二是如何规划实施不同业务场景的接入和已有业务的迁移；&lt;/li&gt;&lt;li&gt;三是上线后遇到的一些典型问题介绍；&lt;/li&gt;&lt;li&gt;四是后续规划和对未来的展望。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;二. 前期调研测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1  对 TiDB 的定位&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们对于 TiDB 的定位，前期在于重点解决 MySQL 的单机性能和容量无法线性和灵活扩展的问题，与 MySQL 形成互补。业界分布式方案很多，我们为何选择了 TiDB 呢？考虑到公司业务规模的快速增长，以及公司内关系数据库以 MySQL 为主的现状，因此我们在调研阶段，对以下技术特性进行了重点考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;协议兼容 MySQL&lt;/b&gt;：这个是必要项。&lt;/li&gt;&lt;li&gt;&lt;b&gt;可在线扩展&lt;/b&gt;：数据通常要有分片，分片要支持分裂和自动迁移，并且迁移过程要尽量对业务无感知。&lt;/li&gt;&lt;li&gt;&lt;b&gt;强一致的分布式事务&lt;/b&gt;：事务可以跨分片、跨节点执行，并且强一致。&lt;/li&gt;&lt;li&gt;&lt;b&gt;支持二级索引&lt;/b&gt;：为兼容 MySQL 的业务，这个是必须的。&lt;/li&gt;&lt;li&gt;&lt;b&gt;性能&lt;/b&gt;：MySQL 的业务特性，高并发的 OLTP 性能必须满足。&lt;/li&gt;&lt;li&gt;&lt;b&gt;跨机房服务&lt;/b&gt;：需要保证任何一个机房宕机，服务能自动切换。&lt;/li&gt;&lt;li&gt;&lt;b&gt;跨机房双写&lt;/b&gt;：支持跨机房双写是数据库领域一大难题，是我们对分布式数据库的一个重要期待，也是美团下一阶段重要的需求。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;业界的一些传统方案虽然支持分片，但无法自动分裂、迁移，不支持分布式事务，还有一些在传统 MySQL 上开发一致性协议的方案，但它无法实现线性扩展，最终我们选择了与我们的需求最为接近的 TiDB。与 MySQL 语法和特性高度兼容，具有灵活的在线扩容缩容特性，支持 ACID 的强一致性事务，可以跨机房部署实现跨机房容灾，支持多节点写入，对业务又能像单机 MySQL 一样使用。&lt;br&gt;&lt;br&gt;&lt;b&gt;2.2  测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对官方声称的以上优点，我们进行了大量的研究、测试和验证。&lt;/p&gt;&lt;p&gt;首先，我们需要知道扩容、Region 分裂转移的细节、Schema 到 kv 的映射、分布式事务的实现原理。而 TiDB 的方案，参考了较多的 Google 论文，我们进行了阅读，这有助于我们理解 TiDB 的存储结构、事务算法、安全性等，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Spanner: Google’s Globally-Distributed Database&lt;/li&gt;&lt;li&gt;Large-scale Incremental Processing Using Distributed Transactions and Notifications&lt;/li&gt;&lt;li&gt;In Search of an Understandable Consensus Algorithm&lt;/li&gt;&lt;li&gt;Online, Asynchronous Schema Change in F1&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们也进行了常规的性能和功能测试，用来与 MySQL 的指标进行对比，其中一个比较特别的测试，是证明 3 副本跨机房部署，确实能保证每个机房分布一个副本，从而保证任何一个机房宕机不会导致丢失超过半数副本。&lt;/b&gt;从以下几个点进行测试：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Raft 扩容时是否支持 learner 节点，从而保证单机房宕机不会丢失 2/3 的副本。&lt;/li&gt;&lt;li&gt;TiKV 上的标签优先级是否可靠，保证当机房的机器不平均时，能否保证每个机房的副本数依然是绝对平均的。&lt;/li&gt;&lt;li&gt;实际测试，单机房宕机，TiDB 在高并发下，QPS、响应时间、报错数量，以及最终数据是否有丢失。&lt;/li&gt;&lt;li&gt;手动 Balance 一个 Region 到其他机房，是否会自动回来。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从测试结果来看，一切都符合预期。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三. 存储生态建设&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;美团的产品线丰富，业务体量大，业务对在线存储的服务质量要求也非常高。因此，从早期做好服务体系的规划非常重要。下面从业务接入层、监控报警、服务部署，来分别介绍一下我们所做的工作。&lt;br&gt;&lt;br&gt;&lt;b&gt;3.1  业务接入层&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当前 MySQL 的业务接入方式主要有两种，DNS 接入和 Zebra 客户端接入。在前期调研阶段，我们选择了 DNS + 负载均衡组件的接入方式，TiDB-Server 节点宕机，15s 可以被负载均衡识别到，简单有效。业务架构如图 2：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fd9faed3064e8efeb78f8224f74bdfb3_r.jpg&quot; data-caption=&quot;图 2 业务架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;347&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fd9faed3064e8efeb78f8224f74bdfb3&quot; data-watermark-src=&quot;v2-9270cf0e10e6e142bd0dea62eb54aa26&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;后面我们会逐渐过渡到当前大量使用的 Zebra 接入方式来访问 TiDB，从而保持与访问 MySQL 的方式一致，一方面减少业务改造的成本，另一方面尽量实现从 MySQL 到 TiDB 的透明迁移。&lt;br&gt;&lt;b&gt;3.2  监控报警&lt;/b&gt;&lt;/p&gt;&lt;p&gt;美团目前使用 Mt-Falcon 平台负责监控报警，通过在 Mt-Falcon 上配置不同的插件，可以实现对多种组件的自定义监控。另外也会结合 Puppet 识别不同用户的权限、文件的下发。这样，只要我们编写好插件脚本、需要的文件，装机和权限控制就可以完成了。监控架构如图 3：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d329d5862cd00f9d6f10e0ecf7b9073c_r.jpg&quot; data-caption=&quot;图 3 监控架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;804&quot; data-rawheight=&quot;483&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d329d5862cd00f9d6f10e0ecf7b9073c&quot; data-watermark-src=&quot;v2-f7fb49c3f75488a38be205b05835e2ae&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;而 TiDB 有丰富的监控指标，使用流行的 Prometheus + Grafana，一套集群有 700+ 的 Metric。从官方的架构图可以看出，每个组件会推送自己的 Metric 给 PushGateWay，Prometheus 会直接到 PushGateWay 去抓数据。&lt;/p&gt;&lt;p&gt;由于我们需要组件收敛，原生的 TiDB 每个集群一套 Prometheus 的方式不利于监控的汇总、分析、配置，而报警已经在 Mt-Falcon 上实现的比较好了，在 AlertManager 上再造一个也没有必要。因此我们需要想办法把监控和报警汇总到 Mt-Falcon 上面，有如下几种方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;方案一：修改源代码，将 Metric 直接推送到 Falcon，由于 Metric 散落在代码的不同位置，而且 TiDB 代码迭代太快，把精力消耗在不停调整监控埋点上不太合适。&lt;/li&gt;&lt;li&gt;方案二：在 PushGateWay 是汇总后的，可以直接抓取，但 PushGateWay 是个单点，不好维护。&lt;/li&gt;&lt;li&gt;方案三：通过各个组件（TiDB、PD、TiKV）的本地 API 直接抓取，优点是组件宕机不会影响其他组件，实现也比较简单。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们最终选择了方案三。该方案的难点是需要把 Prometheus 的数据格式转化为 Mt-Falcon 可识别的格式，因为 Prometheus 支持 Counter、Gauge、Histogram、Summary 四种数据类型，而 Mt-Falcon 只支持基本的 Counter 和 Gauge，同时 Mt-Falcon 的计算表达式比较少，因此需要在监控脚本中进行转换和计算。&lt;br&gt;&lt;br&gt;&lt;b&gt;3.3  批量部署&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 使用 Ansible 实现自动化部署。迭代快，是 TiDB 的一个特点，有问题快速解决，但也造成 Ansible 工程、TiDB 版本更新过快，我们对 Ansible 的改动，也只会增加新的代码，不会改动已有的代码。因此线上可能同时需要部署、维护多个版本的集群。如果每个集群一个 Ansible 目录，造成空间的浪费。我们采用的维护方式是，在中控机中，每个版本一个 Ansible 目录，每个版本中通过不同 inventory 文件来维护。这里需要跟 PingCAP 提出的是，Ansible 只考虑了单集群部署，大量部署会有些麻烦，像一些依赖的配置文件，都不能根据集群单独配置（咨询官方得知，PingCAP 目前正在基于 Cloud TiDB 打造一站式 HTAP 平台，会提供批量部署、多租户等功能，能比较好的解决这个问题）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.4  自动化运维平台&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着线上集群数量的增加，打造运维平台提上了日程，而美团对 TiDB 和 MySQL 的使用方式基本相同，因此 MySQL 平台上具有的大部分组件，TiDB 平台也需要建设。典型的底层组件和方案：SQL 审核模块、DTS、数据备份方案等。自动化运维平台展示如图 4：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb534e712cfff40c4dd8a4d086bb851e_r.jpg&quot; data-caption=&quot;图 4 自动化运维平台展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;531&quot; data-rawheight=&quot;481&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bb534e712cfff40c4dd8a4d086bb851e&quot; data-watermark-src=&quot;v2-1d7fc5cce8af85f15bcd16c544b8f7cb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;3.5  上下游异构数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是在线存储体系中的一环，它同时也需要融入到公司现有的数据流中，因此需要一些工具来做衔接。PingCAP 官方标配了相关的组件。&lt;/p&gt;&lt;p&gt;公司目前 MySQL 和 Hive 结合的比较重，而 TiDB 要代替 MySQL 的部分功能，需要解决 2 个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;MySQL to TiDB&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MySQL 到 TiDB 的迁移，需要解决数据迁移以及增量的实时同步，也就是 DTS，Mydumper + Loader 解决存量数据的同步，官方提供了 DM 工具可以很好的解决增量同步问题。&lt;/li&gt;&lt;li&gt;MySQL 大量使用了自增 ID 作为主键。分库分表 MySQL 合并到 TiDB 时，需要解决自增 ID 冲突的问题。这个通过在 TiDB 端去掉自增 ID 建立自己的唯一主键来解决。新版 DM 也提供分表合并过程主键自动处理的功能。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Hive to TiDB &amp;amp; TiDB to Hive&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Hive to TiDB 比较好解决，这体现了 TiDB 和 MySQL 高度兼容的好处，insert 语句可以不用调整，基于 Hive to MySQL 简单改造即可。&lt;/li&gt;&lt;li&gt;TiDB to Hive 则需要基于官方 Pump + Drainer 组件，Drainer 可以消费到 Kafka、MySQL、TiDB，我们初步考虑用下图 5 中的方案通过使用 Drainer 的 Kafka 输出模式同步到 Hive。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-027ddcdac6f9751c3ba280bcbe0d41bb_r.jpg&quot; data-caption=&quot;图 5 TiDB to Hive 方案图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;831&quot; data-rawheight=&quot;302&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-027ddcdac6f9751c3ba280bcbe0d41bb&quot; data-watermark-src=&quot;v2-da5d862f10832ca37b1ba23f151d34d8&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;四. 线上使用磨合&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于初期上线的业务，我们比较谨慎，基本的原则是：离线业务 -&amp;gt; 非核心业务 -&amp;gt; 核心业务。TiDB 已经发布两年多，且前期经历了大量的测试，我们也深入了解了其它公司的测试和使用情况，可以预期的是 TiDB 上线会比较稳定，但依然遇到了一些小问题。总体来看，在安全性、数据一致性等关键点上没有出现问题。其他一些性能抖动问题，参数调优的问题，也都得到了快速妥善的解决。这里给 PingCAP 的同学点个大大的赞，问题响应速度非常快，与我们内部研发的合作也非常融洽。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1  写入量大、读 QPS 高的离线业务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们上线的最大的一个业务，每天有数百 G 的写入量，前期遇到了较多的问题，我们重点说说。&lt;br&gt;&lt;br&gt;业务场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定的写入，每个事务操作 100~200 行不等，每秒 6w 的数据写入。&lt;/li&gt;&lt;li&gt;每天的写入量超过 500G，以后会逐步提量到每天 3T。&lt;/li&gt;&lt;li&gt;每 15 分钟的定时读 job，5000 QPS（高频量小）。&lt;/li&gt;&lt;li&gt;不定时的查询（低频量大）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;之前使用 MySQL 作为存储，但 MySQL 到达了容量和性能瓶颈，而业务的容量未来会 10 倍的增长。初期调研测试了 ClickHouse，满足了容量的需求，测试发现运行低频 SQL 没有问题，但高频 SQL 的大并发查询无法满足需求，只在 ClickHouse 跑全量的低频 SQL 又会 overkill，最终选择使用 TiDB。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试期间模拟写入了一天的真实数据，非常稳定，高频低频两种查询也都满足需求，定向优化后 OLAP 的 SQL 比 MySQL 性能提高四倍。&lt;/b&gt;但上线后，陆续发现了一些问题，典型的如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.1  TiKV 发生 Write Stall&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 底层有 2 个 RocksDB 作为存储。新写的数据写入 L0 层，当 RocksDB 的 L0 层数量达到一定数量，就会发生减速，更高则发生 Stall，用来自我保护。TiKV 的默认配置：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;level0-slowdown-writes-trigger = 20&lt;/li&gt;&lt;li&gt;level0-stop-writes-trigger = 36&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;遇到过的，发生 L0 文件过多可能的原因有 2 个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;写入量大，Compact 完不成。&lt;/li&gt;&lt;li&gt;Snapshot 一直创建不完，导致堆积的副本一下释放，rocksdb-raft 创建大量的 L0 文件，监控展示如图 6：&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e69159a837553ece67165e5f1d535130_r.jpg&quot; data-caption=&quot;图 6 TiKV 发生 Write Stall 监控展示图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;404&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e69159a837553ece67165e5f1d535130&quot; data-watermark-src=&quot;v2-256e0db1ec5838242fc538eed4517cd7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我们通过以下措施，解决了 Write Stall 的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;减缓 Raft Log Compact 频率（增大 raft-log-gc-size-limit、raft-log-gc-count-limit）&lt;/li&gt;&lt;li&gt;加快 Snapshot 速度（整体性能、包括硬件性能）&lt;/li&gt;&lt;li&gt;max-sub-compactions 调整为 3&lt;/li&gt;&lt;li&gt;max-background-jobs 调整为 12&lt;/li&gt;&lt;li&gt;level 0 的 3 个 Trigger 调整为 16、32、64&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.2  Delete 大量数据，GC 跟不上&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在 TiDB 的 GC 对于每个 kv-instance 是单线程的，当业务删除数据的量非常大时，会导致 GC 速度较慢，很可能 GC 的速度跟不上写入。&lt;br&gt;目前可以通过增多 TiKV 个数来解决，长期需要靠 GC 改为多线程执行，官方对此已经实现，即将发布。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.3  Insert 响应时间越来越慢&lt;/b&gt;&lt;/p&gt;&lt;p&gt;业务上线初期，insert 的响应时间 80 线（Duration 80 By Instance）在 20ms 左右，随着运行时间增加，发现响应时间逐步增加到 200ms+。期间排查了多种可能原因，定位在由于 Region 数量快速上涨，Raftstore 里面要做的事情变多了，而它又是单线程工作，每个 Region 定期都要 heartbeat，带来了性能消耗。tikv-raft propose wait duration 指标持续增长。&lt;br&gt;解决问题的办法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;临时解决&lt;/li&gt;&lt;ul&gt;&lt;li&gt;增加 Heartbeat 的周期，从 1s 改为 2s，效果比较明显，监控展示如图 7：&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2751cc531372bb7229c9e6c080242f36_r.jpg&quot; data-caption=&quot;图 7 insert 响应时间优化前后对比图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;208&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2751cc531372bb7229c9e6c080242f36&quot; data-watermark-src=&quot;v2-d2b25490744c113349c30b801b486786&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;彻底解决&lt;/li&gt;&lt;ul&gt;&lt;li&gt;需要减少 Region 个数，Merge 掉空 Region，官方在 2.1 版本中已经实现了 Region Merge 功能，我们在升级到 2.1 后，得到了彻底解决。&lt;/li&gt;&lt;li&gt;另外，等待 Raftstore 改为多线程，能进一步优化。（官方回复相关开发已基本接近尾声，将于 2.1 的下一个版本发布。）&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.4  Truncate Table 空间无法完全回收&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DBA Truncate 一张大表后，发现 2 个现象，一是空间回收较慢，二是最终也没有完全回收。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;由于底层 RocksDB 的机制，很多数据落在 level 6 上，有可能清不掉。这个需要打开 cdynamic-level-bytes 会优化 Compaction 的策略，提高 Compact 回收空间的速度。&lt;/li&gt;&lt;li&gt;由于 Truncate 使用 delete_files_in_range 接口，发给 TiKV 去删 SST 文件，这里只删除不相交的部分，而之前判断是否相交的粒度是 Region，因此导致了大量 SST 无法及时删除掉。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;考虑 Region 独立 SST 可以解决交叉问题，但是随之带来的是磁盘占用问题和 Split 延时问题。&lt;/li&gt;&lt;li&gt;考虑使用 RocksDB 的 DeleteRange 接口，但需要等该接口稳定。&lt;/li&gt;&lt;li&gt;目前最新的 2.1 版本优化为直接使用 DeleteFilesInRange 接口删除整个表占用的空间，然后清理少量残留数据，已经解决。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.1.5  开启 Region Merge 功能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了解决 region 过多的问题，我们在升级 2.1 版本后，开启了 region merge 功能，但是 TiDB 的响应时间 80 线（Duration 80 By Instance）依然没有恢复到当初，保持在 50ms 左右，排查发现 KV 层返回的响应时间还很快，和最初接近，那么就定位了问题出现在 TiDB 层。研发人员和 PingCAP 定位在产生执行计划时行为和 2.0 版本不一致了，&lt;b&gt;目前已经优化。&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;4.2  在线 OLTP，对响应时间敏感的业务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了分析查询量大的离线业务场景，美团还有很多分库分表的场景，虽然业界有很多分库分表的方案，解决了单机性能、存储瓶颈，但是对于业务还是有些不友好的地方：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;业务无法友好的执行分布式事务。&lt;/li&gt;&lt;li&gt;跨库的查询，需要在中间层上组合，是比较重的方案。&lt;/li&gt;&lt;li&gt;单库如果容量不足，需要再次拆分，无论怎样做，都很痛苦。&lt;/li&gt;&lt;li&gt;业务需要关注数据分布的规则，即使用了中间层，业务心里还是没底。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此很多分库分表的业务，以及即将无法在单机承载而正在设计分库分表方案的业务，主动找到了我们，这和我们对于 TiDB 的定位是相符的。这些业务的特点是 SQL 语句小而频繁，对一致性要求高，通常部分数据有时间属性。在测试及上线后也遇到了一些问题，不过目前基本都有了解决办法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2.1  SQL  执行超时后，JDBC 报错&lt;/b&gt;&lt;/p&gt;&lt;p&gt;业务偶尔报出 privilege check fail。&lt;br&gt;是由于业务在 JDBC 设置了 QueryTimeout，SQL 运行超过这个时间，会发行一个 “kill query” 命令，而 TiDB 执行这个命令需要 Super 权限，业务是没有权限的。&lt;br&gt;其实 kill 自己的查询，并不需要额外的权限，目前已经解决了这个问题：&lt;br&gt;https://github.com/pingcap/tidb/pull/7003，不再需要 Super 权限，已在 2.0.5 上线。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2.2  执行计划偶尔不准&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的物理优化阶段需要依靠统计信息。在 2.0 版本统计信息的收集从手动执行，优化为在达到一定条件时可以自动触发&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据修改比例达到 tidb_auto_analyze_ratio&lt;/li&gt;&lt;li&gt;表一分钟没有变更（目前版本已经去掉这个条件）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但是在没有达到这些条件之前统计信息是不准的，这样就会导致物理优化出现偏差，在测试阶段（2.0 版本）就出现了这样一个案例：业务数据是有时间属性的，业务的查询有 2 个条件，比如：时间+商家 ID，但每天上午统计信息可能不准，当天的数据已经有了，但统计信息认为没有。这时优化器就会建议使用时间列的索引，但实际上商家 ID 列的索引更优化。这个问题可以通过增加 Hint 解决。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 2.1 版本对统计信息和执行计划的计算做了大量的优化，也稳定了基于 Query Feedback 更新统计信息，也用于更新直方图和 Count-Min Sketch，非常期待 2.1 的 GA。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五. 总结展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;经过前期的测试、各方的沟通协调，以及近半年对 TiDB 的使用，我们看好 TiDB 的发展，也对未来基于 TiDB 的合作充满信心。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;接下来，我们会加速推进 TiDB 在更多业务系统中的使用，同时也将 TiDB 纳入了美团新一代数据库的战略选型中。&lt;/b&gt;当前，我们已经全职投入了 3 位 DBA 同学和多位存储计算专家，从底层的存储，中间层的计算，业务层的接入，到存储方案的选型和布道，进行全方位和更深入的合作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;长期来看，结合美团不断增长的业务规模，我们将与 PingCAP 官方合作打造更强大的生态体系&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Titan&lt;/b&gt;：Titan 是 TiDB 下一步比较大的动作，也是我们非常期待的下一代存储引擎，它对大 Value 支持会更友好，将解决我们单行大小受限，单机 TiKV 最大支持存储容量的问题，大大提升大规模部署的性价比。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Cloud TiDB （based on Docker &amp;amp; K8s）&lt;/b&gt;：云计算大势所趋，PingCAP 在这块也布局比较早，今年 8 月份开源了 TiDB Operator，Cloud TiDB 不仅实现了数据库的高度自动化运维，而且基于 Docker 硬件隔离，实现了数据库比较完美的多租户架构。和官方同学沟通，目前他们的私有云方案在国内也有重要体量的 POC，这也是美团看重的一个方向。&lt;/li&gt;&lt;li&gt;&lt;b&gt;TiDB HTAP Platform&lt;/b&gt;：PingCAP 在原有 TiDB Server 计算引擎的基础上，还构建 TiSpark 计算引擎，和他们官方沟通，他们在研发了一个基于列的存储引擎，这样就形成了下层行、列两个存储引擎、上层两个计算引擎的完整混合数据库（HTAP），这个架构不仅大大的节省了核心业务数据在整个公司业务周期里的副本数量，还通过收敛技术栈，节省了大量的人力成本、技术成本、机器成本，同时还解决了困扰多年的 OLAP 的实效性。后面我们也会考虑将一些有实时、准实时的分析查询系统接入 TiDB。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c382078a73f1b6c525bcfd795399c117_r.jpg&quot; data-caption=&quot;图 8 TiDB HTAP Platform 整体架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;539&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c382078a73f1b6c525bcfd795399c117&quot; data-watermark-src=&quot;v2-c0eb01710841afbed7641f0a639677ad&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;后续的物理备份方案，跨机房多写等也是我们接下来逐步推进的场景，总之我们坚信未来 TiDB 在美团的使用场景会越来越多，发展也会越来越好。&lt;/p&gt;&lt;p&gt;TiDB 在业务层面、技术合作层面都已经在美团扬帆起航，美团点评将携手 PingCAP 开启新一代数据库深度实践、探索之旅。后续，还有美团点评架构存储团队针对 TiDB 源码研究和改进的系列文章，敬请期待！&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;赵应钢，美团点评研究员&lt;/p&gt;&lt;p&gt;李坤，美团点评数据库专家&lt;/p&gt;&lt;p&gt;朴昌俊，美团点评数据库专家&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-14-49826990</guid>
<pubDate>Wed, 14 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB at 丰巢：尝鲜分布式数据库</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-12-49418382.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49418382&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-53b245933c4c1344ffe14c3caa58a35b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;作者：丰巢技术团队&lt;/i&gt;&lt;/p&gt;&lt;p&gt;随着丰巢业务系统快速增长，其核心系统的数据量，早就跨越了亿级别，而且每年增量仍然在飞速发展。整个核心系统随着数据量的压力增长，不但系统架构复杂度急剧增长，数据架构更加复杂，传统的单节点数据库，已经日渐不能满足丰巢的需求，当单表数量上亿的时候，Oracle 还能勉强抗住，而 MySQL 到单表千万级别的时候就难以支撑，需要进行分表分库。为此，一款高性能的分布式数据库，日渐成为刚需。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;思考&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在互联网公司业务量增大之后，并行扩展是最常用、最简单、最实时的手段。例如负载均衡设备拆流量，让海量流量变成每个机器可以承受的少量流量，并且通过集群等方式支撑起来整个业务。于是当数据库扛不住的时候也进行拆分。&lt;/p&gt;&lt;p&gt;但有状态数据和无状态数据不同，当数据进行拆分的时候，会发生数据分区，而整个系统又要高可用状态下进行，于是数据的一致性变成了牺牲品，大量的核对工具在系统之间跑着保证着最终的一致性。在业务上，可能业务同学经常会遇到分过库的同学说，这个需求做不了，那个需求做不了，如果有 sql 经验的业务同学可能会有疑问不就是一条 sql 的事情么，其实这就是分库分表后遗症。&lt;/p&gt;&lt;p&gt;为此，我们需要有个数据库帮我们解决以上问题，它的特性应该是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据强一致：支持完整的 ACID；&lt;/li&gt;&lt;li&gt;不分表分库：无论多少数据我们只管插入不需要关心啥时候扩容，会不会有瓶颈；&lt;/li&gt;&lt;li&gt;数据高可用：当我们某台数据库的少部分机器磁盘或者其他挂了的时候，我们业务上可以无感知，甚至某个城市机房发生灾难的时候还可以持续提供服务，数据不丢失；&lt;/li&gt;&lt;li&gt;复杂 SQL 功能：基本上单库的 SQL，都可以在这个数据库上运行，不需要修改或者些许修改；&lt;/li&gt;&lt;li&gt;高性能：在满足高 QPS 的同时，保证比较低的延时。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;选型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;根据以上期望进行分析，我们分析了目前市面上存在的 NewSQL 分布式数据库，列表如下：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7d50aaba4268b4bcffdf1037c9df55fb_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;540&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7d50aaba4268b4bcffdf1037c9df55fb&quot; data-watermark-src=&quot;v2-d9d2d9cabfc430fe93fe923f6c3d86c3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;在综合考虑了开源协议，成熟度，可控度，性能，服务支撑等综合因素之后，我们选择了 TiDB，它主要优势如下：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。    &lt;/p&gt;&lt;ul&gt;&lt;li&gt;水平弹性扩展&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松松应对高并发、海量数据场景。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分布式事务 &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 100% 支持标准的 ACID 事务。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;金融级别的高可用性&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;相比于传统主从（M-S）复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。&lt;/p&gt;&lt;p&gt;基于如上的原因，我们选择了 TiDB，作为丰巢的核心系统的分布式数据库，来取代   Oracle 和 MySQL。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;评估&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 性能测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的基准测试，使用的工具是 sysbanch 进行测试，使用了 8 张基础数据为一千万的表，分别测试了 insert，select，oltp 和 delete 脚本得到数据如下，查询的 QPS 达到了惊人的 14 万每秒，而插入也稳定在 1 万 4 每秒。&lt;/p&gt;&lt;p&gt;核心服务器配置：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ea896dbfcc915d8b30eae37f8cd72bdd_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;218&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ea896dbfcc915d8b30eae37f8cd72bdd&quot; data-watermark-src=&quot;v2-09156297eb416aaa8ee6cdf3d36ea51f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;测试结果：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-175e029b03244dd0853c16f104c56563_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;476&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-175e029b03244dd0853c16f104c56563&quot; data-watermark-src=&quot;v2-803097652d090110d23cbb070bceb613&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;通过～&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 功能测试&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7698939b1c1a4dd75285e254111a6d9a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;363&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7698939b1c1a4dd75285e254111a6d9a&quot; data-watermark-src=&quot;v2-07bcb8e6f8393100108c878fddf734a1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;通过～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;接入&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;因为是核心系统，安全起见，我们采取了多种方案保证验证项目接入的可靠性，保证不影响业务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 项目选择&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在寻找第一个接入项目的时候，我们以下面 4 个特征，进行了选择：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-14b43de242d2761cd9c40c9bd9335c9b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;681&quot; data-rawheight=&quot;443&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-14b43de242d2761cd9c40c9bd9335c9b&quot; data-watermark-src=&quot;v2-e0772a0cd62151e113f42132dd3b2a17&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;最终，我们选择了推送服务。因为推送服务是丰巢用来发送取件通知的核心服务，量非常大，但逻辑简单，而且有备选外部推送方案，所以即便万一出现问题，而不会影响用户。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 代码修改&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;因为 TiDB 是完全兼容 MySQL 语法的，所以在这个项目的接入过程中，我们对代码的修改是很细微的。&lt;/b&gt;SQL 基本零改动，主要是外围代码，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;异步接口修改，数据异步化入库&lt;/li&gt;&lt;li&gt;同步接口修改，实现异常熔断&lt;/li&gt;&lt;li&gt;停止内嵌数据迁移代码&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以上三点，保证了整个系统在不强依赖于数据库，并且能在高并发的情况下通过异步落库保护数据库不被压垮，并且在数据库发生问题的时候，核心业务可以正常进行下去。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;效果&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 查询能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接入 TiDB 之后，原先按照时间维度来拆分的十几个分表，变成了一张大表。最明显的变化，是在大数据量下，数据查询能力有了显著的提升。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e6bda36f6bcce06417c6f8f2c7255247_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;464&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e6bda36f6bcce06417c6f8f2c7255247&quot; data-watermark-src=&quot;v2-d7e565cc555d52e9439b5cfd8ccc79bc&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;2. 监控能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 拥有很完善的监控平台，可以直观的看到容量，以及节点状态：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5ce8bed8502373190e4a9ca35461f2ef_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;220&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5ce8bed8502373190e4a9ca35461f2ef&quot; data-watermark-src=&quot;v2-3866522a4cc9ee73cea13be05dff5712&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;还能了解每个节点负载和 sql 执行的延时：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-88181e69d7396fbd0ecd51bb41aea539_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;175&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;当然还能了解所在机器上的位置，CPU 内存等负载情况：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d995c9bba949f576d89a4aa9c450bbe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;334&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4d995c9bba949f576d89a4aa9c450bbe&quot; data-watermark-src=&quot;v2-e4cb9a05aab6d255d3cb3239c88b18e6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;网络状态也能清晰的监控到：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e08520002a2e483e600ed5eb18d0e69_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;342&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-5e08520002a2e483e600ed5eb18d0e69&quot; data-watermark-src=&quot;v2-7923663063ef472ffbc3b4dc9a4cc89e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;所有这些能让团队能分析出来有问题的 sql，以及数据库本身的问题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 的接入过程，整体还是非常顺利的，由于之前做了很多接入的保障工作，当天切换流量到 TiDB 的过程只用了 10 分钟的时间，在此也要感谢 TiDB 对于 MySQL 语法的兼容性的支持，以及 PingCAP 提供的各种有用的工具。到目前为止，系统的稳定运行了一个多月，很好的满足了丰巢的业务需求。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的改造完成之后，丰巢推送服务对大部分消息进行了落地和查询，截止目前为止，推送服务最大的日落地量已经达到了 5 千万，而如果现在推送服务还使用的还是 MySQL 的方案，就需要上各种的分库分表方案，很多细致的业务就无法或者难以开展。&lt;/p&gt;&lt;p&gt;此次 TiDB 的改造，只是丰巢对于分布式数据技术探索的一小步，未来丰巢会将更多的分布式技术，引入到更多的业务系统，打造更加极致的产品和服务。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-12-49418382</guid>
<pubDate>Mon, 12 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 开源社区指南（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-09-49032099.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49032099&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cd7d9bab60939208425651627bac56f5_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/ed548ab735221a534cfc14702e4c8638&quot; data-hash=&quot;ed548ab735221a534cfc14702e4c8638&quot; data-hovercard=&quot;p$b$ed548ab735221a534cfc14702e4c8638&quot;&gt;@申砾&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;本系列文章旨在帮助社区开发者了解 TiDB 项目的全貌，更好的参与 TiDB 项目开发。大致会分两个角度进行描述：&lt;br&gt;1. 从社区参与者的角度描述如何更好的参与 TiDB 项目开发；&lt;br&gt;2. 从 PingCAP 内部团队的角度展示 TiDB 的开发流程，包括版本规划、开发流程、Roadmap 制定等。&lt;br&gt;希望通过一内一外两条线的描述，读者能在技术之外对 TiDB 有更全面的了解。本篇将聚焦在社区参与者的角度进行描述，也就是“外线”。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;了解 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;参与一个开源项目第一步总是了解它，特别是对 TiDB 这样一个大型的项目，了解的难度比较高，这里列出一些相关资料，帮助 newcomers 从架构设计到工程实现细节都能有所了解：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/docs#tidb-introduction&quot;&gt;Overview&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/blog/2016-10-17-how-we-build-tidb/&quot;&gt;How we build TiDB&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://tikv.github.io/deep-dive-tikv/book/&quot;&gt;Deep Dive TiKV (Work-In-Process)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，最高效地熟悉 TiDB 的方式还是使用它，在某些场景下遇到了问题或者是想要新的 feature，去跟踪代码，找到相关的代码逻辑，在这个过程中很容易对相关模块有了解，不少 Contributor 就是这样完成了第一次贡献。&lt;/p&gt;&lt;p&gt;我们还有一系列的 Infra Meetup，大约两周一次，如果方便到现场的同学可以听到这些高质量的 Talk。除了北京之外，其他的城市（上海、广州、成都、杭州）也开始组织 Meetup，方便更多的同学到现场来面基。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;发现可以参与的事情&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对 TiDB 有基本的了解之后，就可以选一个入手点。在 TiDB repo 中我们给一些简单的 issue 标记了 &lt;a href=&quot;https://github.com/pingcap/tidb/issues?q=is%3Aissue+is%3Aopen+label%3A%22for+new+contributors%22&quot;&gt;for-new-contributors &lt;/a&gt;标签，这些 issue 都是我们评估过容易上手的事情，可以以此为切入点。另外我们也会定期举行一些活动，把框架搭好，教程写好，新 Contributor 按照固定的模式即可完成某一特性开发。&lt;/p&gt;&lt;p&gt;当然除了那些标记为 for-new-contributors 的 issue 之外，也可以考虑其他的 issue，标记为 &lt;a href=&quot;https://github.com/pingcap/tidb/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22&quot;&gt;help-wanted &lt;/a&gt;标签的 issue 可以优先考虑。除此之外的 issue 可能会比较难解决，需要对 TiDB 有较深入的了解或者是对完成时间有较高的要求，不适合第一次参与的同学。&lt;/p&gt;&lt;p&gt;当然除了现有的 issue 之外，也欢迎将自己发现的问题或者是想要的特性提为新的 issue，然后自投自抢 :) 。&lt;/p&gt;&lt;p&gt;当你已经对 TiDB 有了深入的了解，那么可以尝试从 &lt;a href=&quot;https://github.com/pingcap/docs/blob/master/ROADMAP.md&quot;&gt;Roadmap &lt;/a&gt;上找到感兴趣的事项，和我们讨论一下如何参与。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;讨论方案&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;找到一个感兴趣的点之后，可以在 issue 中进行讨论，如果是一个小的 bug-fix 或者是小的功能点，可以简单讨论之后开工。即使再简单的问题，也建议先进行讨论，以免出现解决方案有问题或者是对问题的理解出了偏差，做了无用功。&lt;/p&gt;&lt;p&gt;但是如果要做的事情比较大，可以先写一个详细的设计文档，提交到 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/docs/design&quot;&gt;docs/design &lt;/a&gt;目录下面，这个目录下有设计模板以及一些已有的设计方案供你参考。一篇好的设计方案要写清楚以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;背景知识&lt;/li&gt;&lt;li&gt;解决什么问题&lt;/li&gt;&lt;li&gt;方案详细设计&lt;/li&gt;&lt;li&gt;对方案的解释说明，证明正确性和可行性&lt;/li&gt;&lt;li&gt;和现有系统的兼容性&lt;/li&gt;&lt;li&gt;方案的具体实现&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;用一句话来总结就是写清楚“你做了什么，为什么要做这个，怎么做的，为什么要这样做”。如果对自己的方案不太确定，可以先写一个 Google Doc，share 给我们简单评估一下，再提交 PR。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;提交 PR&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;按照方案完成代码编写后，就可以提交 PR。当然如果开发尚未完成，在某些情况下也可以先提交 PR，比如希望先让社区看一下大致的解决方案，这个时候请将 PR 标记为 WIP。&lt;br&gt;对于 PR 我们有一些要求：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;需要能通过 &lt;code class=&quot;inline&quot;&gt;make dev&lt;/code&gt; 的测试，跑过基本的单元测试；&lt;/li&gt;&lt;li&gt;必须有测试，除非只是改动文档或者是依赖包，其他情况需要有充足的理由说明没有测试的原因；&lt;/li&gt;&lt;li&gt;代码以及注释的质量需要足够高， &lt;a href=&quot;https://github.com/pingcap/community/blob/master/CONTRIBUTING.md#code-style&quot;&gt;这里 &lt;/a&gt;有一些关于编码风格和 commit message 的 guide；&lt;/li&gt;&lt;li&gt;请尽可能详细的填写 PR 的描述，并打上合适的 label。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;对于 PR 的描述，我们提供了一个模板，希望大家能够认真填写，一个好的描述能够加速 PR 的 review 过程。通过这个模板能够向 reviewers 以及社区讲明白：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;这个PR 解决什么问题：相关的问题描述或者是 issue 链接；&lt;/li&gt;&lt;li&gt;如何解决：具体的解决方法，reviewers 会根据这里的描述去看代码变动，所以请将这一段写的尽可能详细且有帮助；&lt;/li&gt;&lt;li&gt;测试的情况；&lt;/li&gt;&lt;li&gt;其他相关信息（如果需要）：benchmark 结果、兼容性问题、是否需要更新文档。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后再说几句测试，正确性是数据库安身立命之本，怎么强调测试都不为过。PR 中的测试不但需要充足，覆盖到所做的变动，还需要足够清晰，通过代码或者注释来表达测试的目的，帮助 reviewer 以及今后可能变动/破坏相关逻辑的人能够容易的理解这段测试。一段完善且清晰的测试也有利于让 reviewer 相信这个 Patch 是正确的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;PR review&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PR review 的过程就是 reviewer 不断地提出 comment，PR 作者持续解决 comment 的过程。&lt;br&gt;&lt;b&gt;每个 PR 在合并之前都需要至少得到两个 Committer/Maintainer 的 LGTM，一些重要的 PR 需要得到三个，比如对于 DDL 模块的修改，默认都需要得到三个 LGTM。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;Tips：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提了PR 之后，可以 at 一下相关的同学来 review&lt;/li&gt;&lt;li&gt;Address comment 之后可以 at 一下之前提过 comment 的同学，标准做法是 comment 一下 “ &lt;b&gt;PTAL @xxx&lt;/b&gt; ”，这样我们内部的 Slack 中可以得到通知，相关的同学会受到提醒，让整个流程更紧凑高效。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;与项目维护者之间的交流&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;目前标准的交流渠道是 GitHub issue&lt;/b&gt; ，请大家优先使用这个渠道，我们有专门的同学来维护这个渠道，其他渠道不能保证得到研发同学的及时回复。这也是开源项目的标准做法。&lt;br&gt;无论是遇到 bug、讨论具体某一功能如何做、提一些建议、产品使用中的疑惑，都可以来提 issue。在开发过程中遇到了问题，也可以在相关的 issue 中进行讨论，包括方案的设计、具体实现过程中遇到的问题等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后请大家注意一点，除了 pingcap/docs-cn 这个 repo 之外，请大家使用英文。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;更进一步&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当你完成上面这些步骤的之后，恭喜你已经跨过第一个门槛，正式进入了 TiDB 开源社区，开始参与 TiDB 项目开发，成为 &lt;b&gt;TiDB Contributor&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;如果想更进一步，深入了解 TiDB 的内部机制，掌握一个分布式数据库的核心模块，并能做出改进，那么可以了解更多的模块，提更多的 PR，进一步向 Committer 发展（ &lt;a href=&quot;https://github.com/pingcap/community/blob/master/become-a-committer.md&quot;&gt;这里 &lt;/a&gt;解释了什么是 Committer）。目前 TiDB 社区的 Committer 还非常少，我们希望今后能出现更多的 Committer 甚至是 Maintainer。&lt;/p&gt;&lt;p&gt;从 Contributor 到 Committer 的门槛比较高，比如今年的新晋 Committer 杜川同学，在成为 Committer 的道路上给 tidb/tikv 项目提交了大约 80 个 PR，并且对一些模块有非常深入的了解。当然，成为 Committer 之后，会有一定的权利，比如对一些 PR 点 LGTM 的权利，参加 PingCAP 内部的技术事项、开发规划讨论的权利，参加定期举办的 TechDay/DevCon 的权利。目前社区中还有几位贡献者正走在从 Contributor 到 Committer 的道路上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-09-49032099</guid>
<pubDate>Fri, 09 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 助力卡思数据视频大数据业务创新</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-11-06-48674946.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/48674946&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-632a19539faeb998a4f082d80f81c175_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;卡思数据是国内领先的视频全网数据开放平台，依托领先的数据挖掘与分析能力，为视频内容创作者在节目创作和用户运营方面提供数据支持，为广告主的广告投放提供数据参考和效果监测，为内容投资提供全面客观的价值评估。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07b63db2487756269fd6da9db5d051ce_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1594&quot; data-rawheight=&quot;753&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-07b63db2487756269fd6da9db5d051ce&quot; data-watermark-src=&quot;v2-69ee6da76a96003dff0ae2094e22aaef&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt; 图 1 卡思数据产品展示图&lt;/p&gt;&lt;h2&gt;&lt;b&gt;业务发展遇到的痛点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;卡思数据首先通过分布式爬虫系统进行数据抓取，每天新增数据量在 50G - 80G 之间，并且入库时间要求比较短，因此对数据库写入性能要求很高，由于数据增长比较快，对数据库的扩展性也有很高的要求。数据抓取完成后，对数据进行清洗和计算，因为数据量比较大，单表 5 亿 + 条数据，所以对数据库的查询性能要求很高。&lt;/p&gt;&lt;p&gt;起初卡思数据采用的是多个 MySQL 实例和一个 MongoDB 集群，如图 2。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;MySQL 存储业务相关数据，直接面向用户，对事务的要求很高，但在海量数据存储方面偏弱，由于单行较大，单表数据超过千万或 10G 性能就会急剧下降。&lt;/li&gt;&lt;li&gt;MongoDB 存储最小单元的数据，MongoDB 有更好的写入性能，保证了每天数据爬取存储速度；对海量数据存储上，MongoDB 内建的分片特性，可以很好的适应大数据量的需求。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-146fd37a7dbce48dd44ca485ffaaf630_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;777&quot; data-rawheight=&quot;330&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-146fd37a7dbce48dd44ca485ffaaf630&quot; data-watermark-src=&quot;v2-db7288bb62cc10adb9d3df1ba44def5c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 2 起初卡思数据架构图 &lt;/p&gt;&lt;p&gt;但是随着业务发展，暴露出一些问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;MySQL 在大数据量的场景下，查询性能难以满足要求，并且扩展能力偏弱，如果采用分库分表方式，需要对业务代码进行全面改造，成本非常高。&lt;/li&gt;&lt;li&gt;MongoDB 对复杂事务的不支持，前台业务需要用到数据元及连表查询，当前架构支持的不太友好。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;架构优化&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 需求&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对我们遇到的问题，我们急需这样一款数据库：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;兼容 MySQL 协议，数据迁移成本和代码改造成本低&lt;/li&gt;&lt;li&gt;插入性能强&lt;/li&gt;&lt;li&gt;大数据量下的实时查询性能强，无需分库分表&lt;/li&gt;&lt;li&gt;水平扩展能力强&lt;/li&gt;&lt;li&gt;稳定性强，产品最好有成熟的案例&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 方案调研&lt;/b&gt;&lt;/p&gt;&lt;p&gt;未选择 TiDB 之前我们调研了几个数据库，Greenplum、HybirdDB for MySQL（PetaData）以及 PolarDB。Greenplum 由于插入性能比较差，并且跟 MySQL 协议有一些不兼容，首先被排除。&lt;/p&gt;&lt;p&gt;HybirdDB for MySQL 是阿里云推出的 HTAP 关系型数据库，我们在试用一段时间发现一些问题：&lt;/p&gt;&lt;p&gt;一是复杂语句导致计算引擎拥堵，阻塞所有业务，经常出现查询超时的情况。&lt;/p&gt;&lt;p&gt;二是连表查询性能低下，网络 I/O 出现瓶颈。举一个常见的关联查询，cd_video 表，2200 万数据，cd_program_video 表，节目和视频的关联表，4700 万数据，在关联字段上都建有索引，如下 SQL：&lt;/p&gt;&lt;p&gt;select &lt;a href=&quot;http://v.id&quot;&gt;v.id&lt;/a&gt;,v.url,v.extra_id,v.title fromcd_video v join cd_program_video pv on &lt;a href=&quot;http://v.id&quot;&gt;v.id&lt;/a&gt; = pv.video_id where program_id =xxx；&lt;/p&gt;&lt;p&gt;当相同查询并发超过一定数量时，就会频繁报数据库计算资源不可用的错误。&lt;/p&gt;&lt;p&gt;三是 DDL 操作比较慢，该字段等操作基本需要几分钟，下发至节点后易出现死锁。&lt;/p&gt;&lt;p&gt;PolarDB 是阿里云新推出新一代关系型数据库，主要思想是计算和存储分离架构，使用共享存储技术。由于写入还是单点写入，插入性能有上限，未来我们的数据采集规模还会进一步提升，这有可能成为一个瓶颈。另外由于只有一个只读实例，在对大表进行并发查询时性能表现一般。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 选择 TiDB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在经历了痛苦的传统解决方案的折磨以及大量调研及对比后，卡思数据最终选择了 TiDB 作为数据仓库及业务数据库。&lt;/p&gt;&lt;p&gt;TiDB 结合了传统的 RDBMS 和 NoSQL 的最佳特性，高度兼容 MySQL，具备强一致性和高可用性，100% 支持标准的 ACID 事务。由于是 Cloud Native 数据库，可通过并行计算发挥机器性能，在大数量的查询下性能表现良好，并且支持无限的水平扩展，可以很方便的通过加机器解决性能和容量问题。另外提供了非常完善的运维工具，大大减轻数据库的运维工作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;上线 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;卡思数据目前配置了两个 32C64G 的 TiDB、三个 4C16G 的 PD、四个 32C128G 的 TiKV。数据量大约 60 亿条、4TB 左右，每天新增数据量大约 5000 万，单节点 QPS 峰值为 3000 左右。&lt;/p&gt;&lt;p&gt;由于数据迁移不能影响线上业务，卡思数据在保持继续使用原数据架构的前提下，使用 Mydumper、Loader 进行数据迁移，并在首轮数据迁移完成后使用 Syncer 进行增量同步。&lt;/p&gt;&lt;p&gt;卡思数据部署了数据库监控系统（Prometheus/Grafana）来实时监控服务状态，可以非常清晰的查看服务器问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;由于 TiDB 对 MySQL 的高度兼容性，在数据迁移完成后，几乎没有对代码做任何修改，平滑实现了无侵入升级。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前卡思数据的架构如图 3：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fac44545432ecf26d884a7440c333c9f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;794&quot; data-rawheight=&quot;606&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fac44545432ecf26d884a7440c333c9f&quot; data-watermark-src=&quot;v2-75128212ab54ea15dc91b47a7cce596d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 3 目前卡思数据架构图&lt;/p&gt;&lt;p&gt;查询性能，单表最小 1000 万，最大 8 亿，有比较复杂的连表查询，整体响应延时非常稳定，监控展示如图 4、图 5。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-54d64dec60af44a379f55b6ff9b4ab84_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;279&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-54d64dec60af44a379f55b6ff9b4ab84&quot; data-watermark-src=&quot;v2-5c0d79b3b7dfa1bd50565bca3bc4dbe0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;图 4 Duration 监控展示图&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0ac9b8d8cd9b6de67cac4a3540531b85_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;244&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0ac9b8d8cd9b6de67cac4a3540531b85&quot; data-watermark-src=&quot;v2-a700f65ed736c50ffbc6ad1db8695976&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt; 图 5 QPS 监控展示图&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前的卡思数据已全部迁移至 TiDB，但对 TiDB 的使用还局限在数据存储上，可以说只实现了 OLTP。卡思数据准备深入了解 OLAP，将目前一些需要实时返回的复杂查询、数据分析下推至 TiDB。既减少计算服务的复杂性，又可增加数据的准确性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;感谢 PingCAP&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;非常感谢 PingCAP 小伙伴们在数据库上线过程中的大力支持，每次遇到困难都能及时、细心的给予指导，非常的专业和热心。相信 PingCAP 会越来越好，相信 TiDB 会越来越完善，引领 NewSQL 的发展。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者：刘广信，火星文化技术经理&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-11-06-48674946</guid>
<pubDate>Tue, 06 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP University · TiDB DBA 官方培训认证计划正式启动</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-31-48098540.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/48098540&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5ac8300d301ef25f49a6b0a7c71d25c4_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;伴随着产品的成熟，TiDB 在越来越多样化的应用场景中落地。在落地过程中，大家遇到问题会寻求官方的答疑和支持，但由于咨询量很大，我们有时无法及时响应。因此，为了赋能社区，提升社区用户满意度，避免因测试用户过多官方无法及时响应的问题，同时打造活跃的 TiDB 技术社区，培养熟悉分布式系统、能独立运维 TiDB 的一流 NewSQL 人才，我们宣布正式成立 &lt;b&gt;PingCAP University。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP University 是 PingCAP 官方设立的对企业和个人进行 TiDB 全线产品培训并认证的部门，其培训讲师团队由来自 PingCAP 官方的资深解决方案架构师、顶尖核心技术研发工程师和高级资深 TiDB DBA 组成，拥有丰富且专业的 TiDB 实践经验和培训经验。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PingCAP University 也在今天正式启动 TiDB DBA 官方培训认证计划。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;通过该培训认证计划，大家可以：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;深度理解 TiDB 架构、原理及最佳实践，具备独立部署、运维和调优 TiDB 的能力&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;提升分布式计算和存储领域的技术前沿视野&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;获得来自 PingCAP 官方的专业技术能力认可，提升个人技术竞争力&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-858843cb89a7ec10d45813c33fc89c29_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;577&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-858843cb89a7ec10d45813c33fc89c29&quot; data-watermark-src=&quot;v2-3e1a2a03a88a23033b9da7cb77327d76&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;培训特色&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;理论与实践结合，强调动手能力（实践超过 50%），提供累计 4 个半天实战&lt;/li&gt;&lt;li&gt;课程滚动更新，包含大量前沿技术解读及实践分享&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB DBA 官方培训认证总览&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;初级 TiDB DBA&lt;/b&gt;：PCTA（PingCAP Certified TiDB Associate）培训及认证&lt;/li&gt;&lt;li&gt;&lt;b&gt;高级 TiDB DBA&lt;/b&gt;：PCTP（PingCAP Certified TiDB Professional） 培训及认证&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-092ade55e28a33bfb8fc788fd4eb1575_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1032&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-092ade55e28a33bfb8fc788fd4eb1575&quot; data-watermark-src=&quot;v2-ebfab4252b3e30025bc0343616c46173&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;培训及考试安排&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PCTA：线上培训及考试&lt;/li&gt;&lt;li&gt;PCTP：线下小班集中培训及考试，时间地点由 PingCAP 统一安排&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;垂询及报名方式&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;点击 &lt;a href=&quot;http://pingcaptidb.mikecrm.com/KXCarRw&quot;&gt;这里&lt;/a&gt; 直接填写报名信息&lt;/li&gt;&lt;li&gt;或联系您的客户总监&lt;/li&gt;&lt;li&gt;或发送邮件至 university-cn@pingcap.com 交流&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;P.S. 2018 年 11 月 30 日前报名还有&lt;b&gt;【官方技术支持服务礼包】&lt;/b&gt;赠送～&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-31-48098540</guid>
<pubDate>Wed, 31 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（二十）Table Partition</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-29-47909702.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47909702&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8606678fbae32d086cdd5e3df15b0beb_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：肖亮亮&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Table Partition&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;什么是 Table Partition&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Table Partition 是指根据一定规则，将数据库中的一张表分解成多个更小的容易管理的部分。从逻辑上看只有一张表，但是底层却是由多个物理分区组成。相信对有关系型数据库使用背景的用户来说可能并不陌生。&lt;/p&gt;&lt;p&gt;TiDB 正在支持分区表这一特性。在 TiDB 中分区表是一个独立的逻辑表，但是底层由多个物理子表组成。物理子表其实就是普通的表，数据按照一定的规则划分到不同的物理子表类内。程序读写的时候操作的还是逻辑表名字，TiDB 服务器自动去操作分区的数据。&lt;br&gt;分区表有什么好处？&lt;/p&gt;&lt;ol&gt;&lt;li&gt;优化器可以使用分区信息做分区裁剪。在语句中包含分区条件时，可以只扫描一个或多个分区表来提高查询效率。&lt;/li&gt;&lt;li&gt;方便地进行数据生命周期管理。通过创建、删除分区、将过期的数据进行 高效的归档，比使用 Delete 语句删除数据更加优雅，打散写入热点，将一个表的写入分散到多个物理表，使得负载分散开，对于存在 Sequence 类型数据的表来说（比如 Auto Increament ID 或者是 create time 这类的索引）可以显著地提升写入吞吐。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;分区表的限制&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;TiDB 默认一个表最多只能有 1024 个分区 ，默认是不区分表名大小写的。&lt;/li&gt;&lt;li&gt;Range, List, Hash 分区要求分区键必须是 INT 类型，或者通过表达式返回 INT 类型。但 Key 分区的时候，可以使用其他类型的列（BLOB，TEXT 类型除外）作为分区键。&lt;/li&gt;&lt;li&gt;如果分区字段中有主键或者唯一索引的列，那么有主键列和唯一索引的列都必须包含进来。即：分区字段要么不包含主键或者索引列，要么包含全部主键和索引列。&lt;/li&gt;&lt;li&gt;TiDB 的分区适用于一个表的所有数据和索引。不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表数据分区，也不能只对表的一部分数据分区。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;常见分区表的类型&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Range 分区：按照分区表达式的范围来划分分区。通常用于对分区键需要按照范围的查询，分区表达式可以为列名或者表达式 ，下面的 employees 表当中 p0, p1, p2, p3 表示 Range 的访问分别是  (min, 1991), [1991, 1996), [1996, 2001), [2001, max) 这样一个范围。&lt;/li&gt;&lt;/ul&gt;&lt;code lang=&quot;text&quot;&gt;
CREATE  TABLE employees (
id INT  NOT  NULL,
fname VARCHAR(30),
separated DATE  NOT  NULL
)
    
PARTITION BY RANGE ( YEAR(separated) ) (
PARTITION p0 VALUES LESS THAN (1991),
PARTITION p1 VALUES LESS THAN (1996),
PARTITION p2 VALUES LESS THAN (2001),
PARTITION p3 VALUES LESS THAN MAXVALUE
);&lt;/code&gt;&lt;ul&gt;&lt;li&gt;List 分区：按照 List 中的值分区，主要用于枚举类型，与 Range 分区的区别在于 Range 分区的区间范围值是连续的。&lt;/li&gt;&lt;li&gt;Hash 分区：Hash 分区需要指定分区键和分区个数。通过 Hash 的分区表达式计算得到一个 INT 类型的结果，这个结果再跟分区个数取模得到具体这行数据属于那个分区。通常用于给定分区键的点查询，Hash 分区主要用来分散热点读，确保数据在预先确定个数的分区中尽可能平均分布。&lt;/li&gt;&lt;li&gt;Key 分区：类似 Hash 分区，Hash 分区允许使用用户自定义的表达式，但 Key 分区不允许使用用户自定义的表达式。Hash 仅支持整数分区，而 Key 分区支持除了 Blob 和 Text 的其他类型的列作为分区键。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB Table Partition 的实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文接下来按照 TiDB 源码的 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/release-2.1&quot;&gt;release-2.1 &lt;/a&gt;分支讲解，部分讲解会在 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/source-code&quot;&gt;source-code &lt;/a&gt;分支代码，目前只支持 Range 分区所以这里只介绍 Range 类型分区 Table Partition 的源码实现，包括 create table、select 、add partition、insert 、drop partition 这五种语句。&lt;/p&gt;&lt;p&gt;&lt;b&gt;create table&lt;/b&gt;&lt;/p&gt;&lt;p&gt;create table 会重点讲构建 Partition 的这部分，更详细的可以看 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-17/&quot;&gt;TiDB 源码阅读系列文章（十七）DDL 源码解析 &lt;/a&gt;，当用户执行创建分区表的SQL语句，语法解析（Parser）阶段会把 SQL 语句中 Partition 相关信息转换成 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ast/ddl.go&quot;&gt;ast.PartitionOptions &lt;/a&gt;，下文会介绍。接下来会做一系列 Check，分区名在当前的分区表中是否唯一、是否分区 Range 的值保持递增、如果分区键构成为表达式检查表达式里面是否是允许的函数、检查分区键必须是 INT 类型，或者通过表达式返回 INT 类型、检查分区键是否符合一些约束。&lt;/p&gt;&lt;p&gt;解释下分区键，在分区表中用于计算这一行数据属于哪一个分区的列的集合叫做分区键。分区键构成可能是一个字段或多个字段也可以是表达式。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// PartitionOptions specifies the partition options.
type PartitionOptions struct {
Tp          model.PartitionType
Expr        ExprNode
ColumnNames []*ColumnName
Definitions []*PartitionDefinition
}
	​
// PartitionDefinition defines a single partition.
type PartitionDefinition struct {
Name     model.CIStr
LessThan []ExprNode
MaxValue bool
Comment  string
}&lt;/code&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;PartitionOptions&lt;/code&gt; 结构中 Tp 字段表示分区类型， &lt;code class=&quot;inline&quot;&gt;Expr&lt;/code&gt; 字段表示分区键， &lt;code class=&quot;inline&quot;&gt;ColumnNames&lt;/code&gt; 字段表示 Columns 分区，这种类型分区有分为 Range columns 分区和 List columns 分区，这种分区目前先不展开介绍。 &lt;code class=&quot;inline&quot;&gt;PartitionDefinition&lt;/code&gt; 其中 Name 字段表示分区名， &lt;code class=&quot;inline&quot;&gt;LessThan&lt;/code&gt; 表示分区 Range 值， &lt;code class=&quot;inline&quot;&gt;MaxValue&lt;/code&gt; 字段表示 Range 值是否为最大值， &lt;code class=&quot;inline&quot;&gt;Comment&lt;/code&gt; 字段表示分区的描述。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/ddl_api.go#L905&quot;&gt;CreateTable &lt;/a&gt;Partition 部分主要流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;把上文提到语法解析阶段会把 SQL语句中 Partition 相关信息转换成 &lt;code class=&quot;inline&quot;&gt;ast.PartitionOptions&lt;/code&gt; , 然后 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L41&quot;&gt;buildTablePartitionInfo &lt;/a&gt;负责把&lt;code class=&quot;inline&quot;&gt;PartitionOptions&lt;/code&gt; 结构转换 &lt;code class=&quot;inline&quot;&gt;PartitionInfo&lt;/code&gt; ,  即 Partition 的元信息。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L88&quot;&gt;checkPartitionNameUnique &lt;/a&gt;检查分区名是否重复，分表名是不区大小写的。&lt;/li&gt;&lt;li&gt;对于每一分区 Range 值进行 Check， &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/table.go#L469&quot;&gt;checkAddPartitionValue &lt;/a&gt;就是检查新增的 Partition 的 Range 需要比之前所有 Partition 的 Range 都更大。&lt;/li&gt;&lt;li&gt;TiDB 单表最多只能有 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L329&quot;&gt;1024 个分区 &lt;/a&gt;，超过最大分区的限制不会创建成功。&lt;/li&gt;&lt;li&gt;如果分区键构成是一个包含函数的表达式需要检查表达式里面是否是允许的函数 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L107&quot;&gt;checkPartitionFuncValid &lt;/a&gt;。&lt;/li&gt;&lt;li&gt;检查分区键必须是 INT 类型，或者通过表达式返回 INT 类型，同时检查分区键中的字段在表中是否存在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L149&quot;&gt;checkPartitionFuncType &lt;/a&gt;。&lt;/li&gt;&lt;li&gt;如果分区字段中有主键或者唯一索引的列，那么多有主键列和唯一索引列都必须包含进来。即：分区字段要么不包含主键或者索引列，要么包含全部主键和索引列 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L348&quot;&gt;checkRangePartitioningKeysConstraints &lt;/a&gt;。&lt;/li&gt;&lt;li&gt;通过以上对 &lt;code class=&quot;inline&quot;&gt;PartitionInfo&lt;/code&gt; 的一系列 check 主要流程就讲完了，需要注意的是我们没有对 &lt;code class=&quot;inline&quot;&gt;PartitionInfo&lt;/code&gt; 的元数据持久化单独存储而是附加在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/model/model.go#L142&quot;&gt;TableInfo &lt;/a&gt;Partition 中。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;add partition&lt;/b&gt;&lt;/p&gt;&lt;p&gt;add partition 首先需要从 SQL 中解析出来 Partition 的元信息，然后对当前添加的分区会有一些 Check 和限制，主要检查是否是分区表、分区名是已存在、最大分区数限制、是否 Range 值保持递增，最后把 Partition 的元信息 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/model/model.go#L308&quot;&gt;PartitionInfo &lt;/a&gt;追加到 Table 的元信息 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/model/model.go#L142&quot;&gt;TableInfo &lt;/a&gt;中，具体如下:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;检查是否是分区表，若不是分区表则报错提示。&lt;/li&gt;&lt;li&gt;用户的 SQL 语句被解析成将 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ast/ddl.go#L880&quot;&gt;ast.PartitionDefinition &lt;/a&gt;然后 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/ddl_api.go#L2123&quot;&gt;buildPartitionInfo &lt;/a&gt;做的事就是保存表原来已存在的分区信息例如分区类型，分区键，分区具体信息，每个新分区分配一个独立的 PartitionID。&lt;/li&gt;&lt;li&gt;TiDB 默认一个表最多只能有 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L329&quot;&gt;1024 个分区 &lt;/a&gt;，超过最大分区的限制会报错&lt;/li&gt;&lt;li&gt;对于每新增一个分区需要检查 Range 值进行 Check， &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/table.go#L469&quot;&gt;checkAddPartitionValue &lt;/a&gt;简单说就是检查新增的 Partition 的 Range 需要比之前所有 Partition 的 Rrange 都更大。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L88&quot;&gt;checkPartitionNameUnique &lt;/a&gt;检查分区名是否重复，分表名是不区大小写的。&lt;/li&gt;&lt;li&gt;最后把 Partition 的元信息 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/model/model.go#L308&quot;&gt;PartitionInfo &lt;/a&gt;追加到 Table 的元信息 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/model/model.go#L142&quot;&gt;TableInfo &lt;/a&gt;.Partition 中，具体实现在这里 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/table.go#L459&quot;&gt;updatePartitionInfo &lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;drop partition&lt;/b&gt;&lt;/p&gt;&lt;p&gt;drop partition 和 drop table 类似，只不过需要先找到对应的 Partition ID，然后删除对应的数据，以及修改对应 Table 的 Partition 元信息，两者区别是如果是 drop table 则删除整个表数据和表的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/model/model.go#L142&quot;&gt;TableInfo &lt;/a&gt;元信息，如果是 drop partition 则需删除对应分区数据和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/model/model.go#L142&quot;&gt;TableInfo &lt;/a&gt;中的 Partition 元信息，删除分区之前会有一些 Check 具体如下:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;只能对分区表做 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/ddl_api.go#L1355&quot;&gt;drop partition 操作 &lt;/a&gt;，若不是分区表则报错提示。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L269&quot;&gt;checkDropTablePartition &lt;/a&gt;检查删除的分区是否存在，TiDB 默认是不能删除所有分区，如果想删除最后一个分区，要用 drop table 代替。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L283&quot;&gt;removePartitionInfo &lt;/a&gt;会把要删除的分区从 Partition 元信息删除掉，删除前会做 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/partition.go#L269&quot;&gt;checkDropTablePartition &lt;/a&gt;的检查。&lt;/li&gt;&lt;li&gt;对分区表数据则需要拿到 PartitionID 根据插入数据时候的编码规则构造出 StartKey 和 EndKey 便能包含对应分区 Range 内所有的数据，然后把这个范围内的数据删除，具体代码实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/ddl/delete_range.go#L250&quot;&gt;这里 &lt;/a&gt;。&lt;/li&gt;&lt;li&gt;编码规则：&lt;br&gt;Key： &lt;code class=&quot;inline&quot;&gt;tablePrefix_rowPrefix_partitionID_rowID&lt;/code&gt;&lt;br&gt;startKey： &lt;code class=&quot;inline&quot;&gt;tablePrefix_rowPrefix_partitionID&lt;/code&gt;&lt;br&gt;endKey： &lt;code class=&quot;inline&quot;&gt;tablePrefix_rowPrefix_partitionID + 1&lt;/code&gt; &lt;/li&gt;&lt;li&gt;删除了分区，同时也将删除该分区中的所有数据。如果删除了分区导致分区不能覆盖所有值，那么插入数据的时候会报错。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;Select 语句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Select 语句重点讲 Select Partition 如何查询的和分区裁剪（Partition Pruning），更详细的可以看 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-6/&quot;&gt;TiDB 源码阅读系列文章（六）Select 语句概览 &lt;/a&gt;。&lt;/p&gt;&lt;p&gt;一条 SQL 语句的处理流程，从 Client 接收数据，MySQL 协议解析和转换，SQL 语法解析，逻辑查询计划和物理查询计划执行，到最后返回结果。那么对于分区表是如何查询的表里的数据的，其实最主要的修改是 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/planner/core/rule_partition_processor.go#L39&quot;&gt;逻辑查询计划 &lt;/a&gt;阶段，举个例子：如果用上文中 employees 表作查询, 在 SQL 语句的处理流程前几个阶段没什么不同，但是在逻辑查询计划阶段， &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/planner/core/rule_partition_processor.go#L46&quot;&gt;rewriteDataSource &lt;/a&gt;将 DataSource 重写了变成 Union All 。每个 Partition id 对应一个 Table Reader。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select * from employees&lt;/code&gt;&lt;p&gt;等价于：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;select * from (union all
select * from p0 where id &amp;lt; 1991
select * from p1 where id &amp;lt; 1996
select * from p2 where id &amp;lt; 2001
select * from p3 where id &amp;lt; MAXVALUE)&lt;/code&gt;&lt;p&gt;通过观察 &lt;code class=&quot;inline&quot;&gt;EXPLAIN&lt;/code&gt; 的结果可以证实上面的例子，如图 1，最终物理执行计划中有四个 Table Reader 因为 employees 表中有四个分区， &lt;code class=&quot;inline&quot;&gt;Table Reader&lt;/code&gt; 表示在 TiDB 端从 TiKV 端读取， &lt;code class=&quot;inline&quot;&gt;cop task&lt;/code&gt; 是指被下推到 TiKV 端分布式执行的计算任务。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4b7fc3aa7830e5350b4a4ae2b6df58e9_r.jpg&quot; data-caption=&quot;图 1：EXPLAIN 输出&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;379&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4b7fc3aa7830e5350b4a4ae2b6df58e9&quot; data-watermark-src=&quot;v2-f631b41e76235890b1fd41fdaf5157b0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;用户在使用分区表时，往往只需要访问其中部分的分区, 就像程序局部性原理一样，优化器分析 &lt;code class=&quot;inline&quot;&gt;FROM&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;WHERE&lt;/code&gt; 子句来消除不必要的分区，具体还要优化器根据实际的 SQL 语句中所带的条件，避免访问无关分区的优化过程我们称之为分区裁剪（Partition Pruning），具体实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/planner/core/rule_partition_processor.go#L70&quot;&gt;这里 &lt;/a&gt;，分区裁剪是分区表提供的重要优化手段，通过分区的裁剪，避免访问无关数据，可以加速查询速度。当然用户可以刻意利用分区裁剪的特性在 SQL 加入定位分区的条件，优化查询性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Insert 语句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-4/&quot;&gt;Insert 语句 &lt;/a&gt;是怎么样写入 Table Partition ?&lt;/p&gt;&lt;p&gt;其实解释这些问题就可以了：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;普通表和分区表怎么区分？&lt;/li&gt;&lt;li&gt;插入数据应该插入哪个 Partition？&lt;/li&gt;&lt;li&gt;每个 Partition 的 RowKey 怎么编码的和普通表的区别是什么？&lt;/li&gt;&lt;li&gt;怎么将数据插入到相应的 Partition 里面?&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;普通 Table 和 Table Partition 也是实现了 Table 的接口，load schema 在初始化 Table 数据结构的时候，如果发现 &lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt; 里面没有 Partition 信息，则生成一个普通的 &lt;code class=&quot;inline&quot;&gt;tables.Table&lt;/code&gt; ，普通的 Table 跟以前处理逻辑保持不变，如果 &lt;code class=&quot;inline&quot;&gt;tableInfo&lt;/code&gt; 里面有 Partition 信息，则会生成一个&lt;code class=&quot;inline&quot;&gt;tables.PartitionedTable&lt;/code&gt; ，它们的区别是 RowKey 的编码方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每个分区有一个独立的 Partition ID，Partition ID 和 Table ID 地位平等，每个 Partition 的 Row 和 index 在编码的时候都使用这个 Partition 的 ID。&lt;/li&gt;&lt;li&gt;下面是 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/table/tables/partition.go#L171&quot;&gt;PartitionRecordKey &lt;/a&gt;和普通表 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/table/tables/tables.go#L261&quot;&gt;RecordKey &lt;/a&gt;区别。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; (1) 分区表按照规则编码成 Key-Value pair：&lt;/p&gt;&lt;p&gt;        Key: &lt;code class=&quot;inline&quot;&gt;tablePrefix_rowPrefix_partitionID_rowID&lt;/code&gt;&lt;br&gt;        Value: &lt;code class=&quot;inline&quot;&gt;[col1, col2, col3, col4]&lt;/code&gt; &lt;/p&gt;&lt;p&gt;(2) 普通表按照规则编码成 Key-Value pair：&lt;/p&gt;&lt;p&gt;        Key: &lt;code class=&quot;inline&quot;&gt;tablePrefix_rowPrefix_tableID_rowID&lt;/code&gt;&lt;br&gt;        Value: &lt;code class=&quot;inline&quot;&gt;[col1, col2, col3, col4]&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/table/tables/partition.go#L177&quot;&gt;locatePartition &lt;/a&gt;操作查询到应该插入哪个 Partition，目前支持 RANGE 分区插入到那个分区主要是通过范围来判断，例如在 employees 表中插入下面的 sql，通过计算范围该条记录会插入到 p3 分区中，接着调用对应 Partition 上面的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/release-2.1/table/tables/tables.go#L406&quot;&gt;AddRecord &lt;/a&gt;方法，将数据插入到相应的 Partition 里面。&lt;/li&gt;&lt;/ul&gt;&lt;code lang=&quot;text&quot;&gt;INSERT INTO employees VALUES (1, &#39;PingCAP TiDB&#39;, &#39;2003-10-15&#39;),&lt;/code&gt;&lt;ul&gt;&lt;li&gt;插入数据时，如果某行数据不属于任何 Partition，则该事务失败，所有操作回滚。如果 Partition 的 Key 算出来是一个 &lt;code class=&quot;inline&quot;&gt;NULL&lt;/code&gt; ，对于不同的 Partition 类型有不同的处理方式：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;对于 Range Partition：该行数据被插入到最小的那个 Partition&lt;/li&gt;&lt;li&gt;对于 List partition：如果某个 Partition 的 Value List 中有 &lt;code class=&quot;inline&quot;&gt;NULL&lt;/code&gt; ，该行数据被插入那个 Partition，否则插入失败&lt;/li&gt;&lt;li&gt;对于 Hash 和 Key Partition： &lt;code class=&quot;inline&quot;&gt;NULL&lt;/code&gt; 值视为 0，计算 Partition ID 将数据插入到对应的 Partition&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;在 TiDB 分区表中分区字段插入的值不能大于表中 Range 值最大的上界，否则会报错&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;End&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 目前支持 Range 分区类型，具体以及更细节的可以看 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/source-code&quot;&gt;这里 &lt;/a&gt;。剩余其它类型的分区类型正在开发中，后面陆续会和大家见面，敬请期待。它们的源码实现读者届时可以自行阅读，流程和文中上述描述类似。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-29-47909702</guid>
<pubDate>Mon, 29 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>我们要做点更酷的事情，来场 Hackathon 怎么样？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-25-47610023.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47610023&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7370ffeb0809ae9bdc74ea11bbe3c1b1_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;i&gt;1024 程序员节，&lt;/i&gt;&lt;br&gt;&lt;i&gt;总把我们标签化为格子衬衫和后退的发际线（很烦啊。。）&lt;/i&gt;&lt;br&gt;&lt;i&gt;发张堆满编程语言名称的图片表示尊重（好吧。。）&lt;/i&gt;&lt;br&gt;&lt;i&gt;我们自己的节日，我们有自己的更酷的玩儿法——&lt;/i&gt;&lt;br&gt;&lt;b&gt;&lt;i&gt;报名一场 Hackathon，怎么样？&lt;/i&gt;&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB Hackathon2018&lt;/b&gt; &lt;b&gt;将于 12 月 1 - 2 日在 PingCAP 北京总部举办。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本场 Hackathon &lt;b&gt;主题为 TiDB Ecosystem&lt;/b&gt;，参赛团队将在两天一夜的时间里完成一个作品，当然我们也欢迎个人开发者独立报名参赛～ 我司 Co-Founder、首席架构师、技术 VP 等 &lt;b&gt;「PingCAP 大神」将担任导师团，手把手带练，&lt;/b&gt;更邀请了&lt;b&gt;业内大牛评审团&lt;/b&gt; 对每个小组的作品进行打分，获胜队伍将得到&lt;b&gt;丰厚现金奖励和面试直通车&lt;/b&gt;的机会。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;奖项设置&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一等奖（1 支队伍）：   ¥ 60,000 现金奖励 &lt;/p&gt;&lt;p&gt;二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;对于现场表现突出的小伙伴，我们也设置了最佳创意奖和最佳贡献奖哦～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;选题方向&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;参赛作品需围绕 TiDB 及其周边生态实现，选题不限。我们有以下选题方向供小伙伴们参考：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 数据可视化，基于异地多机房部署全局视图等&lt;/li&gt;&lt;li&gt;执行计划可视化（explain 的输出生成图，对于 expensive 的步骤在图中高亮，统计信息的图形化展示，比如 histogram）&lt;/li&gt;&lt;li&gt;TiKV 潜在瓶颈分析，cost 量化分析工具（可以结合 wPerf 论文，应用到我们的项目中，发现潜在的环以及锁依赖之类的。甚至对于每个 query 的 cost 进行量化，比如导致的每个线程 cpu circle 消耗、context switch 次数，cache miss 情况等等）&lt;/li&gt;&lt;li&gt;玩转 TiKV，集成其它一些引擎接口，如 Redis&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你有更多脑洞大开的选题，想为 TiDB 做一些更好玩儿的周边工具，可以在报名之后与 &lt;b&gt;TiDB Robot（微信号：tidbai）&lt;/b&gt;沟通交流，小伙伴们也可以自由组队报名（每支队伍不超过 3 人），我们会进行审核～另外，暂时没有队伍和选题意向的同学可以在报名后与 TiDB Robot 联系组队。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参考资料&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;源码地址：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/&quot;&gt;https://github.com/pingcap/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tikv/&quot;&gt;https://github.com/tikv/&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;官方文档&lt;/b&gt;：&lt;a href=&quot;https://pingcap.com/docs-cn/&quot;&gt;https://pingcap.com/docs-cn/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;技术博客&lt;/b&gt;：&lt;a href=&quot;https://pingcap.com/blog-cn/&quot;&gt;https://pingcap.com/blog-cn/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参赛 Tips&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;比赛时间&lt;/b&gt;：12 月 1 日 10:00  - 12 月 2 日 18:00&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名时间&lt;/b&gt;：即日起至 11 月 23 日 17:00&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名审核&lt;/b&gt;：5 个工作日内反馈审核结果&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名链接&lt;/b&gt;：点击 &lt;a href=&quot;http://nc9hsk15y2xczuor.mikecrm.com/3AarNns&quot;&gt;这里&lt;/a&gt; 报名&lt;br&gt;&lt;br&gt;* 本次大赛诚招志愿者参与活动现场支持。如果你想近距离接触技术大咖，体验大赛氛围，那就联系 TiDB Robot（微信号：tidbai）报名吧～志愿者也可以获得活动定制纪念品哦！&lt;br&gt;* 详细比赛日程请关注近期官方微信公号（ID: PingCAP）推送&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/0zhMVPLEUq8trbY3923B (二维码自动识别)&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-25-47610023</guid>
<pubDate>Thu, 25 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>一致性模型</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-23-47445841.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47445841&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c8b584a8186554d98b4bb5442eeeafcd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘（siddontang）&lt;/p&gt;&lt;p&gt;有时候，在跟一些同学讨论 TiKV 事务模型的时候，我都提到了 Linearizability，也提到了 Snapshot Isolation，以及需要手动 lock 来保证 Serializable Snapshot Isolation，很多时候，当我嘴里面蹦出来这些名词的时候，有些同学就一脸懵逼了。所以我觉得有必要仔细来解释一下，顺带让我自己将所有的 isolation 以及 consistency 这些情况都归纳总结一遍，让自己也理解透彻一点。&lt;/p&gt;&lt;p&gt;幸运的是，业内已经有很多人做了这个事情，譬如在 &lt;a href=&quot;http://www.vldb.org/pvldb/vol7/p181-bailis.pdf&quot;&gt;Highly Available Transactions: Virtues and Limitations&lt;/a&gt; 这篇论文里面，作者就总结了不同模型是否能满足 Highly Available Transactions(HATs)。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-38087fea60b99e9c2e34a151c1cd6a08_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;258&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-38087fea60b99e9c2e34a151c1cd6a08&quot; data-watermark-src=&quot;v2-7ee2fd316c00de39dcf3b26620cce6a0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;图中，红色圆圈里面的模型属于 Unavailable，蓝色的属于 Sticky Available，其余的就是  Highly Available。这里解释下相关的含义：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Unavailable：当出现网络隔离等问题的时候，为了保证数据的一致性，不提供服务。熟悉 CAP 理论的同学应该清楚，这就是典型的 CP 系统了。&lt;/li&gt;&lt;li&gt;Sticky Available：即使一些节点出现问题，在一些还没出现故障的节点，仍然保证可用，但需要保证 client 的操作是一致的。&lt;/li&gt;&lt;li&gt;Highly Available：就是网络全挂掉，在没有出现问题的节点上面，仍然可用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Unavailable 比较容易理解，这里在讨论下 Sticky 和 Highly，对于 Highly Available 来说，如果一个 server 挂掉了，client 可以去连接任意的其他 server，如果这时候仍然能获取到结果，那么就是 Highly Available 的。但对于 Sticky 来说，还需要保证 client 操作的一致性，譬如 client 现在 server 1 上面进行了很多操作，这时候 server 1 挂掉了，client 切换到 server 2，但在 server 2 上面看不到 client 之前的操作结果，那么这个系统就不是 Sticky 的。所有能在 Highly Available 系统上面保证的事情一定也能在 Sticky Available 系统上面保证，但反过来就不一定了。&lt;/p&gt;&lt;p&gt;Jepsen 在&lt;a href=&quot;https://jepsen.io/consistency&quot;&gt;官网&lt;/a&gt;上面有一个简化但更好看一点的图&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb3847f8b9e69b1154cfdf6591af0202_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bb3847f8b9e69b1154cfdf6591af0202&quot; data-watermark-src=&quot;v2-706a307a3c684b7713aa678335b0baa9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;下面，我会按照 Jepsen 里面的图，对不同的 model 进行解释一下。至于为啥选择 Jepsen 里面的例子，一个是因为 Jepsen 现在是一款主流的测试不同分布式系统一致性的工具，它的测试用例就是测试的是上图提到的模型，我们自然也会关心这些模型。另外一个就是这个模型已经覆盖了大多数场景了，理解了这些，大部分都能游刃有余处理了。&lt;/p&gt;&lt;p&gt;如果大家仔细观察，可以发现，从根节点 Strict Serializable，其实是有两个分支的，一个对应的就是数据库里面的 Isolation（ACID 里面的 I），另一个其实对应的是分布式系统的 Consistency（CAP 里面的 C），在 HATs 里面，叫做 Session Guarantees。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Isolation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;要对 Isolation 有个快速的理解，其实只需要看 &lt;a href=&quot;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf&quot;&gt;A Critique of ANSI SQL Isolation Levels&lt;/a&gt; 这篇论文就足够了，里面详细的介绍了数据库实现中遇到的各种各样的 isolation 问题，以及不同的 isolation level 到底能不能解决。&lt;/p&gt;&lt;p&gt;在论文里面，作者详细的列举了多种异常现象，这里大概介绍一下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P0 - Dirty Write&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Dirty Write 就是一个事务，覆盖了另一个之前还未提交事务写入的值。假设现在我们有两个事务，一个事务写入 x = y = 1，而另一个事务写入 x = y = 2，那么最终的结果，我们是希望看到 x 和 y 要不全等于 1，要不全等于 2。但在 Dirty Write 情况下面，可能会出现如下情况：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f9420db92296f248e521212a86bd33d1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;310&quot; data-rawheight=&quot;177&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f9420db92296f248e521212a86bd33d1&quot; data-watermark-src=&quot;v2-55a99d7a4bcd04bb2d166e9ac33009a3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;可以看到，最终的值是 x = 2 而 y = 1，已经破坏了数据的一致性了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P1 - Dirty Read&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Dirty Read 出现在一个事务读取到了另一个还未提交事务的修改数据。假设现在我们有一个两个账户，x 和 y，各自有 50 块钱，x 需要给 y 转 40 元钱，那么无论怎样，x + y = 100 这个约束是不能打破的，但在 Dirty Read 下面，可能出现：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a2b718ff1efaf2a194275bfb7ff1bced_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;343&quot; data-rawheight=&quot;172&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a2b718ff1efaf2a194275bfb7ff1bced&quot; data-watermark-src=&quot;v2-e6146413f66d4fe5679ec476ea9633be&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在事务 T2，读取到的 x + y = 60，已经打破了约束条件了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P2 - Fuzzy Read&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Fuzzy Read 也叫做 Non-Repeatable Read，也就是一个还在执行的事务读取到了另一个事务的更新操作，仍然是上面的转账例子：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d827daeddda6b1707d9d721f95a9f1db_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;341&quot; data-rawheight=&quot;166&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d827daeddda6b1707d9d721f95a9f1db&quot; data-watermark-src=&quot;v2-909c1d04a9fe89a09272b083bf22b579&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在 T1 还在运行的过程中，T2 已经完成了转账，但 T1 这时候能读到最新的值，也就是 x + y = 140 了，破坏了约束条件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P3 - Phantom&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Phantom 通常发生在一个事务首先进行了一次按照某个条件的 read 操作，譬如 SQL 里面的 &lt;code class=&quot;inline&quot;&gt;SELECT WHERE P&lt;/code&gt;，然后在这个事务还没结束的时候，另外的事务写入了一个新的满足这个条件的数据，这时候这个新写入的数据就是 Phantom 的了。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2f8f49d023908e37d376c59fe70b83fe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;555&quot; data-rawheight=&quot;163&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2f8f49d023908e37d376c59fe70b83fe&quot; data-watermark-src=&quot;v2-c68b450aacc22072b667197b5fca85ab&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;假设现在 T1 按照某个条件读取到了所有雇员 a，b，c，这时候 count 是 3，然后 T2 插入了一个新的雇员 d，同时更新了 count 为 4，但这时候 T1 在读取 count 的时候会得到 4，已经跟之前读取到的 a，b，c 冲突了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P4 - Lost Update&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们有时候也会遇到一种 Lost Update 的问题，如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0ec0ae1e2ab8faf39d3a2ac241805d5a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;275&quot; data-rawheight=&quot;132&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0ec0ae1e2ab8faf39d3a2ac241805d5a&quot; data-watermark-src=&quot;v2-22e2ce89eb33e3b91d492ffa7559d430&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;在上面的例子中，我们没有任何 dirty write，因为 T2 在 T1 更新之前已经提交成功，也没有任何 dirty read，因为我们在 write 之后没有任何 read 操作，但是，当整个事务结束之后，T2 的更新其实丢失了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;P4C - Cursor Lost Update&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Cursor Lost Update 是上面 Lost Update 的一个变种，跟 SQL 的 cursor 相关。在下面的例子中，RC(x) 表明在 cursor 下面 read x，而 WC(x) 则表明在 cursor 下面写入 x。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-41b6ac72eef6631f1a1b519b1bae22ec_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;317&quot; data-rawheight=&quot;134&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-41b6ac72eef6631f1a1b519b1bae22ec&quot; data-watermark-src=&quot;v2-f043051e2c5dcb038d9ca5dac74724c2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如果我们允许 T2 在  T1 RC 和 WC 之间写入数据，那么 T2 的更新也会丢失。&lt;/p&gt;&lt;p&gt;&lt;b&gt;A5A - Read Skew&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Read Skew 发生在两个或者多个有完整性约束的数据上面，还是传统的转账例子，需要保证 x + y = 100，那么 T1 就会看到不一致的数据了。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bee88aafb7485a0ee2b236dfbf1fc7fe_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;342&quot; data-rawheight=&quot;168&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bee88aafb7485a0ee2b236dfbf1fc7fe&quot; data-watermark-src=&quot;v2-1d53742a9442a787055a5570a211b7d7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;A5B - Write Skew&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Write Skew 跟 Read Skew 比较类似，假设 x + y &amp;lt;= 100，T1 和 T2 在执行的时候都发现满足约束，然后 T1 更新了 y，而 T2 更新了 x，然后最终结果打破了约束，如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27784693015ffe46fde0048b629336fc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;339&quot; data-rawheight=&quot;163&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-27784693015ffe46fde0048b629336fc&quot; data-watermark-src=&quot;v2-cbbd6978ff401beb981159d476f26e1b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;Isolation Levels&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面我们介绍了不同的异常情况，下面的表格说明了，在不同的隔离级别下面，那些异常情况可能发生：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98b3731ffae0c53321617da70017601a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;630&quot; data-rawheight=&quot;271&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-98b3731ffae0c53321617da70017601a&quot; data-watermark-src=&quot;v2-e879cb84c711e5d3f411752013581b54&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;NP - Not Possible，在该隔离级别下面不可能发生&lt;/li&gt;&lt;li&gt;SP - Sometimes Possible，在该隔离级别下面有时候可能发生&lt;/li&gt;&lt;li&gt;P - Possible，在该隔离级别下面会发生&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;鉴于网上已经对不同的 Isolation Level，尤其是 MySQL 的解释的太多了，这里就简单的解释一下。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Read Uncommitted - 能读到另外事务未提交的修改。&lt;/li&gt;&lt;li&gt;Read Committed - 能读到另外事务已经提交的修改。&lt;/li&gt;&lt;li&gt;Cursor Stability - 使用 cursor 在事务里面引用特定的数据，当一个事务用 cursor 来读取某个数据的时候，这个数据不可能被其他事务更改，除非 cursor 被释放，或者事务提交。&lt;/li&gt;&lt;li&gt;Monotonic Atomic View - 这个级别是 read committed 的增强，提供了一个原子性的约束，当一个在 T1 里面的 write 被另外事务 T2 观察到的时候，T1 里面所有的修改都会被 T2 给观察到。&lt;/li&gt;&lt;li&gt;Repeatable Read - 可重复读，也就是对于某一个数据，即使另外的事务有修改，也会读取到一样的值。&lt;/li&gt;&lt;li&gt;Snapshot - 每个事务都会在各自独立，一致的 snapshot 上面对数据库进行操作。所有修改只有在提交的时候才会对外可见。如果 T1 修改了某个数据，在提交之前另外的事务 T2 修改并提交了，那么 T1 会回滚。&lt;/li&gt;&lt;li&gt;Serializable - 事务按照一定顺序执行。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外需要注意，上面提到的 isolation level 都不保证实时约束，如果一个进程 A 完成了一次写入 w，然后另外的进程 B 开始了一次读取 r，r 并不能保证观察到 w 的结果。另外，在不同事务之间，这些 isolation level 也不保证不同进程的顺序。一个进程可能在一次事务里面看到一次写入 w，但可能在后面的事务上面没看到同样的 w。事实上，一个进程甚至可能看不到在这个进程上面之前的写入，如果这些写入都是发生在不同的事务里面。有时候，他们还可能会对事务进行排序，譬如将 write-only 的事务放到所有的 read 事务的后面。&lt;/p&gt;&lt;p&gt;要解决这些问题，我们需要引入顺序约束，这也就是下面 Session Guarantee 要干的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Session Guarantee&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 HATs 论文里面，相关的概念叫做 Session Guarantee，主要是用来保证在一个 session 里面的实时性约束以及客户端的操作顺序。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Writes Follow Reads&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果某个进程读到了一次写入 w1 写入的值 v，然后进行了一次新的写入 w2，那么 w2 写入的值将会在 w1 之后可见。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Monotonic Reads&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个进程开始了一次读取 r1，然后在开始另一次读取 r2，那么 r2 不可能看到 r1 之前数据。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Monotonic Writes&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个进程先进行了一次写入 w1，然后在进行了一次写入 w2，那么所有其他的进程都会观察到 w1 在 w2 之前发生。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Read Your Writes&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个进程先进行了一次写入 w，然后后面执行了一次读取 r，那么 r 一定会看到 w 的改动。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PRAM&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PRAM 就是 Pipeline Random Access Memory，对于单个进程的写操作都被观察到是顺序的，但不同的进程写会观察到不同的顺序。譬如下面这个操作是满足 PRAM 的，但不满足后面说的 Causal。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff2541b159c86357affa7d99ea5ada82_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;310&quot; data-rawheight=&quot;165&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-ff2541b159c86357affa7d99ea5ada82&quot; data-watermark-src=&quot;v2-803e3938c3a11c087360711b85e30659&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;Causal&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Causal 确定了有因果关系的操作在所有进程间的一致顺序。譬如下面这个：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-83163b55feb11508651baa8e834f7369_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;358&quot; data-rawheight=&quot;162&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-83163b55feb11508651baa8e834f7369&quot; data-watermark-src=&quot;v2-dc8e7b39dd320e689f93f8656748865c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 和 P4 来说，无论是先读到 2，还是先读到 1， 都是没问题的，因为 P1 和 P2 里面的 write 操作并没有因果性，是并行的。但是下面这个：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6b1daeebfd990cecb82687b46d80418c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;360&quot; data-rawheight=&quot;165&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6b1daeebfd990cecb82687b46d80418c&quot; data-watermark-src=&quot;v2-a579e40eaa5a6c55bbc68c02a3a2c596&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;就不满足 Cansal 的一致性要求了，因为对于 P2 来说，在 Write 2 之前，进行了一次 Read 1 的操作，已经确定了 Write 1 会在 Write 2 之前发生，也就是确定了因果关系，所以 P3 打破了这个关系。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sequential&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Sequential 会保证操作按照一定顺序发生，并且这个顺序会在不同的进程上面都是一致的。一个进程会比另外的进程超前，或者落后，譬如这个进程可能读到了已经是陈旧的数据，但是，如果一个进程 A 从进程 B 读到了某个状态，那么它就不可能在读到 B 之前的状态了。&lt;/p&gt;&lt;p&gt;譬如下面的操作就是满足 Sequential 的：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e254f620c178957e286dedc8b39521c6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;357&quot; data-rawheight=&quot;161&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e254f620c178957e286dedc8b39521c6&quot; data-watermark-src=&quot;v2-a54247f317d5539b43f6f1d43bfe7bc7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 来说，它仍然能读到之前的 stale 状态 1。但下面的就不对了：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0894ed397fa0d0bcbfc5e8ad9a47dfbf_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;358&quot; data-rawheight=&quot;164&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-0894ed397fa0d0bcbfc5e8ad9a47dfbf&quot; data-watermark-src=&quot;v2-443516e6968a62e0a43cf08e7d87e6a4&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 来说，它已经读到了最新的状态 2，就不可能在读到之前的状态 1 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Linearizable&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Linearizability 要求所有的操作都是按照一定的顺序原子的发生，而这个顺序可以认为就是跟操作发生的时间一致的。也就是说，如果一个操作 A 在 B 开始之前就结束了，那么 B 只可能在 A 之后才能产生作用。&lt;/p&gt;&lt;p&gt;譬如下面的操作：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f66bc3e9f6504131cf24a2a940cd94f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;302&quot; data-rawheight=&quot;161&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-3f66bc3e9f6504131cf24a2a940cd94f&quot; data-watermark-src=&quot;v2-f876bd93b74fe1b9d004ffd3a171c148&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;对于 P3 和 P4 来说，因为之前已经有新的写入，所以他们只能读到 2，不可能读到 1。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Strict Serializable&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;终于来到了 Strict Serializable，大家可以看到，它结合了 serializable 以及 linearizable，也就是说，它会让所有操作按照实时的顺序依次操作，也就是所有的进程会观察到完全一致的顺序，这也是最强的一致性模型了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;好了，最后再来聊聊 &lt;a href=&quot;https://github.com/tikv/tikv&quot;&gt;TiKV&lt;/a&gt;，TiKV 是一个支持分布式事务的 key-value database。对于某个事务，TiKV 会通过 PD 这个服务在事务开始的时候分配一个 start timestamp，以及事务提交的时候分配一个 commit timestamp。因为我们的授时是通过 PD 这个单点服务进行的，所以时间是一定能保证单调递增的，也就是说，我们所有的操作都能跟保证实时有序，也就是满足 Linearizable。&lt;/p&gt;&lt;p&gt;TiKV 采用的是常用的 MVCC 模型，也就是每个 key-value 实际存储的时候，会在 key 上面带一个 timestamp，我们就可以用 timestamp 来生成整个数据库的 snapshot 了，所以 TiKV 是 snapshot isolation 的。既然是 snapshot isolation，那么就会遇到 write skew 问题，所以 TiKV 额外提供了 serializable snapshot isolation，用户需要显示的对要操作的数据进行 lock 操作。&lt;/p&gt;&lt;p&gt;但现在 TiKV 并不支持对 range 加 lock，所以不能完全的防止 phantom，譬如假设最多允许 8 个任务，现在已经有 7 个任务了，我们还可以添加一个任务，但这时候另外一个事务也做了同样的事情，但添加的是不同的任务，这时候就会变成 9 个任务，另外的事务在 scan 的时候就会发现打破了约束。这个也就是 A Critique of ANSI SQL Isolation Levels 里面提到的 sometimes possible。&lt;/p&gt;&lt;p&gt;所以，TiKV 是 snapshot isolation + linearizable。虽然 TiKV 也可以支持 Read Committed，但通常不建议在生产环境中使用，因为 TiKV 的 Read Committed 跟传统的还不太一样，可能会出现能读到一个事务提交到某个节点的数据，但这时候在另外的节点还读不到这个事务提交的数据，毕竟在分布式系统下面，不同节点的事务提交也是有网络延迟的，不可能同时执行。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在分布式系统里面，一致性是非常重要的一个概念，理解了它，在自己设计分布式系统的时候，就能充分的考虑到底系统应该提供怎样的一致性模型。譬如对于 TP 数据库来说，就需要有一个比较 strong 的一致性模型，而对于一些不重要的系统，譬如 cache 这些，就可以使用一些比较 weak 的模型。对 TiKV 来说，我们在 Percolator 基础上面，也一直在致力于分布式事务的优化，如果你对这方面感兴趣，欢迎联系我 tl@pingcap.com。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;原文链接：&lt;a href=&quot;https://www.jianshu.com/p/3673e612cce2&quot;&gt;一致性模型&lt;/a&gt;&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;延展阅读 &lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;i&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486947&amp;amp;idx=1&amp;amp;sn=28f3fe47d380e0ee991c207251fdd415&amp;amp;chksm=eb162a89dc61a39f47bb4d3f90be9789f4b7f0a23ada7979ee65d21efcb43edd9f5e8254ff2b&amp;amp;scene=21#wechat_redirect&quot;&gt;线性一致性和 Raft&lt;/a&gt;&lt;/i&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;i&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486842&amp;amp;idx=1&amp;amp;sn=2e21e65010f497693f26cfc344e418fe&amp;amp;chksm=eb162a10dc61a30650269d414de2cfe4eeff08e0d5e9b50834c3353c70850c83b796fd2be364&amp;amp;scene=21#wechat_redirect&quot;&gt;TiKV 是如何存取数据的（上）&lt;/a&gt;&lt;/i&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;i&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486872&amp;amp;idx=1&amp;amp;sn=1f8d7e88cd92878142a444c2aea8e764&amp;amp;chksm=eb162af2dc61a3e4a6675f86f91e8bd97886b6fd8006662df2f8e58f5190514a192a259beb25&amp;amp;scene=21#wechat_redirect&quot;&gt;TiKV 是如何存储数据的（下）&lt;/a&gt;&lt;/i&gt;&lt;/u&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-23-47445841</guid>
<pubDate>Tue, 23 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>线性一致性和 Raft</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-22-47117804.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47117804&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-85e813810e9221590c5a48b11d906dc2_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：沈泰宁&lt;/p&gt;&lt;p&gt;在讨论分布式系统时，共识算法（Consensus algorithm）和一致性（Consistency）通常是讨论热点，两者的联系很微妙，很容易搞混。一些常见的误解：使用了 Raft [0] 或者 paxos 的系统都是线性一致的（Linearizability [1]，即强一致），其实不然，共识算法只能提供基础，要实现线性一致还需要在算法之上做出更多的努力。以 TiKV 为例，它的共识算法是 Raft，在 Raft 的保证下，TiKV 提供了满足线性一致性的服务。&lt;/p&gt;&lt;p&gt;本篇文章会讨论一下线性一致性和 Raft，以及 TiKV 针对前者的一些优化。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;线性一致性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;什么是一致性，简单的来说就是评判一个并发系统正确与否的标准。线性一致性是其中一种，CAP [2] 中的 C 一般就指它。什么是线性一致性，或者说怎样才能达到线性一致？在回答这个问题之前先了解一些背景知识。&lt;/p&gt;&lt;p&gt;&lt;b&gt;背景知识&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了回答上面的问题，我们需要一种表示方法描述分布式系统的行为。分布式系统可以抽象成几个部分:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Client&lt;/li&gt;&lt;li&gt;Server&lt;/li&gt;&lt;li&gt;Events&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Invocation&lt;/li&gt;&lt;li&gt;Response&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Operations&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Read&lt;/li&gt;&lt;li&gt;Write&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;一个分布式系统通常有两种角色，Client 和 Server。Client 通过发起请求来获取 Server 的服务。一次完整请求由两个事件组成，Invocation（以下简称 Inv）和 Response（以下简称 Resp）。一个请求中包含一个 Operation，有两种类型 Read 和 Write，最终会在 Server 上执行。&lt;/p&gt;&lt;p&gt;说了一堆不明所以的概念，现在来看如何用这些表示分布式系统的行为。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c6efe0b1804c98ae04cd2ba866aea6f9_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;232&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-c6efe0b1804c98ae04cd2ba866aea6f9&quot; data-watermark-src=&quot;v2-2dbf1014330a7675f4198926546c6826&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图展示了 Client A 的一个请求从发起到结束的过程。变量 x 的初始值是 1，“x R() A” 是一个事件 Inv 意思是 A 发起了读请求，相应的 “x OK(1) A” 就是事件 Resp，意思是 A 读到了 x 且值为 1，Server 执行读操作（Operation）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如何达到线性一致&lt;/b&gt;&lt;/p&gt;&lt;p&gt;背景知识介绍完了，怎样才能达到线性一致？这就要求 Server 在执行 Operations 时需要满足以下三点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;瞬间完成（或者原子性）&lt;/li&gt;&lt;li&gt;发生在 Inv 和 Resp 两个事件之间&lt;/li&gt;&lt;li&gt;反映出“最新”的值&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下面我举一个例子，用以解释上面三点。&lt;/p&gt;&lt;p&gt;&lt;b&gt;例：&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6465b3ad4bd77c4926e2786c020b5c46_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;799&quot; data-rawheight=&quot;440&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6465b3ad4bd77c4926e2786c020b5c46&quot; data-watermark-src=&quot;v2-83bbf021252b353fec99845780381d71&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;先下结论，上图表示的行为满足线性一致。&lt;/p&gt;&lt;p&gt;对于同一个对象 x，其初始值为 1，客户端 ABCD 并发地进行了请求，按照真实时间（real-time）顺序，各个事件的发生顺序如上图所示。对于任意一次请求都需要一段时间才能完成，例如 A，“x R() A” 到 “x Ok(1) A” 之间的那条线段就代表那次请求花费的时间，而请求中的读操作在 Server 上的执行时间是很短的，相对于整个请求可以认为瞬间，读操作表示为点，并且在该线段上。线性一致性中没有规定读操作发生的时刻，也就说该点可以在线段上的任意位置，可以在中点，也可以在最后，当然在最开始也无妨。&lt;/p&gt;&lt;p&gt;第一点和第二点解释的差不多了，下面说第三点。&lt;/p&gt;&lt;p&gt;反映出“最新”的值？我觉得三点中最难理解就是它了。先不急于对“最新”下定义，来看看上图中 x 所有可能的值，显然只有 1 和 2。四个次请求中只有 B 进行了写请求，改变了 x 的值，我们从 B 着手分析，明确 x 在各个时刻的值。由于不能确定 B 的 W（写操作）在哪个时刻发生，能确定的只有一个区间，因此可以引入&lt;b&gt;上下限&lt;/b&gt;的概念。对于 x=1，它的上下限为&lt;b&gt;开始到事件“x W(2) B”&lt;/b&gt;，在这个范围内所有的读操作必定读到 1。对于 x=2，它的上下限为 &lt;b&gt;事件“x Ok() B”&lt;/b&gt; 到结束，在这个范围内所有的读操作必定读到 2。那么“x W(2) B”到“x Ok() B”这段范围，x 的值是什么？&lt;b&gt;1 或者 2&lt;/b&gt;。由此可以将 x 分为三个阶段，各阶段”最新”的值如下图所示:&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-14f1c87da0956711e7d1325446ea2619_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;996&quot; data-rawheight=&quot;614&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-14f1c87da0956711e7d1325446ea2619&quot; data-watermark-src=&quot;v2-196f91a809357196ccf0e3ef5881865f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;清楚了 x 的变化后理解例子中 A C D 的读到结果就很容易了。&lt;/p&gt;&lt;p&gt;最后返回的 D 读到了 1，看起来是 “stale read”，其实并不是，它仍满足线性一致性。D 请求横跨了三个阶段，而读可能发生在任意时刻，所以 1 或 2 都行。同理，A 读到的值也可以是 2。C 就不太一样了，C 只有读到了 2 才能满足线性一致。因为 “x R() C” 发生在 “x Ok() B” 之后（happen before [3]），可以推出 R 发生在 W 之后，那么 R 一定得读到 W 完成之后的结果：2。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一句话概括：在分布式系统上实现寄存器语义。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;实现线性一致&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如开头所说，一个分布式系统正确实现了共识算法并不意味着能线性一致。共识算法只能保证多个节点对某个对象的状态是一致的，以 Raft 为例，它只能保证不同节点对 Raft Log（以下简称 Log）能达成一致。那么 Log 后面的状态机（state machine）的一致性呢？并没有做详细规定，用户可以自由实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Raft 是一个强 Leader 的共识算法，只有 Leader 能处理客户端的请求，集群的数据（Log）的流向是从 Leader 流向 Follower。其他的细节在这就不赘述了，网上有很多资料 [4]。&lt;/p&gt;&lt;p&gt;In Practice&lt;/p&gt;&lt;p&gt;以 TiKV 为例，TiKV 内部可分成多个模块，Raft 模块，RocksDB 模块，两者通过 Log 进行交互，整体架构如下图所示，consensus 就是 Raft 模块，state machine 就是 RocksDB 模块。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-18b6d578da3ad19604d89bfc0dbe7641_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;627&quot; data-rawheight=&quot;389&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-18b6d578da3ad19604d89bfc0dbe7641&quot; data-watermark-src=&quot;v2-fcadf6608de8a0d1478f67e3838f0943&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Client 将请求发送到 Leader 后，Leader 将请求作为一个 Proposal 通过 Raft 复制到自身以及 Follower 的 Log 中，然后将其 commit。TiKV 将 commit 的 Log 应用到 RocksDB 上，由于 Input（即 Log）都一样，可推出各个 TiKV 的状态机（即 RocksDB）的状态能达成一致。但实际多个 TiKV 不能保证同时将某一个 Log 应用到 RocksDB 上，也就是说各个节点不能&lt;b&gt;实时&lt;/b&gt;一致，加之 Leader 会在不同节点之间切换，所以 Leader 的状态机也不总有最新的状态。Leader 处理请求时稍有不慎，没有在最新的状态上进行，这会导致整个系统违反线性一致性。&lt;b&gt;好在有一个很简单的解决方法：依次应用 Log，将应用后的结果返回给 Client。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这方法不仅简单还通用，读写请求都可以这样实现。这个方法依据 commit index 对所有请求都做了排序，使得每个请求都能反映出状态机在执行完前一请求后的状态，可以认为 commit 决定了 R/W 事件发生的顺序。Log 是严格全序的（total order），那么自然所有 R/W 也是全序的，将这些 R/W 操作一个一个应用到状态机，所得的结果必定符合线性一致性。这个方法的缺点很明显，性能差，因为所有请求在 Log 那边就被序列化了，无法并发的操作状态机。&lt;br&gt;这样的读简称 LogRead。由于读请求不改变状态机，这个实现就显得有些“重“，不仅有 RPC 开销，还有写 Log 开销。优化的方法大致有两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;ReadIndex&lt;/li&gt;&lt;li&gt;LeaseRead&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;ReadIndex&lt;/b&gt;&lt;/p&gt;&lt;p&gt;相比于 LogRead，ReadIndex 跳过了 Log，节省了磁盘开销，它能大幅提升读的吞吐，减小延时（但不显著）。Leader 执行 ReadIndex 大致的流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;记录当前的 commit index，称为 ReadIndex&lt;/li&gt;&lt;li&gt;向 Follower 发起一次心跳，如果大多数节点回复了，那就能确定现在仍然是 Leader&lt;/li&gt;&lt;li&gt;等待状态机&lt;b&gt;至少&lt;/b&gt;应用到 ReadIndex 记录的 Log&lt;/li&gt;&lt;li&gt;执行读请求，将结果返回给 Client&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;第 3 点中的“至少”是关键要求，它表明状态机应用到 ReadIndex 之后的状态都能使这个请求满足线性一致，不管过了多久，也不管 Leader 有没有飘走。为什么在 ReadIndex 只有就满足了线性一致性呢？之前 LogRead 的读发生点是 commit index，这个点能使 LogRead 满足线性一致，那显然发生这个点之后的 ReadIndex 也能满足。&lt;/p&gt;&lt;p&gt;&lt;b&gt;LeaseRead&lt;/b&gt;&lt;/p&gt;&lt;p&gt;LeaseRead 与 ReadIndex 类似，但更进一步，不仅省去了 Log，还省去了网络交互。它可以大幅提升读的吞吐也能显著降低延时。基本的思路是 Leader 取一个比 Election Timeout 小的租期，在租期不会发生选举，确保 Leader 不会变，所以可以跳过 ReadIndex 的第二步，也就降低了延时。 LeaseRead 的正确性和时间挂钩，因此时间的实现至关重要，如果漂移严重，这套机制就会有问题。&lt;/p&gt;&lt;p&gt;Wait Free&lt;/p&gt;&lt;p&gt;到此为止 Lease 省去了 ReadIndex 的第二步，实际能再进一步，省去第 3 步。这样的 LeaseRead 在收到请求后会立刻进行读请求，不取 commit index 也不等状态机。由于 Raft 的强 Leader 特性，在租期内的 Client 收到的 Resp 由 Leader 的状态机产生，所以只要状态机满足线性一致，那么在 Lease 内，不管何时发生读都能满足线性一致性。有一点需要注意，只有在 Leader 的状态机应用了当前 term 的第一个 Log 后才能进行 LeaseRead。因为新选举产生的 Leader，它虽然有全部 committed Log，但它的状态机可能落后于之前的 Leader，状态机应用到当前 term 的 Log 就保证了新 Leader 的状态机一定新于旧 Leader，之后肯定不会出现 stale read。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本文粗略地聊了聊线性一致性，以及 TiKV 内部的一些优化。最后留四个问题以便更好地理解本文：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;对于线性一致中的例子，如果 A 读到了 2，那么 x 的各个阶段是怎样的呢？&lt;/li&gt;&lt;li&gt;对于下图，它符合线性一致吗？（温馨提示：请使用游标卡尺。;-P）&lt;/li&gt;&lt;/ol&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-58c02cee775ff40a6f89e29afb3e7fe5_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;739&quot; data-rawheight=&quot;432&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-58c02cee775ff40a6f89e29afb3e7fe5&quot; data-watermark-src=&quot;v2-165658e7cfbec5e0b5c61f0df93c982a&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;3. Leader 的状态机在什么时候没有最新状态？要线性一致性，Raft 该如何解决这问题？&lt;/p&gt;&lt;p&gt;4. FollowerRead 可以由 ReadIndex 实现，那么能由 LeaseRead 实现吗？&lt;/p&gt;&lt;p&gt;如有疑问或想交流，欢迎联系我：&lt;b&gt;shentaining@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;[0].Ongaro, Diego. Consensus: Bridging theory and practice. Diss. Stanford University, 2014.&lt;br&gt;[1].Herlihy, Maurice P., and Jeannette M. Wing. “Linearizability: A correctness condition for concurrent objects.” ACM Transactions on Programming Languages and Systems (TOPLAS) 12.3 (1990): 463-492.&lt;br&gt;[2].Gilbert, Seth, and Nancy Lynch. “Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services.” Acm Sigact News 33.2 (2002): 51-59.&lt;br&gt;[3].Lamport, Leslie. “Time, clocks, and the ordering of events in a distributed system.” Communications of the ACM 21.7 (1978): 558-565.&lt;br&gt;[4].&lt;a href=&quot;https://raft.github.io/&quot;&gt;https://raft.github.io/&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-22-47117804</guid>
<pubDate>Mon, 22 Oct 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
