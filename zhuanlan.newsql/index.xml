<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 12 Oct 2018 04:15:35 +0800</lastBuildDate>
<item>
<title>TiKV 是如何存储数据的（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-11-46524530.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46524530&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ef0379b7d20b5347e99e16cc5f6bed9e_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;u&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486842&amp;amp;idx=1&amp;amp;sn=2e21e65010f497693f26cfc344e418fe&amp;amp;chksm=eb162a10dc61a30650269d414de2cfe4eeff08e0d5e9b50834c3353c70850c83b796fd2be364&amp;amp;scene=21#wechat_redirect&quot;&gt;上篇文章&lt;/a&gt;&lt;/u&gt;中，我们介绍了与 TiKV 处理读写请求相关的基础知识，下面将开始详细的介绍 TiKV 的读写流程。Enjoy~&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;作者：唐刘 siddontang&lt;/p&gt;&lt;h2&gt;&lt;b&gt;RawKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiKV 提供两套 API，一套叫做 RawKV，另一套叫做 TxnKV。TxnKV 对应的就是上面提到的 Percolator，而 RawKV 则不会对事务做任何保证，而且比 TxnKV 简单很多，这里我们先讨论 RawKV。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Write&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-08650031b484425439a68ed74eca75c3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;675&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-08650031b484425439a68ed74eca75c3&quot; data-watermark-src=&quot;v2-1fd4a870d321c5da5c89ad8b1e17ccd3&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;当进行写入，譬如 Write a = 1，会进行如下步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Client 找 PD 问 a 所在的 Region&lt;/li&gt;&lt;li&gt;PD 告诉 Region 相关信息，主要是 Leader 所在的 TiKV&lt;/li&gt;&lt;li&gt;Client 将命令发送给 Leader 所在的 TiKV&lt;/li&gt;&lt;li&gt;Leader 接受请求之后执行 Raft 流程&lt;/li&gt;&lt;li&gt;Leader 将 a = 1 Apply 到 KV RocksDB 然后给 Client 返回写入成功&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;Read&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-633b8d2972993810a83683ae9a9fbf7f_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;660&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-633b8d2972993810a83683ae9a9fbf7f&quot; data-watermark-src=&quot;v2-2f6356ecb30b884ce25ceec89af1c519&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;对于 Read 来说，也是一样的操作，唯一不同在于 Leader 可以直接提供 Read，不需要走 Raft。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TxnKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Write&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d4e569db6e896428f6d61f59dd10b934_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;649&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d4e569db6e896428f6d61f59dd10b934&quot; data-watermark-src=&quot;v2-8b72f207ab9b77f534c6393acb27b488&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;对于 TxnKV 来说，情况就要复杂的多，不过大部分流程已经在 Percolator 章节进行说明了。这里需要注意的是，因为我们要快速的 seek 到最新的 commit，所以在 RocksDB 里面，我们会先将 TS 使用 bigendian 生成 8 字节的 bytes，然后将这个 bytes 逐位取反，在跟原始的 key 组合存储到 RocksDB 里面，这样就能保证最新的提交存放到前面，seek 的时候就能直接定位了，当然 seek 的时候，也同样会将对应的 TS 按照相同的方式编码处理。&lt;/p&gt;&lt;p&gt;譬如，假设一个 key 现在有两次提交，commitTS 分别为 10 和 12，startTS 则是 9 和 11，那么在 RocksDB 里面，key 的存放顺序则是：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Write CF：

a_12 -&amp;gt; 11
a_10 -&amp;gt; 9

Data CF:

a_11 -&amp;gt; data_11
a_9 -&amp;gt; data_9&lt;/code&gt;&lt;p&gt;另外，还需要注意的是，对于 value 比较小的情况，TiKV 会直接将 value 存放到 Write CF 里面，这样 Read 的时候只要走 Write CF 就行了。在写入的时候，流程如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;PreWrite：

Lock CF: W a -&amp;gt; Lock + Data

Commit:
Lock CF: R a -&amp;gt; Lock + 10 + Data
Lock CF: D a

Write CF: W a_11 -&amp;gt; 10 + Data&lt;/code&gt;&lt;p&gt;对于 TiKV 来说，在 Commit 阶段无论怎样都会读取 Lock 来判断事务冲突，所以我们可以从 Lock 拿到数据，然后再写入到 Write CF 里面。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Read&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-59ca441db4424772565202a0b7b3e5bb_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;659&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-59ca441db4424772565202a0b7b3e5bb&quot; data-watermark-src=&quot;v2-e3239f73c2c07d91376dd4fd8a766bc1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Read 的流程之前的 Percolator 已经有说明了，这里就不详细解释了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;SQL Key Mapping&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们在 TiKV 上面构建了一个分布式数据库 TiDB，它是一个关系型数据库，所以大家需要关注的是一个关系型的 table 是如何映射到 key-value 上面的。假设我们有如下的表结构：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t1 {
	id BIGINT PRIMARY KEY,
	name VARCHAR(1024),
	age BIGINT,
	content BLOB,
	UNIQUE(name),
	INDEX(age),
}&lt;/code&gt;&lt;p&gt;上面我们创建了一张表 t1，里面有四个字段，id 是主键，name 是唯一索引，age 是一个索引。那么这个表里面的数据是如何对应到 TiKV 的呢？&lt;/p&gt;&lt;p&gt;在 TiDB 里面，任何一张表都有一个唯一的 ID，譬如这里是 11，任何的索引也有唯一的 ID，上面 name 就是 12，age 就是 13。我们使用前缀 t 和 i 来区分表里面的 data 和 index。对于上面表 t1 来说，假设现在它有两行数据，分别是 (1, “a”, 10, “hello”) 和 (2, “b”, 12, “world”)，在 TiKV 里面，每一行数据会有不同的 key-value 对应。如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;PK
t_11_1 -&amp;gt; (1, “a”, 10, “hello”)
t_11_2 -&amp;gt; (2, “b”, 12, “world”)

Unique Name
i_12_a -&amp;gt; 1
i_12_b -&amp;gt; 2

Index Age
i_13_10_1 -&amp;gt; nil
i_13_12_2 -&amp;gt; nil&lt;/code&gt;&lt;p&gt;因为 PK 具有唯一性，所以我们可以用 t + Table ID + PK 来唯一表示一行数据，value 就是这行数据。对于 Unique 来说，也是具有唯一性的，所以我们用 i + Index ID + name 来表示，而 value 则是对应的 PK。如果两个 name 相同，就会破坏唯一性约束。当我们使用 Unique 来查询的时候，会先找到对应的 PK，然后再通过 PK 找到对应的数据。&lt;/p&gt;&lt;p&gt;对于普通的 Index 来说，不需要唯一性约束，所以我们使用 i + Index ID + age + PK，而 value 为空。因为 PK 一定是唯一的，所以两行数据即使 age 一样，也不会冲突。当我们使用 Index 来查询的时候，会先 seek 到第一个大于等于 i + Index ID + age 这个 key 的数据，然后看前缀是否匹配，如果匹配，则解码出对应的 PK，再从 PK 拿到实际的数据。&lt;/p&gt;&lt;p&gt;TiDB 在操作 TiKV 的时候需要保证操作 keys 的一致性，所以需要使用 TxnKV 模式。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面简单的介绍了下 TiKV 读写数据的流程，还有很多东西并没有覆盖到，譬如错误处理，Percolator 的性能优化这些，如果你对这些感兴趣，可以参与到 TiKV 的开发，欢迎联系我 tl@pingcap.com。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-11-46524530</guid>
<pubDate>Thu, 11 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 是如何存取数据的（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-10-46372968.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46372968&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-427f9cc9aaef7836737e7c751e2324ec_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：唐刘 &lt;/blockquote&gt;&lt;p&gt;本文会详细的介绍 TiKV 是如何处理读写请求的，通过该文档，同学们会知道 TiKV 是如何将一个写请求包含的数据更改存储到系统，并且能读出对应的数据的。&lt;/p&gt;&lt;p&gt;本文分为上下两篇，在上篇中，我们将介绍一些基础知识，便于大家去理解后面的流程。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基础知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6489ef5e81f554b62f7b3b592ca977b3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6489ef5e81f554b62f7b3b592ca977b3&quot; data-watermark-src=&quot;v2-6199c4b5150737aa28f158a06fa8bb09&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;TiKV 使用 Raft 一致性算法来保证数据的安全，默认提供的是三个副本支持，这三个副本形成了一个 Raft Group。&lt;/p&gt;&lt;p&gt;当 Client 需要写入某个数据的时候，Client 会将操作发送给 Raft Leader，这个在 TiKV 里面我们叫做 Propose，Leader 会将操作编码成一个 entry，写入到自己的 Raft Log 里面，这个我们叫做 Append。&lt;/p&gt;&lt;p&gt;Leader 也会通过 Raft 算法将 entry 复制到其他的 Follower 上面，这个我们叫做 Replicate。Follower 收到这个 entry 之后也会同样进行 Append 操作，顺带告诉 Leader Append 成功。&lt;br&gt;当 Leader 发现这个 entry 已经被大多数节点 Append，就认为这个 entry 已经是 Committed 的了，然后就可以将 entry 里面的操作解码出来，执行并且应用到状态机里面，这个我们叫做 Apply。&lt;/p&gt;&lt;p&gt;在 TiKV 里面，我们提供了 Lease Read，对于 Read 请求，会直接发给 Leader，如果 Leader 确定自己的 lease 没有过期，那么就会直接提供 Read 服务，这样就不用走一次 Raft 了。如果 Leader 发现 lease 过期了，就会强制走一次 Raft 进行续租，然后再提供 Read 服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Multi Raft&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-02fcecc350e76cac6d8a35bdc3febfb3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;443&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-02fcecc350e76cac6d8a35bdc3febfb3&quot; data-watermark-src=&quot;v2-cdfe9eadb97a3d203cc670f488af3cff&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;因为一个 Raft Group 处理的数据量有限，所以我们会将数据切分成多个 Raft Group，我们叫做 Region。切分的方式是按照 range 进行切分，也就是我们会将数据的 key 按照字节序进行排序，也就是一个无限的 sorted map，然后将其切分成一段一段（连续）的 key range，每个 key range 当成一个 Region。&lt;/p&gt;&lt;p&gt;两个相邻的 Region 之间不允许出现空洞，也就是前面一个 Region 的 end key 就是后一个 Region 的 start key。Region 的 range 使用的是前闭后开的模式  [start, end)，对于 key start 来说，它就属于这个 Region，但对于 end 来说，它其实属于下一个 Region。&lt;br&gt;TiKV 的 Region 会有最大 size 的限制，当超过这个阈值之后，就会分裂成两个 Region，譬如 [a, b) -&amp;gt; [a, ab) + [ab, b)，当然，如果 Region 里面没有数据，或者只有很少的数据，也会跟相邻的 Region 进行合并，变成一个更大的 Region，譬如 [a, ab) + [ab, b) -&amp;gt; [a, b)。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Percolator&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于同一个 Region 来说，通过 Raft 一致性协议，我们能保证里面的 key 操作的一致性，但如果我们要同时操作多个数据，而这些数据落在不同的 Region 上面，为了保证操作的一致性，我们就需要分布式事务。&lt;/p&gt;&lt;p&gt;譬如我们需要同时将 a = 1，b = 2 修改成功，而 a 和 b 属于不同的 Region，那么当操作结束之后，一定只能出现 a 和 b 要么都修改成功，要么都没有修改成功，不能出现 a 修改了，但 b 没有修改，或者 b 修改了，a 没有修改这样的情况。&lt;/p&gt;&lt;p&gt;最通常的分布式事务的做法就是使用 two-phase commit，也就是俗称的 2PC，但传统的 2PC 需要有一个协调者，而我们也需要有机制来保证协调者的高可用。这里，TiKV 参考了 Google 的 Percolator，对 2PC 进行了优化，来提供分布式事务支持。&lt;/p&gt;&lt;p&gt;Percolator 的原理是比较复杂的，需要关注几点：&lt;/p&gt;&lt;p&gt;首先，Percolator 需要一个服务 timestamp oracle (TSO) 来分配全局的 timestamp，这个 timestamp 是按照时间单调递增的，而且全局唯一。任何事务在开始的时候会先拿一个 start timestamp (startTS)，然后在事务提交的时候会拿一个 commit timestamp (commitTS)。&lt;/p&gt;&lt;p&gt;Percolator 提供三个 column family (CF)，Lock，Data 和 Write，当写入一个 key-value 的时候，会将这个 key 的 lock 放到 Lock CF 里面，会将实际的 value 放到 Data CF 里面，如果这次写入 commit 成功，则会将对应的 commit 信息放到入 Write CF 里面。&lt;/p&gt;&lt;p&gt;Key 在 Data CF 和 Write CF 里面存放的时候，会把对应的时间戳给加到 Key 的后面。在 Data CF 里面，添加的是 startTS，而在 Write CF 里面，则是 commitCF。&lt;/p&gt;&lt;p&gt;假设我们需要写入 a = 1，首先从 TSO 上面拿到一个 startTS，譬如 10，然后我们进入 Percolator 的 PreWrite 阶段，在 Lock 和 Data CF 上面写入数据，如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Lock CF: W a = lock
Data CF: W a_10 = value&lt;/code&gt;&lt;p&gt;后面我们会用 W 表示 Write，R 表示 Read， D 表示 Delete，S 表示 Seek。&lt;/p&gt;&lt;p&gt;当 PreWrite 成功之后，就会进入 Commit 阶段，会从 TSO 拿一个 commitTS，譬如 11，然后写入：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Lock CF: D a
Write CF: W a_11 = 10&lt;/code&gt;&lt;p&gt;当 Commit 成功之后，对于一个 key-value 来说，它就会在 Data CF 和 Write CF 里面都有记录，在 Data CF 里面会记录实际的数据， Write CF 里面则会记录对应的 startTS。&lt;br&gt;当我们要读取数据的时候，也会先从 TSO 拿到一个 startTS，譬如 12，然后进行读：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Lock CF: R a
Write CF: S a_12 -&amp;gt; a_11 = 10
Data CF: R a_10&lt;/code&gt;&lt;p&gt;在 Read 流程里面，首先我们看 Lock CF 里面是否有 lock，如果有，那么读取就失败了。如果没有，我们就会在 Write CF 里面 seek 最新的一个提交版本，这里我们会找到 11，然后拿到对应的 startTS，这里就是 10，然后将 key 和 startTS 组合在 Data CF 里面读取对应的数据。&lt;br&gt;上面只是简单的介绍了下 Percolator 的读写流程，实际会比这个复杂的多。&lt;/p&gt;&lt;p&gt;&lt;b&gt;RocksDB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 会将数据存储到 RocksDB，RocksDB 是一个 key-value 存储系统，所以对于 TiKV 来说，任何的数据都最终会转换成一个或者多个 key-value 存放到 RocksDB 里面。&lt;/p&gt;&lt;p&gt;每个 TiKV 包含两个 RocksDB 实例，一个用于存储 Raft Log，我们后面称为 Raft RocksDB，而另一个则是存放用户实际的数据，我们称为 KV RocksDB。&lt;/p&gt;&lt;p&gt;一个 TiKV 会有多个 Regions，我们在 Raft RocksDB 里面会使用 Region 的 ID 作为 key 的前缀，然后再带上 Raft Log ID 来唯一标识一条 Raft Log。譬如，假设现在有两个 Region，ID 分别为 1，2，那么 Raft Log 在 RocksDB 里面类似如下存放：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;1_1 -&amp;gt; Log {a = 1}
1_2 -&amp;gt; Log {a = 2}
…
1_N -&amp;gt; Log {a = N}
2_1 -&amp;gt; Log {b = 2}
2_2 -&amp;gt; Log {b = 3}
…
2_N -&amp;gt; Log {b = N}&lt;/code&gt;&lt;p&gt;因为我们是按照 range 对 key 进行的切分，那么在 KV RocksDB 里面，我们直接使用 key 来进行保存，类似如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;a -&amp;gt; N
b -&amp;gt; N&lt;/code&gt;&lt;p&gt;里面存放了两个 key，a 和 b，但并没有使用任何前缀进行区分。&lt;/p&gt;&lt;p&gt;RocksDB 支持 Column Family，所以能直接跟 Percolator 里面的 CF 对应，在 TiKV 里面，我们在 RocksDB 使用 Default CF 直接对应 Percolator 的 Data CF，另外使用了相同名字的 Lock 和 Write。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 会将自己所有的 Region 信息汇报给 PD，这样 PD 就有了整个集群的 Region 信息，当然就有了一张 Region 的路由表，如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18bf04cad2aa6a7995a78e9518a0d0e1_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;484&quot; data-rawheight=&quot;418&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-18bf04cad2aa6a7995a78e9518a0d0e1&quot; data-watermark-src=&quot;v2-fd49907324671035b34aa6b19a1b3f78&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;当 Client 需要操作某一个 key 的数据的时候，它首先会向 PD 问一下这个 key 属于哪一个 Region，譬如对于 key a 来说，PD 知道它属于 Region 1，就会给 Client 返回 Region 1 的相关信息，包括有多少个副本，现在 Leader 是哪一个副本，这个 Leader 副本在哪一个 TiKV 上面。&lt;/p&gt;&lt;p&gt;Client 会将相关的 Region 信息缓存到本地，加速后续的操作，但有可能 Region 的 Raft Leader 变更，或者 Region 出现了分裂，合并，Client 会知道缓存失效，然后重新去 PD 获取最新的信息。&lt;/p&gt;&lt;p&gt;PD 同时也提供全局的授时服务，在 Percolator 事务模型里面，我们知道事务开始以及提交都需要有一个时间戳，这个就是 PD 统一分配的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;基础知识就介绍到这里，下篇我们将详细的介绍 TiKV 的读写流程～ &lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-10-46372968</guid>
<pubDate>Wed, 10 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>雷神 Thor —— TiDB 自动化运维平台</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-10-08-46185503.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46185503&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-557ce943fab1b90541ff2d490292bc16_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：瞿锴，同程艺龙资深 DBA &lt;/blockquote&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;背景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;随着互联网的飞速发展，业务量可能在短短的时间内爆发式地增长，对应的数据量可能快速地从几百 GB 涨到几百个 TB，传统的单机数据库提供的服务，在系统的可扩展性、性价比方面已经不再适用。为了应对大数据量下业务服务访问的性能问题，MySQL 数据库常用的分库、分表方案会随着 MySQL Sharding（分片）的增多，业务访问数据库逻辑会越来越复杂。而且对于某些有多维度查询需求的表，需要引入额外的存储或牺牲性能来满足查询需求，这样会使业务逻辑越来越重，不利于产品的快速迭代。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 的架构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 作为 PingCAP 旗下开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。&lt;/p&gt;&lt;p&gt;TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。&lt;/p&gt;&lt;p&gt;TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。&lt;/p&gt;&lt;p&gt;PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。&lt;/p&gt;&lt;p&gt;上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-dfe437d191248134116e53aea0296e98_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;473&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-dfe437d191248134116e53aea0296e98&quot; data-watermark-src=&quot;v2-6fa8417f9ee498b4632ae6108b2e867e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;由此可见，分布式系统本身的复杂性导致手工部署和运维的成本是比较高的，并且容易出错。传统的自动化部署运维工具如 Puppet / Chef / SaltStack / Ansible 等，由于缺乏状态管理，在节点出现问题时不能及时自动完成故障转移，需要运维人员人工干预。有些则需要写大量的 DSL 甚至与 Shell 脚本一起混合使用，可移植性较差，维护成本比较高。&lt;/p&gt;&lt;p&gt;针对 TiDB 这种复杂的分布式数据库，我们考虑通过对 TiDB 容器化管理，实现以下几个目的：&lt;/p&gt;&lt;p&gt;一、屏蔽底层物理资源&lt;/p&gt;&lt;p&gt;二、提升资源利用率（CPU、内存）&lt;/p&gt;&lt;p&gt;三、提升运维效率&lt;/p&gt;&lt;p&gt;四、精细化管理&lt;/p&gt;&lt;p&gt;因此结合上述需要，我们开发了雷神系统来统一管理和维护 TiDB，其整体架构如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-992b9ecce8d568b33541b73fa9ad11b2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1018&quot; data-rawheight=&quot;511&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-992b9ecce8d568b33541b73fa9ad11b2&quot; data-watermark-src=&quot;v2-dee14b705d51f32695209dbacb771bd1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;从架构图中可以看出此方案是 TiDB 的私有云架构。最下层是容器云，中间一层是开发的容器编排工具，最上面一层针对 TiDB 特性和实际使用中遇到的问题点，进行了针对性开发从而实现了 TiDB 集群实例的统一化管理。下面将逐个介绍各个模块的功能。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;容器调度&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前主流的的容器编排系统 Kuberbetes 曾是我们容器调度的首选解决方案。但 TiDB 作为数据库服务需要将数据库存储到本地磁盘，而 Kuberbetes 对 Local Storage 不支持（目前新的版本已经开始支持）。针对 TiDB 的特性和业务需求，我们决定自己实现一套容器编排系统，具体解决以下问题： &lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持 LocalStorage，解决数据存储问题&lt;/li&gt;&lt;li&gt;基于 cpuset-cpus 实现 CPU 资源的随机均衡分配&lt;/li&gt;&lt;li&gt;定制化，支持 label，实现特定服务运行在特定宿主机上；宿主机资源限制&lt;/li&gt;&lt;li&gt;容器的主动发现和通知，以便将之前未管理的宿主机接入统一管理&lt;/li&gt;&lt;li&gt;容器的全生命周期的管理&lt;/li&gt;&lt;li&gt;容器异常的修复和通知&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;雷神 Thor 采用了模块化设计，分为控制模块和代理模块，其整体架构如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-28a86e4adc0a0f145c9550a05b5f48ec_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;585&quot; data-rawheight=&quot;623&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-28a86e4adc0a0f145c9550a05b5f48ec&quot; data-watermark-src=&quot;v2-f2782c72ef3ce96e42140b41f3696c4f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;说明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;控制模块包含了 Allocator，Label，Discover，Manage，Customize。Allocator 主要负责宿主机资源的分配；Label 主要用于标签定制；Customize 主要负责定制化需求； Discover 主要负责容器的发现和异常检测；Manage 主要负责整体的调度和分发。&lt;/li&gt;&lt;li&gt;代理模块主要负责资源检查和信息收集、接受控制端的命令。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;集群管理&lt;/b&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-08f65ecac29c104de00d9d3275bb34b4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;530&quot; data-rawheight=&quot;436&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-08f65ecac29c104de00d9d3275bb34b4&quot; data-watermark-src=&quot;v2-572a148e311363b3c8a4f47828df8e6d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;集群管理是整套系统的核心模块之一，包含了 TiDB 集群的日常维护操作，实现了 TiDB 初始化、平滑升级、弹性容量管理、监控的整合、集群的维护、节点的维护等功能。虽然 PingCAP 提供了基于 Ansible 的自动部署方案，但是依然需要填写大量的内容和检查相关机器设定来完成部署。通过此系统只需要将需求按照如何格式提交，即可完成整套集群的部署，部署时间从之前 2 个小时，缩减为 2 分钟左右。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据库管理&lt;/b&gt;&lt;br&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-babcc4bebbf0727ef16051ceeea49e47_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;801&quot; data-rawheight=&quot;431&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-babcc4bebbf0727ef16051ceeea49e47&quot; data-watermark-src=&quot;v2-7688be0215c1f39d4339c06c3e8f2eb7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;数据库管理是日常运维很核心的一块，此模块通过任务完成统计信息更新、过载保护、慢查询分析和 SQL 预警。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.统计信息更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 虽然会自动更新统计信息，但需要达到固定的变更百分比，因 TiDB 是作为分片库的合并库，数据量高达几十亿，若依赖自身的统计信息维护，将出现因统计信息不准确而触发的慢查询，故针对此种情况，设计和开发统计信息自动更新，除常规设定外，还可设定例外，避免因统计信息更新时影响业务的正常使用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 过载保护&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过对 SQL 的执行时间和内存的使用情况分析，针对不同的集群可以定制不同的过载保护策略，也可以使用统一的过载保护策略；当触发策略时，会将相关信息通过微信的方式通知相关人员。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 慢查询分析和 SQL 预警&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过 ELK 构建慢查询分析系统，通过 mysql-sniffer、flume、kafka、spark、hadoop 构建 SQL 预警，通过对趋势的分析和预判，为后续自动化容量管理做数据的积累。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据同步&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们尝试将 TiDB 作为所有数据的集合库提供复杂查询，分片集群则提供简单查询，同时由于 TiDB 高度兼容 MySQL 的连接协议为满足复杂的业务查询需求，我们基于 PingCAP 的数据同步工具 Syncer 进行了代码重构，开发了 hamal 同步工具，可以自定义库名和表名，同时新增了同步状态监控，如 TPS、延迟等，如果出现异常，会通过微信告警。从 MySQL 将数据实时同步到 TiDB 来确保数据的一致。该实时同步查询系统架构如下所示：&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8ad16b7b9d86910c4a9b6b7bdf9cde86_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;650&quot; data-rawheight=&quot;469&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-8ad16b7b9d86910c4a9b6b7bdf9cde86&quot; data-watermark-src=&quot;v2-30a07f231b88e76c42df5f5bf582f3cb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;Hamal 是伪装成 mysql 从，从 mysql 主上通过主从复制协议来解析成对应的 sql 语句，并经过过滤、改写等步骤，将最终语句在目标库执行的工具。Hamal 主要包含以下特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;position 以及 gtid 模式支持&lt;/li&gt;&lt;li&gt;自动切换主从支持（需要提前配置好主从服务列表）&lt;/li&gt;&lt;li&gt;多目标库支持（多 tidb-server）&lt;/li&gt;&lt;li&gt;binlog 心跳支持&lt;/li&gt;&lt;li&gt;库、表级别过滤，重写支持（用于分片合库）&lt;/li&gt;&lt;li&gt;库表级别额外索引支持&lt;/li&gt;&lt;li&gt;拆解字段支持（额外输出选择某几个字段的小表）&lt;/li&gt;&lt;li&gt;字段过滤支持&lt;/li&gt;&lt;li&gt;智能更新表结构&lt;/li&gt;&lt;li&gt;多线程合并小事务后执行，多种分发策略&lt;/li&gt;&lt;li&gt;纯文本执行模式支持&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Hamal 的内部实现如下：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73520b9115d50bf2cce7e93b3c229993_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;827&quot; data-rawheight=&quot;419&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-73520b9115d50bf2cce7e93b3c229993&quot; data-watermark-src=&quot;v2-1b352156ecac7dcaa98007b8a141d7c7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt; &lt;br&gt;从架构图中可以看出，通过设定不同的 generators，hamal 支持同步到不同目的库或者其他存储方式。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;监控和告警中心&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;监控对于系统的重要性不言而喻。能否有效的告警直接影响着监控的质量，因此监控的核心是监控数据的采集和有效的告警。监控数据主要有三种系统本身的运行状态，例如 CPU、内存、磁盘、网络的使用情况；各种应用的运行状况，例如数据库、容器等，处理网络上发送过来的数据。通过监控项设定和监控例外，可以灵活的定制监控信息的收集。合理、灵活的监控规则可以帮助更快、更精确的定位异常，通过告警策略和告警例外满足不同的告警需求。监控和告警中心的架构图如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4dab4417616d0f38524d33cf8caed068_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;473&quot; data-rawheight=&quot;422&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4dab4417616d0f38524d33cf8caed068&quot; data-watermark-src=&quot;v2-376f9db0cb3f9d9cc931ff24a7e97049&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;其中，监控数据的采集一部分依赖于现有监控系统中的数据，如 zabbix 之类；一部分通过 TiDB 的 API 获取，一部分是开源的收集器，因此导致原始数据存储在不同类型的数据库，通过开发的同步工具，将上述数据同步独立部署的 TiDB 集群，以便后续的数据分析。可视化的实现主要基于 grafana 来完成。告警模块是基于实际的需求，进行开发和实现的，未采用现有的一些开源方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在对 TiDB 的使用过程中，我们按照 1 库 1 集群的方式进行服务部署，这种部署方式可以有效避免不同库的压力不均导致相互影响的问题，同时性能监控精准到库级别，而使用了雷神系统后，能够有效的在单台服务器上对各种服务资源进行快速部署，提升资源利用率的同时避免资源争用带来的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;系统上线一年以来，已完成公司所有 TiDB 集群从物理机部署到容器化的平稳迁移；管理了数百台机器和数十套 TiDB Cluster，接入应用数百个，承载着几十 T 的数据量，峰值 TPS 数十万；上线前部署一个 TiDB 集群需要花费将近 2 个小时，雷神系统上线后只需要 2 分钟即可部署完成。有效的提升了 DBA 的运维效率和整个 TiDB 服务的可用性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;未来我们将继续深入，从审计和 SQL 分析方面着手，为业务提供更多的效率提升和稳定性保障。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/0cHC8yPzNgKgFUmIWEsJ5g?scene=25#wechat_redirect&quot;&gt;雷神Thor—TIDB自动化运维平台&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-10-08-46185503</guid>
<pubDate>Mon, 08 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十九）tikv-client（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-27-45475314.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45475314&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fa485b637a9f12bf5a48586d49285dfd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：周昱行&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43926052&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了数据读写过程中 tikv-client 需要解决的几个具体问题，本文将继续介绍 tikv-client 里的两个主要的模块——负责处理分布式计算的 copIterator 和执行二阶段提交的 twoPhaseCommitter。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;copIterator&lt;/b&gt;&lt;/h2&gt;&lt;h2&gt;&lt;b&gt;1.copIterator 是什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在介绍 copIterator 的概念之前，我们需要简单回顾一下前面 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;TiDB 源码阅读系列文章（六）&lt;/a&gt;中讲过的 distsql 和 coprocessor 的概念以及它们和 SQL 语句的关系。&lt;/p&gt;&lt;p&gt;tikv-server 通过 coprocessor 接口，支持部分 SQL 层的计算能力，大部分只涉及单表数据的常用的算子都可以下推到 tikv-server 上计算，计算下推以后，从存储引擎读取的数据虽然是一样的多，但是通过网络返回的数据会少很多，可以大幅节省序列化和网络传输的开销。&lt;/p&gt;&lt;p&gt;distsql 是位于 SQL 层和 coprocessor 之间的一层抽象，它把下层的 coprocessor 请求封装起来对上层提供一个简单的 &lt;code class=&quot;inline&quot;&gt;Select&lt;/code&gt; 方法。执行一个单表的计算任务。最上层的 SQL 语句可能会包含 &lt;code class=&quot;inline&quot;&gt;JOIN&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;SUBQUERY&lt;/code&gt; 等复杂算子，涉及很多的表，而 distsql 只涉及到单个表的数据。一个 distsql 请求会涉及到多个 region，我们要对涉及到的每一个 region 执行一次 coprocessor 请求。&lt;/p&gt;&lt;p&gt;所以它们的关系是这样的，一个 SQL 语句包含多个 distsql 请求，一个 distsql 请求包含多个 coprocessor 请求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;copIterator 的任务就是实现 distsql 请求，执行所有涉及到的 coprocessor 请求，并依次返回结果。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. 构造 coprocessor task&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一个 distsql 请求需要处理的数据是一个单表上的 index scan 或 table scan，在 Request 包含了转换好的 KeyRange list。接下来，通过 region cache 提供的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/region_cache.go#L138&quot;&gt;LocateKey&lt;/a&gt; 方法，我们可以找到有哪些 region 包含了一个 key range 范围内的数据。&lt;/p&gt;&lt;p&gt;找到所有 KeyRange 包含的所有的 region 以后，我们需要按照 region 的 range 把 key range list 进行切分，让每个 coprocessor task 里的 key range list 不会超过 region 的范围。&lt;/p&gt;&lt;p&gt;构造出了所有 coprocessor task 之后，下一步就是执行这些 task 了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. copIterator 的执行模式&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了更容易理解 copIterator 的执行模式，我们先从最简单的实现方式开始， 逐步推导到现在的设计。&lt;/p&gt;&lt;p&gt;copIterator 是 &lt;code class=&quot;inline&quot;&gt;kv.Response&lt;/code&gt; 接口的实现，需要实现对应 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L516&quot;&gt;Next&lt;/a&gt; 方法，在上层调用 Next  的时候，返回一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L390:6&quot;&gt;coprocessor response&lt;/a&gt;，上层通过多次调用 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法，获取多个 coprocessor response，直到所有结果获取完。&lt;/p&gt;&lt;p&gt;最简单的实现方式，是在 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法里，执行一个 coprocessor task，返回这个 task 的执行结果。&lt;/p&gt;&lt;p&gt;这个执行方式的一个很大的问题，大量时间耗费在等待 coprocessor 请求返回结果，我们需要改进一下。&lt;/p&gt;&lt;p&gt;coprocessor 请求如果是由 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 触发的，每次调用 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 就必须等待一个 &lt;code class=&quot;inline&quot;&gt;RPC  round trip&lt;/code&gt; 的延迟。我们可以改造成请求在 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 被调用之前触发，这样就能在 Next 被调用的时候，更早拿到结果返回，省掉了阻塞等待的过程。&lt;/p&gt;&lt;p&gt;在 copIterator 创建的时候，我们启动一个后台 worker goroutine 来依次执行所有的 coprocessor task，并把执行结果发送到一个 response channel，这样前台 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法只需要从这个 channel 里  receive 一个 coprocessor response 就可以了。如果这个 task 已经执行完成，&lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法可以直接获取到结果，立即返回。&lt;/p&gt;&lt;p&gt;当所有 coprocessor task 被 work 执行完成的时候，worker 把这个 response channel 关闭，&lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法在 receive channel 的时候发现 channel 已经关闭，就可以返回 &lt;code class=&quot;inline&quot;&gt;nil response&lt;/code&gt;，表示所有结果都处理完成了。&lt;/p&gt;&lt;p&gt;以上的执行方案还是存在一个问题，就是 coprocessor task 只有一个 worker 在执行，没有并行，性能还是不理想。&lt;/p&gt;&lt;p&gt;为了增大并行度，我们可以构造多个 worker 来执行 task，把所有的 task 发送到一个 task channel，多个 worker 从这一个 channel 读取 task，执行完成后，把结果发到 response channel，通过设置 worker 的数量控制并发度。&lt;/p&gt;&lt;p&gt;这样改造以后，就可以充分的并行执行了，但是这样带来一个新的问题，task 是有序的，但是由于多个 worker 并行执行，返回的 response 顺序是乱序的。对于不要求结果有序的 distsql 请求，这个执行模式是可行的，我们使用这个模式来执行。对于要求结果有序的 distsql 请求，就不能满足要求了，我们需要另一种执行模式。&lt;/p&gt;&lt;p&gt;当 worker 执行完一个 task 之后，当前的做法是把 response 发送到一个全局的 channel 里，如果我们给每一个 task 创建一个 channel，把 response 发送到这个 task 自己的 response channel 里，Next 的时候，就可以按照 task 的顺序获取 response，保证结果的有序。&lt;/p&gt;&lt;p&gt;以上就是 copIterator 最终的执行模式。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. copIterator 实现细节&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;理解执行模式之后，我们从源码的角度，分析一遍完整的执行流程。&lt;/p&gt;&lt;p&gt;&lt;b&gt;前台执行流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;前台的执行的第一步是 CopClient 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L82&quot;&gt;Send&lt;/a&gt; 方法。先根据 distsql 请求里的 &lt;code class=&quot;inline&quot;&gt;KeyRanges&lt;/code&gt; &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L238&quot;&gt;构造 coprocessor task&lt;/a&gt;，用构造好的 task 创建 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L88&quot;&gt;copIterator&lt;/a&gt;，然后调用 copIterator 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L438&quot;&gt;open&lt;/a&gt; 方法，启动多个后台 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L452&quot;&gt;worker goroutine&lt;/a&gt;，然后启动一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L454&quot;&gt;sender&lt;/a&gt; 用来把 task 丢进 task channel，最后 copIterator 做为 &lt;code class=&quot;inline&quot;&gt;kv.Reponse&lt;/code&gt; 返回。&lt;/p&gt;&lt;p&gt;前台执行的第二步是多次调用 &lt;code class=&quot;inline&quot;&gt;kv.Response&lt;/code&gt; 的 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 方法，直到获取所有的 response。&lt;/p&gt;&lt;p&gt;copIterator 在 &lt;code class=&quot;inline&quot;&gt;Next&lt;/code&gt; 里会根据结果是否有序，选择相应的执行模式，无序的请求会从 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L526&quot;&gt;全局 channel 里获取结果&lt;/a&gt;，有序的请求会在每一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L537&quot;&gt;task 的 response channel&lt;/a&gt; 里获取结果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;后台执行流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L417&quot;&gt;从 task channel 获取到一个 task&lt;/a&gt; 之后，worker 会执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L424&quot;&gt;handleTask&lt;/a&gt; 来发送 RPC 请求，并处理请求的异常，当 region 分裂的时候，我们需要重新构造 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L572&quot;&gt;新的 task&lt;/a&gt;，并重新发送。对于有序的 distsql 请求，分裂后的多个 task 的执行结果需要发送到旧的 task 的 response channel 里，所以一个 task 的 response channel 可能会返回多个 response，发送完成后需要 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/coprocessor.go#L428&quot;&gt;关闭 task 的 response channel&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;twoPhaseCommitter&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 2PC 简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2PC 是实现分布式事务的一种方式，保证跨越多个网络节点的事务的原子性，不会出现事务只提交一半的问题。&lt;/p&gt;&lt;p&gt;在 TiDB，使用的 2PC 模型是 Google percolator 模型，简单的理解，percolator 模型和传统的 2PC 的区别主要在于消除了事务管理器的单点，把事务状态信息保存在每个 key 上，大幅提高了分布式事务的线性 scale 能力，虽然仍然存在一个 timestamp oracle 的单点，但是因为逻辑非常简单，而且可以 batch 执行，所以并不会成为系统的瓶颈。&lt;/p&gt;&lt;p&gt;关于 percolator 模型的细节，可以参考这篇文章的介绍 &lt;a href=&quot;https://pingcap.com/blog-cn/percolator-and-txn/&quot;&gt;https://pingcap.com/blog-cn/percolator-and-txn/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. 构造 twoPhaseCommitter&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当一个事务准备提交的时候，会创建一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L62&quot;&gt;twoPhaseCommiter&lt;/a&gt;，用来执行分布式的事务。&lt;/p&gt;&lt;p&gt;构造的时候，需要做以下几件事情&lt;/p&gt;&lt;ul&gt;&lt;li&gt; href=&quot;https&lt;code class=&quot;inline&quot;&gt;://github.&lt;/code&gt;com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L91&quot;&amp;gt;从 memBuffer 和 lockedKeys 里收集所有的 key 和 mutation&lt;br&gt;&lt;code class=&quot;inline&quot;&gt;memBuffer&lt;/code&gt; 里的 key 是有序排列的，我们从头遍历 &lt;code class=&quot;inline&quot;&gt;memBuffer&lt;/code&gt; 可以顺序的收集到事务里需要修改的 key，value 长度为 0 的 entry 表示 &lt;code class=&quot;inline&quot;&gt;DELETE&lt;/code&gt; 操作，value 长度大于 0 表示 &lt;code class=&quot;inline&quot;&gt;PUT&lt;/code&gt; 操作，&lt;code class=&quot;inline&quot;&gt;memBuffer&lt;/code&gt; 里的第一个 key 做为事务的 primary key。&lt;code class=&quot;inline&quot;&gt;lockKeys&lt;/code&gt; 里保存的是不需要修改，但需要加读锁的 key，也会做为 mutation 的 &lt;code class=&quot;inline&quot;&gt;LOCK&lt;/code&gt; 操作，写到 TiKV 上。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L132&quot;&gt;计算事务的大小是否超过限制&lt;/a&gt;&lt;br&gt;在收集 mutation 的时候，会统计整个事务的大小，如果超过了最大事务限制，会返回报错。&lt;br&gt;太大的事务可能会让 TiKV 集群压力过大，执行失败并导致集群不可用，所以要对事务的大小做出硬性的限制。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L164&quot;&gt;计算事务的 TTL 时间&lt;/a&gt;&lt;br&gt;如果一个事务的 key 通过 &lt;code class=&quot;inline&quot;&gt;prewrite&lt;/code&gt; 加锁后，事务没有执行完，tidb-server 就挂掉了，这时候集群内其他 tidb-server 是无法读取这个 key 的，如果没有 TTL，就会死锁。设置了 TTL 之后，读请求就可以在 TTL 超时之后执行清锁，然后读取到数据。&lt;br&gt;我们计算一个事务的超时时间需要考虑正常执行一个事务需要花费的时间，如果太短会出现大的事务无法正常执行完的问题，如果太长，会有异常退出导致某个 key 长时间无法访问的问题。所以使用了这样一个算法，TTL 和事务的大小的平方根成正比，并控制在一个最小值和一个最大值之间。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;3. execute&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 twoPhaseCommiter 创建好以后，下一步就是执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L562&quot;&gt;execute&lt;/a&gt; 函数。&lt;/p&gt;&lt;p&gt;在 &lt;code class=&quot;inline&quot;&gt;execute&lt;/code&gt; 函数里，需要在 &lt;code class=&quot;inline&quot;&gt;defer&lt;/code&gt; 函数里执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L572&quot;&gt;cleanupKeys&lt;/a&gt;，在事务没有成功执行的时候，清理掉多余的锁，如果不做这一步操作，残留的锁会让读请求阻塞，直到 TTL 过期才会被清理。第一步会执行 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L585&quot;&gt;prewriteKeys&lt;/a&gt;，如果成功，会从 PD 获取一个 &lt;code class=&quot;inline&quot;&gt;commitTS&lt;/code&gt; 用来执行 &lt;code class=&quot;inline&quot;&gt;commit&lt;/code&gt; 操作。取到了 &lt;code class=&quot;inline&quot;&gt;commitTS&lt;/code&gt; 之后，还需要做以下验证:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;commitTS&lt;/code&gt; 比 &lt;code class=&quot;inline&quot;&gt;startTS&lt;/code&gt; 大&lt;/li&gt;&lt;li&gt;schema 没有过期&lt;/li&gt;&lt;li&gt;事务的执行时间没有过长&lt;/li&gt;&lt;li&gt;如果没有通过检查，事务会失败报错。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过检查之后，执行最后一步 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L620&quot;&gt;commitKeys&lt;/a&gt;，如果没有错误，事务就提交完成了。&lt;/p&gt;&lt;p&gt;当 &lt;code class=&quot;inline&quot;&gt;commitKeys&lt;/code&gt; 请求遇到了网络超时，那么这个事务是否已经提交是不确定的，这时候不能执行 &lt;code class=&quot;inline&quot;&gt;cleanupKeys&lt;/code&gt; 操作，否则就破坏了事务的一致性。我们对这种情况返回一个特殊的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L625&quot;&gt;undetermined error&lt;/a&gt;，让上层来处理。上层会在遇到这种 error 的时候，把连接断开，而不是返回给用一个执行失败的错误。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L533&quot;&gt;prewriteKeys&lt;/a&gt;,  &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L537&quot;&gt;commitKeys&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L541&quot;&gt;cleanupKeys&lt;/a&gt; 有很多相同的逻辑，需要把 keys 根据 region 分成 batch，然后对每个 batch 执行一次 RPC。&lt;/p&gt;&lt;p&gt;当 RPC 返回 region 过期的错误时，我们需要把这个 region 上的 keys 重新分成 batch，发送 RPC 请求。&lt;/p&gt;&lt;p&gt;这部分逻辑我们把它抽出来，放在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L191&quot;&gt;doActionOnKeys&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L239&quot;&gt;doActionOnBatches&lt;/a&gt; 里，并实现 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L319&quot;&gt;prewriteSinlgeBatch&lt;/a&gt;，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L421&quot;&gt;commitSingleBatch&lt;/a&gt;，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L497&quot;&gt;cleanupSingleBatch&lt;/a&gt; 函数，用来执行单个 batch 的 RPC 请求。&lt;/p&gt;&lt;p&gt;虽大部分逻辑是相同的，但是不同的请求在执行顺序上有一些不同，在 &lt;code class=&quot;inline&quot;&gt;doActionOnKeys&lt;/code&gt; 里需要特殊的判断和处理。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;prewrite&lt;/code&gt; 分成的多个 batch 需要同步并行的执行。&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;commit&lt;/code&gt; 分成的多个 batch 需要先执行第一个 batch，成功后再异步并行执行其他的 batch。&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;cleanup&lt;/code&gt; 分成的多个 batch 需要异步并行执行。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L239:29&quot;&gt;doActionOnBatches&lt;/a&gt; 会开启多个 goroutines 并行的执行多个 batch，如果遇到了 error，会把其他正在执行的 &lt;code class=&quot;inline&quot;&gt;context cancel&lt;/code&gt; 掉，然后返回第一个遇到的 error。&lt;/p&gt;&lt;p&gt;执行 &lt;code class=&quot;inline&quot;&gt;prewriteSingleBatch&lt;/code&gt; 的时候，有可能会遇到 region 分裂错误，这时候 batch 里的 key 就不再是一个 region 上的 key 了，我们会在这里递归的调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.2/store/tikv/2pc.go#L352&quot;&gt;prewriteKeys&lt;/a&gt;，重新走一遍拆分 batch 然后执行 &lt;code class=&quot;inline&quot;&gt;doActionOnBatch&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;prewriteSingleBatch&lt;/code&gt; 的流程。这部分逻辑在 &lt;code class=&quot;inline&quot;&gt;commitSingleBatch&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;cleanupSingleBatch&lt;/code&gt; 里也都有。&lt;/p&gt;&lt;p&gt;twoPhaseCommitter 包含的逻辑只是事务模型的一小部分，主要的逻辑在 tikv-server 端，超出了这篇文章的范围，就不在这里详细讨论了。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;更多 TiDB 源码阅读系列文章详见：&lt;a href=&quot;http://pingcap.com/blog-cn/#%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB&quot;&gt;Blog-cns&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-27-45475314</guid>
<pubDate>Thu, 27 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 集群版本的安全迁移</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-22-45144603.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45144603&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3bc0f0e99ad335bf0ff6992419402210_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：陈书宁&lt;/p&gt;&lt;h2&gt;&lt;b&gt;问题描述&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 TiDB 的产品迭代中，不免会碰到一些兼容性问题出现。通常协议上的兼容性 protobuf 已经能帮我们处理的很好，在进行功能开发，性能优化时，通常会保证版本是向后兼容的，但并不保证向前兼容性，因此，当集群中同时有新旧版本节点存在时，旧版本不能兼容新版本的特性，就有可能造成该节点崩溃，影响集群可用性，甚至丢失数据。目前在有不兼容的版本升级时，会要求进行离线升级，但这会影响到服务，我们需要一个适合的机制来进行不停服务的升级。因此我们需要在进行滚动升级时，让这些不能保证整个集群的向后兼容性的功能不被启用。只有在保证集群中所有节点都已经升级完成后，我们才安全的启用这些功能。&lt;/p&gt;&lt;p&gt;常见的当我们对引入新的 &lt;code class=&quot;inline&quot;&gt;RaftCommand&lt;/code&gt; 的时候，旧版本的 TiKV 并不能识别新的添加的 &lt;code class=&quot;inline&quot;&gt;RaftCommand&lt;/code&gt;，对于不能认知的 &lt;code class=&quot;inline&quot;&gt;RaftCommand&lt;/code&gt; TiKV 有不同的处理，可能会报错退出或忽略。比如为了支持 Raft Learner, 在 raftpb 里对添加新的 ConfChange 类型。 当 PD 在进行 Region 调度时，会先发送 &lt;code class=&quot;inline&quot;&gt;AddLearner&lt;/code&gt; 到 TiKV 上，接受到这个命令的肯定是这个 Region 的 Leader，在进行一系列检查后，会将该命令 Proposal, 而 Follwer 如果是旧版本的话，在 Apply 这条 Command 就会出错。而在滚动升级时，很有可能存在 Leader 是新版本，Follwer 是老版本的情况。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;引入版本检查机制&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的版本定义是遵循 Semver 的版本规则的。版本格式一般由主版本号（Major），次版本号（Minor），修订号（Patch），版本号递增规则如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;主版本号：当进行了不兼容的 API 修改。&lt;/li&gt;&lt;li&gt;次版本号：当做了向下兼容的功能性新增。&lt;/li&gt;&lt;li&gt;修订号：当做了向下兼容的问题修正。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;先行版本号（PreRelase）及版本编译信息可以加到“主版本号.次版本号.修订号”的后面，作为延伸。比如 TiDB 目前的版本是 2.1.0-beta，先行版号为 beta 版。&lt;/p&gt;&lt;p&gt;在此之前，集群并没有版本的概念，虽然每个组件都有各自的版本信息，但各个节点的各自组件的版本都可以任意的。没有一个管理机制可以管理或查看所有组件的版本信息。为了解决滚动升级过程中存在多个版本的兼容性问题，这里引入集群版本的概念，并由 TiDB 集群的中心节点 PD 来进行管理和检查。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;具体实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1.升级集群&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 PD 中，会设置一个 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 的键值对，对应当前运行集群中 TiKV 节点中最旧的版本。也就是必须要兼容这个版本， 因此不能打开集群中其他新版本的节点的一些不兼容的特性。&lt;/p&gt;&lt;p&gt;在集群启动的时候，每个 TiKV 都需要向 PD 注册，注册时会带上版本信息。当当前 TiKV 的版本低于集群版本的时候，该 TiKV 会注册失败。因为此时集群的版本已经是更高的版本了，而加入旧版本的节点需要对旧版本进行兼容，为了防止已有的特性降级，直接拒绝不兼容的版本加入，目前默认主版本号和此版本号一样则为兼容的版本。&lt;/p&gt;&lt;p&gt;如果 TiKV 的版本高于或等于当前的 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 时， TiKV 能够注册成功并成功启动。每次注册都会触发 PD 的一次检查，会检测当前集群中正常运行的 TiKV 的最低版本，并与当前的 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 进行比对，如果最低版本比 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 更加新，则将 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 更新。因此每次滚动升级的时候，能够自动更新集群的版本。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 版本特性的开启&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 很多功能是需要 PD 的参与，目前这些新功能的开启也是通过 PD 进行控制的。在 PD 中，会将每个版本新特性记录下来，在 TiKV 2.0 中，对应有 Raft Leaner， Region Merge。 TiKV 2.1 中有 Batch Split，Joint Consensus 等。这些特性都需要 PD 的参与与控制。比如说 Add Leaner，Region Merge，Joint Consensus 需要 PD 下发调度给 TiKV，Batch Split 则是 TiKV 主动发起并请求 PD 分配新的 Region ID。因此这些功能都是能通过 PD 进行控制的。PD 会通过比对当前的集群版本，选择开启当前集群版本所支持的新特性。从而保证版本的兼容性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 集群回滚&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当升级完成后，如果遇到问题需要进行集群进行回滚时， 需要手动修改集群版本后。PD 提供了 pdctl 可以通过命令手动修改集群的 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt;，这时旧版本的 TiKV 就能注册并启动，从而进行回滚。&lt;/p&gt;&lt;p&gt;PD 对 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 是通过 etcd 进行了持久化，在每次 PD 启动的时候，leader 都会从 etcd kv 中加载出 &lt;code class=&quot;inline&quot;&gt;clustrer_version&lt;/code&gt;，然后提供服务。从而保证在 PD leader 切换后 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt; 的一致性。另外 PD 本身的版本可能会小于当前 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt;。因此在滚动升级的时候，需要先升级 PD，如果只升级了 TiKV，虽然 &lt;code class=&quot;inline&quot;&gt;cluster_version&lt;/code&gt;已经更新到新的版本的，但 PD 并不能开启新的功能，因为对它来说是不支持的。如果出现这种情况，PD 的日志中会有报警。在升级的时候，最好按 PD，TiKV，TiDB 的顺序逐一对各个组件。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;后续计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面提到的新功能特性一般都是需要 PD 参与的。而有些特性不需要PD的参与，因此需要保证这种特性在 TiKV 之间是可以兼容的，实现的时候可以采用类是 &lt;code class=&quot;inline&quot;&gt;http2 &amp;lt;-&amp;gt; http&lt;/code&gt; 的方式，对请求进行降级装发，保留两套接口等。另为 TiDB 目前是自身保证可以无缝兼容，但与 TiKV 可能存在兼容性问题，往后同样考虑让TiDB 也在 PD上进行注册。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-22-45144603</guid>
<pubDate>Sat, 22 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在爱奇艺的应用及实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-21-45078083.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45078083&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d6f3202173d72ff80b810466ed58c39_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;爱奇艺，中国高品质视频娱乐服务提供者，2010 年 4 月 22 日正式上线，推崇品质、青春、时尚的品牌内涵如今已深入人心，网罗了全球广大的年轻用户群体，积极推动产品、技术、内容、营销等全方位创新。企业愿景为做一家以科技创新为驱动的伟大娱乐公司。我们在前沿技术领域也保持一定的关注度。&lt;br&gt;&lt;br&gt;随着公司业务的快速发展，原来普遍使用的 MySQL 集群遇到了很多瓶颈，比如单机 MySQL 实例支撑的数据量有限，只能通过不停删除较旧的数据来维持数据库的运转。同时单表的数据行数不断增大导致查询速度变慢。急需一种可扩展、高可用同时又兼容 MySQL 访问方式的数据库来支撑业务的高速发展。&lt;br&gt;&lt;br&gt;我司从 2017 年年中开始调研 TiDB，并且在数据库云部门内部系统中使用了 TiDB 集群。从今年 TiDB 推出 2.0 之后，TiDB 愈发成熟，稳定性与查询效率都有很大提升。今年陆续接入了边控中心、视频转码、用户登录信息等几个业务，这几个业务背景和接入方式如下详述。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;项目介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 边控中心&lt;/b&gt;&lt;/p&gt;&lt;p&gt;边控中心存储的是机器的安全统计信息，包括根据 DC、IP、PORT 等不同维度统计的流量信息。上层业务会不定期做统计查询，其业务页面如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-15d28d946b829179d42b8620b349debc_r.jpg&quot; data-caption=&quot;图 1 边控中心上层业务页面（一）&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;452&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-15d28d946b829179d42b8620b349debc&quot; data-watermark-src=&quot;v2-7b9ea19dfc7d3397f0bab3d27e03cb93&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2c4de3f6fcc83f7ea9a62dc54d638216_r.jpg&quot; data-caption=&quot;图 2 边控中心上层业务页面（二）&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;450&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2c4de3f6fcc83f7ea9a62dc54d638216&quot; data-watermark-src=&quot;v2-e5e6c3b09be14fc25b72696dfb9ad41d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;在选型过程中，也考虑过时序型数据库 Apache Druid（http://druid.io），但是 Druid 聚合查询不够灵活，最终放弃 Druid 选择了 TiDB 数据库。TiDB 几乎完全兼容 MySQL 的访问协议，可以使用现有的 MySQL 连接池组件访问 TiDB，业务迁移成本低，开发效率高。&lt;/p&gt;&lt;p&gt;边控中心是爱奇艺第一个在线业务使用 TiDB 的项目，所以我们制定了详细的上线计划。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一，部署单独的 TiDB 集群。然后，为了数据安全，部署了 TokuDB 集群，用作 TiDB 集群的备份数据库。&lt;/li&gt;&lt;li&gt;第二，我们通过 TiDB-Binlog 将 TiDB 集群的数据变更实时同步到 TokuDB 集群中，作为 TiDB 的灾备方案。&lt;/li&gt;&lt;li&gt;第三，前端部署了自研的负载均衡中间件，以最大化利用多个 TiDB 节点的计算能力，同时保证 TiDB 节点的高可用。&lt;/li&gt;&lt;li&gt;第四，部署 Prometheus 和 Grafana 监控 TiDB 集群健康状况，同时 Grafana 接入了公司的告警平台，会及时将告警信息通过短信、邮件等方式通知到运维值班同事。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;边控中心上线过程中，也遇到了一些问题，都比较顺利的解决了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最常见的问题是连接超时。经过仔细排查发现是统计信息严重过时导致执行计划无法选择最优解造成的，这个问题其实是关系型数据库普遍存在的问题，普遍的解决思路是手工进行统计信息收集，或者通过 hint 的方式来固定执行计划，这两种方式对使用者都有一定的要求，而最新版本的 TiDB 完善了统计信息收集策略，比如增加了自动分析功能，目前这个问题已经解决。&lt;/li&gt;&lt;li&gt;还遇到了加索引时间较长的问题。这一方面是由于 DDL 执行信息更新不及时，造成查询 DDL 进度时看到的是滞后的信息。另一方面是由于有时会存在 size 过大的 Region，导致加索引时间变长。这个问题反馈给 PingCAP 官方后得到比较积极的响应，大 Region 已经通过增加 Batch split 等功能在新版的 TiDB 中修复了。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;边控中心上线以后，在不中断业务的情况下成功做过版本升级，修改 TiKV 节点内部参数等操作，基本对业务没有影响。在升级 TiKV 节点过程中会有少量报错，如“region is unvailable[try again later]、tikv server timeout”等。这是由于缓存信息滞后性造成的，在分布式系统中是不可避免的，只要业务端有重试机制就不会造成影响。&lt;/p&gt;&lt;p&gt;边控中心上线以后，数据量一直在稳定增长，但查询性能保持稳定，响应时间基本保持不变，能做到这点殊为不易，我个人的理解，这个主要依赖 TiDB 底层自动分片的策略，TiDB 会根据表数据量，按照等长大小的策略（默认 96M）自动分裂出一个分片，然后通过一系列复杂的调度算法打散到各个分布式存储节点上，对一个特定的查询，不管原表数据量多大，都能通过很快定位到某一个具体分片进行数据查询，保证了查询响应时间的稳定。&lt;/p&gt;&lt;p&gt;边控中心数据量增长情况如下：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bd4d272c646f0101976b275af7fce2f1_r.jpg&quot; data-caption=&quot;图 3 边控中心数据量增长情况&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;300&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bd4d272c646f0101976b275af7fce2f1&quot; data-watermark-src=&quot;v2-0d25d4f2f5e63ae12c69de8980bbdc2b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;TiDB 底层自动分片策略：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9ef0617a97f8882565939b6e988fa9db_r.jpg&quot; data-caption=&quot;图 4 TiDB 底层自动分片策略&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;390&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-9ef0617a97f8882565939b6e988fa9db&quot; data-watermark-src=&quot;v2-6f6ed608bed0599e79e20f89185e27e2&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;2. 视频转码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;视频转码业务是很早就接入 TiDB 集群的一个业务。视频转码数据库中主要存储的是转码生产过程中的历史数据，这些数据在生产完成后还需要进一步分析处理，使用 MySQL 集群时因为容量问题只好保留最近几个月的数据，较早的数据都会删掉，失去了做分析处理的机会。&lt;/p&gt;&lt;p&gt;针对业务痛点，在 2017 年年底部署了 TiDB 独立集群，并全量+增量导入数据，保证原有 MySQL 集群和新建 TiDB 集群的数据一致性。在全量同步数据过程中，起初采用 Mydumper+Loader 方式。Loader 是 PingCAP 开发的全量导入工具，但是导入过程总遇到导入过慢的问题，为解决这个问题，PingCAP 研发了 TiDB-Lightning 作为全量同步工具。TiDB-Lightning 会直接将导出的数据直接转化为 sst 格式的文件导入到 TiKV 节点中，极大的提高了效率，1T 数据量在 5-6 个小时内就能完成，在稳定运行一段时间后将流量迁移到了 TiDB 集群，并且扩充了业务功能，迄今稳定运行。&lt;/p&gt;&lt;p&gt;TiDB-Lightning 实现架构图：&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-27e095315c85adac271ea24948063dad_r.jpg&quot; data-caption=&quot;图 5 TiDB-Lightning 实现架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-27e095315c85adac271ea24948063dad&quot; data-watermark-src=&quot;v2-1e7d216f79633015a2d4b15ba598ff00&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;3. 用户登录信息&lt;/b&gt;&lt;/p&gt;&lt;p&gt;用户登录信息项目的数据量一直在稳定增长，MySQL 主备集群在不久的将来不能满足存储容量的需求。另外，由于单表数据量巨大，不得不在业务上进行分表处理，业务数据访问层代码变得复杂和缺乏扩展性。在迁移到 TiDB 后，直接去掉了分库分表，简化了业务的使用方式。另外，在 MySQL 中存在双散表并进行双写。在 TiDB 中进一步合并成了一种表，利用 TiDB 的索引支持多种快速查询，进一步简化了业务代码。&lt;/p&gt;&lt;p&gt;在部署增量同步的过程中使用了官方的 Syncer 工具。Syncer 支持通过通配符的方式将多源多表数据汇聚到一个表当中，是个实用的功能，大大简化了我们的增量同步工作。目前的 Syncer 工具还不支持在 Grafana 中展示实时延迟信息，这对同步延迟敏感的业务是个缺点，据官方的消息称已经在改进中，同时 PingCAP 他们重构了整个 Syncer，能自动处理分表主键冲突，多源同时 DDL 自动过滤等功能，总之通过这套工具，可以快速部署 TiDB “实时”同步多个 MySQL，数据迁移体验超赞。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d1610958e01bbddab6a46d66d3d36e11_r.jpg&quot; data-caption=&quot;图 6 Syncer 架构&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;531&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d1610958e01bbddab6a46d66d3d36e11&quot; data-watermark-src=&quot;v2-236621aba796853905372a8aa18c0655&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;在我们公司业务对数据库高可用有两个需求：一个是机房宕机了，服务仍然可用。另一个是，多机房的业务，提供本机房的只读从库，提升响应速度。针对这些不同的需求，TiDB 集群采用了多机房部署的方式，保证其中任一个机房不可用时仍然正常对外提供服务（如下图）。对每个 TiKV 节点设置 label 后，TiDB 集群在每个机房都有一份数据的副本，PD 集群会自动调度到合适的副本进行读操作，也可以满足第二个要求。为了满足迁移过程中的高可用性，会在流量迁移完成后部署 TiDB 到 MySQL 的实时同步。Drainer 支持指定同步开始的时间戳，有力支持了反向同步功能。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f4cc9896480eb2192e3ed6cf8c798d72_r.jpg&quot; data-caption=&quot;图 7  TiDB 集群多机房部署形式&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;866&quot; data-rawheight=&quot;848&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f4cc9896480eb2192e3ed6cf8c798d72&quot; data-watermark-src=&quot;v2-fa9e101a090eec110df644e9b64743f7&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;在整个运维过程中，PingCAP 的小伙伴们提供了及时的帮助，帮助我们定位问题并提出建议，保证了业务的有序运行。在此表示由衷的感谢！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;适用范围&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在实践过程中感受到 TiDB 解决的痛点主要是横向扩展和高可用。单机数据库支撑的数据量有限，如果采用分库分表 + proxy 的方式，无论 proxy 是在客户端还是服务端都增加了运维的成本。同时 proxy 的查询效率在很多场景下不能满足要求。另外，proxy 对事务的支持都比较弱，不能满足数据强一致性的要求。&lt;b&gt;TiDB 可以直接替代 proxy+MySQL 的架构，服务高可用性、数据高可用性、横向扩展性都由 TiDB 集群完成，完美解决了数据量增量情况下出现的很多问题。而且，TiDB 在数据量越大的情况下性能表现得比 MySQL 越惊艳。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一些改进建议&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;统计信息的收集期望更加的智能化，选择更好的时机自动完成而且不影响线上业务。&lt;/li&gt;&lt;li&gt;OLTP 和 OLAP 混合场景下相互间的隔离和尽量互不影响还有许多工作值得推进。&lt;/li&gt;&lt;li&gt;一些外围工具还需要提供高可用特性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;未来计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我司仍有其它业务在接入 TiDB 服务，目前正在评估测试中。一些业务场景是 OLTP+OLAP 混合的场景，TiSpark 正好可以大展身手。目前在测试集群发现 TiSpark 查询时对 OLTP 业务的影响还是比较大的，必须限制 TiSpark 对 TiDB 集群造成的压力。还部署了单独 TiDB 集群做 OLAP 场景的测试，对内部参数做了针对性的优化。未来计划会继续加大对 TiDB 的投入，贡献一些 PR 到社区，其中很大的一部分工作是增强 TiDB-Binlog 的功能，和现有的一些数据同步组件整合起来，支持 TiDB 到 Kudu、HBase 等的同步。&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;作者：朱博帅，爱奇艺资深数据库架构师&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-21-45078083</guid>
<pubDate>Fri, 21 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP 完成 C 轮 5000 万美元融资</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-12-44322174.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/44322174&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-11fb7be39efa3b3e40af9addc6780530_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;近日，新型分布式关系型数据库公司 PingCAP 宣布完成 5000 万美元 C 轮融资，这是目前为止新型分布式关系型数据库领域的最大笔融资。本轮融资由复星、晨兴资本领投，华创资本、云启资本、经纬中国等多家投资机构跟投，将主要用于技术研发和全球化生态系统建设。&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-11fb7be39efa3b3e40af9addc6780530_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2210&quot; data-rawheight=&quot;1266&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-11fb7be39efa3b3e40af9addc6780530&quot; data-watermark-src=&quot;v2-09412e37d5508a38e75aabc1e07680a6&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;PingCAP 成立于 2015 年，是面向全球的开源的新型分布式关系型数据库公司，其核心产品 TiDB 项目是基础软件领域的重大创新，实现了水平弹性伸缩、分布式事务、强一致性的多副本数据安全、实时 OLAP 等重要特性，是大数据时代理想的数据库集群和云数据库解决方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;真正落地的 HTAP 融合型通用数据库&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;TiDB 作为一款定位于 HTAP（Hybrid Transactional/Analytical Processing）的融合型通用数据库产品，很早就开始尝试融合 OLTP 和 OLAP 的边界。互联网背景出身的 PingCAP 创始团队的每名成员，都经历过数据指数级增长的时期，具备处理海量数据的经验，这让 TiDB 在满足 OLTP 分布式性能的基础上融合了有场景意义的 OLAP 性能。目前 TiDB 已演进为一套技术栈，既能解决用户业务快速增长过程中海量数据存储、超大规模并发访问问题，又能支持复杂的实时查询分析，极大的提高了用户生产力。&lt;/p&gt;&lt;p&gt;尤其面对风险控制要求更高的金融行业，TiDB 表现出了架构的先进性和高效的性能，水平扩展能力、交易处理能力、功能指标特性均在应用中具备较大的优势，被成功应用在金融核心交易场景中。PingCAP 目前已经成为一家在互联网领域和传统金融领域均有大规模落地的新型分布式数据库公司。&lt;/p&gt;&lt;p&gt;截止目前 TiDB 已有准生产测试（POC）用户 1400 余家，其中 300 余家企业已经将其应用在实际生产环境中，涉及互联网、游戏、银行、证券、保险、第三方支付、政府、电信、航空、制造业、新零售、快消等多个领域。此外，还与国内外多家主流的大型公有云厂商深度集成，提供公有云数据库服务。&lt;/p&gt;&lt;p&gt;复星新技术与新经济产业集团副总裁丛永罡说：“在 PingCAP 持续 3 年的产品打磨和不断实践验证后，TiDB 成为早期将 HTAP 这个概念从实验室带到现实的产品之一。其 TiDB 开源项目获得业内高度认可，并已将国内大多数互联网独角兽企业揽为用户，这具有里程碑式的意义，也是业内高度认可的体现。”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;进一步构建全球化生态体系&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;作为一款基础设施领域的明星级开源项目，TiDB 项目目前在 GitHub 上拥有 15000+ 的 Star，集合了 200 多位 Contributor，入选 CNCF Cloud Native Landscape， 2018 Big Data &amp;amp; AI Landscape。此外， Databricks、Mobike、SpeedyCloud、韩国三星研究院等机构人员也已参与到 TiDB 项目的合作开发中，全球顶级云计算技术基金会 CNCF 也于 8 月 28 日正式接纳 TiDB 项目核心组件之一 TiKV 为基金会项目，TiDB 在全球技术社区的影响力开始爆发。&lt;/p&gt;&lt;p&gt;回顾 PingCAP 的发展历史，用 3 年时间逐步打造产品和布局，以稳健的产品表现及高速的公司发展获得业界瞩目。PingCAP 联合创始人、CEO 刘奇表示，作为一家技术驱动为核心的公司，PingCAP 从创立的第一天起，就专注于解决大数据和云计算时代的海量存储和计算问题，我们将持续保持技术驱动的内核和开源的生命力，不断强化技术和产品优势，为行业带来更多期待。&lt;/p&gt;&lt;p&gt;晨兴资本副总裁刘凯表示：“一直以来，数据库领域都是产品研发能力和商业运营能力的最高级竞技场，PingCAP 持续深耕互联网领域客户，取得了骄人业绩，已成为规模互联网企业和金融企业的主流选择，我们很高兴能够和公司一起成长，共同打造开源软件生态。”&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://pingcap.com/&quot;&gt;PingCAP&lt;/a&gt; 此前曾在 2015 年获得经纬中国的天使轮融资，2016 年获得云启资本领投 A 轮融资，2017 年获得华创资本领投 B 轮融资。2018 年获得复星、晨兴资本领投的 C 轮融资，成为目前为止新型分布式关系型数据库领域的最大笔融资。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-12-44322174</guid>
<pubDate>Wed, 12 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP 2019 校园招聘全面启动</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-11-44292776.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/44292776&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-810e53a9d8f2ecf7336f521243084f05_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;我们是谁？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;以技术产品为驱动的全球化高科技公司；&lt;/li&gt;&lt;li&gt;工程师文化，技术极客的摇篮，ACMer 的聚集地；&lt;/li&gt;&lt;li&gt;挑战计算机科学前沿、工程难度极高的分布式数据库领域&lt;/li&gt;&lt;li&gt;服务于 1000+ 国内外企业，用户覆盖众多国内外独角兽公司&lt;/li&gt;&lt;li&gt;开源理念坚定践行者，TiDB 在 GitHub 上拥有 200+ Contributors、14000+ Stars&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;PingCAP 发展大事记&lt;/b&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-937f01a1eb8603212760ce66964b3c11_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;980&quot; data-rawheight=&quot;615&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-937f01a1eb8603212760ce66964b3c11&quot; data-watermark-src=&quot;v2-4a95b150a60d690babcbf0516c40893d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;典型用户&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;核心产品 TiDB 在生产环境使用超过 200 家，覆盖互联网、游戏、金融、电信、航空、国家部委、制造业、新零售、快消等行业&lt;/li&gt;&lt;li&gt;典型用户：北京银行、饿了么、今日头条、美团、摩拜单车、去哪儿、同程旅游、转转等&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;校招日历&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;9月上旬-10月中旬：投递简历&lt;/li&gt;&lt;li&gt;9月中旬-10月上旬：线下交流会&lt;/li&gt;&lt;li&gt;9月中旬-10月下旬：笔试 &amp;amp; 面试&lt;/li&gt;&lt;li&gt;10月上旬-10月下旬：Offer 发放&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;为什么选择我们&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;挑战分布式领域前沿技术的创新实现，追求个人技术视野和能力的极限&lt;/li&gt;&lt;li&gt;体验纯正的开源和工程师文化，感受 Gmail/GitHub/Slack/JIRA/Trello/Confluence 等协作工具的魅力碰撞&lt;/li&gt;&lt;li&gt;获得改变世界和创造未来的成就感&lt;/li&gt;&lt;li&gt;享受 One-on-One Mentoring 培养方式，为你定制化个人成长路线&lt;/li&gt;&lt;li&gt;加入国际化的发展舞台，北京、上海、杭州、广州、深圳、成都、硅谷虚位以待！Remote 工作模式也别样精彩&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-63678390e72e2d93de56b5d83a212f7e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1500&quot; data-rawheight=&quot;1011&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-63678390e72e2d93de56b5d83a212f7e&quot; data-watermark-src=&quot;v2-8a6207dbe18e5041be114bd4c06a5b5d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;&lt;b&gt;我们需要这样的你&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;拥有快速学习的能力&lt;/li&gt;&lt;li&gt;对新事物充满好奇心&lt;/li&gt;&lt;li&gt;信仰并崇尚开源文化&lt;/li&gt;&lt;li&gt;有强烈的自我驱动力&lt;/li&gt;&lt;li&gt;Get things done, always&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;别犹豫，你就是我们苦苦寻找的那一个！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;在招职位&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;研发类&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Infrastructure Engineer（包括分布式存储、分布式计算、分布式调度、商业工具、SRE、Cloud 等方向）&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;非研发类&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;OPS Engineer&lt;/li&gt;&lt;li&gt;Technical Writer&lt;/li&gt;&lt;li&gt;Marketing Specialist&lt;/li&gt;&lt;li&gt;HR Management Trainee&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;i&gt;更多职位信息：&lt;a href=&quot;https://www.pingcap.com/recruit-cn/join/#positions&quot;&gt;https://www.pingcap.com/recruit-cn/join/#positions&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Ti 星人「推荐」通道&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;提到「推荐」，首先想到的是内推？NO! NO! NO! 在这里，「推荐」通道向全世界小伙伴开放！你可以成为最强伯乐，全局搜索你身边的 Ti 星人并推荐给我们，推荐成功，即有惊喜 Bonus 相送；也可以毛遂自荐，加入 PingCAP，成为改变世界的新力量！&lt;/li&gt;&lt;li&gt;&lt;b&gt;伯乐推荐邮件格式&lt;/b&gt;：[2019 校招伯乐] 学校-姓名-职位名-伯乐姓名-伯乐手机号&lt;/li&gt;&lt;li&gt;&lt;b&gt;毛遂自荐邮件格式&lt;/b&gt;：[2019 校招] 学校-姓名-职位名&lt;/li&gt;&lt;li&gt;&lt;b&gt;简历投递通道：&lt;u&gt;&lt;a href=&quot;mailto:hire@pingcap.com&quot;&gt;hire@pingcap.com&lt;/a&gt;&lt;/u&gt;&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-11-44292776</guid>
<pubDate>Tue, 11 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>使用 TiKV 构建分布式类 Redis 服务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-07-43959766.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43959766&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-828ba4512736d7f2cb3e6664c5fbf3b3_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘&lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是 Redis&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://redis.io/&quot;&gt;Redis&lt;/a&gt; 是一个开源的，高性能的，支持多种数据结构的内存数据库，已经被广泛用于数据库，缓存，消息队列等领域。它有着丰富的数据结构支持，譬如 String，Hash，Set 和 Sorted Set，用户通过它们能构建自己的高性能应用。&lt;/p&gt;&lt;p&gt;Redis 非常快，没准是世界上最快的数据库了，它虽然使用内存，但也提供了一些持久化机制以及异步复制机制来保证数据的安全。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Redis 的不足&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Redis 非常酷，但它也有一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;内存很贵，而且并不是无限容量的，所以我们不可能将大量的数据存放到一台机器。&lt;/li&gt;&lt;li&gt;异步复制并不能保证 Redis 的数据安全。&lt;/li&gt;&lt;li&gt;Redis 提供了 transaction mode，但其实并不满足 ACID 特性。&lt;/li&gt;&lt;li&gt;Redis 提供了集群支持，但也不能支持跨多个节点的分布式事务。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;所以有时候，我们需要一个更强大的数据库，虽然在延迟上面可能赶不上 Redis，但也有足够多的特性，譬如：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;丰富的数据结构&lt;/li&gt;&lt;li&gt;高吞吐，能接受的延迟&lt;/li&gt;&lt;li&gt;强数据一致&lt;/li&gt;&lt;li&gt;水平扩展&lt;/li&gt;&lt;li&gt;分布式事务&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;b&gt;为什么选择 TiKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;大约 4 年前，我开始解决上面提到的 Redis 遇到的一些问题。为了让数据持久化，最直观的做法就是将数据保存到硬盘上面，而不是在内存里面。所以我开发了 &lt;a href=&quot;https://github.com/siddontang/ledisdb&quot;&gt;LedisDB&lt;/a&gt;，一个使用 Redis 协议，提供丰富数据结构，但将数据放在 RocksDB 的数据库。LedisDB 并不是完全兼容 Redis，所以后来，我和其他同事继续创建了 &lt;a href=&quot;https://github.com/reborndb/reborn&quot;&gt;RebornDB&lt;/a&gt;，一个完全兼容 Redis 的数据库。&lt;br&gt;无论是 LedisDB 还是 RebornDB，因为他们都是将数据放在硬盘，所以能存储更大量的数据。但它们仍然不能提供 ACID 的支持，另外，虽然我们可以通过 &lt;a href=&quot;https://github.com/CodisLabs/codis&quot;&gt;codis&lt;/a&gt; 去提供集群的支持，我们也不能很好的支持全局的分布式事务。&lt;/p&gt;&lt;p&gt;所以我们需要另一种方式，幸运的是，我们有&lt;a href=&quot;https://github.com/pingcap/tikv&quot;&gt;TiKV&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;TiKV 是一个高性能，支持分布式事务的 key-value 数据库。虽然它仅仅提供了简单的 key-value API，但基于 key-value，我们可以构造自己的逻辑去创建更强大的应用。譬如，我们就构建了 &lt;a href=&quot;https://github.com/pingcap/tidb&quot;&gt;TiDB&lt;/a&gt; ，一个基于 TiKV 的，兼容 MySQL 的分布式关系型数据库。TiDB 通过将 database 的 schema 映射到 key-value 来支持了相关 SQL 特性。所以对于 Redis，我们也可以采用同样的办法 - 构建一个支持 Redis 协议的服务，将 Redis 的数据结构映射到 key-value 上面。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何开始&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-22f36db3ad8dd94b0d520e54185f28d7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;600&quot; data-rawheight=&quot;460&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-22f36db3ad8dd94b0d520e54185f28d7&quot; data-watermark-src=&quot;v2-f1bf888ee752ea16863a39c751e33f11&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;整个架构非常简单，我们仅仅需要做的就是构建一个 Redis 的 Proxy，这个 Proxy 会解析 Redis 协议，然后将 Redis 的数据结构映射到 key-value 上面。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Redis Protocol&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Redis 协议被叫做 &lt;a href=&quot;https://redis.io/topics/protocol&quot;&gt;RESP&lt;/a&gt;(Redis Serialization Protocol)，它是文本类型的，可读性比较好，并且易于解析。它使用 “rn” 作为每行的分隔符并且用不同的前缀来代表不同的类型。例如，对于简单的 String，第一个字节是 “+”，所以一个 “OK” 行就是 “+OKrn”。&lt;br&gt;大多数时候，客户端会使用最通用的 Request-Response 模型用于跟 Redis 进行交互。客户端会首先发送一个请求，然后等待 Redis返回结果。请求是一个 Array，Array 里面元素都是 bulk strings，而返回值则可能是任意的 RESP 类型。Redis 同样支持其他通讯方式：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Pipeline - 这种模式下面客户端会持续的给 Redis 发送多个请求，然后等待 Redis 返回一个结果。&lt;/li&gt;&lt;li&gt;Push - 客户端会在 Redis 上面订阅一个 channel，然后客户端就会从这个 channel 上面持续受到 Redis push 的数据。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下面是一个简单的客户端发送 &lt;code class=&quot;inline&quot;&gt;LLEN mylist&lt;/code&gt; 命令到 Redis 的例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;C: *2\r\n
C: $4\r\n
C: LLEN\r\n
C: $6\r\n
C: mylist\r\n

S: :48293\r\n&lt;/code&gt;&lt;p&gt;客户端会发送一个带有两个 bulk string 的 array，第一个 bulk string 的长度是 4，而第二个则是 6。Redis 会返回一个 48293 整数。正如你所见，RESP 非常简单，自然而然的，写一个 RESP 的解析器也是非常容易的。&lt;/p&gt;&lt;p&gt;作者创建了一个 Go 的库 &lt;a href=&quot;http://github.com/siddontang/goredis&quot;&gt;goredis&lt;/a&gt;，基于这个库，我们能非常容易的从连接上面解析出 RESP，一个简单的例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// Create a buffer IO from the connection.
br := bufio.NewReaderSize(conn, 4096)
// Create a RESP reader.
r := goredis.NewRespReader(br)
// Parse the Request
req := r.ParseRequest()&lt;/code&gt;&lt;p&gt;函数 &lt;code class=&quot;inline&quot;&gt;ParseRequest&lt;/code&gt; 返回一个解析好的 request，它是一个 &lt;code class=&quot;inline&quot;&gt;[][]byte&lt;/code&gt; 类型，第一个字段是函数名字，譬如 “LLEN”，然后后面的字段则是这个命令的参数。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiKV 事务 API&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在我们开始之前，作者将会给一个简单实用 TiKV 事务 API 的例子，我们调用 &lt;code class=&quot;inline&quot;&gt;Begin&lt;/code&gt; 开始一个事务：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;txn, err := db.Begin()&lt;/code&gt;&lt;p&gt;函数 &lt;code class=&quot;inline&quot;&gt;Begin&lt;/code&gt; 创建一个事务，如果出错了，我们需要判断 err，不过后面作者都会忽略 err 的处理。&lt;/p&gt;&lt;p&gt;当我们开始了一个事务之后，我们就可以干很多操作了：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;value, err := txn.Get([]byte(“key”))
// Do something with value and then update the newValue to the key.
txn.Put([]byte(“key”), newValue)&lt;/code&gt;&lt;p&gt;上面我们得到了一个 key 的值，并且将其更新为新的值。TiKV 使用乐观事务模型，它会将所有的改动都先缓存到本地，然后在一起提交给 Server。&lt;/p&gt;&lt;code lang=&quot;go&quot;&gt;// Commit the transaction
txn.Commit(context.TODO())&lt;/code&gt;&lt;p&gt;跟其他事务处理一样，我们也可以回滚这个事务：&lt;/p&gt;&lt;code lang=&quot;go&quot;&gt;txn.Rollback()&lt;/code&gt;&lt;p&gt;如果两个事务操作了相同的 key，它们就会冲突。一个事务会提交成功，而另一个事务会出错并且回滚。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;映射 Data structure 到 TiKV&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;现在我们知道了如何解析 Redis 协议，如何在一个事务里面做操作，下一步就是支持 Redis 的数据结构了。Redis 主要有 4 中数据结构：String，Hash，Set 和 Sorted Set，但是对于 TiKV 来说，它只支持 key-value，所以我们需要将这些数据结构映射到 key-value。&lt;/p&gt;&lt;p&gt;首先，我们需要区分不同的数据结构，一个非常容易的方式就是在 key 的后面加上 Type flag。例如，我们可以将 ’s’ 添加到 String，所以一个 String key “abc” 在 TiKV 里面其实就是 “abcs”。&lt;/p&gt;&lt;p&gt;对于其他类型，我们可能需要考虑更多，譬如对于 Hash 类型，我们需要支持如下操作：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;HSET key field1 value1
HSET key field2 value2
HLEN key&lt;/code&gt;&lt;p&gt;一个 Hash 会有很多 fields，我有时候想知道整个 Hash 的个数，所以对于 TiKV，我们不光需要将 Hash 的 key 和 field 合在一起变成 TiKV 的一个 key，也同时需要用另一个 key 来保存整个 Hash 的长度，所以整个 Hash 的布局类似：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;key + ‘h’ -&amp;gt; length
key + ‘f’ + field1 -&amp;gt; value
key + ‘f’ + field2 -&amp;gt; value &lt;/code&gt;&lt;p&gt;如果我们不保存 length，那么如果我们想知道 Hash 的 length，每次都需要去扫整个 Hash 得到所有的 fields，这个其实并不高效。但如果我们用另一个 key 来保存 length，任何时候，当我们加入一个新的 field，我们都需要去更新这个 length 的值，这也是一个开销。对于我来说，我倾向于使用另一个 key 来保存 length，因为 &lt;code class=&quot;inline&quot;&gt;HLEN&lt;/code&gt; 是一个高频的操作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;例子&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作者构建了一个非常简单的例子 &lt;a href=&quot;https://github.com/siddontang/redis-tikv-example&quot;&gt;example&lt;/a&gt; ，里面只支持 String 和 Hash 的一些操作，我们可以 clone 下来并编译：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;git clone https://github.com/siddontang/redis-tikv-example.git $GOPATH/src/github.com/siddontang/redis-tikv-example

cd $GOPATH/src/github.com/siddontang/redis-tikv-example
go build&lt;/code&gt;&lt;p&gt;在运行之前，我们需要启动 TiKV，可以参考&lt;a href=&quot;https://github.com/pingcap/tikv#deploying-to-production&quot;&gt;instruction&lt;/a&gt;，然后执行：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;./redis-tikv-example&lt;/code&gt;&lt;p&gt;这个例子会监听端口 6380，然后我们可以用任意的 Redis 客户端，譬如 &lt;code class=&quot;inline&quot;&gt;redis-cli&lt;/code&gt; 去连接：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;redis-cli -p 6380
127.0.0.1:6380&amp;gt; set k1 a
OK
127.0.0.1:6380&amp;gt; get k1
&quot;a&quot;
127.0.0.1:6380&amp;gt; hset k2 f1 a
(integer) 1
127.0.0.1:6380&amp;gt; hget k2 f1
&quot;a&quot;&lt;/code&gt;&lt;h2&gt;&lt;b&gt;尾声&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;现在已经有一些公司基于 TiKV 来构建了他们自己的 Redis Server，并且也有一个开源的项目&lt;a href=&quot;https://github.com/yongman/tidis&quot;&gt;tidis&lt;/a&gt; 做了相同的事情。&lt;code class=&quot;inline&quot;&gt;tidis&lt;/code&gt; 已经比较完善，如果你想替换自己的 Redis，可以尝试一下。&lt;br&gt;正如同你所见，TiKV 其实算是一个基础的组件，我们可以在它的上面构建很多其他的应用。如果你对我们现在做的事情感兴趣，欢迎联系我：&lt;a href=&quot;mailto:tl@pingcap.com&quot;&gt;tl@pingcap.com&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文发表于唐刘老师博客：&lt;a href=&quot;https://www.jianshu.com/p/b4dee8372d8d&quot;&gt;使用 TiKV 构建分布式类 Redis 服务&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-07-43959766</guid>
<pubDate>Fri, 07 Sep 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读（十八）tikv-client（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-09-06-43926052.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/43926052&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-828ba4512736d7f2cb3e6664c5fbf3b3_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：周昱行&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在整个 SQL 执行过程中，需要经过 Parser，Optimizer，Executor，DistSQL 这几个主要的步骤，最终数据的读写是通过 tikv-client 与 TiKV 集群通讯来完成的。&lt;br&gt;为了完成数据读写的任务，tikv-client 需要解决以下几个具体问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如何定位到某一个 key 或 key range 所在的 TiKV 地址？&lt;/li&gt;&lt;li&gt;如何建立和维护和 tikv-server 之间的连接？&lt;/li&gt;&lt;li&gt;如何发送 RPC 请求？&lt;/li&gt;&lt;li&gt;如何处理各种错误？&lt;/li&gt;&lt;li&gt;如何实现分布式读取多个 TiKV 节点的数据？&lt;/li&gt;&lt;li&gt;如何实现 2PC 事务？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们接下来就对以上几个问题逐一解答，其中 5、6 会在下篇中介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何定位 key 所在的 tikv-server&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们需要回顾一下之前 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-1/&quot;&gt;《三篇文章了解 TiDB 技术内幕——说存储》&lt;/a&gt; 。这篇文章中介绍过的一个重要的概念：Region。&lt;/p&gt;&lt;p&gt;TiDB 的数据分布是以 Region 为单位的，一个 Region 包含了一个范围内的数据，通常是 96MB 的大小，Region 的 meta 信息包含了 StartKey 和 EndKey 这两个属性。当某个 key &amp;gt;= StartKey &amp;amp;&amp;amp; key &amp;lt; EndKey 的时候，我们就知道了这个 key 所在的 Region，然后我们就可以通过查找该 Region 所在的 TiKV 地址，去这个地址读取这个 key 的数据。&lt;/p&gt;&lt;p&gt;获取 key 所在的 Region, 是通过向 PD 发送请求完成的。PD client 实现了这样一个接口：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/pd/pd-client/client.go#L49&quot;&gt;GetRegion(ctx context.Context, key []byte) (*metapb.Region, *metapb.Peer, error)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;通过调用这个接口，我们就可以定位这个 key 所在的 Region 了。&lt;/p&gt;&lt;p&gt;如果需要获取一个范围内的多个 Region，我们会从这个范围的 StartKey 开始，多次调用 &lt;code class=&quot;inline&quot;&gt;GetRegion&lt;/code&gt; 这个接口，每次返回的 Region 的 EndKey 做为下次请求的 StartKey，直到返回的 Region 的 EndKey 大于请求范围的 EndKey。&lt;/p&gt;&lt;p&gt;以上执行过程有一个很明显的问题，就是我们每次读取数据的时候，都需要先去访问 PD，这样会给 PD 带来巨大压力，同时影响请求的性能。&lt;/p&gt;&lt;p&gt;为了解决这个问题，tikv-client 实现了一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_cache.go#L50&quot;&gt;RegionCache&lt;/a&gt; 的组件，缓存 Region 信息， 当需要定位 key 所在的 Region 的时候，如果 RegionCache 命中，就不需要访问 PD 了。RegionCache 的内部，有两种数据结构保存 Region 信息，一个是 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_cache.go#L55&quot;&gt;map&lt;/a&gt;，另一个是 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_cache.go#L56&quot;&gt;b-tree&lt;/a&gt;，用 map 可以快速根据 region ID 查找到 Region，用 b-tree 可以根据一个 key 找到包含该 key 的 Region。&lt;/p&gt;&lt;p&gt;严格来说，PD 上保存的 Region 信息，也是一层 cache，真正最新的 Region 信息是存储在 tikv-server 上的，每个 tikv-server 会自己决定什么时候进行 Region 分裂，在 Region 变化的时候，把信息上报给 PD，PD 用上报上来的 Region 信息，满足 tidb-server 的查询需求。&lt;br&gt;当我们从 cache 获取了 Region 信息，并发送请求以后， tikv-server 会对 Region 信息进行校验，确保请求的 Region 信息是正确的。&lt;/p&gt;&lt;p&gt;如果因为 Region 分裂，Region 迁移导致了 Region 信息变化，请求的 Region 信息就会过期，这时 tikv-server 就会返回 Region 错误。遇到了 Region 错误，我们就需要&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_cache.go#L318&quot;&gt;清理 RegionCache&lt;/a&gt;，重新&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_cache.go#L329&quot;&gt;获取最新的 Region 信息&lt;/a&gt;，并重新发送请求。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何建立和维护和 tikv-server 之间的连接&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当 TiDB 定位到 key 所在的 tikv-server 以后，就需要建立和 TiKV 之间的连接，我们都知道， TCP 连接的建立和关闭有不小的开销，同时会增大延迟，使用连接池可以节省这部分开销，TiDB 和 tikv-server 之间也维护了一个连接池 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/client.go#L83&quot;&gt;connArray&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;TiDB 和 TiKV 之间通过 gRPC 通信，而 gPRC 支持在单 TCP 连接上多路复用，所以多个并发的请求可以在单个连接上执行而不会相互阻塞。&lt;/p&gt;&lt;p&gt;理论上一个 tidb-server 和一个 tikv-server 之间只需要维护一个连接，但是在性能测试的时候发现，单个连接在并发-高的时候，会成为性能瓶颈，所以实际实现的时候，tidb-server 对每一个 tikv-server 地址维护了多个连接，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/client.go#L159&quot;&gt;并以 round-robin 算法选择连接&lt;/a&gt;发送请求。连接的个数可以在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/config/config.toml.example#L215&quot;&gt;config&lt;/a&gt; 文件里配置，默认是 16。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何发送 RPC 请求&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;tikv-client 通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/kv.go#L127&quot;&gt;tikvStore&lt;/a&gt; 这个类型，实现 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/kv/kv.go#L247&quot;&gt;kv.Storage&lt;/a&gt; 这个接口，我们可以把 tikvStore 理解成 tikv-client 的一个包装。外部调用 &lt;code class=&quot;inline&quot;&gt;kv.Storage&lt;/code&gt; 的接口，并不需要关心 RPC 的细节，RPC 请求都是 tikvStore 为了实现 &lt;code class=&quot;inline&quot;&gt;kv.Storage&lt;/code&gt; 接口而发起的。&lt;/p&gt;&lt;p&gt;实现不同的 &lt;code class=&quot;inline&quot;&gt;kv.Storage&lt;/code&gt; 接口需要发送不同的 RPC 请求。比如实现 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/kv/kv.go#L233&quot;&gt;Snapshot.BatchGet&lt;/a&gt; 需要&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/kvproto/pkg/tikvpb/tikvpb.pb.go#L61&quot;&gt;tikvpb.TikvClient.KvBatchGet&lt;/a&gt;方法；实现 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/kv/kv.go#L128&quot;&gt;Transaction.Commit&lt;/a&gt;，需要 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/kvproto/pkg/tikvpb/tikvpb.pb.go#L57&quot;&gt;tikvpb.TikvClient.KvPrewrite&lt;/a&gt;, &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/kvproto/pkg/tikvpb/tikvpb.pb.go#L58&quot;&gt;tikvpb.TikvClient.KvCommit&lt;/a&gt; 等多个方法。&lt;/p&gt;&lt;p&gt;在 tikvStore 的实现里，并没有直接调用 RPC 方法，而是通过一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/client.go#L76&quot;&gt;Client&lt;/a&gt; 接口调用，做这一层的抽象的主要目的是为了让下层可以有不同的实现。比如用来测试的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/mockstore/mocktikv/rpc.go#L493&quot;&gt;mocktikv 就自己实现了 Client 接口&lt;/a&gt;，通过本地调用实现，并不需要调用真正的 RPC。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/client.go#L180&quot;&gt;rpcClient&lt;/a&gt; 是真正实现 RPC 请求的 Client 实现，通过调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/tikvrpc/tikvrpc.go#L419&quot;&gt;tikvrpc.CallRPC&lt;/a&gt;，发送 RPC 请求。&lt;code class=&quot;inline&quot;&gt;tikvrpc.CallRPC&lt;/code&gt; 再往下层走，就是调用具体&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/kvproto/pkg/tikvpb/tikvpb.pb.go#L152&quot;&gt;每个 RPC  生成的代码&lt;/a&gt;了，到了生成的代码这一层，就已经是 gRPC 框架这一层的内容了，我们就不继续深入解析了，感兴趣的同学可以研究一下 gRPC 的实现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何处理各种错误&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们前面提到 RPC 请求都是通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/client.go#L76&quot;&gt;Client&lt;/a&gt; 接口发送的，但实际上这个接口并没有直接被各个 tikvStore 的各个方法调用，而是通过一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_request.go#L46&quot;&gt;RegionRequestSender&lt;/a&gt; 的对象调用的。&lt;br&gt;&lt;code class=&quot;inline&quot;&gt;RegionRequestSender&lt;/code&gt; 主要的工作除了发送 RPC 请求，还要负责处理各种可以重试的错误，比如网络错误和部分 Region 错误。&lt;/p&gt;&lt;p&gt;&lt;b&gt;RPC 请求遇到的错误主要分为两大类：Region 错误和网络错误。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/tikvrpc/tikvrpc.go#L359&quot;&gt;Region  错误&lt;/a&gt; 是由 tikv-server 收到请求后，在 response 里返回的，常见的有以下几种:&lt;/p&gt;&lt;p&gt;1.&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/kvproto/pkg/errorpb/errorpb.pb.go#L207&quot;&gt;NotLeader&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种错误的原因通常是 Region 的调度，PD 为了负载均衡，可能会把一个热点 Region 的 leader 调度到空闲的 tikv-server 上，而请求只能由 leader 来处理。遇到这种错误就需要 tikv-client 重试，把请求发给新的 leader。&lt;/p&gt;&lt;p&gt;2. &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/kvproto/pkg/errorpb/errorpb.pb.go#L210&quot;&gt;StaleEpoch&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这种错误主要是因为 Region 的分裂，当 Region 内的数据量增多以后，会分裂成多个新的 Region。新的 Region 包含的 range 是不同的，如果直接执行，返回的结果有可能是错误的，所以 TiKV 就会拒绝这个请求。tikv-client 需要从 PD 获取最新的 Region 信息并重试。&lt;/p&gt;&lt;p&gt;3. &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/vendor/github.com/pingcap/kvproto/pkg/errorpb/errorpb.pb.go#L211&quot;&gt;ServerIsBusy&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这个错误通常是因为 tikv-server 积压了过多的请求处理不完，tikv-server 如果不拒绝这个请求，队列会越来越长，可能等到客户端超时了，请求还没有来的及处理。所以做为一种保护机制，tikv-server 提前返回错误，让客户端等待一段时间后再重试。&lt;/p&gt;&lt;p&gt;另一类错误是网络错误，错误是由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_request.go#L129&quot;&gt;SendRequest 的返回值&lt;/a&gt; 返回的 error 的，遇到这种错误通常意味着这个 tikv-server 没有正常返回请求，可能是网络隔离或 tikv-server down 了。tikv-client 遇到这种错误，会调用 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_request.go#L140&quot;&gt;OnSendFail&lt;/a&gt; 方法，处理这个错误，会在 RegionCache 里把这个请求失败的 tikv-server 上的&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/region_cache.go#L453&quot;&gt;所有 region 都 drop 掉&lt;/a&gt;，避免其他请求遇到同样的错误。&lt;br&gt;当遇到可以重试的错误的时候，我们需要等待一段时间后重试，我们需要保证每次重试等待时间不能太短也不能太长，太短会造成多次无谓的请求，增加系统压力和开销，太长会增加请求的延迟。我们用指数退避的算法来计算每一次重试前的等待时间，这部分的逻辑是在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/backoff.go#L176&quot;&gt;Backoffer&lt;/a&gt; 里实现的。&lt;/p&gt;&lt;p&gt;在上层执行一个 SQL 语句的时候，在 tikv-client 这一层会触发多个顺序的或并发的请求，发向多个 tikv-server，为了保证上层 SQL 语句的超时时间，我们需要考虑的不仅仅是单个 RPC 请求，还需要考虑一个 query 整体的超时时间。&lt;/p&gt;&lt;p&gt;为了解决这个问题，&lt;code class=&quot;inline&quot;&gt;Backoffer&lt;/code&gt; 实现了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/backoff.go#L267&quot;&gt;fork&lt;/a&gt; 功能， 在发送每一个子请求的时候，需要 fork 出一个 &lt;code class=&quot;inline&quot;&gt;child Backoffer&lt;/code&gt;，&lt;code class=&quot;inline&quot;&gt;child Backoffer&lt;/code&gt; 负责单个 RPC 请求的重试，它记录了 &lt;code class=&quot;inline&quot;&gt;parent Backoffer&lt;/code&gt; 已经等待的时间，保证总的等待时间，不会超过 query 超时时间。&lt;/p&gt;&lt;p&gt;对于不同错误，需要等待的时间是不一样的，每个 &lt;code class=&quot;inline&quot;&gt;Backoffer&lt;/code&gt; 在创建时，会&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/backoff.go#L96&quot;&gt;根据不同类型，创建不同的 backoff 函数&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;以上就是 tikv-client 上篇的内容，我们在下篇会详细介绍实现分布式计算相关的&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/coprocessor.go#L354&quot;&gt;copIterator&lt;/a&gt;&lt;/b&gt; &lt;b&gt;和实现分布式事务的&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://github.com/pingcap/tidb/blob/v2.1.0-rc.1/store/tikv/2pc.go#L66&quot;&gt;twoPCCommiter&lt;/a&gt;。&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-09-06-43926052</guid>
<pubDate>Thu, 06 Sep 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
