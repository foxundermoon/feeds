<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>编程语言与高级语言虚拟机杂谈（仮）</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/</link>
<description>探讨编程语言的设计与实现</description>
<language>zh-cn</language>
<lastBuildDate>Fri, 12 Oct 2018 17:30:51 +0800</lastBuildDate>
<item>
<title>考不上三本也能懂系列——处理声明（一）</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-10-04-45971898.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45971898&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3eef6665d6cb158c6d8c1677e11b18fd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;你现在所阅读的并不是第一篇文章，你可能想看&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25959684&quot;&gt;目录和前言&lt;/a&gt;。&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本来还想说一下怎么用正则表达式做C++词法分析的，因为raw string literal不能用正则表达式做。不过想来想去也没有什么好说的。总的来说，所有其他的token都可以被正则表达式表达，而raw string literal，我们只要把&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;R&quot;Fuck(&lt;/code&gt;&lt;p&gt;作为一个token，遇到这个token的时候写代码人肉扩展到&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;)Fuck&quot;&lt;/code&gt;&lt;p&gt;这里就好了。VLPP的词法分析和着色类支持这种做法，毫无压力。&lt;/p&gt;&lt;p&gt;C++的声明是很复杂，而且还很乱，相同的东西有无数种不同的写法，这不仅给使用者带来了困难，也给编译器作者带来了困难。Bjarne Stroustrup当初要兼容C语言当然是可以理解的，但是完全可以不需要兼容到这个份上的，很多语法完全可以在出现C++要素之后开始不兼容C语言。举个简单的例子，C语言是可以这么写的&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;typedef struct
{
  int bitch;
} Fuck;&lt;/code&gt;&lt;p&gt;但是一旦你添加了C++要素，譬如说&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;typedef struct
{
  int bitch;
  string shit;
} Fuck;&lt;/code&gt;&lt;p&gt;马上报错（typedef和struct不要这么组合使用），没什么不好的。最后给语言加上一个不兼容的开关，好让大多数有洁癖的人使用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;阅读C++声明（一）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;C++有别于其他所有语言，它的语法结构并不反映抽象语法树的结构。譬如说我们一般认为类里面有变量和函数和嵌套类型生命，但是当你写C++语法分析器的时候，不能这么想。变量和函数其实是一个东西，当你做完语法分析之后，看看到底这个狗东西是什么类型，才决定他是变量还是函数。MSDN给这个狗东西起了个名字叫Declarator。&lt;/p&gt;&lt;p&gt;一般来说，一个C++的变量或者函数，或者是typedef后面的那一段，或者是所有可以临时声名名字的东西（如函数参数，if、for、switch里面的“变量条件”等），都包含Declarator。当然它本身不是Declarator，它的结构是这样的：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;Type Declarator1 [Initializer], Declarator2 [Initializer] ...&lt;/code&gt;&lt;p&gt;呵呵呵&lt;/p&gt;&lt;p&gt;这是什么意思呢？让我们来看下面的这行C++代码：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int const fuck {0}, *shit = nullptr;&lt;/code&gt;&lt;p&gt;那么对应到上面的结构就是&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;Type = &quot;int const&quot;
Declarator1 = &quot;fuck&quot;
    Initializer = &quot;{0}&quot;
Declarator2 = &quot;*shit&quot;
    Initializer = &quot;= nullptr&quot;&lt;/code&gt;&lt;p&gt;简单易懂。如果是函数指针的话也一样：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int (__stdcall *fuck)(int);

Type = &quot;int&quot;
Declarator1 = &quot;(__stdcall *fuck)(int)&quot;&lt;/code&gt;&lt;p&gt;需要注意的是，根据Declarator出现的不同的地方，它是可以有名字或者没有名字，也可以有初始化结构或者没有。譬如说我们定义一个类型：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;using Fuck = int(*)(int);
typedef int(*Fuck)(int);&lt;/code&gt;&lt;p&gt;这两行代码其实是一样的，他们拆开分别就是&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;Type = &quot;int&quot;
Declrator1 = &quot;(*)(int)&quot;&lt;/code&gt;&lt;p&gt;和&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;Type = &quot;int&quot;
Declarator1 = &quot;(*Fuck)(int)&quot;&lt;/code&gt;&lt;p&gt;简单易懂。所以我们写C++语法分析器的时候，不要把声明和类型割裂地看，而是在当成这种结构一顿parse之后，再来看看这棵树是否符合要求。举个简单的例子，下面的代码就是错误的，因为函数和变量不能一起出现在同一个声明里：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int fuck, Shit(int x);&lt;/code&gt;&lt;p&gt;在语法分析的时候我们不管这个东西，分析完了再来看，发现一个是变量，一个是函数，果断糊用户一脸。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;阅读C++声明（二）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;弄明白了大概的做法之后，就可以看一下比较细节的东西。首先这个Declarator可以嵌套，而且括号可以随便加，也就是说下面的两行代码其实是一个意思：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int Fuck(int);
int ((((((((((Fuck))))))))))(int);&lt;/code&gt;&lt;p&gt;但是函数和数组这两种Declarator不能嵌套，譬如说下面这行代码是不行的：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int (Fuck(int))[10];&lt;/code&gt;&lt;p&gt;当然道理很简单，因为函数类型不能是值，函数指针类型才可以。同理函数和函数也不能嵌套，但是数组和数组可以，也就是说下面的两行代码其实是一个意思：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int a[1][2];
int (a[1])[2];&lt;/code&gt;&lt;p&gt;简单易懂。总的来说，只要用于修饰数组或者函数的Declarator不是一个名字而是更复杂的东西的话，括号就必须加上。这条规定是用来破除歧义的。举个简单的例子，我们可以写一个函数指针类型：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int (*fuck)(int);&lt;/code&gt;&lt;p&gt;因为*是用来修饰函数的，而且*fuck“不是一个名字而是更复杂的东西”，所以必须加括号。如果不这样的话，你就分辨不了到底&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int*fuck(int);&lt;/code&gt;&lt;p&gt;到底是一个函数还是一个变量了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;阅读C++声明（三）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;弄明白了这件事情之后，我们就可以轻松脑内解读各种超复杂C++声明了。关键是不要把类型和定义割裂开。类型只是一个没有名字的定义。就算是最简单的：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int&lt;/code&gt;&lt;p&gt;其实它真正要表达的事情是：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int &amp;lt;名字不知道哪里去了&amp;gt;&lt;/code&gt;&lt;p&gt;而控制名字该不该出现，该不该有很多个的，是这个代码放在哪里，而不是这个代码想要表达什么内容。举几个简单的例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;变量&lt;/b&gt;：名字就是必须的，而且可以有很多个。当然VC++允许你直接写“int;”，然后它会给你一个warning。&lt;/li&gt;&lt;li&gt;&lt;b&gt;函数参数&lt;/b&gt;：名字就不是必须的。特别是在函数声明（指的是没有函数体）而不是定义的时候，那个名字根本就没有用。&lt;/li&gt;&lt;li&gt;&lt;b&gt;需要类型的地方&lt;/b&gt;：名字是不能出现的，最简单的有一个类的父类，你不能写“struct Fuck : Shit s {};”你也不能写“Fuck&amp;lt;Shit s&amp;gt;”。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;看到这里，相信大家已经完全学会如何阅读C++声明了。完整的内容参见这里：&lt;a href=&quot;https://docs.microsoft.com/en-us/cpp/cpp/overview-of-declarators&quot;&gt;Overview of Declarators&lt;/a&gt; 。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;阅读C++声明（四）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;那上面Type和Declarator1的分界线到底在哪里呢？其实很简单，只要你分析Type一路下去，直到看到左括号、左方括号、左大括号、一个名字的时候，你就知道Type已经到头了。这个符号将作为Declarator1的第一个符号开始被分析。Type本身是不嵌套的，只是一个简单的左递归，写起来特别爽。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;动手写语法分析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;了解到这个份上，剩下的事情也就是熟练运用你们学过的编译原理的内容。在我的项目里面，对这部分声明做语法分析的地方是在这里：&lt;a href=&quot;https://github.com/vczh-libraries/Document/blob/master/Tools/CppDoc/Core/Source/Parser_Declarator.cpp#L816&quot;&gt;https://github.com/vczh-libraries/Document/blob/master/Tools/CppDoc/Core/Source/Parser_Declarator.cpp#L816&lt;/a&gt; 。我们可以看到参数里面有很多东西，其中引用了两个枚举值：&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;enum class DeclaratorRestriction
{
	Zero,
	Optional,
	One,
	Many,
};

enum class InitializerRestriction
{
	Zero,
	Optional,
};&lt;/code&gt;&lt;p&gt;这分别用来控制Declarator的名字数量，以及初始化部分的数量。在不同的地方需要分析一个声名的时候，会传进去不同的参数。这个参数会影响这部分语法分析对于同一个符号的理解。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;尾声&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;当然Declarator的部分到这里并没有结束，因为C++在处理这些东西的时候，需要同时做语义分析，也就是通过名字具体的意思来对同一个符号做不同的理解。举个简单的例子，当你看到这样一行代码的时候&lt;/p&gt;&lt;code lang=&quot;cpp&quot;&gt;int (Fuck::Shit /* 后面还有 ... */&lt;/code&gt;&lt;p&gt;到底Shit应该理解为Fuck的子类型呢，还是Declarator的名字呢？你只有确实地直到Fuck是个什么东西，你才能得到答案。这部分将在下一篇文章得到一半地解答。&lt;/p&gt;</description>
<author>vczh</author>
<guid isPermaLink="false">2018-10-04-45971898</guid>
<pubDate>Thu, 04 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>考不上三本也能实现C++编译器——前言</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-10-03-45888762.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/45888762&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3eef6665d6cb158c6d8c1677e11b18fd_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;你现在所阅读的并不是第一篇文章，你可能想看&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25959684&quot;&gt;目录和前言&lt;/a&gt;。&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在GacUI1.0的功能马上就要做完的时候，我曾经提出过要&lt;a href=&quot;https://zhuanlan.zhihu.com/p/44566477&quot;&gt;把以前的垃圾C++文档生成器（类似doxygen）重新做一遍&lt;/a&gt;。所以就开了&lt;a href=&quot;https://github.com/vczh-libraries/Document&quot;&gt;这个项目&lt;/a&gt;。按照设想的进度来看，目前完成了大约1/4。整个项目的内容，就是把我的C++代码都索引起来，生成正确的链接（含函数体，上个版本还不行），最后再生成出另一个像MSDN那样的页面，最后把两者组合起来，生成索引，做个假的搜索引擎。于是写一个C++前端就在所难免。&lt;/p&gt;&lt;p&gt;有人问过我为什么不用doxygen，因为doxygen不能满足我的所有要求，我也不想把我的代码和注释改成doxygen能懂的那样，而且doxygen处理模板效果也不好。最重要的是，我如果在注释里写了一些代码片段作为sample，doxygen也不会替我运行一下看看是不是对并正确索引和着色的。再加上这是个个人项目，我实在想不出什么理由非要放弃一些功能从而使用doxygen不可。&lt;/p&gt;&lt;p&gt;因此我又重新把MSDN的C++语法手册快速浏览了一遍，整理出需求之后，就开始做了。显然，Windows下的GacUI需要饮用大量的VC++提供的头文件，如果我的编译器只支持标准C++的话，明显parser就会直接失败，所以我还只能支持那些VC++特有的功能不可。但是实际上还行，因为VC++大部分特有的功能是通过#pragma来实现的，剩下一部分是通过简化C++对语法的要求来实现的。&lt;/p&gt;&lt;p&gt;在实现的时候我觉得，为了代码索引做的C++编译器难度要比真实的C++编译器要低得多，考不上三本完全也能自己搞出来，所以我决定一边开发一边写这个文章的系列。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;需求&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;代码索引跟真正的C++编译器差别相当大，这体现在四个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;代码索引不需要支持宏运算和文件系统&lt;/b&gt;。几乎所有靠谱的C++编译器都有一个预处理的功能，因此我要求用户给我提供一个预处理完的文件，是完全没有问题的，而且也十分合理。因此我就省掉了那些复杂的宏运算，而只要专注于C++本身就可以了。#include之类的破事也没有了。VC++生成的预处理文件包含#line命令，所以我不用自己展开也能知道每一行到底在原来的文件的什么地方。最后宏如果要索引，那个比支持宏运算要简单多了，预处理前的文件从头到尾扫一遍就可以了。&lt;/li&gt;&lt;li&gt;&lt;b&gt;代码索引不需要处理所有的语法和语义错误&lt;/b&gt;。我完全可以要求用户必须喂给我一个能通过编译的预处理文件，因此有些事情就变得简化了。举个简单的例子，static和virtual是不能同时出现在一个函数上面的，但是我完全不用管，因为如果用户真的给了我一个正确的C++程序，那我就可以通过static来判断它是不是静态函数，忽略virtual是否也出现。虽然这其实都是些小事，但是积少成多，整个程序要操心的事情简直大幅缩短。&lt;/li&gt;&lt;li&gt;&lt;b&gt;代码索引处理模板的逻辑与真正的C++编译器是完全不同的&lt;/b&gt;。GacUI是一个库，库就意味着很多模板类和模板函数可能根本就没有在GacUI本身用过，因为他们是提供给下游用户的。但是作为一个代码索引程序，它必须要完整地分析整个模板函数的内容。举个简单的例子，一个带有template&amp;lt;typename T&amp;gt;的函数，声明了一个typename T::Fuck fuck;这样的变量，那Fuck的链接到底要怎么生成呢？C++编译器可能直接就没管，因为你的函数都没有被用到，不需要展开。而代码索引需要做的，则是找到所有叫Fuck的内部类型，然后根据后面的代码再来去掉那些明显不可能出现在这里的。&lt;/li&gt;&lt;li&gt;&lt;b&gt;代码索引处理各种重载的精确度不需要很高&lt;/b&gt;。C++的重载规则十分复杂，而代码索引其实可以取巧。因为它不需要真的resolve到一个确定的符号上。而且对于模板函数里面的重载引用你是根本没办法做这件事情的，因为模板函数根本还没展开你怎么可能知道重载的结果呢。所以代码索引的类型推导程序，从一开始就默认一个符号是可以有多重意思的。如果你根据上下文还是没办法确定到一个符号上，那没关系，我们就当它是多个符号。整条表达式后面的所有链接都有可能指向多个目标。虽然编译器不能这么写，但是代码索引恰恰就需要这样。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里面有一些细节还需要考虑，譬如一个带有template&amp;lt;typename T&amp;gt;的函数，用Fuck&amp;lt;T&amp;amp;&amp;amp;&amp;gt;::xxx的方法来使用一个带有特化的模板类Fuck，你是不能简单地挑选template&amp;lt;template T&amp;gt; struct Fuck&amp;lt;T&amp;amp;&amp;amp;&amp;gt;的这个分支的，因为T&amp;amp;&amp;amp;也有可能是左值引用。在这种时候你就只能被迫同意Fuck&amp;lt;T&amp;amp;&amp;gt;和Fuck&amp;lt;T&amp;amp;&amp;amp;&amp;gt;的两个分支都是正确的。&lt;/p&gt;&lt;p&gt;种种的原因导致了使用clang作为前端的doxygen其实不适合做这种工作，因为clang根本就没有为这种事情考虑过，而GacUI大量使用模板，这个细节无法忽视。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;进度&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;现在我的项目实际上表达式、类型重命名和模板都还没有做，其他的事情做了，所以只完成了1/4。所以这个系列文章会花费较长的时间来更新。不过尽管如此，在这前面的1/4里面，我已经遇到了很多有意思的问题，够写几篇文章了。当然本系列文章不会讨论C++，而是讨论编译器本身，因此各种C++奇技淫巧将不会出现在系列文章里。&lt;/p&gt;&lt;p&gt;总的来说，如果你们想要自己玩成这样的项目的话，只要懂得手写递归向下的语法分析器，剩下的事情就是去扣C++语法规范里面的细节，堆苦力把他们堆出来。这个事情一点都不难，只是要时间而已，广大考不上三本的同学完全也能够做出来。唯一的区别可能是，如果我花了半年做出来，不熟练的人可能要好几年（逃&lt;/p&gt;</description>
<author>vczh</author>
<guid isPermaLink="false">2018-10-03-45888762</guid>
<pubDate>Wed, 03 Oct 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>Scala macro 2018 实用指南</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-07-12-39379432.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39379432&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scala的metaprogramming 目前比较混乱，有runtime reflection,compile time macro,scalameta,macro paradise ,而下一代scala(dotty)的元编程也还没完全定下来。&lt;/p&gt;&lt;p&gt;scalameta : 只是一个库，不带任何编译器插件，只是用来变换语法数，没有任何reflection的功能，所以需要结合macro使用。&lt;/p&gt;&lt;p&gt;查找资料后发现macro paradise + scalameta这个应该是比较好用的。但是需要注意Scalameta的版本最高是1.8.0&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;工程设置：注意macro必须单独开个project,要调用macro的project需要指定dependency&lt;/p&gt;&lt;code lang=&quot;scala&quot;&gt;val macroSettings = Seq(
  libraryDependencies ++= macroDeps,
  addCompilerPlugin(&quot;org.scalameta&quot; %% &quot;paradise&quot; % &quot;3.0.0-M11&quot; cross CrossVersion.full)
)

lazy val macros = (project in file(&quot;macros&quot;))
  .settings(macroSettings: _*)

lazy val macroUsage = project
  .in(file(&quot;macroUsage&quot;))
  .dependsOn(macros) // macro!
  .settings(macroSettings: _*)&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;macro有好几种，比较常见的是用于生成代码的annotation macro和更加general的def macro&lt;/p&gt;&lt;code lang=&quot;scala&quot;&gt;import scala.annotation.{StaticAnnotation, compileTimeOnly}
import scala.language.experimental.macros
import scala.meta._

@compileTimeOnly(&quot;enable macro paradise to expand macro annotations&quot;)
class mappable extends StaticAnnotation {
  inline def apply(ast: Any): Any = meta {
    ast match {
      case xx@q&quot;..$mods class $tName (..$params) extends $template &quot; =&amp;gt;
        val add=q&quot;&quot;&quot;def printit=println(&quot;macros print1111 !&quot;)&quot;&quot;&quot;
        val result = q&quot;&quot;&quot;
          $xx
        &quot;&quot;&quot;
        println(mods)
        println(tName)
        q&quot;&quot;&quot;..$mods class $tName(..$params) {
      $add
    }&quot;&quot;&quot;
    }
  }
}
&lt;/code&gt;&lt;p&gt;annotation usage:&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;  @mappable
  case class sdfsdf(a: Int)&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;def macro:&lt;/p&gt;&lt;code lang=&quot;scala&quot;&gt;import scala.language.experimental.macros

object defMacros {
  import scala.reflect.macros.blackbox
  def isEvenLog(number: Int): Unit = macro isEvenLogImplementation

  def isEvenLogImplementation(c: blackbox.Context)(number: c.Expr[Int]): c.Tree = {
    import c.universe._
    println(&quot;isEvenLogImplementation&quot;)
    println(number.toString())
    q&quot;&quot;&quot;
      if ($number%2==0){
        println($number.toString + &quot; is even&quot;)
      }else {
        println($number.toString + &quot; is odd&quot;)
      }
    &quot;&quot;&quot;
  }

  import scala.reflect.macros.blackbox.Context

  /*
  def anylen[t](x: Seq[t]) = macro map[t]

  def map[T : c.WeakTypeTag](c: blackbox.Context)(p: c.Expr[Seq[T]]): c.Tree = {
    import c.universe._
    q&quot;&quot;&quot;1&quot;&quot;&quot;
  }
 */
}&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;关于macro的未来()：&lt;/p&gt;&lt;a href=&quot;https://www.scala-lang.org/blog/2018/04/30/in-a-nutshell.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-2f3c06cf5e89f8a53d50972874d33cc5&quot; data-image-width=&quot;399&quot; data-image-height=&quot;648&quot; data-image-size=&quot;120x160&quot;&gt;Macros: the Plan for Scala 3&lt;/a&gt;&lt;a href=&quot;https://www.scala-lang.org/blog/2017/10/09/scalamacros.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-2f3c06cf5e89f8a53d50972874d33cc5&quot; data-image-width=&quot;399&quot; data-image-height=&quot;648&quot; data-image-size=&quot;120x160&quot;&gt;Roadmap towards non-experimental macros&lt;/a&gt;&lt;a href=&quot;https://dotty.epfl.ch/docs/reference/principled-meta-programming.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot;&gt;Principled Meta Programming&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Martin awodey</author>
<guid isPermaLink="false">2018-07-12-39379432</guid>
<pubDate>Thu, 12 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>tensorflow on idris学习项目</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-07-06-39147186.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39147186&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;希望在idris中实现安全的深度学习api。目前已经成功调用C api获取tf版本&lt;/p&gt;&lt;a href=&quot;https://github.com/doofin/tensorflow-idris&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-03ab6f034de1e41a73ac9fd84abbf1bf&quot; data-image-width=&quot;420&quot; data-image-height=&quot;420&quot; data-image-size=&quot;ipico&quot;&gt;doofin/tensorflow-idris&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Martin awodey</author>
<guid isPermaLink="false">2018-07-06-39147186</guid>
<pubDate>Fri, 06 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>机器学习与编译优化的入门介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-05-15-36884760.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36884760&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;该篇文章也算凑个AI的热点::)。 对编译器后端技术基本熟悉的研究工作者应该会感觉写中后端优化策略相当地依赖于既有领域经验，所以说设计一个比较好的启发是优化策略是相当的困难并且玄学(说的就是GCC中的LRA和LLVM中的Spiller)。机器学习算法的主要优势就是学习已有的经验，从而降低对人类的工作负担，实现一个相对较优的决策。比如：根据以往的气候数据预测将来多少天的天气，根据地质结构数据等预测某个地区的石油、天然气等矿产的储量。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;编译器研究人员在设计Loop unrolling策略的时候，会考虑多种不同的因子对展开策略的影响。比如：目标机器的向量寄存器的数据宽度，循环内部的指令数，分支语句的数目，算术运算指令的数目，访存操作的数目等。以往的算法都是根据已有的benchmark得到这个决策结果。很显然这个过程可以使用机器利用机器学习算法来辅助编译器设计人员[1]。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;另外一方面，当前所有的寄存器分配算法中用到的Spilling策略都是基于启发式的优先级策略，这方面也可以从机器特性，程序结构中抽取对应的特征向量来决定溢出哪一个物理寄存器是最合适的[2]。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;当然，还可以利用机器学习的算法，从输入的命令行选项，目标机器的特性（如：机器字长，寄存器数目，寄存器类别，指令种类，指令支持的操作，cache特征）来学习得到一个相对比较合适的pass调度顺序，当然这个模型的决策变量非常之多，训练的数据量也比较大。而且模型中使用到的参数的选择对模型的效果非常重要，目前学界还没有比较好的模型[3][4]。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;文章[5]中给出了当前两者结合的研究热点。&lt;/p&gt;&lt;p&gt;[1]. &lt;a href=&quot;ftp://nozdr.ru/biblio/kolxo3/Cs/CsLn/A/Artificial%20Intelligence..%20Methodology,%20Systems,%20and%20Applications,%2010%20conf.,%20AIMSA%202002%28LNCS2443,%20Springer,%202002%29%28ISBN%203540441271%29%28287s%29_CsLn_.pdf#page=49&quot;&gt;ftp://nozdr.ru/biblio/kolxo3/Cs/CsLn/A/Artificial%20Intelligence..%20Methodology,%20Systems,%20and%20Applications,%2010%20conf.,%20AIMSA%202002%28LNCS2443,%20Springer,%202002%29%28ISBN%203540441271%29%28287s%29_CsLn_.pdf#page=49&lt;/a&gt; (p41).&lt;/p&gt;&lt;p&gt;[2]. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.3402&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.3402&amp;amp;rep=rep1&amp;amp;type=pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3]. &lt;a href=&quot;https://www.eecis.udel.edu/~cavazos/cgo-2006-talk.pdf&quot;&gt;https://www.eecis.udel.edu/~cavazos/cgo-2006-talk.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4].&lt;a href=&quot;https://www.researchgate.net/profile/Abdul_Wahid_Memon/publication/225732776_Milepost_GCC_Machine_Learning_Enabled_Self-tuning_Compiler/links/0fcfd50ca24ef6fdcb000000/Milepost-GCC-Machine-Learning-Enabled-Self-tuning-Compiler.pdf&quot;&gt;https://www.researchgate.net/profile/Abdul_Wahid_Memon/publication/225732776_Milepost_GCC_Machine_Learning_Enabled_Self-tuning_Compiler/links/0fcfd50ca24ef6fdcb000000/Milepost-GCC-Machine-Learning-Enabled-Self-tuning-Compiler.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5]. &lt;a href=&quot;https://arxiv.org/abs/1801.04405&quot;&gt;[1801.04405] A Survey on Compiler Autotuning using Machine Learning&lt;/a&gt;&lt;/p&gt;</description>
<author>「已注销」</author>
<guid isPermaLink="false">2018-05-15-36884760</guid>
<pubDate>Tue, 15 May 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>又发现JDK的一个bug，这次是：ConcurrentHashMap</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-05-01-36297733.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36297733&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;更新：ConcurrentHashMap的作者Doug Lea确认这是一个逻辑缺陷：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6084f2b7252c5ad32039a682737aade4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1498&quot; data-rawheight=&quot;320&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6084f2b7252c5ad32039a682737aade4&quot; data-watermark-src=&quot;v2-c19ea84d64f48f2b9a9efb9590aeccf9&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;a href=&quot;https://bugs.openjdk.java.net/browse/JDK-8202422?focusedCommentId=14182353&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14182353&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot;&gt;Bug链接&lt;/a&gt;&lt;p&gt;并在他维护的JSR166规范里提交了修改：&lt;/p&gt;&lt;a href=&quot;http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/ConcurrentHashMap.java?r1=1.310&amp;amp;r2=1.311&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot;&gt;http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/main/java/util/concurrent/ConcurrentHashMap.java?r1=1.310&amp;amp;r2=1.311&lt;/a&gt;&lt;p&gt;分割线以下是我当时给JDK提这个bug后写的：&lt;/p&gt;&lt;p&gt;------------------------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;JDK的源码都没人仔细看吗？我刚开始看JDK-1.8的ConcurrentHashMap的源码，就发现构造函数有问题，给Java提了bug，果然如此。&lt;/p&gt;&lt;a href=&quot;https://bugs.openjdk.java.net/browse/JDK-8202422&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot;&gt;https://bugs.openjdk.java.net/browse/JDK-8202422&lt;/a&gt;&lt;p&gt;而且assign给了大神Doug Lea:&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0a0bd99d31f7c543ef66788dab694bbc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;534&quot; data-rawheight=&quot;64&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;我在so上也问了这个问题，有人认为这是一个优化技巧，但在逻辑上有一点说不太通，如果增加一个文档说明，把3/2这个计算参数的说明加进去，也勉强可以说得过去。总之，目前来看，确实是有逻辑缺陷的。&lt;/p&gt;&lt;p&gt;SO链接：&lt;/p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/50083966/bug-parameter-initialcapacity-of-concurrenthashmaps-construct-method&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-2d47e939feed796bcf7483d306661c88&quot; data-image-width=&quot;316&quot; data-image-height=&quot;316&quot; data-image-size=&quot;ipico&quot;&gt;Bug: parameter &#39;initialCapacity&#39; of ConcurrentHashMap&#39;s construct method?&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Old Driver</author>
<guid isPermaLink="false">2018-05-01-36297733</guid>
<pubDate>Tue, 01 May 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>榨干机器硬件性能: JVM＆GPU</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-04-30-36284998.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36284998&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-657d4c369db90c1bfe3ea9dd06a173e0_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着过去几年机器学习 模型训练，以及区块链领域中（币圈和链圈） 对计算力的要求，人们对硬件计算速度的要求越来越高。很自然的，作为传统科学计算领域， 基于GPU的加速也获得了大量的关注：Tensorflow 底层利用GPU来计算；大量的挖矿软件( e.g., ethminer)直接对GPU暴力使用。在16,17年，由于币价格的爆发，对GPU显卡挖矿的需求，直接导致Nvida的股票价格翻了好几倍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一　需求&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;然而很遗憾的是，目前GPU显卡API操作，主要是基于两大框架: Opencl 和CUDA。这两种框架实际上需要开发人员对框架底层有大量的了解, 主要体现在： &lt;/p&gt;&lt;ol&gt;&lt;li&gt;自己需要在底层实现kernel函数&lt;/li&gt;&lt;li&gt;自己申请，管理GPU的内存，并负责 Host memory和GPU memory的通讯。&lt;/li&gt;&lt;li&gt;自己去手动优化Kernle 方法的实现，比如基于数据类型的优化。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;由于这种复杂性，GPU的应用(e.g, coin mining, Machine Learning) 对高层语言开发者, 比如作为目前最通用的编程平台JVM(Java或者其他JVM语言),　是一件非常复杂的实现. 开发者只能通过自己写JNI的方式，对GPU做封装，然后自己在上层通过Java调用（这种方式对于绝大部分的程序员来说，可行性不高）。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;本文的目的并不真正深入J9对 GPU的具体技术细节，更多的还是从上层的科普角度出发。自己在14,15年，以及后来的17年了解 参与，讨论了部分J9这方面的调研和工作，包括后来15年在pppj也接触了Rice＆IBM Tokyo RD那边的Akihiro和Kazuaki等博士 关于这方面的沟通，理了几遍代码。&lt;/p&gt;&lt;p&gt;首先，需要特别澄清的是:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;JVM Specification 并没有制定JVM要对GPU的支持。这个Feature只是IBM J9 Java8自己一个特有的属性。(Hotspot不清楚，谁知道的喊声？)&lt;/li&gt;&lt;li&gt;J9 Java 8是最早开始支持 Cuda GPU的，至少我当时15年是，今天可能还有其它家的也支持（待考证）。&lt;/li&gt;&lt;li&gt;本文也区分另外一个Java &amp;amp; GPU的开源项目 &lt;b&gt;&lt;a href=&quot;https://github.com/Syncleus/aparapi&quot;&gt;aparapi&lt;/a&gt;&lt;/b&gt; 。Aparapi是在Java 语言中支持GPU, 但是需要开发者自己操作类似Kernel函数的，开发者需要知道GPu开发理论知识背景。而J9 不需要高层感知底下任何关于CUDA/OPENCL等知识, 它是直接在Runtime这一层去支持的。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;本文阅读需要一些背景：　&lt;/p&gt;&lt;ul&gt;&lt;li&gt;简单知道JVM以及bytecode&lt;/li&gt;&lt;li&gt;简单知道GPU以及CUDA是什么，以及知道为什么会有GPU这玩意&lt;/li&gt;&lt;li&gt;知道JIT 以及编译器是用来干什么的。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;二　大概原理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;J9 对 GPU 的支持主要是在以下两个方面&lt;/p&gt;&lt;ol&gt;&lt;li&gt;CUDA GPU (或者严格说基于Nvida家的CUDA框架)。&lt;/li&gt;&lt;li&gt;支持仅限于 Java 8中的Stream API.  比如： &lt;/li&gt;&lt;/ol&gt;&lt;code lang=&quot;text&quot;&gt;     LongStream.range(low, up).parallel().forEach(i -&amp;gt; &amp;lt;lambda&amp;gt;)&lt;/code&gt;&lt;p&gt;Java8中的 Stream API 是从高层应用中去抽象出来了一个Parallel ，而GPU本身是在物理硬件上实现了 Same Instruction Multiple Data (SIMD)的数据并行。所以，直接通过GPU实现上层并行的逻辑是一个很自然而然的想法。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;大概的框架流程图如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57abb2c1b1faafd601b0de246072263d_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;245&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;1， J9 Interpreter 解释bytecode指令的时候，检测 并识别出来 Stream API中的foreach (for_loops) 以及lambda closure (这中间涉及到Invokedynamic). &lt;/p&gt;&lt;p&gt;2, JIT compiler (TR in J9) 此时进行优化，将产生两部分代码: Host machine  code, and target GPU code（NVVM IR）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Host Machine Code (i.e., CPU here)运行的，这部分将包括：在GPU申请内存，GPU-CPU 内存之间的相互复制，调用Nvida的driver 来编译，启动NVVM IR在GPU上的执行。 &lt;/li&gt;&lt;li&gt;NVVM IR: 严格上来说是对应着lambda closure， 这部分最后会有变成Parallel Thread Execution (PTX) 指令，并最终由Nvida编译器生成具体GPU上的指令。综合起来，这块的转化为：　&lt;/li&gt;&lt;/ul&gt;&lt;code lang=&quot;text&quot;&gt;bytecode-&amp;gt; NVVM IR-&amp;gt;PTX instruction-&amp;gt; Nvida GPU  instruction.&lt;/code&gt;&lt;h2&gt;&lt;b&gt;三　优化方案&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;直接利用GPU实现上层Java 语言的并行，能提高上层应用的运效率。这个是在比较理想的状况下能够成立的。&lt;/p&gt;&lt;p&gt;所以，在对lambda closure-&amp;gt; NVVM转化的时候，JVM还需要做一些其他方面的优化。对于计算能力，或者说 对于计算速度的提升，或者说 在考虑榨干 现有硬件的条件下，一般是从两个方面去考虑：内存，指令。&lt;/p&gt;&lt;h2&gt;3.1 内存　（Array aligning）&lt;/h2&gt;&lt;p&gt;通过内存优化Runtime的性能，这本身是一个非常大的范围： 比如通过memory management, GC, cache, locality等种种。细说起来需要一本书来完成。&lt;/p&gt;&lt;p&gt;J9对GPU的支持中，我们说的内存优化是指的是GPU中的array(i.e., device memory)的处理, 而非host memory中的array。在cuda原先memory allocation方法中 。原先的管理方式是直接讲array object (array header and array body) 放入连续的一块地址中(starting from 0)。在新的优化，实际上重新对array object进行placement 使得body从128 的整数位(e.g., index 31) 开始。如下图：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f0023fae5dd4e0537cdf0487cf2dc45a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;483&quot; data-rawheight=&quot;174&quot; data-watermark=&quot;&quot; data-original-src=&quot;&quot; data-watermark-src=&quot;&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;这么做的理由主要是基于两种条件：　a) 内存的操作更多的是对元素中read and write，对array header的操作并没有那么频繁（对比而言）, 所以header的读写的重要性不高; b) 　在128 index对齐后，读或者写可以在一个GPU指令周期内完成，而前者需要两个指令周期(第一个：　０－１２7，　第二个周期: １２８－３８４ )．&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;当然，除了array aligning, J9 也对内存其他方面进行的优化(不细说了)，比如基于jit对内存region 读写进行识别,　对指令进行re-order,　以达到high memory cache hit in GPU, 又或者减少不必要的复制指令 for copying from GPU memory to host memory，有或对 array header elimination. &lt;/p&gt;&lt;h2&gt;3.2 指令优化（Lambda Closure Optimization）&lt;/h2&gt;&lt;p&gt;指令优化属于传统的JIT 编译器方面的内容, 所以传统的JIT  optimization（e.g. , Deadcode elimination, ）基本上都可以拿过来用，毕竟lambda closure里面也是bytecode。这一部分就不需要细讲。&lt;/p&gt;&lt;p&gt;可以拿出来说的是 cross lambda method calling.  Exactly speaking, the caller is inside of lambda while the callee is out of lambda closure. 比如下面这个例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;public class Sample{
    public void myMethod(args...){}
    public void anotherMethod(){
        intSteam...forEach( i -&amp;gt;{
                myMethod(receiver, other-args);
                obj.anotherMethod();..
        });
    }
    public void anotherMethod(){}
} &lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在这个例子中， myMethod 和anotherMethod调用都是跨lambda closure (直白点：myMethod, anotherMethod 都不是closure内的方法). 这就产生一个问题或者中间有两个gap:  &lt;/p&gt;&lt;p&gt;a)  GPU上高速执行的代码调用CPU上低速执行的代码　－_－!!&lt;/p&gt;&lt;p&gt;b)  GPU上还要在runtime 决定　方法的具体实现方法(Java上若无显示标注方法是 invokevirtiual)。 =_=&lt;/p&gt;&lt;p&gt;　为了决定具体某个方法的实现，the receiver of a method call 和　virtual method table 需要在runtime时候从host memory 复制到device memory中去。为了使得程序跑的正确，这两个Gap将会kill GPU的效率。&lt;/p&gt;&lt;p&gt;　　To resolve both Gaps,  J9中JIT 编译器直接进行inline Caching (IC)优化（Akihiro认为是Method Inling). 在VM中，Inline Caching之前是SELF　language中(For detail, please refer Dr Urs Hölzle&#39;s PhD thesis [3])。&lt;/p&gt;&lt;p&gt;　　简单的归纳下就是在生成NVVM的时候，先直接假定 the type of method call receiver是哪一种，然后将被调用的方法实现直接inline到方法调用处。为了生成代码的正确性，在原先call site之前插入一个guard (中文不知道如何翻译？？)进行检测。若检测没有成功，则jmp到原先低速的方法（也就是这个时候GPU停下来去要求CPU执行：看当前receiver具体是哪路神仙(这个GPU也可以做，但是需要先copy from host memory to device memory)，CPU执行callee&#39;s　method）.　所以对于上面lambda内 obj.anotherMethod();　变成了&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;if(receiver is someType){
    SomeType&#39;s anotherMethod real Implementation and will be executed at GPU kernel.
}else{
    invoke receiver.anotherMethod(..)  //execute on CPU
}&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;四  附注：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;性能benchmark结果可以参考文章4. &lt;/li&gt;&lt;li&gt;本文的图来自4,5&lt;/li&gt;&lt;li&gt;转载请保留原作者的名字&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;【１】Project &lt;a href=&quot;https://github.com/Syncleus/aparapi&quot;&gt;Syncleus/aparapi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;【２】&lt;a href=&quot;https://docs.nvidia.com/cuda/nvvm-ir-spec/index.html&quot;&gt;CUDA Toolkit Documentation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;【３】Urs Hölzle, Adaptive Optimization for Self: Reconciling High Performance with Exploratory Programming. Ph.D. thesis, Stanford, CA, USA, 1995, UMI Order No. GAX95-12396.&lt;/p&gt;&lt;p&gt;【４】Kazuaki Ishizaki, Akihiro Hayashi, Gita Koblents and Vivek Sarkar, Compiling and Optimizing Java 8 Programs for GPU Execution/&lt;/p&gt;&lt;p&gt;【５】Akihiro Hayashi, Kazuaki Ishizaki, and Gita Koblents, Machine-Learning-based Performance Heuristics for Runtime CPU/GPU Selection. PPPJ 2015.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Shijie XU</author>
<guid isPermaLink="false">2018-04-30-36284998</guid>
<pubDate>Mon, 30 Apr 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>[新闻] 大部分Intel hardware intrinsic 将在 .NET Core 2.1 中启用</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-03-26-34960352.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34960352&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;随着 .NET Core 2.1 发布的临近，上周&lt;a href=&quot;https://github.com/dotnet/coreclr&quot;&gt;CoreCLR&lt;/a&gt; 已经停止向master 分支中提交新功能。&lt;/p&gt;&lt;p&gt;所以目前已经确定，&lt;a href=&quot;https://github.com/dotnet/corefx/issues/22940&quot;&gt;Intel hardware intrinsic 项目&lt;/a&gt;将作为一个&lt;a href=&quot;https://github.com/dotnet/corefx/issues/27486&quot;&gt;Preview 特性&lt;/a&gt;在 .NET Core 2.1 正式发布版中启用。&lt;/p&gt;&lt;p&gt;1. .&lt;b&gt;NET Core 2.1 正式发布版中将启用所有的SSE，SSE2，SSE3，SSSE3，SSE4.1，AVX，LZCNT，POPCNT intrinsic，以及大约70%的AVX2 和SSE4.2 中的Crc32 intrinsic.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2. 作为一个Preview 特性，用户在程序中必须显式安装/引用一个Nuget 包（System.Runtime.Intrinsics.Experimental），这个包中并没有任何实际代码，但它负责向用户暴露可用的intrinsic API。在成为正式特新之前，这些API 可能还会轻微改动。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我会随后在专栏里写一个系列文章来教大家使用这个hardware intrinsic 功能（安装，配置，C# SIMD编程，等等）。也希望大家在GitHub 上向我们多多提交意见和bug report :)&lt;/p&gt;</description>
<author>彭飞</author>
<guid isPermaLink="false">2018-03-26-34960352</guid>
<pubDate>Mon, 26 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>一个让Netty作者也感到惊讶的错误</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-03-16-34609401.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34609401&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;为了表示我不是标题党，先来个截图：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ce8476a71905621c52ff6e1003e96baa_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;747&quot; data-rawheight=&quot;135&quot;&gt;&lt;p&gt;Netty是Java世界里网络编程框架的明星，也是我非常喜欢和推崇的开源项目之一。但其核心的Future接口实现却犯了一个基本的逻辑错误，本文就指出了Netty中的核心Future接口在实现cancel和isDone方法时违反了约定规则的问题。&lt;/p&gt;&lt;p&gt;首先来看java.util.concurrent.Future#cancel方法的javadoc约定：&lt;/p&gt;&lt;blockquote&gt;After this method returns, subsequent calls to isDone will always return true.&lt;br&gt;&lt;/blockquote&gt;&lt;p&gt;就是说，在调用了cancel方法后，再调用isDone将永远返回true。&lt;/p&gt;&lt;p&gt;Netty的Future接口继承了Java的Future接口:&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;public interface Future&amp;lt;V&amp;gt; extends java.util.concurrent.Future&amp;lt;V&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;所以在实现的时候理应遵循这一约定，但Netty截止到目前的最新版本中(4.1.21)，并没有遵循这一约定，参见下面的代码例子：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;import io.netty.util.concurrent.GlobalEventExecutor;

import io.netty.util.concurrent.Promise;

public class DefaultPromiseIsDoneTest {

    private final Promise defaultPromise = GlobalEventExecutor.INSTANCE.newPromise();

    public static void main(String args[]) {

        DefaultPromiseIsDoneTest main = new DefaultPromiseIsDoneTest();

        main.isDoneTest();

    }

    private void isDoneTest() {

        defaultPromise.setUncancellable();

        defaultPromise.cancel(false);

        boolean isDone = defaultPromise.isDone();

        System.out.println(isDone);

    }
}&lt;/code&gt;&lt;p&gt;运行后，控制台打印的是 false。 而按照约定，应该打印true才对。&lt;/p&gt;&lt;p&gt;Netty其它几个实现类也没有遵循这一约定：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;io.netty.channel.group.VoidChannelGroupFuture#isDone
io.netty.channel.VoidChannelPromise#isDone&lt;/code&gt;&lt;p&gt;我在Netty的github上提出了这个问题，得到了Netty官方的确认。&lt;/p&gt;&lt;p&gt;https://github.com/netty/netty/issues/7712&lt;/p&gt;&lt;p&gt;但由于修改会导致当前版本用户受到影响，所以Netty准备在下一个大版本中修复这一问题。&lt;/p&gt;&lt;p&gt;我们在异步编程，实现Future接口的时候，对cancel和isDone方法的理解很可能会依赖于直觉，而没有严格对照接口文档中约定的逻辑来实现。甚至像Netty这样的老司机也犯了大意的错误。特写出这篇文章，跟大家共勉。&lt;/p&gt;&lt;p&gt;具体的讨论可以参见我的stackoverflow帖子（本文开头的图片就截自下面的帖子）：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/48792248/does-netty-violate-the-contract-of-future-cancel-method&quot;&gt;does-netty-violate-the-contract-of-future-cancel-method&lt;/a&gt;&lt;/p&gt;</description>
<author>Old Driver</author>
<guid isPermaLink="false">2018-03-16-34609401</guid>
<pubDate>Fri, 16 Mar 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>对JDK-lang包里一个方法的改进</title>
<link>https://henix.github.io/feeds/zhuanlan.hllvm/2018-03-16-34608787.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34608787&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;JDK-lang包里的一个方法：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;java.lang.Integer.numberOfLeadingZeros(int)&lt;/code&gt;&lt;p&gt;这个方法是用来计算int的二进制值从左到右有连续多少个0。&lt;br&gt;我们知道Java里的int型是有负数的，负数的二进制第1位肯定是1，所以如果参数i小于0，应该直接返回0就可以了。&lt;br&gt;但我们看JDK里的实现：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;public static int numberOfLeadingZeros(int i) {
        // HD, Figure 5-6
        if (i == 0)
            return 32;
        int n = 1;
        if (i &amp;gt;&amp;gt;&amp;gt; 16 == 0) { n += 16; i &amp;lt;&amp;lt;= 16; }
        if (i &amp;gt;&amp;gt;&amp;gt; 24 == 0) { n +=  8; i &amp;lt;&amp;lt;=  8; }
        if (i &amp;gt;&amp;gt;&amp;gt; 28 == 0) { n +=  4; i &amp;lt;&amp;lt;=  4; }
        if (i &amp;gt;&amp;gt;&amp;gt; 30 == 0) { n +=  2; i &amp;lt;&amp;lt;=  2; }
        n -= i &amp;gt;&amp;gt;&amp;gt; 31;
        return n;
    }&lt;/code&gt;&lt;p&gt;可以看到JDK里的实现里并没有对负数的情况进行判断，而是走了下面4个if分支判断和位移操作，这在参数i 为负数的情况下肯定是不必要的，而且也会影响性能。&lt;/p&gt;&lt;p&gt;如果继续挖掘的话，可以看到代码里有一行注释：&lt;/p&gt;&lt;blockquote&gt;// HD, Figure 5-6&lt;br&gt;&lt;/blockquote&gt;&lt;p&gt;注释里HD的意思是指《Hacker&#39;s Delight》这本书，意思是该方法的实现逻辑参考了这本书，那我们就来看下《Hacker&#39;s Delight》书里的实现代码：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;int nlz(unsigned x) {
int n;
if (x == 0) return(32);
n = 1;
if ((x &amp;gt;&amp;gt; 16) == 0) {n = n +16; x = x &amp;lt;&amp;lt;16;}
if ((x &amp;gt;&amp;gt; 24) == 0) {n = n + 8; x = x &amp;lt;&amp;lt; 8;}
if ((x &amp;gt;&amp;gt; 28) == 0) {n = n + 4; x = x &amp;lt;&amp;lt; 4;}
if ((x &amp;gt;&amp;gt; 30) == 0) {n = n + 2; x = x &amp;lt;&amp;lt; 2;}
n = n - (x &amp;gt;&amp;gt; 31);
return n;
}&lt;/code&gt;&lt;p&gt;可以看到这是C语言的实现，乍一看，貌似和JDK里的Java实现是一样的，但仔细看，你会发现方法参数x是unsigned类型的，因为unsigned类型不会有负数，不需要判断负数的情况，所以《Hacker&#39;s Delight》书里的实现是没问题的，而JDK实现里的方法参数是int类型，是需要判断负数的情况的。&lt;/p&gt;&lt;p&gt;所以我们可以大胆的推测，JDK的程序员当初在实现这个方法的时候，只是把&lt;br&gt;《Hacker&#39;s Delight》书里的实现改为了Java实现，而没有考虑到参数类型的区别。&lt;/p&gt;&lt;p&gt;这个方法在JDK里是被标记为intrinsic的，意思是该方法针对不同的硬件有更底层的原语级的实现，但这并不代表Java实现的逻辑就不需要被优化，因为：&lt;br&gt;1.在有些硬件上可能没有intrinsic支持。&lt;br&gt;2.用户显式关闭了intrinsic调用。&lt;br&gt;3.没有开启JIT编译。&lt;/p&gt;&lt;p&gt;除了Integer类之外，Long类里也有相同功能的方法需要改进：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;java.lang.Long.numberOfLeadingZeros(long)&lt;/code&gt;&lt;p&gt;我给OpenJDK提了bug，其实应该叫改进/增强(Enhancement)，OpenJDK官方经过测试，发现我修改后的方案确实会提升性能，于是愉快的修复了这个问题：&lt;a href=&quot;https://bugs.openjdk.java.net/browse/JDK-8189230&quot;&gt;bug链接&lt;/a&gt;&lt;br&gt;不过大家可能要等到Java-11发布的时候才能看到这个修改了。:)&lt;/p&gt;</description>
<author>Old Driver</author>
<guid isPermaLink="false">2018-03-16-34608787</guid>
<pubDate>Fri, 16 Mar 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>
